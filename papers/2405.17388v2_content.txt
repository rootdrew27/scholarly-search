SECTION: Non-Unitary Quantum Machine Learning

We introduce several probabilistic quantum algorithms that overcome the normal unitary restrictions in quantum machine learning by leveraging the Linear Combination of Unitaries (LCU) method. Among our investigations are quantum native implementations of Residual Networks (ResNet), where we show that residual connections between layers of a variational ansatz can prevent barren plateaus in models which would otherwise contain them. Secondly, we implement a quantum analogue of average pooling layers from convolutional networks using single qubit controlled basic arithmetic operators and show that the LCU success probability remains stable for the MNIST database. This method can be further generalised to convolutional filters, while using exponentially fewer controlled unitaries than previous approaches. Finally, we propose a general framework for applying a linear combination of irreducible subspace projections on quantum encoded data. This enables a quantum state to remain within an exponentially large space, while selectively amplifying specific subspaces relative to others, alleviating simulability concerns that arise when fully projecting to a polynomially sized subspace. We demonstrate improved classification performance for partially amplified permutation invariant encoded point cloud data when compared to non-invariant or fully permutation invariant encodings. We also demonstrate a novel rotationally invariant encoding for point cloud data via Schur-Weyl duality. These quantum computing frameworks are all constructed using the LCU method, suggesting that further novel quantum machine learning algorithms could be created by utilising the LCU technique.

SECTION: IIntroduction

Quantum computing is an emerging technology with the potential to solve certain problems far more efficiently than classical techniquesShor (1997); Cao et al. (2019); Herman et al. (2022). The search for useful applications of quantum computers within the domain of machine learning is of particular importance given the significant impact classical machine learning has had on many fields and industries in recent yearsTouvron et al. (2023); Chang et al. (2023); Frieder et al. (2023). Various quantum machine learning algorithms have been proposed, with some of the most common examples attempting to recreate a quantum analogue of the classical neural networkAbbas et al. (2021); Beer et al. (2020). However, the inherently unitary operations of quantum algorithms impose significant limitations, as they restrict the implementation of non-unitary operations that are essential in many classical machine learning models. To address this issue, we explore the Linear Combination of Unitaries (LCU) methodAndrew Childs (2012); Berry et al. (2015), a technique that employs ancilla qubits to probabilistically implement a linear combination of unitary operations, which therefore permits the implementation of non-unitary operations in quantum circuits. This unlocks the possibility of implementing non-unitary operations within quantum machine learning (QML) applications. We utilise this to present several novel applications of the LCU method with various advantages in the field of quantum machine learning.

In SectionIIwe adapt the classical residual learning framework to quantum variational circuits, facilitating a quantum native implementation of Residual Networks (ResNet)He et al. (2015). By partially skipping layers of the network, classical residual networks are able to avoid the vanishing gradient problem by allowing the gradients to flow through shallower sections of the networkHe et al. (2015); Marion et al. (2022). We show that a quantum ResNet may similarly provide a method of avoiding barren plateaus in Variational Quantum Circuit (VQC) models, by maintaining shallow depth contributions in the final loss function. Furthermore, we show that by including terms that parameterise the strength of the residual connections, it is possible to increase the lower bound of the probability of success of the LCU procedure helping to alleviate one of the LCU method’s principal issues.

In SectionIIIwe implement a quantum analogue of average pooling operations from convolutional neural networks (CNN)Rawat and Wang (2017); Sharma et al. (2018); Al-Saffar et al. (2017)by using the LCU method. This provides an efficient implementation of average pooling for amplitude encoded image data which we demonstrate for any size pooling window. This may further be generalised to convolutional filters leading to an exponential improvement in the number of controlled unitaries required compared to previous techniquesWei et al. (2022); Chen et al. (2022). We demonstrate that the LCU probability of success will equalin the case where all pixels are of the same colour and will decrease when pixels in the local pooling window of dimensionbecome more diverse. For real-world images, we provide the intuition that the probability remains relatively stable since most pixels are similar locally, except at the edges of subjects in the image. This intuition is supported by empirical evidence onpixel images in the MNISTDeng (2012)database, which shows that probability decreases but levels off to a finite value asincreases, and shows no discernible trend when increasing image size.

In SectionIVwe present a method for projecting quantum encoded data to any combination of irreducible representation subspaces of a finite group, presenting a general framework for implementing full or partial symmetries in the encoding step of quantum machine learning models. These techniques are intended to reduce the effective dimension of quantum encoded data in an effort to improve generalisation performance, which has been reported to decline as the number of qubits and hence the dimension of the encoded quantum states increasesHuang et al. (2021). We show that this technique can recreate previous work on permutation invariant encodings for point cloud dataHeredge et al. (2024)as a special case. Furthermore, we implement a novel rotationally invariant encoding for point cloud data using the new technique by leveraging Schur-Weyl duality. This results in an encoded quantum state for point cloud data that is invariant if classical input point cloud data is rotated in 3-dimensional space, hence strongly enforcing rotation invariance on any model that subsequently uses this rotationally invariant input state. We further show that any combination of projections can be implemented at once, allowing certain symmetric subspaces of the data to be amplified or contracted to give increased flexibility over the amount of symmetry in the encoding. We demonstrate that intermediate levels of permutation symmetry for point cloud encoded data leads to an improved classification performance when compared to a non-symmetric or a fully permutation symmetric encoding.

These implementations illustrate the ability of the LCU method to benefit the field of QML and a summary of these contributions is provided in Table1. This work covers three different algorithmic frameworks that all utilise the same LCU method in their construction which are located in self-contained sections which may be read in any order:

Quantum Native ResNetis detailed in SectionII

Quantum Native Average Poolingis detailed in SectionIII

Irreducible Representation Projectionsare detailed in SectionIV

The remainder of this introductory section will introduce these three frameworks, followed by a summary of the LCU method used in their constructions.

SECTION: I.1Quantum Native ResNet

A common issue in the training of variational quantum circuit (VQC) models is the issue of barren plateaus leading to vanishing gradients. Classical Residual Networks (ResNet) have profoundly impacted deep learning by enabling the training of extremely deep neural networks through the introduction of skip connections that mitigate the vanishing gradient problemHe et al. (2015); Marion et al. (2022). This suggests that the implementation of Residual Networks within a quantum variational model could provide a significant advancement in quantum machine learning if they could similarly be utilised to avoid the problem of barren plateaus inherent in many VQC models. This line of reasoning was suggested in a recent review of barren plateausLarocca et al. (2024)with the caveat that the no-cloning theorem may make residual and skipped connections difficult to achieve in quantum circuits. In this work, we shall show a probabilistic implementation of a quantum native ResNet that does not require cloning states and could show promise against barren plateaus in VQC models.

There has been active interest in building quantum ResNet inspired algorithms in the literature, with a primary focus being on quantum-classical hybrid models that use the powerful modern architecture of classical ResNet models, while including quantum machine learning subroutines to produce a hybrid algorithmHassan et al. (2024); Sagingalieva et al. (2023); Zaman et al. (2024). There have also been proposals to implement quantum residual connections by utilising several quantum neural network models in series with residual connections between themKashif and Al-Kuwari (2024). A native VQC implementation of a quantum ResNet algorithm has previously been introduced inCrognaletti et al. (2024,), in which skipped connections are possible in a VQC model if the implemented variational layers are restricted to be of the form of a unitary circuit followed by a product Pauli encoding, followed by the unitary circuit conjugate. This implements the quantum ResNet natively on a quantum device; however, as the authors note, this does not cover any general unitary variational layer, since implementing residual connections for a generalwould not be a unitary process overall and was therefore not considered in this approach. A common theme explored in these previous works was utilising the effectiveness of classical ResNet models in tackling the vanishing gradients problem of deep neural networks and applying this reasoning in a quantum setting to the problem of barren plateaus.

Applying residual connections in a quantum setting corresponds to operating on a stateto produce

whereby a portion of the previous stateis able to skip the variational operatorin that layer. This allows the overall model cost function to retain terms that have only passed through one variational layer, corresponding to very shallow circuits, while still providing terms that have been passed through all layers and hence potentially very deep circuits. The operator which would result in this would be of the form

which in general is not a unitary operator. The key challenge therefore in implementing a quantum native ResNet analogue is that it would require implementation of non-unitary operators, something that becomes possible with the LCU framework. In this work, we translate the ResNet architecture to a quantum setting by applying residual connection with the LCU framework to facilitate the flow of quantum information across deeper or more complex quantum circuits, while allowing the strength of the residual connection to be chosen freely. This introduces a potential new class of VQC ResNet models which could provide possible protection against barren plateaus in complex VQC models.

The use of ancilla qubits to implement ResNet-like architectures in QML models has previously been exploredWen et al. (2024), revealing that residual connections within the data encoding segment of a circuit can expand the frequency spectrum of the resulting model, leading to more expressive encodings. In contrast, our work introduces a framework for quantum ResNets exclusively within the variational portion of a VQC model. We provide a detailed proof of the probability of success of the LCU procedure, demonstrating that the lower bound of this probability can be adjusted by varying the residual connection strength. Additionally, we illustrate that applying quantum residual layers to a model can mitigate the occurrence of barren plateaus in circuits which would otherwise contain them. We also demonstrate that quantum ResNets can be viewed as equivalent to ensembles of unitary VQC models with additional non-unitary terms. While we show that quantum ResNets can avoid barren plateaus, we also discuss how they may likely be classically simulatable in many cases, at least in the case that the connection between absence of barren plateaus and classical simulatabilityCerezo et al. (2023)is valid for the constituent components. We propose the solution to this quantum ResNet simulatability issue may lie in the non-unitary terms and suggest a characterisation of these terms as a topic for further research.

SECTION: I.2Average Pooling Layers

Classical Convolution Neural Networks (CNN) are of significant importance to machine learning, mainly due to their structured manner of handling image and video dataRawat and Wang (2017); Sharma et al. (2018); Al-Saffar et al. (2017); Vu et al. (2024). Inspiration from these models has led to the development of quantum analogues. Quantum convolution neural networks have been previously proposedCong et al. (2019); Umeano et al. (2023)to classify quantum states with certain symmetry-protected topological phases and to classify image datasetsHur et al. (2022); Li et al. (2020). In these models variational circuits are used during convolutional layers followed by further variational circuits and measurements in the pooling layer to perform dimensionality reduction such that the operations are performed in a manner that respects certain symmetries of the data. Significant benefits of these models, such as avoiding barren plateausPesah et al. (2021), have been identified. Quantum-classical hybrid techniques have also been developed that utilise classical convolution neural network architectures alongside quantum modelsLiu et al. (2021).

The implementation we present here differs in that we focus entirely on implementing a subroutine of classical CNN models, the average pooling layer, for amplitude encoded image data. We consider the subroutine where a pooling window of sizepasses over the image and outputs the average of all pixels found within the pooling window. We show that this can be implemented natively on a quantum circuit by utilising the LCU method which could lead to an improvement over performing the subroutine classically, as quantum parallelism allows the averaging operation to apply to all pixel simultaneously. This demonstrates the possible utility of the LCU method, while providing a potentially advantageous subroutine for future quantum convolutional neural network models.

Previous work has investigated the LCU technique for creating convolutional layer filtersWei et al. (2022)based on spatial filteringYao et al. (2017), which can recover average pooling as a special case. This work did not generalise to any size, restricting instead to, but stated the method would be requiremulti-controlled operators in general. In contrast, we show a valid proof for anyand an efficient circuit implementation which requires onlysingle-qubit controlled unitaries, leading to an exponential improvement inover previous workWei et al. (2022). We also show that our construction can be generalised by adjusting the ancilla qubit state initialisation in order to implement a general convolutional layer filter, recovering the main result ofWei et al. (2022)while maintaining an exponential improvement in.

SECTION: I.3Irreducible Representation Subspace Symmetry Projections

A known issue in Quantum Machine Learning (QML) is that as the number of qubits increases there is a decrease in the generalisation performance of algorithmsHuang et al. (2021). A common empirical explanation of this is that the exponentially large Hilbert space leads to an overly expressive feature encoding where overtraining on the data becomes commonplace. Without an accompanied exponential increase in the training data, this leads to an overall reduction in the performance in the validation data set. A possible solution to the issue of overtraining is to reduce the expressibility of the encoding. Examples of techniques that have attempted this range from projecting kernels to a lower-dimensional spaceKübler et al. (2021)and approaches that are capable of encoding inductive biases directly into quantum statesBowles et al. (2023). Furthermore, geometric QML techniques have studied methods for creating variational circuits that are equivariant with respect to data symmetriesMeyer et al. (2022); Nguyen et al. (2022); West et al. (2024); Schatzki et al. (2024); Tüysüz et al. (2024)in similar attempts to reduce the expressibility of QML models. We instead focus on implementing symmetries directly into the quantum encoded data, which is a stricter implementation of symmetry, meaning our procedure is agnostic to the trainable classification procedure.

In previous work a quantum encoding was proposed using permutation symmetry, which led to a reduction in the dimensionality of the encoding and improved classification performanceHeredge et al. (2024). This was discussed in the context of point cloud data (unordered collection of points in 3 dimensions that collectively represent an image), where each point cloudconsists ofpoints and each pointis a 3-dimensional vector. As points do not have intrinsic ordering, the ordering of the points as they are input into a classification algorithm should ideally have no effect on the outcome. Therefore, the point cloud data naturally has point ordering permutation invariance. In general, a machine learning classifier, could return a different result depending on the order of the points, that is,, unless it has been specifically constructed to respect the permutation symmetry. The permutation invariant encodingHeredge et al. (2024)acts by creating an equal quantum superposition of all permutations of the data. In the two-state case, given two pointsencoded into the quantum statethis would correspond to preparing the permutation invariant state

However, it has been shown that the permutation invariant state preparation procedure

cannot be implemented via a unitary operationBuzek and Hillery (2000). However, this process can be implemented in a probabilistic manner using ancilla qubitsBarenco et al. (1996). This was shown to lead to improved classification performance for point cloud image classificationHeredge et al. (2024).

In this work, we demonstrate a generalisation of this technique that allows projections to any irreducible representation subspace of a finite group. Unlike previous worksHeredge et al. (2024), this means that we are no longer restricted to the symmetric subspace or the permutation group. Furthermore, our technique allows for linear combinations of projections to any irreducible representation subspaces.

Utilising this framework, we demonstrate a rotationally invariant encoding for point cloud data as an example use case. This encoding produces the same quantum encoded state each time, even if the data input point cloud is rotated by any amount in 3-dimensions. We show that this is achieved both theoretically and numerically. This is a highly desirable property of the model as point cloud data naturally has rotational symmetry. Especially in applications such as computer vision for autonomous vehicles it is of upmost importance that subjects in the image, such as pedestrians, are correctly identified regardless of the angle from which they are being viewed. Previous work has focused on implementing rotational and permutation symmetry in models for point cloud dataLi et al. (2024), which did so by implementing an equivariant variational model. We highlight that our work does not use equivariant variational models but projects quantum input states to a rotationally invariant subspace, hence strictly enforcing rotational invariance into any model for which this input encoded state is passed, as we effectively delete all information of the state which is not rotationally invariant.

The permutation and rotationally invariant encodings mentioned previously succeed in reducing the dimension of the encoding, but we note that this reduction may indeed be too drastic, which could lead to classically simulatable approaches or simply delete too much information about the input state, hindering the model performance. We therefore show how our new framework allows for linear combinations of projections that can be utilised to introduce parameterised symmetry subspace amplification. In this setting the dimension of the quantum state can remain exponentially large, while subspaces associated with certain symmetries can have their relative weightings adjusted. We focus on the weighting of the permutation symmetric subspace relative to all other subspaces, which can be continuously adjusted using a hyperparameter. We show that by implementing an intermediate amount of permutation symmetry for point cloud data classification, it is possible to gain higher accuracy scores than using either non-invariant encodings or the fully permutation invariant encodings suggested in previous workHeredge et al. (2024). A visualisation of these applications is shown in Figure1.

SECTION: I.4Linear Combinations of Unitaries Method

All results in this paper are specific cases of the LCU method described in this section. Let us define the general framework of how the LCU method works in a quantum circuit as detailed inAndrew Childs (2012); Berry et al. (2015). An insightful tutorial on the LCU method can also be found atGuala et al.. The LCU procedure allows the implementation of any operatorthat is itself a linear combination ofunitary operators. The operatoracts on a target state that is contained in anqubit target register. The target state is denoted. We can define the operatoracting onas

where for simplicityand any negative sign or complex phase can be absorbed into the unitaryandis a normalisation constant for the final target state.

In order to implement this, we need to define an ancilla preparation operatorwhich prepares theancilla qubits, that are initially in a basis state, into the following state

whereis a normalisation constant for the ancilla state andare basis states of thedimensional Hilbert space for thequbit ancilla register denoted by, which can be taken to be the computational basis states. The operator itself can be explicitly written as

where any termsforwill not be used and hence can be ignored.

After the ancilla qubits are prepared, we then apply a selection operator. The selection operator applies the unitary operationto the target register stateon the condition that the ancilla qubit is in the state, which can be defined as

If we now combine the preparation and selection operators, we have

The final step consists of applyingwhich is defined as

Applying this to the circuit results in

wherecollects terms that will be discarded and can therefore be ignored. We now need to measure the ancilla register and discard any results when the ancilla is not measured in thestate. The probability of measuring thestate will equal the probability of success of the LCU methodwhich can be written as

Discarding any results in which the ancilla is not measured in thestate we see that the remaining state will be projected to

whereis the normalisation constant for the final state, which can then be written as

Hence, the operator, which is a linear combination of unitaries and hence may itself be non-unitary, has been applied to the stateCamps et al. (2023).

The goal of this work is to demonstrate how the LCU method described above can be used in QML tasks to achieve desirable traits in the model architecture that are not possible in a strict unitary setting. The main results of this work rely on specifying preparation and selection operators, showing that they can be implemented on a quantum device, and then repeating the LCU framework detailed here to prove that they result in the desired non-unitary operation. An example LCU circuit for the implementation ofis shown in Figure2.

SECTION: IIQuantum Native ResNet

SECTION: II.1Variational Quantum Circuit Model Preliminaries

For a vector of classical input dataa standard quantum variational circuit model consists of anqubit encoding circuitthat encodes the classical data into a quantum state. This encoded state can also be represented as a density matrix defined by

Alternativelyandcould be quantum data in which no encoding process needs to be considered.

The input stateis then passed throughlayers of variational quantum circuitswhereis a vector of variational parameters that can be adjusted as the model is trained. We can therefore represent the overall variational circuit as

whereis a vector containing all variational parameters for all layers such that. Finally, measurement is made of some Hermitian observable. For simplicity, we will consider a loss function for the model defined as

where any insights from this loss function with regards to barren plateaus can often be extended to other, more general loss functions. Training a model consists of variationally adjusting the parametersuntil the cost function matches some known data labelsto within some acceptable error.

SECTION: II.2Quantum ResNet Implementation

The key concept of ResNetHe et al. (2015)is the introduction of residual blocks. Instead of learning a mappingon some data, the model instead learns some residual functionsuch that

whereis the input to the block,is the learned residual mapping andis the output of the block. This means the outputof each layercan be defined by

whereis the initial data input. In order to create a quantum version of this framework, we consider the quantum ResNetCrognaletti et al. (2024,)that can be defined as

whereis the variational unitary for layer,is the output of the layer,is the input of the layer, andcorresponds to the initial input state. This initial data input state could be quantum dataor it could be a quantum state that encodes classical data, whereis a-dimensional classical input data vector encoded into a quantum state through a data encoding circuitsuch that. Implementation of quantum ResNet of this form involves applying an operator

to the state. This presents a problem, as the operator is not necessarily unitary in general for all. Therefore, we proceed with implementing it via the LCU method.

To maintain the most general case, we shall consider adding some additional control into the magnitude of the skipped connections parameterised for each layer by some amount. Therefore the definition of a quantum residual connection we shall use is

whereis a normalisation constant.

This can be encoded with the LCU framework in a quantum circuit by applying thesingle qubit operator to the-th ancilla qubit denoted bydefined by

where terms involvingdo not have an effect on the circuit and can be ignored. Hence we can write the action of preparing the-th ancilla qubit as

such thatand hence

where for simplicity. The selection operator is defined to be controlled by the-th ancilla qubit as

We can then define the overall selection operator by specifying the ordering

such thatis applied first.

It is possible to probabilistically implement a quantum ResNet architecture on a quantum circuit where each layer of the variational circuit permits a residual connection defined as

whereis the-th layer of the variational circuit, the constantscan be freely chosen, the input to the layer is the stateand the output of the layer is the state. The termis a normalisation constant. The algorithm can be applied for all layerssimultaneously with a fixed probability of success

whereis an initial input state given to the algorithm which can be quantum data, or a quantum state encoded by classical data via an encoding circuitsuch that

We use the preparation and selection operators defined in Equation25and Equation28, respectively, with the LCU framework as outlined in SectionI.4.

Theoperator corresponds to performing single qubit initialisation onqubits and is clearly implementable on a quantum device. Likewisecorresponds to a controlledgate, whereis defined to be unitary, which is controlled by the-th qubit. Asis unitary, theoperation can also be implemented on a quantum device.

We consider applying the LCU procedure to the first ancilla qubit only. Starting with the first qubit preparation operator

Subsequently, the selection operator which is controlled by the first qubit is applied

Consider the conjugate preparation operator,

wherecollects terms that will not be used, as we will require the ancilla to be in thestate. Applying this conjugate operator we can write the state as

wherecollects terms that will be discarded and can therefore be ignored. The first ancilla qubit is now measured, and the result is discarded unless it is found to be in thestate. The probability of measuring the ancilla in thestate will be equal to

which will depend on the strength of the residual connection parameterised byas well as the real component of, which will depend on the quantum encoded stateand the variational operator used.

If we succeed in finding the first ancilla in thestate, then the target state will now be

and hence ignoring the extra ancilla qubits we have

whereis the required normalisation constant. Hence, for layerwe have shown that the quantum residual connection defined in Equation22is implemented for the original input state.

Assume now thatis correctly implemented by the procedure and consider the subsequent implementation of. We prepare the-th ancilla using

Through the same procedure as previously we see

Applying the conjugate preparation operator for the-th qubit which may be written as

to the ancillas we see that

wherecollects terms that will end up being discarded and hence can be ignored. Measuring the ancilla qubit we can see that the probability of measuring the-th qubit in thestate is given by

Ensuring the process is only continued if the ancilla is in thestate we find

Ignoring the unused ancillas we can therefore write the output of layeras

whereis a normalisation constant. Hence, assuming that the stateis correctly implemented by the procedure, we have shown that the output statewill be correctly implemented according to the quantum residual connection defined in Equation22. As we have shown thatcan be implemented correctly from the data input state, then by inductive reasoningis correctly implemented for all.

The overall probability of successwill rely on allqubits being successfully measured in thestate such thatand hence

as required.
∎

We therefore show that the most general form of ResNet where connections can be skipped at every layer in a variational quantum circuit is probabilistically implementable. An example circuit architecture that demonstrates the process in the first two layers is shown in Figure3. This implementation requires the number of ancilla qubits to equal. For a more qubit efficient but less general version, see AppendixGin which the number of ancilla used scales.

SECTION: II.3Probabilistic Scaling

During the proof in the previous section we found in Equation40that the probabilityof measuring the-the qubit in thestate, which is required for implementing the LCU method, to be

This depends on the strength of the residual connection, the quantum state of the previous stepand the variational circuit.

Note that in generallies in the range. Therefore, the probability of success lies in the range. The worst-case scenario therefore occurs whenas in this case the probability of success is within the rangeand therefore there is a chance that the algorithm cannot be implemented. However, asis varied to be closer toorthis gives an increasing lower bound offor the probability of success (ifthe probability of success is equal to, but would trivially mean that the skip connection is simply not performed. Likewise, ifthen the success probability is equal tobut corresponds to not implementing the variational circuitat all). This means that the lower bound of the probability of success varies with the strength of the residual connection for the layer, as shown in Figure4.

The termdetermines whether we will be close to the lower bound probabilityor the upper bound of. We see that ifthen we reach the upper bound and ifwe reach the lower bound. If restrictions were placed on the formcan take, there is potential to increase the lower bound probability even further.

As shown previously overall probability of successwill rely on allqubits being successfully measured in thestate such thatand hence

Therefore, the lower bound of the overall probability of success is given bywhich can be adjusted to be betweenandby varying the strength of the residual layers through the variables. Although we highlight that this cannot be arbitrarily adjusted, as ifreachesorthis would trivially correspond to no residual connection at all, and more generally the value ofmay be decided by alternative factors for a particular model or dataset.

If for a given architecture the probability of success for any layer is bounded between. Then the probability of overall success must be bounded between. In the case of, this means that the probability will decay exponentially with, which is a key drawback of this method. However, if the number of layers used is chosen to scale logarithmically with the number of qubitsthen the algorithm can still run in timein general, whereis the number of qubits for the target state register that initially contains. Note that whenwe have a purely unitary model. Therefore, forwe will have access to models that are at least as expressive as a standard unitary VQC model, with the potential to be even more expressive. Hence, even settingwould still allow a greater variation in expressivity of the models compared to the standard unitary case. Furthermore, as discussed previously, the lower bounds can be adjusted by varying the strength of the residual connections for a given architecture.

SECTION: II.4Avoiding Barren Plateaus with Residual Connections

Several works have been undertaken to characterise the conditions under which VQC models exhibit barren plateausLarocca et al. (2024). A model is said to contain barren plateaus ifthe following condition holdsLarocca et al. (2022)

whereis the variance calculated over a uniform distribution of parameters. If the model exhibits exponential gradient concentration then this makes training models difficult. The structure of the variational ansatz plays an important role in determining this value, as for a wide range of cases the loss function gradient variance will decay exponentially if the dynamical Lie algebra (DLA) of the variational circuit generators is exponential in dimensionFontana et al. (2023); Ragone et al. (2024). Note that an important assumption in these characterisations is usually that the circuits are sufficiently deep to form approximate designs, meaning that the depth of the circuit is also an important consideration regarding the presence of barren plateausRagone et al. (2024). Previous work has shown that using an ensemble of several shallow depth models can avoid loss function concentrationFriedrich and Maziero (2024). We show that the quantum ResNet provides a method of creating exponentially large ensembles of unitary VQC models, in which shallower depth components can help avoid barren plateaus, while also providing additional non-unitary contributions to the variance. However, if these shallower layers can be efficiently simulated classically and the non-unitary terms exponentially vanish, then the entire model may be at risk of being classically simulated. This finding suggests the importance of further exploring the non-unitary components of quantum ResNet models.

By introducing residual connections between layers of the ansatz it is possible to effectively mitigate barren plateaus in the model. This is similar to the classical role of ResNet in which vanishing gradients are mitigated in deep networks by allowing the gradients to skip over portions of the overall networkMarion et al. (2022); He et al. (2015). For example, take the case where a variational ansatz can be separated into two separate sectionsfollowed by. Furthermore, assume that when combined in series the overall operatorexhibits barren plateaus. Consider a residual connection introduced between the input and the output of the first layerwith residual connection strength, and no residual connection over the second layer. Starting with an initial statewe see the states produced in this circuit are given by

whereis a normalisation constant. It follows that the final state can be written as

This corresponds to applying the operator

and normalising the resultant state by a factor. We now consider some quantum encoded density matrix state, where, which is evolved by this variational operator. The resulting loss function for the model with respect to a measurement operatoris defined by

Whileis not in general unitary we can decompose its corresponding loss function into unitary evolution type terms and non-unitary evolution terms by considering the following expansion

where we can collect the non-unitary terms together by representing the expression as

where. It is now possible to identify three distinct terms in the loss function.

This component is identical to the unitary VQC loss function if no residual component had been implemented. It corresponds to a deep circuit consisting offollowed byin series, which we will assume exhibits barren plateaus.

This component is identical to the unitary VQC loss function if the variational circuit consisted ofonly. We will assume that this model does not exhibit barren plateaus, as has been shown to be the case for many variational circuitsSchatzki et al. (2024); Wiersema et al. (2023); West et al. (2024); Diaz et al. (2023), but may be vulnerable to being classically simulatedCerezo et al. (2023).

This component contains the non-unitary element of the loss function. It appears similar to theterm with the key difference that instead ofbeing unitary evolved we have. Whileis Hermitian, it does not necessarily have a trace equal to 1 nor is it positive semidefinite in general.

Settingand absorbing this factor along with the normalisation constant into the loss definition we can write

A visual interpretation of this resulting quantum ResNet model is shown in Figure5. We can therefore find the gradient of this loss function with respect to parametersas

The resulting gradient variance term can then be written as

By construction we know thatdoes not lead to barren plateaus and we can assume thatdoes not decay exponentially. Hence the overall quantum ResNet model has gradient varianceand therefore does not exhibit barren plateaus. The shallow depth component has mitigated barren plateaus in the overall model. This is demonstrated experimentally in Figure6which shows that the gradient variancefor the overall quantum ResNet model decays sub-exponentially.

It has recently been reported that a broad class of VQC models that avoid barren plateaus are also classically simulatableCerezo et al. (2023), limiting their potential for quantum advantage. While quantum residual connections offer a means to circumvent barren plateaus, they may still lead to scenarios where the model is well-approximated by the shallow component of the loss function, which may be classical simulatableCerezo et al. (2023). By construction we expect theto exponentially vanish, and if the same happens to theterm then this implies that the entire quantum ResNet model could be approximated efficiently on a classical computer within a given error. This raises the question: Are quantum ResNet models that avoid barren plateaus classically simulatable in general? If we take the assumption thatexponentially vanishes andis classically simulatable, this means the answer depends on the characteristics of the non-unitary term. If theterm does not decay exponentially and cannot be classically simulated, then this condition could lead to a situation in which a model with at least one residual connection could be difficult to simulate, and simultaneously avoid barren plateaus. This non-unitary term, has not yet been characterised in general and therefore highlights a possible search space for future research, however, we note that this may not necessarily be a common situation. We show in Figure7that for the particular quantum ResNet architecture we consider in our numerics, thatexponentially decays with an increasing number of qubits, which suggests that this specific architecture may be vulnerable to classical simulation. However, we only consider a limited example and note that there is a large space which remains unknown and is open to further work. Generalised quantum operations of the form, which are implemented by the LCU procedure, have been shown to form a convex set and the extreme points of this set are the unitary operationsGudder (2007). This means that the space of operators that can be considered is much larger than that which has previously been studied in the literature, and a full characterisation of this general space is beyond the scope of this current work.

In the following portion we use the term layer to refer to quantum ResNet layers, such thatcorresponds to the number residual connections and hence the number of controlled unitaries in the model. Each individual controlled unitaryis a variational ansatz, which in many cases is composed of repeated layers of a certain gate architecture; to avoid confusion, we will refer to the repeated layers within these unitaryterms as sublayers. We will now denote the unitary in the-th residual network layer as, wherespecifies the number of repeated sublayers in the ansatz corresponding to that particular unitary.

Previous work on the characterisation of barren plateaus makes assumptions that the circuits involved are sufficiently deepRagone et al. (2024); Fontana et al. (2023). As the quantum ResNet allows layer skipping, this means that there may always be shallow depth circuit components in the final loss function, which will not satisfy this assumption. We now consider a deep circuit composed of many repeated sublayers of the same structure of variational gates. We show that it is possible withlayers of quantum ResNet to effectively implement an ensemble ofdifferent ansätze where the number of sublayers of the individual ansatz terms in the ensemble ranges fromto.

The uniform ensemble quantum ResNet architecture is created usingquantum residual layers by ensuring the number of repeated sublayersin the-th unitaryis given byfor. To prevent a constant term in the loss function arising from the identity, we also initially apply a unitary operator consisting of a single sublayer, without using a residual connection, which we denote as. This corresponds to applying the operator

and normalising the resultant state by a factor. This term expands out to give an operation consisting of a linear combination ofterms. When unitaries multiply to create these terms, the number of sublayers add together. It is therefore clear that this procedure results in a operator

whereis a unitary corresponding to

Whereis the set that indexes theterms that multiply together to give a total number of sublayers. The state is also normalised by a factorafter the operation is applied. In total, we haveterms where the number of sublayers in each terms is in the range. This will lead to a loss function withunitary VQC model loss functions, covering sublayer depths fromto, in addition to non-unitary cross terms.

Many investigations into barren plateaus specifically require circuits to be of a certain depth, for example, requiring sufficient depth to form an approximate design over a Lie groupRagone et al. (2024). While bounds have been found for this depth for certain circuits, the quantum ResNet would allow an agnostic approach where many different layers can be trialled in the same model run and where shallow circuit components could guarantee the overall model does not exhibit barren plateaus. We see that forquantum ResNet layers one can implementdifferent unitary terms in an ensemble, in addition to further non-unitary cross terms.

Loss function concentration implies loss function gradient concentration, and hence this metric can be similarly used to discuss the presence of barren plateausArrasmith et al. (2022). An ensemble sum of all terms with differing numbers of sublayers may be able to avoid barren plateaus due to the presence of shallower depth components within the average ensemble, as shown in Figure8. This reaffirms previous results showing quantum ensemble methods can avoid barren plateausFriedrich and Maziero (2024). However, the quantum ResNet will also provide additional sources of variance from the non-unitary terms in the loss function, although a detailed characterisation of these terms is beyond the scope of this work.

Note that as the number of quantum ResNet layersincreases, the number of terms grows exponentially, meaning that any individual term will have a weighting that decays exponentially due to the normalisation of the state after the operation is applied. Therefore, ifis increased, one would need to ensure a sufficient amount of non-exponentially concentrating terms survive to still avoid barren plateaus. By initialising the ancilla qubits, one can vary the weightings of particular terms in the ensemble. This flexibility could allow the creation of models that can be pushed close to the boundary of barren plateaus but still remain in the trainable region. Similarly to the arguments made for the previous model, if the non-unitary terms vanish, then we would expect the loss function to be on average well approximated by the shallow non-vanishing terms which do not exhibit barren plateaus individually (excluding rare potential configurations in which deep terms still provide non-zero contributions). If these shallow terms turn out to be classically simulatableCerezo et al. (2023)then this means that the overall quantum ResNet will be classically simulatable to within some given error. Efforts to avoid this situation should focus on finding settings in which the non-unitary terms do not exponentially vanish; it remains an open question whether this is possible.

Previously we showed in Equation40that the strength of the residual connection determined a lower bound of the probability of success of a given layer. We also noted that the probability of overall success decays exponentially in the number of residual connections. We show in Figure9the impact of these effects on the expected number of repeated attempts required to achieve a successful LCU procedure. While the success probability decays exponentially init allows the construction of ensembles of size, which therefore leads to a linear relationship between expected attempts and ensemble size.

We also note that in the case that a given residual layer provides an exponentially vanishing contribution to the overall loss, from both its unitary and non-unitary contributions, then this could potentially be used to improve the probability of success scaling of the algorithm by allowing failed implementations of that particular layer to be accepted as successes. In a scenario in which multiple ansätze are being tested simultaneously, in which one may not know which contain barren plateaus or not, it would be possible to ignore any failures for ansätze which do not contribute meaningfully to the loss. This means that the probability of successful implementation would decay exponentially with the number of useful quantum ResNet layers implementedthat provide non-vanishing contributions to the loss, rather than the total number of layers. The implication of this however, is that one could simply discard these unused terms completely from the model and restrict to. In this case an ensemble ofmodels could then be manually constructed, which may be able to approximate the quantum ResNet results. Therefore, any benefit from future research in this direction would be focussed on the ability to search through a wide range of ansätze at the same time, and find those that provide meaningful contributions, rather than any quantum advantage inherent in the model performance itself. Although in the worst case settings the cost related to the probabilistic nature of the LCU procedure may render the quantum ResNet infeasible.

Although we show that quantum ResNet frameworks can avoid barren plateaus, it is possible that many common architectures may approach a solution which is vulnerable to classical simulation. This would occur when the quantum ResNet is well approximated by an ensemble of classically simulatable shallow depth terms. Perhaps this situation should be expected, as it has previously been observed that classical deep ResNets can behave as ensembles of shallow networks, where a previous study reported that the gradient of alayer ResNet was dominated by contributions from paths of depth betweenlayersVeit et al. (2016). We again highlight that the key to further advancements in the quantum ResNet implementation will likely rest on constructing models in which the non-unitary terms do not exponentially vanish and remain hard to simulate classically. This provides an expanded search space compared to strictly unitary models which could be subject to a more in depth characterisation in future work. Overall the question of whether this ensemble-creating property of quantum ResNet can be used effectively therefore remains a question for further research, although the reported success of VQC ensemble modelsFriedrich and Maziero (2024)may motivate further investigation into the efficient creation of ensembles within a single quantum device.

SECTION: IIIAverage Pooling Layers

SECTION: III.1Quantum Average Pooling Implementation

In a Convolution Neural Network (CNN) it is common to find a pooling layer. This layer acts to reduce the dimension of the data by considering a tile of fixed size that passes over the data and performs some operation, such as averaging, on all the datapoints in the tile.

A classical average pooling layer consists of a pooling window of sizepixels that passes over an image consisting ofpixels, with a certain strideRawat and Wang (2017); Sharma et al. (2018); Al-Saffar et al. (2017). We shall focus on the case where the pooling window moves across the image one pixel at a time, corresponding to a stride value. For each position of the pooling window, all pixels within the pooling window are averaged together, and this average is output as the value of a pixel in a new image. In classical techniques depending on the size ofandthe number of output pixels will be some number less thanand hence the pooling corresponds to reducing the dimension of the image. In the quantum technique, there is no penalty for calculating allterms as the operations are done in parallel on the quantum state, hence we shall consider this case and leave the dimensionality reduction as a subroutine that can be implemented after the averaging.

We consider an image ofpixels where each pixel is indexed byand the pixel colour value corresponds to. If we focus on the average pooling window which isin dimension, then classically we wish to redefine each pixel label by

whereis a pixel translation action which acts on theindices ofto retrieve the values other pixels through

so that they can be added to the average. The pixels accessed bydefine the pooling tile. For occasions in which the pooling window covers pixels outside the image, it is common to include some padding of the imageYu et al. (2023), for example, any pixels outside theregion can be padded by zeros, giving a padded image of dimension.

There have been many investigations focused on finding quantum parallels to CNN models, whereby measurements are taken of certain qubits such that the dimensionality of the data is reduced. For example, in some setups the pooling layer corresponds to a variational ansatz followed by a measurement of a qubitHur et al. (2022). InCong et al. (2019)an effective measurement was chosen corresponding to the symmetry and details of their specific problem concerning Quantum Phase Estimation. Although these popularised methods achieve the goal of pooling through reducing the dimensionality of the quantum state, they have not focused on giving a replication of an averaging pooling layer from classical CNN models for image data. In this section, we shall therefore demonstrate how LCU methods can be used to perform average pooling on quantum encoded image data. We shall utilise amplitude encoding with distinct coordinatesandfor the image, although any encoding for the data could be used, as long as the correct transformations are implemented with the LCU method.

Take animage samplewhererepresents the pixel colour value and,are the index coordinates of the pixel with. We shall utilise real amplitude encoding by defining a quantum state with two registers as

whereis a normalisation constant and. Once we have an image encoded into a quantum state in this manner, we can consider the type of operation required by average pooling. In a simple case, we can consider only theregister for. We will need to apply an operation that takesfor some normalisation constant, to perform an averaging over pixels amplitudes. This will result in the statehaving its amplitude transformed to the sum of the amplitudes of theandstates before being normalised (and therefore averaged). This operation is implemented by, whereand. These operators are implemented by decrement and increment gates. We can see that by taking

that it is not a unitary operation. Hence, to implement average pooling on a quantum device, we utilise LCU methods.

It is possible to probabilistically implement an averaging pooling layer on an image that has been amplitude encoded into a quantum state as specified in Equation62, such that the average pooling operationhas the effect

where

by using the LCU framework from SectionI.4. The termsandare the normalisation constants for the initial and final states, respectively.

For simplicity, we consider the ancilla qubits to be composed of two registers. We initialise these registers to the following

In this settingandcorrespond to the computational basis states of a Hilbert space ofqubits, which are labelled byand. In this basis,andcontinuing for all values until. The preparation operator therefore takes the form

wherecollects terms withsuch thatand will therefore not be used in the algorithm and can be ignored. This can be clearly implemented by a unitary operation. It can also be shown thatcan be realised with a unitary operator. Binary addition is possible to implement on a quantum circuitVedral et al. (1996)as shown in Figure11that shows. In general, we shall define aadding operator as, which may be formed by applyingin seriestimes or through a more optimised gate specific for that value of. The inverse of this operator, found by taking the Hermitian conjugate, will subsequently be the subtraction operator.

In order forto recover the correct amplitude, we can utilise theandoperators. We can therefore definethrough the action of these operators as

Now consider the action ofon the amplitude encoded image as

Relabelling the indices in the sum asandthis can be written as

We can now define the selection operator as

which corresponds to implementing controlledoperators, which are respectively applied when the ancilla is in the state. The selection operator is therefore unitary and can be applied on a quantum circuit.

Following the LCU procedure by first preparing the ancilla qubits gives

applying the selection operator results in

Applying the inverse preparation operator defined as

we can therefore see the state can be written as

We now wish to measure the ancilla qubits, discarding any states whenis not measured, hence we can ignore theterms. The probabilityof measuring thestate will therefore be

After selecting only the cases where the ancillas are measured in thestate, the final state will be projected to

whereterm is required such that the state is normalised. Expanding out the operation ofit is possible to see that

The termis the overall normalisation factor of the final state. Hence, the average pooling operation

has been implemented on a quantum circuit.
∎

Through this framework the average pooling operation can be implemented as is visualised for apooling window in Figure10.

In terms of the image boundaries, it would be possible to apply null padding to the image by introducing extra qubits in thestates. Without any padding, the quantum pooling window will treat the image as periodic and could include pixels from opposite sides of the image when located close to the image edge. It is worth mentioning that classical CNNs perform this averaging as a means of dimensionality reduction, as the total number of averages taken is usually less than the total number of pixels in the image. In the quantum case, however, it takes no additional time to average every single pixel in the image, and therefore we presented this as the most general case. Subsequently, to truly perform the quantum analogue of pooling, certain values would be discarded to reduce the dimensionality of the problem. The exact method will depend on exactly what kind of dimensionality reduction is desired, although we discuss how this could be performed in AppendixD.

SECTION: III.2Algorithm Scaling

The advantage of average pooling layers is well documented in classical neural networksGalanis et al. (2022); Gholamalinezhad and Khosravi (2020); Zafar et al. (2022). The method suggested in our work would allow this feature to be implemented on quantum encoded images in quantum machine learning models. The utility of this in the context of a quantum advantage will therefore be dependent on whether other quantum operations within the model can achieve some advantage over classical models. For example, recent empirical studies for amplitude encoded image data suggest that quantum models may in some circumstances display an improved robustness against adversarial attacks compared to classical methodsWest et al. (2023a,b). Indeed, theoretical guarantees on quantum robustness have recently been reportedDowling et al. (2024). While this is not the focus of our work, the quantum average pooling layers we introduce may be of use in further studies regarding quantum encoded image data. We will therefore focus instead on examining the circuit complexity and probabilistic scaling of the method.

In order to implement an average pooling layer with a pooling window size ofone needs to implement a linear combinationunitaries via the LCU method, whereby these unitaries correspond to selecting all pixels within the average pooling window. This means that in a givenregister one needs to create a linear combination ofunitaries. A general technique for doing this using onlyancilla for any LCU circuit would be to usemulti-controlled operators, whereby each ancilla basis state activates exactly one of the multi-controlled operators and no others i.e.. Previous related work on implementing general filter masks for quantum convolutional layers used this approach where they state that the number of multi-controlled unitaries that must be implemented is equal to the size of the filter maskWei et al. (2022); Chen et al. (2022). However, we show that by focusing on average pooling and considering that subtraction operators form a closed set, that a more efficient circuit implementation is possible which usessingle-qubit controlled operators.

Without loss of generality consider only theregister. We need to ensure that this has an equal superposition ofterms such thatruns fromto. This can be achieved usingqubits and single qubit controlled applications ofoperators. In this caseis implemented by the-th ancilla qubit and corresponds to theoperation. This operation subtractsfrom the binary register and can be formed by theoperation applied to themost significant qubits and the identity operator applied to theleast significant qubits. If, whereis the total number of ancilla qubits and controlled operations then we have a set of operatorswhere the-th element is applied if the-th ancilla is in the 1 state. As we have an equal superposition of allbasis states in the ancillas, this means that we will find an equal superposition ofterms which consist of all possible combinations of the operators in. The ancilla basis states can be thought of as selecting subsets of, with the resultant operation found by multiplying all operators together in that subset such that the indices decrease from left to right. As we have chosen the scaling of these elements to be, we can see that considering all possible combinations of these terms will result in an equal sum ofoperators whereruns fromto.

We can then setto see that the number of ancillas and controlled operators must scale as. Therefore, the procedure requiresunitaries that correspond to subtraction operators, that act on the separateandtarget registers and are controlled byancilla registers. An example circuit which involves 4 ancilla qubits and 4 controlled unitaries is shown in Figure12in which 16 total combinations of operators are implemented. Note that ifis less thanthen the final layer could be adjusted to bebut we may require multi-control qubits in order to prevent degeneracy and maintain and equally weighted combination of operators, see AppendixF.

To perform the averaging classically for a stride sizeit would require finding the average ofvalues forpixels, giving a scaling ofin general. Therefore classical averaging requiresarithmetic operations, while the quantum average pooling we suggest requirescontrolled subtraction operations. The exact scaling of the controlled subtraction operations depends on if ancilla qubits can be utilised, however we show this uses at worstbasic operations (see AppendixE) giving a total ofbasic operations in the overall LCU method while usingtarget qubits for the image encodings andancilla qubits.

Previous work built an LCU based quantum convolutional layer using afilter of the form

such that the filter passes over the image and calculatesfor the pixel value in the windowWei et al. (2022). They show that average pooling can be obtained as a special case where. We note that this work did not explicitly show a proof for a generalwindow, instead considering only. They used multi-controlled operators in which each ancilla qubit state only implements exactly one unitary, meaning that their technique requiresmulti-controlled operators. They report their unitary operations as consisting ofbasic operators, which would correspond to an overall scaling of. Hence, the circuit implementation that we present, which scales as, corresponds to a polynomial advantage inand an exponential advantage inover this previous technique when considering average pooling specifically.

Furthermore, although we started with the more specific case of average pooling, our entire algorithm can be generalised to recreate the quantum convolutional filters as presented inWei et al. (2022). This is achieved by introducing amplitudes into the ancilla qubits instead of using an equal superposition. We see this by considering a new preparation operator in which all ancillas (for bothandregisters) are entangled such that

where for simplicity we sayis a real amplitude of the ancilla basis state. This will mean that the terms in the linear combination ofoperators will have an associated weighting equal to. Therefore the transformation on the pixel value amplitudes in the image will be

We can therefore identify that this performs a general quantum convolutional filter as originally described inWei et al. (2022), while utilising exponentially fewer unitary operators in terms of. A comparison of this reduction in circuit complexity is shown in Figure13when applying aconvolutional filter defined as

This general convolution case reduces to the previously discussed averaging case when the ancilla qubits are in an equal superposition. We highlight that in this section we do not discuss the actual pooling step itself, and hence any improvement is confined to the averaging / convolutional subroutine of the circuit. Further details on the practical implementation of the pooling step and quantum convolutional neural network framework can be found inWei et al. (2022).

We also note that our implementation is easily generalised to data types with dimension greater than two by adding additional registers for extra dimensions. For-dimensional data we requirequbits to encode the image intodifferent registers. In this case, the window has a total-dimensional volume of, and hence using the implementation from previous workWei et al. (2022)would requireunitaries. In contrast, our technique would requireoperators in total withancilla total qubits when considering all registers and would therefore use exponentially fewer unitaries in both data dimensionand window size.

When considering the fact that this is a probabilistic algorithm with a chance of failure, the situation becomes slightly more complicated, as the probability will depend on the image itself. As shown previously, the probability of success is equal to

If we had an image in which every pixel has the exact same colour value, we can effectively setand therefore. We expect real-world images to have pixels that are close in colour value to other local pixels nearby on average with the exceptions occurring at the edges of subjects within the image. We therefore expect the probability to remain relatively stable overall, although one could construct adversarial example images that result in low probabilities. To gain a practical understanding of this probability scaling we considered the MNIST fashion datasetDeng (2012), we empirically show the scaling of the probability of success with respect toandin Figure14and Figure15, respectively. These results indicate that the probability of success decreases but levels off after a certain point asincreases, and that there is no discernible trend when increasing. These results align with our intuition for real-world images. The general structure and content of real-world images (and their local pixel similarities) remain consistent asincreases; therefore, there should be no discernible decrease infrom increasing. On the other hand, increasingmeans considering a larger neighbourhood of pixels. Initially, asincreases, the probability of encountering edges within this neighbourhood also increases, causingto decrease. However, beyond a certain point, further increasingadds less new information because most of the image regions are already accounted for and edges covered, solevels off. The exact probability will be very image dependent; there may also exist techniques to prepare images such that the probabilities are improved, which we leave as an open question for further research. In cases where the probability of success remains high, it corresponds to pixels being similar to each other locally, this in turn means that the average pooling action on those qubits locally will be well approximated by the identity operation. It is important to note therefore that these conditions could be more prone to classical simulation techniques and further work should be carried out on this possibility before any concrete advantages are claimed.

SECTION: IVIrreducible Subspace Projections

In order to discuss the irreducible subspace projections circuit, we first give a brief overview of representation theory definitions.

SECTION: IV.1Representation Theory Preliminaries

Following standard texts on group and representation theoryFulton and Harris (1991); Ragone et al. (2023)we provide a brief summary and introduction to the underlying mathematical framework utilised in this section.

The definition of a representation of a groupcan be given as

A representation of a grouprefers to a pair, whereis a vector space andis a group homomorphism, whereis the general linear group of invertible matrices that acts on the vector spaceof the representation. The homomorphism maps group elementsto matrices.

Often either the homomorphism, the vector spaceor the image subgroupcan be referred to as the “representation” depending on context.

For a given representationa subrepresentation is a vector subspacefor which any vectorremains withinwhen acted on by any representation of the group, that is,.

If a representation does not contain any non-trivial subrepresentations (the trivial spaces being the empty subspaceand the entire space) then it is said to be an irreducible representation.

If a representation does contains a non-trivial subrepresentation, then it is called a reducible representation. Representations can often be decomposed into a direct sum of their irreducible representations, in which case they are called completely reducible. Maschke’s TheoremMaschke (1898)states that any finite-dimensional representation of a finite groupover a fieldwill be completely reducible (so long as the field characteristic does not divide the order of the group). It is also the case that every finite-dimensional representation of compact Lie groups is completely reducibleHall (2015). If a representationis completely reducible, then there exists a basis in which we can writeas

whereare the irreducible representations indexed by, whereis the total number of irreducible representations. In this work we will often refer toas the irreducible representation for simplicity, although strictly it is the label that indexes the irreducible representations. The quantityis called the multiplicity of the irreducible representation. We can also define the degree of a representation as. In this basisis in a block-diagonal form. This change of basis also decomposes the representation vector spaceas

The conjugacy class of a group and the character of a representation for a given group element can be defined as

For a grouptwo given elementsare said to be conjugate ifsuch that

and hence the conjugacy class can be defined as

corresponding to the set of all elements that are conjugate to.

For a representationof the group, the character can be defined as

which is the trace of the representation ofon. For the irreducible representationsindexed bywe shall definefor simplicity.

In particular, as the trace permits cyclic permutation, this means thatand thereforeis constant on the conjugacy classes of. i.e., ifthen. It is also worth noting that as the identity element corresponds to an identity matrix, taking the trace of an identity matrix will result in the fact that. Hence, the degree of an irreducible representation can be found by.

We will now introduce a key result of this work regarding projecting quantum encoded states to any linear combination of irreducible subspaces of a given finite group.

SECTION: IV.2Subspace Projection Circuit

We start by observing a result from the representation theory of finite groups which statesJean-Pierre

Letbe a representation of. The canonical decomposition into an irreducible representation is given by, where the irreducible representations have charactersand degrees. Then the projectionofonto the spaceis given by:

whereis the character of group elementfor irreducible representation, andis the matrix representation of group elementacting on the space.

This is a known result in representation theory; for more details, see reference texts such asFulton and Harris (1991);Jean-Pierre. In this section, we explore a method for implementing this projection on a quantum circuit using the Linear Combination of Unitaries (LCU) technique. Specifically, we demonstrate the practicality of realising the projection described in Theorem3on a quantum device. In the most comprehensive scenario, we establish that a quantum circuit can execute combinations of suchprojections at the same time via the LCU method.

Letbe a quantum state encoded onqubits. Letbe a unitary representation of a finite group, where the representatives for group elementsare denotedand are unitary operators that acts onand can be implemented in a quantum device. Utilising the Linear Combination of Unitaries framework on a quantum circuit, one can probabilistically apply a linear combination of irreducible representation projections

such thatprojectsto the subspacecorresponding to the irreducible representation subspace indexed bywith degree. The constantscan be freely chosen,is the normalisation constant for the final state after projection, andis the total number of irreducible representations.

As we intend to implement a linear combination of projections, we shall consider a slightly more general form of the LCU method. We first perform a pre-initialisation step on theancilla qubits, initially in the basis state, using an operatorto prepare the statedefined as

wherecan be chosen to adjust the relative amounts of a given representation,is the degree of the representation, andis a normalisation constant for the quantum state. The statesare basis states of thedimensional Hilbert space for thequbit ancilla register denoted by. They can be taken to be computational basis states. We highlight that after this pre-initialisation the ancilla register is in a combination up tobasis states, which are indexed by the irreducible representations. The inclusion of theterm here ensures that the representation weightings are correct later on. At this point, every statecorresponds to a different irreducible representation of the group. We defineto correspond to the trivial representation.

The next step corresponds to applying an operator that takes each representation labelled stateinto a sum of basis states,which are now labelled by the elements of the group, where each basis stateinherits a weighting according to the charactercorresponding to the representationand the relevant group element. To help improve readability, we define. These correspond to the same basis states in the ancilla register, but emphasises the fact that are labelled by the group elements.

As we consider a combination of multiple projections at the same time, then, in order to maintain generality of our framework, instead of requiringto be a different operator for each individual irreducible representation (indexed by) as would be the standard case in LCU methods, we will consider a generalised preparation operator corresponding to the unitarywhich has the effect of applying the correct character for every irreducible representationand every group elementsuch that

where in the most general form

where the terms grouped together aswill not be used in the algorithm and can hence be ignored. Implementing this corresponds to constructing a matrix that contains the character of every group element for every irreducible representation. This matrix will have the form

where thewill never affect the algorithm, but are required as the matrices involved must be of size. The firstcolumns correspond to the vectors that contain the characters for each element in a given representation. Considering the character orthogonality theoremHuppert (1998)which states that

this means that the character vectors of irreducible representations form an orthonormal basis. Theterms can be chosen utilising the Gram-Schmidt procedure or otherwise to ensure that all column vectors ofform an orthonormal basis. A matrix whose column vectors form an orthonormal basis is unitary. Hence, our generalised preparation stepcan be implemented on a quantum circuit.

Theoperator can be implemented by applying the unitary quantum gate representationto thequbit target statefor each corresponding group elementin the ancilla register

As long asis a compact group there will be unitary irreducible representationsvia the Peter-Weyl theoremDeitmar (2002). Hencecan be implemented in a quantum circuit for compact groups. Using controlled gates, in which the operationis applied only when the ancilla qubit is in the state, then the operatoris successfully implemented.

We have shown that the preparation and selection operators can be implemented on a quantum circuit, now all that remains is to combine the operators together to view the full action of the LCU procedure. Pre-initialising the ancillas

followed by applying preparation operatoron the ancillas gives

The selection operator applied to the circuit can then be written

The conjugateterm can be written as

whererepresents terms that will not end up contributing and hence we can ignore. Applying the conjugateterm, and separating out terms that will not be used further we find

where we can ignore all termsas they will be discarded if ever measured. Note that sinceis defined as the trivial representation, it follows that. We now measure the ancilla qubits and find that they will be found in the statewith a probabilitygiven by

By only retaining states in which the ancilla was measured in thestate, we will have prepared the state

whereis the normalisation constant of the final state, as required.
∎

A simple corollary regarding the special case in which during the pre-initialisation stageand, such that only one irreducible representation is selected.

The projection given in Theorem3can be probabilistically implemented on anqubit quantum stateby utilising a Linear Combination of Unitaries in a quantum circuit where

such thatprojectsfrom the spaceto an irreducible representation subspace.

This shows that the LCU method can be adapted through careful selection of the preparation and selection operators to reproduce the projection onto any combination of irreducible representations. An overall schematic of the representation projection circuit is shown in Figure16. Note that after the projection, the state may no longer be a pure state.

In order forancilla qubits to have a basis state for each group element representation ofit would require. Hence, the number of qubits required scales as. However, the character implementation unitarywhich is used in the ancilla preparation stage has a dimension that scales withwhich may be prohibitive in certain cases. For example, ifis taken to be the permutation group, where the representation operatorscorrespond to permutingqubits in the target state, then we requireancilla qubits, however we are required to initialise a unitary of size, which may be difficult. A proposed solution outlined in AppendixAis to utilise a smaller version ofcorresponding to the character table where each ancilla qubit state represents a conjugacy class rather than individual group elements. In this case, the size of the unitary required could be significantly reduced, as it would scale only with the number of conjugacy classes, denoted by. Hence, this alternative implementation would require ancilla qubits of orderto encode the character table state, but then it would also requireextra registers, one per conjugacy class, with sufficient qubits to produce a superposition of states for every element in the conjugacy class. This means more qubits are required in total, but the unitary is easier to implement. The number of conjugacy classes in, for example, that is approximately approached in the asymptotic limit is

which is super-polynomial but sub-exponentialFulton and Harris (1991). This would be a significant improvement in scaling compared to. This allows a trade-off between total qubits and the ease of unitary preparation. Note that in this section, we introduced a very general framework, and improvements in circuit efficiency to implementmay well be possible for specific groups, representations, and data types.

The probability of successis shown in Equation98which is equal to the probability of measuring the ancillas in thestate. This can be simplified by utilising the result of Theorem4to observe that

Any quantum state can be written as a decomposition in terms of its components on the irreducible subspaces

whereis the multiplicity of representation. We defineand see that it denotes the component ofthat occupies the subspaces of the irreducible representation. Afteris projected byonto the irreducible subspace ofit will equal. Noting thatwill be orthogonal for differentvalues, we can therefore write

Therefore, the probability of success depends on the amount that the initial stateoccupies the relevant irreducible subspaces in the projection. The normalisation condition in the general state means that. In the case that we project fully to one specific spacethen

which will depend on how much of the statelies in the subspace of irreducible representation. Iflies fully within the space, then. Conversely, ifhas no components in the subspace for irreducible representationthenand the algorithm is impossible to run. An advantage of the additional control introduced by theparameters is that we can freely choose the weightings to potentially improve the probability of success. In general, the probability of success will depend greatly on data encoding and choice of representations.

SECTION: IV.3Symmetry Invariant Encodings for Point Cloud Data

In this subsection we discuss projections to a single irreducible subspace in order to highlight how these subspaces can correspond to symmetries of the input data. However, it should be noted that these projections could take the quantum state to a polynomially sized space which may be classically simulatable, as has previously been shown to be the case with equivariant variational modelsAnschuetz et al. (2023); Goh et al. (2023). The following subsection will address this issue by instead considering all subspaces, and hence maintaining an exponentially large space overall, but allowing certain subspaces to be amplified relative to the others. Investigating single subspace projections remains useful in this context as it allows the identification of which irreducible representation subspace correspond to symmetries of the underlying data. We therefore proceed to highlight how certain irreducible representation subspaces correspond to symmetries of the underlying data when it has been encoded into a quantum state. In particular we focus on point cloud data due to its inherent permutation and rotation symmetry.

A point cloud is a collection of three-dimensional vectors (the points) that when viewed as a collective represent an image. Amongst other applications they are often associated with computer vision algorithms, as a primary method for performing three-dimensional imaging is the use of the Light Detection and Ranging (LiDAR) system, which produces point clouds as its data outputRaut and Patole (2023). We can consider a point cloudas a set of three-dimensional vectorsthat overall forms an image. We can consider a form of quantum encoding in which each individual pointis encoded into a quantum stateleading to a separable quantum state for the overall point cloud as

The statescould be single qubits, in which case the total number of qubits in this target register would be. However, in general, eachcould be a state encoded onqubits, in which case we can consider eachas a-dimensional qudit andwould denote the number of qudits in the system that encodes.

The ordering of the points within the setdoes not affect the overall image; however, in general a machine learning algorithm may output different results depending on the ordering of the points in the data input array. A solution to prevent this by utilising permutation symmetric encodings for point clouds was suggested in previous workHeredge et al. (2024)where a quantum superposition of all possible permutations was used, leading to a permutation invariant quantum encoding such that

This previous work can be viewed as a special case of the LCU method described previously, in which the group isand the stateis projected to the symmetric irreducible representation subspace (in which the character for all group elements is equal to one). The representations of the group elementsthat act onare denoted byand correspond to SWAP gates that permute the constituent statesaccordingly. This projection would correspond to applying the projector

providing the result proposed in Equation107and recreating the work ofHeredge et al. (2024)as a special case of a more general framework.

The novelty of the projection technique we propose in the LCU framework is that it allows expansion to many other possible symmetries beyond permutation invariance. Here we shall outline another example, rotationally invariant encodings of point clouds that contain four points utilising aninvariant encoding. This is motivated by the fact thatis the double cover of, which is the group that corresponds to rotations in three dimensions, which means that each element ofcorresponds to exactly two elements in.

In this framework, we consider point clouds in which the pointsare represented in spherical coordinates. We shall ignore the radial componentfor the sake of simplicity, although this could be included in any practical implementation in an appropriate manner.

We propose an encoding in which for each pointis encoded into the following quantum state

such that theandangle of the point is encoded into the respective angles of a single qubit in the Bloch sphere representation.

Rotation of a point cloud corresponds to rotating every individual point by the same amount and in the same direction such that. Considering this in terms of the quantum encoded state above, it would correspond to the application of the same rotationon each qubit, rotating every qubit state about the Bloch sphere by the same amount. In order to have a quantum encoded point cloud that is invariant to rotations of the point cloud, it would require the following invariance

which would be invariance under the action.

We consider irreducible representations of the group, where the representations of group elementscorrespond to the SWAP gatesthat permute the constituent pointsaccordingly. We are able to use this because Schur-Weyl duality (see AppendixBfor a detailed discussion) provides a relation between irreducible finite-dimensional representations between the symmetric group and general linear group. This means that for the one-dimensional trivial representation ofof multiplicity, there will correspond an-dimensional representation ofcovering the same subspaceKirby and Strauch (2018);Kirby; Ragone et al. (2023). The character table foris shown in Figure2.

If we utilise the irreducible representation projection procedure to project the stateto the subspace of irreducible representation, with characters, then this corresponds to projecting to the basis statesKirby and Strauch (2018);Kirby; Ragone et al. (2023)

and

When writing the action ofin the Schur basis, as shown in Figure21, it can be seen that the above basis statesare invariant under the action ofas they are in the subspace associated with the trivial representation ofKirby; Kirby and Strauch (2018). We are able to reach this space through projecting indue to Schur-Weyl duality, since the irreducible subspaces ofandare simultaneously block diagonalised. This means that we have effectively projected the quantum encoded point cloud state to a subspace which is invariant with respect to three-dimensional rotations of the point cloud. This is a desirable symmetry for point clouds, as they are naturally invariant to three-dimensional rotations.

In order to demonstrate this numerically, we show in Figure17that the rotationally invariant encoding introduced by this projection gives a constant overlap equal to unity when comparing two identical but rotated point clouds. This constant overlap of unity is maintained as the degree of rotation is increased, demonstrating that the encoding is producing rotationally invariant encoded states. It is also demonstrated that, without applying this symmetry projection, a non-invariant encoding produces an overlap between identical but rotated point clouds that decreases as the magnitude of the rotation is increased. This is significant as it means that without a rotationally invariant encoding, the exact same point cloud, rotated byradians, would produce a quantum state that appears completely different and will give zero overlap with the original orientation of the point cloud.

SECTION: IV.4Symmetric Subspace Amplification

The rotationally invariant encoding discussed previously, as well as previous work on permutation invariant encodingsHeredge et al. (2024)have been implemented in a binary fashion: the initial quantum state is either projected to a fully permutation invariant state or remains unchanged. Such an implementation significantly reduces the dimensionality of the encoding, yielding benefits in certain scenarios through improved generalisation of the model. This section explores the potential advantages of introducing a continuous spectrum of invariance with respect to some symmetry, rather than adhering to binary extremes, and investigates whether optimising this aspect as a hyperparameter could enhance classification performance in quantum machine learning (QML) models.

Recent studies suggest that permutation equivariant variational circuits may be classically tractable under specific conditionsAnschuetz et al. (2023); Goh et al. (2023), indicating that a drastic reduction in dimensionality might increase the likelihood of classical simulatability. This raises concerns that fully projecting to a polynomially sized subspace could render algorithms susceptible to classical simulation. To address these issues, we propose a novel approach that involves partially amplifying the portion of the quantum state into a given invariant space. Specifically, we will consider amplifying the permutation invariant subspace, although any irreducible subspace could be chosen. Apart from edge cases, the quantum state will still in general be exponential in dimension but the permutation symmetric subspace will have a higher weighting compared to all other subspaces; the amount of permutation symmetry amplification is governed by a hyperparameterwhich will therefore also affect the expressivity of the encoding. This method provides enhanced control over training performance and facilitates the tuning of the model to achieve optimal results. For data types with inherent permutation symmetry, such as point cloud data, the optimal global classification function must also exhibit permutation invariance. However, the specific outcome of a QML model depends on the circuit architecture, classification protocol, and inherent limitations of QML models, suggesting that a purely permutation invariant QML algorithm may not necessarily be the closest to the global solution. We hypothesise that by incrementally adjusting the degree of permutation invariance in the model, we can converge towards a value that is closer to the true global optimum performance than is possible with an non-invariant, or fully permutation invariant model. This concept is illustrated in Figure18.

The framework introduced previously allows the implementation of any linear combination of projections to an irreducible representation subspace with full control of the ratios of these projections. One can consider decomposing a state into its irreducible representation components, as shown in Figure19and gaining control over the relative ratios between the amplitude components, allowing them to be adjusted to suit the model and data.

Via the LCU framework we previous showed in Theorem4that it is possible to implement a projection onto a quantum state in the following form

where theparameters can be controlled via the initial state of the ancilla qubits as

In order to implement the symmetric subspace amplification algorithm, one can define a parameterthat parameterises the amount of symmetry in the encoding. Then we can assign the followingvalues

Hence, the initial ancilla state will be of the form

Theterm can be varied to adjust the amount of permutation symmetry. Whenthis corresponds to an equal projection on all irreducible representations, since the resulting operation is an equal projection onto all subspaces (weighted by the dimension of the subspace) and hence will leave the state unchanged. In contrast, the case wherewill result in projection onto the symmetric subspace only. Asincreases, this corresponds to continuously amplifying the portion of the state that lies in the symmetric subspace.

In order to investigate the potential of symmetric subspace amplification, we implemented the model proposed here utilising the aforementioned technique alongside Qiskitstatevector_simulatorAbraham et al. (2019). This was used to encode point cloud data and perform classification on the sphere and torus point cloud dataset as specified inHeredge et al. (2024). More details can be found in AppendixC.

We record the average test accuracy over 10 experiments for a givenand then varyto see which value is optimal for the data. The results presented in Figure20illustrate that increasing the degree of symmetry yields the highest test accuracy at an intermediate value, demonstrating the potential advantage of this technique. Moreover, it is observed that while a fully symmetric projection () surpasses the performance of the non-symmetrised configuration (), there is a significant reduction in dimensionality as we approach a fully symmetric state. This reduction corresponds to projecting onto a polynomial size space for the case of symmetric subspacesHeredge et al. (2024). Theparameter is the ratio of the symmetric subspace to all other subspaces. In general one could select any relative weighting for all the irreducible subspaces, at the cost of having more parameters to optimise. We envisage that in practice a grid search would be used to find these hyperparameter values and that they would be optimised using a cross validation set, allowing final classification performance to be assessed on an unseen testing set.

A key concern with fully symmetric states is their potential for efficient classical simulation due to this polynomially sized space. In contrast, the technique of partial symmetrisation not only achieves higher accuracy but also resides in a higher-dimensional space, possibly making it more challenging to simulate classically. While computer vision data can consist of thousands of points, there are example datasets that may be more suitable in the near term, such as particle physics collision classification tasks in which there may be less than 10 particles (points) in a given eventHeredge et al. (2021). This would likely be a nearer term goal for the application of point cloud specific algorithms, although the method described in this paper could be applied to many symmetries across various different data types.

SECTION: VConclusion

In this study, we have demonstrated the applicability and flexibility of the Linear Combination of Unitaries method in enhancing Quantum Machine Learning architectures. Our work provides several implementations of classical machine learning structures within the quantum domain, achieving not only a foundational translation of these concepts but also demonstrating potential for computational advantages.

The implementation of quantum ResNet demonstrates a procedure that can avoid the trainability issues associated with barren plateaus by allowing shallow depth components to survive in the final loss function. It is still a question of further research as to understanding the exact dynamics of the non-unitary terms. We demonstrated that by parameterising the strength of the residual connections throughterms, one can increase the lower bound probability of success of the LCU method. This provides a possible avenue to tackle the key problem of the LCU method, which is that the implementations can only be performed probabilistically.

We also demonstrated an implementation of quantum native average pooling layers commonly applied in convolutional neural networks. These layers have demonstrated success in classical techniques and therefore have the potential to improve quantum convolutional neural networks. While classically one would need to calculateaverages, the quantum parallelism inherent in our technique applies the averaging to all pixels (which are amplitude encoded into a quantum state) simultaneously. By generalising our work further, we can recreate quantum convolutional filters as has been previously proposedWei et al. (2022), while utilising exponentially fewer controlled unitary operations.

Finally, we demonstrated an integration of irreducible representation projections into a quantum framework, allowing for the encoding of data symmetries directly into the quantum state, which has the potential to enhance the model’s generalisation capabilities across various data structures. This general irreducible subspace projection framework includes previous work regarding permutation invariant encodings for point cloudsHeredge et al. (2024)as a special case, while in SectionIV.3.2we introduced a novel rotationally invariant encoding for point cloud data using thegroup. We further introduced in SectionIV.4a method of parameterising the amount of symmetry in an encoding as a tuneable hyperparameter. This allows the quantum state to remain in an exponentially large space, while certain subspaces are amplified relative to each other, helping to mitigate some of the simultability concerns associated with fully projecting to a polynomially sized subspace. This added flexibility resulted in an improved performance for point cloud data when encoding an intermediate amount of permutation symmetry when compared to either a fully permutation invariant or noninvariant encoding. These were illustrative examples of how the framework could be utilised and there could be many possible symmetries and datasets for which this framework could be similarly adapted and optimised.

As the field of quantum computing continues to mature, the methods and frameworks presented here offer promising avenues for developing more sophisticated quantum algorithms that leverage both the computational benefits of quantum mechanics and the established successes of classical machine learning architectures. By utilising LCU methods we have shown non-unitary operations can be applied in a QML setting; this research not only extends the theoretical possibilities and flexibility of QML algorithms but also provides practical frameworks for their application, setting the stage for further evolution of quantum machine learning models.

SECTION: Author Contributions

J. Heredge envisaged the project, initially focused on irreducible subspace projections, with M. Sevior and L. Hollenberg as an extension of their previous workHeredge et al. (2024). J. Heredge devised the ResNet and Average Pooling layers applications. The theorems and numerical simulations were developed by J. Heredge with the help of M. West. M. Sevior and L. Hollenberg supervised the overall project. All authors contributed in reviewing the manuscript.

SECTION: Acknowledgements

This research was supported by the Australian Research Council from grant DP210102831. J. Heredge acknowledges the support of the Australian Government Research Training Program Scholarship and the support of the N.D. Goldsworthy Scholarship. This work was supported by the University of Melbourne through the establishment of an IBM Quantum Network Hub at the University. We thank Dougal Davis for early discussions on representation theory that helped aid the development of the irreducible subspace projection work. We also thank Giulio Crognaletti for discussions on current quantum ResNet literature.

SECTION: Appendix AConjugacy Class Implementation

In the implementation of irreducible subspace projections detailed in SectionIV, an operatorwas required that contained the character of every element in the group. This meant that the dimension of the matrix scaled with, which can be problematic for some groups, such as the permutation groupwhere. To tackle this, in this section we will consider a unitary operatorthat contains the character for each conjugacy class in the group, with additional ancilla qubit registers per conjugacy class prepared in an equal superposition that then acts to distribute these characters to the corresponding group elements. This effectively only requires encoding the character table of the group into a unitary operator, and hencescales with the number of conjugacy classes of. This has the potential to drastically reduce the size of the unitary that must be applied, at the expense of requiring additional ancilla qubits. We show that utilising this circuit structure recreates the result of Theorem4and is therefore a valid alternative approach.

The character orthogonality theoremHuppert (1998)stated previously in Equation91relates to a sum over all the elements of the group. As the character is the same for all elements in a conjugacy class, this can be adjusted to a sum over all conjugacy classesby introducing a termthat represents the number of group elements in the conjugacy class. Therefore, the character orthogonality theorem can be written

Therefore, to create a matrix with orthonormal columns (to ensureis unitary) the characters for a conjugacy classmust be weighted by square root of the number of elements in the conjugacy class. Hence, we require that

where in this case the conjugacy classesare labelling the basis statesdefined asthe basis states of thedimensional Hilbert space for thequbit ancilla register denoted by. These can be taken to be the computational basis states.

If we considerwith its character table given in Table3then we see that in this case the appropriate unitary matrix to be constructed would be

This successfully allows for the construction of a unitary matrixthat scales in size with the number of conjugacy classes as opposed to the number of group elements. We therefore have satisfied the constraint thatis unitary and can be implemented on a quantum device. In generalcan be written

wherecollects terms associated withwhich will not be used in the construction.

Similarly to the main text, the first step is the pre-initialisation of the ancilla qubits to some combination of states that index the different irreducible representations

whereis the initial state of the ancilla qubit register, usually assumed to be. By applyingto this pre-initialised ancilla state, one can write

where as previously statedare the same basis states, usually taken to be the computational basis states, but we have switched frombeing indexed by the irreducible representation, to the basis states being labelled by the conjugacy class. This contrasts toin the main text, where the group elements label the ancilla states. After application ofthe ancilla qubits now have basis states corresponding to the conjugacy classes. The selection operator requires the creation of additional qubit ancilla registers, denoted by, for each conjugacy class which are encoded into an equal superposition ofstates

whereare basis statesof thedimensional Hilbert space for thequbit ancilla register, which can be taken to be the computational basis states. The groups elementsthat are contained in the conjugacy classnow label the basis states in register. Each register has the requirementto ensure that there are sufficient qubits in the register such that each element inhas a corresponding basis state. Theare prepared on aqubit register which is initially in a basis statethrough the operation

wheresummarises terms associated withwhich will not be present in any calculations.

Overall the operations up to this point can be written as

The controlled operations are performed similarly to the main text, except in this case the group elementis indexed by bothwhich determines the conjugacy class andwhich indexes the element within the given conjugacy class. In this casewill be controlled by both the conjugacy class stateand the element selector within the conjugacy classof the registerassociated with the conjugacy class. The action of this selection operator can be defined as

which is implemented by each unitarybeing controlled by both theandstates. Applying this operator one can see the effect is

where we are being flexible with the precise positioning in the tensor product of the unused registersfor eachterm for the sake of readability. The notation we are using is that for a givenelement in the sum over all conjugacy classes, allregisters which will not affect theoperator becauseare written first, with the casewritten to the right of this. In reality the register position will be different for each, but this becomes difficult to denote in the notation.

We can now uncompute allregisters by noting that

This means that if we require these registers to be measured in thethen we can ignore the terms summarised byassociated with. Application ofto all such registers gives

We measure the registers which previously containedstates and discard unless we measure allstates. This discards the terms collected by thein the previous equation.

The final steps consist of applyingand measuring the conjugacy classancillas to be in the initial state. Due to the fact that the state, which is commonly assumed to be, is used to index the first representation, we can write

where noticeablydue to the fact that we are free to defineto always correspond to the trivial representation when constructing. Applying this operator to the conjugacy class ancilla qubits in the circuit therefore results in

whereis the normalisation constant of the final state. Due to the fact that conjugacy classes partition the group, the labels of the conjugacy classalong with the labels of the elements within each conjugacy classwill uniquely index each group element. In addition, all elements in the same conjugacy class have the same character i.e.,for. Hence, we can relabel the above expression in terms of group elements, rather thanand, to explicitly see that it can be written as

This is the precise form of Equation86in Theorem4. Hence, we have provided another framework that satisfies the theorem in the main text. As the final step consisted only of reordering the indexing, it follows that probability of successwill be the same as in the main text.

The dimension ofscales with the number of conjugacy classes of the groupas opposed toin the main text, which scales with the number of elements in the group. This means thatcould potentially be much easier to implement than. However, a caveat is that an additional ancillary qubit registeris required for each conjugacy class, where each register will contain a number of qubits of the order. This presents a trade-off between unitary implementation difficulty and the number of ancilla qubits required. The true difficulty in implementing either unitary will ultimately depend on the group, but we provide both of these general techniques as possible starting points for future implementations.

SECTION: Appendix BRotational Invariance via Schur-Weyl

In this section, we demonstrate how certain irreducible representations ofcould correspond to rotationally invariant encoding states when using the encoding specified in SectionIV.3.2. Following the work and explanations ofKirby and Strauch (2018); Ragone et al. (2023)and in particular the thesisKirbywe reproduce an overview of Schur-Weyl duality and the concept of the Schur basis and add discussion at points linking this to how certain irreducible representation subspaces would correspond to rotationally invariant point cloud encodings in the case considered in Equation109.

SECTION: B.1Introduction to Schur Transforms

The rotational invariant point cloud encoding we propose in SectionIV.3.2relies on a property of the probabilistic irreducible subspace projection circuit when considering the group, which in effect performs a projection to basis states of the Schur basis. Circuits that implement quantum Schur transforms have previously been introduced, such as those that implement them through the unitary group by iteratively applying the Clebsch-Gordan transformsBacon et al. (2006)and alternative methods that implement it by considering the action of the symmetric group using quantum Fourier transformsKrovi (2019). Indeed, further investigation on whether the use of these existing algorithms could be adapted to more efficiently refine our procedure would be an interesting further research direction, as our implementation derives from the most general case of Theorem4which applies to any groupand therefore may not be the most efficient in practice.

The Schur transform is related to the concept of Schur-Weyl duality. In general, we can considerqudits of dimensioninside a vector spacewith a computational basis written as. There are two representations on this space that are related to each other by Schur-Weyl duality. One of the representations is that of the Symmetric Group, whose elements consist of all possible permutations ofobjects. The representation ofon this vector space would simply consist of permuting the qudits. For a given group elementone can write the action of the representationon this vector space as

Hence, eachsimply corresponds to a different permutation of thequdits.

The second group to consider is the group of allunitary operators. As each qudit forms a-dimensional vector, we see that the natural representationof the groupacting on the vector spacewould correspond to the-fold product action, where the sameis applied to each qudit. This can be written as

The two actionsandare fully reducible and hence can be written as a direct sum of their irreducible representations

Note that the actionsandcommute with each other. The Schur-Weyl duality therefore states that there exists a basis which simultaneously decomposes the action ofandinto irreducible representations as

We can write this Schur basis aswhich decomposes the action ofandas

This action will decompose the vector spaceas

Note that since these subspacesandare irreducible, the action of the representationoron a vector in spaces will keep the vector in that space. We will focus on building the Schur basis through considering the action offor.

SECTION: B.2Rotational Invariance for Two Points is Trivial

If we wish to find states that are rotationally invariant as we rotate points in a 3 dimensional point cloud, we should first consider what this means on the point cloud data. Each point can be represented by a vector in. If the entire point cloud is rotated, this amounts to every point being transformed by the same rotation, which is equivalent to applying a rotation matrix from the groupto each point.

A natural way we choose to represent rotations of points in a quantum encoding is as rotations on the Bloch sphere representation of a qubit as was detailed in SectionIV.3.2. This is further motivated by the fact thatis the double cover of, which means that every point incorresponds to two points in, which means that we can useto model rotations in three-dimensional space classified by. To produce an encoding like this, we simply need to apply the parameterised rotation gatesandto an initialstate, whereare the angle coordinates of a point in radial coordinates. We are now left with the angular direction of the point represented in the Bloch sphere of a single qubit. If we do this for allpoints in the point cloud, we will havequbits. A rotation of the entire point cloud can now be represented by the application of anyunitary to every qubit simultaneously. This is a tensor representation of thegroup and can be written explicitly asfor.

To further study this, we shall resort to the case consisting of only two points. We again follow standard explanations from reference textsKirby and Strauch (2018); Ragone et al. (2023);Kirbywhile relating these points back to the rotationally invariant encoding we propose throughout the discussion. In this case rotation of the point cloud corresponds to applying the representation, to the two qubits. Note that this construction commutes with the SWAP operator, where SWAP corresponds to permuting the two qubits. This fact means thatand SWAP can be simultaneously diagonalised in a common basis.

If we consider two qubits such thatand the groupthen a natural representation on two qubits would be. If we change from the computational basis to the Schur basis, then we can see that this is a basis of eigenvectors for the SWAP operator that is completely diagonalised in this basis. We can show this explicitly as

As bothhave the same action when applied to the basis states, this means it corresponds to the trivial representation1of. The action on this subspace leaves states unchanged and hence they have an eigenvalue of. The action of SWAP when applied to the basis state, leads to a sign flip (eigenvalue of -1) which is therefore denoted as thesignrepresentation of, where the sign of the state gets flipped by SWAP and remains unchanged under.

We can simultaneously block diagonaliseand SWAP as they both commute. Henceis block diagonalised in this basis. This means that if we have a state in the space spanned bythat it will in this space under the operation of. It is possible to identify fora symmetric eigenspace, denoted, with eigenvaluealong with an anti-symmetric eigenspace, denoted, with an eigenvalue.

If we want to find a state that is invariant under, which in this case corresponds to permuting the order of the qubits, then the state needs to be in the eigenspace of the trivial representation of, this corresponds to the state formed with the basis, as in this basis bothand SWAP both leave the state unchanged,hence the state is permutation invariant. Projections to this subspace is how permutation invariant encodings are performed, as initially suggested inHeredge et al. (2024).

However, while the symmetric space is closed under the action, the application of the unitaries will still change the state. If we have a unitary matrix given by

where. If one applies a Schur transform towhich transforms it into the basis described previously it has been shown that it takes a block diagonal formKirby; Kirby and Strauch (2018)

and the SWAP operator can be written as

The symmetric subspace consists of the upper left block.will transform the state, but keep it within the symmetric subspace. This also means that any variational circuit of the formwill similarly keep the state symmetric. This is the intuition behind geometric QML techniques in which variational layers can be constructed, such asin this case, that preserve the symmetry of the state they act on while still allowing variational parameters to be adjustedMeyer et al. (2022). Although in this work we do not consider creating variational circuits that preserve symmetry, instead we focus on projecting quantum encoded states to irreducible subspaces, which strictly enforces the symmetry invariance in the model as all information in the quantum state is deleted except the portion lying in the chosen irreducible subspace before the training and classification step are considered. It is important to note that the multiplicity of the subspace ofcorresponds to the dimension of the representation ofin that subspace and vice versa.

If we require a state to be rotationally invariant using the encoding previously described, we require that the state lies in the subspace corresponding to the trivial representation of, as under the trivial representation the state will be unchanged by the action. In the case, this would correspond to the basis consisting of a single eigenvector. This is now the trivial representation forbut corresponds to thesignrepresentation in. This means that the state is invariant underbut the SWAP operator changes its sign, hence it is not invariant under permutation. As the dimension and multiplicity of the space is 1, the only normalised state that can exist in this space would be the state. Therefore, any projection onto the antisymmetric space forwould correspond to projection to the state, which would provide rotational invariance, but result in a trivial encoding as all information about the data would be lost. Hence we show that asandcan be simultaneously block diagonalised, that we can perform projections forthat take the state to a space that is the trivial representation ofand is therefore a rotationally invariant state. Note that it would not be possible in this set-up to have a state which is both permutation invariant and rotationally invariant, as they correspond to orthogonal irreducible subspaces.

We also note that if we consider the case where one attempts to create a equivariant variational quantum model that is rotationally invariant in a similar manner to how permutation equivariant models are created in this context, then the variational layer would have to be composed of SWAP gates. These clearly do not have the ability to be parameterised by any variational parameters and therefore it is not possible to create such a variational circuit if strictly following the line of reasoning presented here, although they could be implemented with a different encoding and approach. This highlights a further difference between the rotationally invariant projections proposed here, which enforces symmetry in the state itself, and equivariant VQC models.

SECTION: B.3Rotationally Invariant Encoding for

The case presented fordemonstrated a rotationally invariant projection is possible, but it always corresponds to the stateand hence is deleting all information about the encoded state. The space is technically one-dimensional, but when considering the normalisation condition of quantum states, the projection is effectively to a zero-dimensional space in terms of the information that is retained. Although the motivation for performing these projections is to reduce the dimensionality of the encoding to aid the generalisation ability of the overall model, this is a trivially large reduction in dimensionality which has no use in practice. We should now investigate the irreducible representations offorto find a less trivial example. We would like to find a subspace where forthe dimension of the irreducible representation isand the multiplicity is. This means that the corresponding subspace of, will have dimensionand multiplicity. This would mean thatis still in the trivial representation, meaning the state is unchanged under the action, however it gives a wider range of possible states within this subspace, and hence some information about the encoded state is preserved.

Using the work ofKirby; Kirby and Strauch (2018)we consider the group. In this case the action ofwhen written in the Schur basis is shown in Figure21. Within this decomposition, we can identify that there are two basis elements in the Schur basis that are invariant under the action of. This is the trivial representation ofwhich has dimension equal to 1, but has a multiplicity equal to 2. This correspond to the basis states

and

Due to the Schur-Weyl duality, we know that one of the irreducible subspaces ofwill correspond to the same basis states. However, in this case the multiplicity of the irreducible representation ofwill be 1 and the dimension will equal 2. One can find that by projecting onto therepresentation of(as specified in Table2) using the projection circuit proposed in SectionIV, the quantum input statewill projected onto some state. In this case there are now two basis states that can be used. However, due to the normalisation constraintthe effective dimension is reduced to be equal to 1 overall. This means that at least some information from the original input state is retained when the projection is performed and is therefore a non-trivial example, although effective projection to a-dimensional space may be too great a dimensionality reduction in practice.

In general, if it is possible to calculate the multiplicity of the trivial representation of dimension 1 ofto be, then by Schur-Weyl duality there exists an irreducible subspace ofof dimensionand multiplicity of. Projecting to this subspace will therefore result in reducing the dimensionality of the encoded data to, after considering the normalisation condition. We provide this rotationally invariant encoding as an example to demonstrate how the irreducible subspace projection circuit could be utilised for point cloud data, complementing previous work on permutation invariant encodings of point cloud dataHeredge et al. (2024). It may be the case that this is not feasible or useful forand such investigations could be subject to further research. However, the main motivation was to provide an additional example of how the projection framework could be used to encode symmetry in a model. In general, the irreducible subspace projection framework we introduced can be used for any representation of any finite groupalong with any encoding procedure forand hence there exists ample flexibility for application to a wide array of problems beyond those mentioned as examples in this work.

SECTION: Appendix CPoint Cloud Numeric Details

This section specifies the details of the numerical results reported in SectionIV.4. To generate the data,points were sampled from the surface of a shape, either a sphere or a torus as originally used inHeredge et al. (2024), to create point clouds. The process is repeated with an equal amount of point clouds from each shape until the desired number of total samples is reached. These are split into training sets (80%) and testing sets (20%). We evaluated the performance of the model on the test set and averaged the accuracy in 10 experiments in which a newly generated dataset is used each time. Both the sphere and torus are centred at the origin, with the torus scaled to match the sphere’s average point magnitude. All data is normalised betweenandto be encoded as rotation angles.

To encode a point cloud, each pointis first encoded into a two qubit quantum stateusing two repeated layers of the encoding circuit shown in Figure22. Then the corresponding statevector is found using Qiskitstatevector_simulatorAbraham et al. (2019). From here we can write the entire point cloud as. In order to perform the simulations we then found the projection ofonto each irreducible subspace classically utilising the result specified in Theorem3and the character table for. From here theparameters specified in Equation115are used to produce the correct linear combination of projections and arrive at the partially symmetric subspace amplified state, with the amount of symmetry parameterised by. We then implement a quantum support vector machine classification by calculating the inner product between the data points to form a kernel matrix, which is then input to a classical support vector machine for the final classificationHavlíček et al. (2019); Heredge et al. (2024). We recorded the average test accuracy over 10 experiments for a givenand then repeated with differentvalues and plotted the results to see which value ofis optimal for the data.

SECTION: Appendix DDimensionality Reduction in Pooling Layers

Regarding the average pooling layers implemented in this work in SectionIII, it is crucial to understand that we have confined our operations to averaging quantum states across image translations. Notably, binary addition operates cyclically, where adding 1 to the highest value loops back to the lowest value, meaning our tiling would wrap around the edges of the image to perform the averaging. This may be an undesirable effect, unless the image has some periodic feature. It is also the case that the average pooling described does not provide any dimensionality reduction, as we can calculate the pooling window average for every pixel at no additional computational cost.

To perform the dimensionality reduction, and to prevent the image being treated as periodic, one method could involve deleting any states in whichafter the averaging part of the pooling layer is implemented by implementing

To perform this without any a priori information of the data or architecture, one can define theandoperators alongside two ancilla flag qubits, one for theandflags, respectively.

and

One can now effectively remove unwanted states to reduce the dimensionality by measuring the ancilla warning qubits and disregarding results unlessis measured. This will delete any states in which the average pooling layer will have wrapped around the sides of the image.

Clearly as this is a probabilistic procedure we expect that significantly more efficient implementations are possible depending on the exact specifics of the problem. For example, if it is known that some of the most significant qubits correspond to pixels that should not be used, then they can simply be discarded without needing to implement flag operators and extra ancilla qubits. Implementation of the discarding part of the pooling process will therefore be dependent on the exact requirements of the model, although in the worst-case scenario resorting to usingoperators, as described above, to remove specific states would succeed in reducing the image dimensionality. We refer the reader toWei et al. (2022)for more details on implementing pooling within a full quantum convolutional neural network framework.

SECTION: Appendix ESubtraction Circuit Scaling

The subtraction / decrement operator we consider is controlled by a single ancilla qubit meaning that overall we considerqubits consisting of a total ofmulti-controlled Toffolli gates, with the largest being controlled byqubits, and the amount of controlling qubits decreasing byeach time such that the final gate is a CNOT gate. Fortotal qubits thequbit multi-controlled Toffoli can be decomposed into at worstbasic operationsBarenco et al. (1995), which may be improved if ancillas are usedBaker et al. (2019). Thequbit controlled Toffoli withcan be created bybasic operationsBarenco et al. (1995). As there aregates of this type in total, their overall contribution will be bounded by. Hence, overall we can upper bound the required number of basic operations atto create the basic controlled subtraction gate (Although it has also been suggested linear scaling may be possible for increment/decrement gates using extra ancillasGidney; Khattar and Gidney (2024); Gidney (2018)). Note that as we consider subtraction operators where the subtraction amount doubles each time, this means subsequent subtraction operators can be implemented by ignoring an additional least significant qubit as the subtraction amount doubles. This means that in practise subsequent subtraction operators will use even fewer gates, although we will not include this in our complexity calculation. Asand as we requireoperators in total then overall we requirebasic operations to implement the average pooling.

SECTION: Appendix FDegeneracy Avoidance in Average Pooling

If window lengthwhereis the number of ancilla qubits and controlled operators then we need to change the final subtraction operator value. For example ifthen we would we would generate alloperatorsby using only three controlled unitaries. However if we hadthen we could attempt to implement this usingbut writing this out in full one will see this implements

which correctly has onlyterms, but there is a degeneracy formeaning that it has double weighting and we do not have an equal superposition. This may however be preferable if one wishes to create a general convolutional filter, where in this case the pixel corresponding toin the convolutional filter is supposed to be given a weighting double that of all others.

If one wishes to avoid this degeneracy though, then it can be achieved by avoiding an equal superposition of all ancilla qubits and instead initialising them to avoid repeating terms. In the above example both the ancilla statesandresult in an implementation of. Setting the amplitude of either of these states to zero would remove the degeneracy and correctly implement the average pooling layer again.

SECTION: Appendix GInput Skip Connections Only ResNet

In this section we shall discuss a less general but more qubit efficient implementation of quantum ResNet where the skipped connection is not between each layer, but only between the input and every other layer in the circuit (until immediately before the final layer).

It is possible to probabilistically implement a quantum ResNet that only includes skipped connections between the input and every other layer by utilising the LCU method within a quantum variational model. In this context, the implementation of a Quantum Native ResNet forlayers is defined as the implementation of the operator

wherecorresponds to a unitary variational gate implemented in layerandis a normalisation constant. The coefficientscorrespond to the desired weighting contribution for each layer and can be freely adjusted subject to the requirement that.

The preparation operator can be implemented onancilla qubits as a unitary operator

where the statesare basis states of thedimensional Hilbert space for thequbit ancilla register denoted by. This is usually taken to be the computational basis with. We are only concerned with theterm, as that operator is only applied tosuch that

subject to the condition that. Subsequently, the selection operator can be applied as

whereis a product of unitary operatorsand hence clearly implementable on a quantum circuit. Applying the LCU framework we can see that

We can apply the conjugate preparation operator which in general can be written as

to find that

The next step is to measure the ancilla qubits and discard results when the ancilla is not in thestate, hence we can ignore termsfor. The probabilityof measuring the ancillas in thestate corresponds to

and will hence be dependent on the architecture and initial data encoding. Requiring the ancillas to be in thestate we see that

where, as required.
∎

This LCU method will successfully prepare the desired residual network. Hence we have shown that VQC models can be built with skipped connections under the quantum ResNet framework by utilising the LCU method to implement these non-unitary operations. An example circuit implementation for the four-layer caseis shown in Figure23. Notably, this method is more qubit efficient requiringqubits forlayers, as opposed toqubits in the previous case.

In terms of the probabilistic scaling we see

Hence, the probability of success depends on the encoding stateand the variational layers, but can also be adjusted through the strength of the residual connection using theparameters.

SECTION: G.1Two Gate Input Worked Example

In this section we give a brief worked example for the two-layer case of our LCU quantum ResNet with equal weightings.

Consider the encoded quantum state aswhich will be evolved by the first layer of a variational circuitresulting in the state.

If we wish to introduce a quantum ResNet type skipped connection between the input to the first layer then one realisation of this would be implementing the evolution

In general, this is not a unitary operation. However, the desired ResNet skipped connection can indeed be written as a linear combination of unitary operations

This can be implemented using the LCU method by definingequal to the Hadamard gate such that

and

After applying theandoperators and measuring the ancilla qubit to be in thestate, then the appropriatecan be prepared. We show this explicitly through each step for clarity starting with the preparation operator

applying the selection operator

applying the inverse preparation operator, which is a Hadamard gate we find

measuring the ancilla and requiring it to be in thestate gives

which is probabilistically prepared with a probability equal to

Note that the important part of the probability scaling is the real component of. In the case thatthen success is guaranteed, and in the casethen success is impossible. For generalmatrices and statesthen the success will vary. It may therefore in practice be worth placing restrictions onto ensure thatdoes not approach too close to -1 resulting in extremely low success probabilities. However, as mentioned in the main text, if the strength of the residual connections are adjusted it can be possible to increase the lower bound. This example used equal strength in the residual connections for simplicity, which corresponds to the worst-case lower bound.

SECTION: References