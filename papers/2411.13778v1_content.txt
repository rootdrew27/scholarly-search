SECTION: A Survey on Adversarial Robustness of LiDAR-based Machine Learning Perception in Autonomous Vehicles

In autonomous driving, the combination of AI and vehicular technology offers great potential. However, this amalgamation comes with vulnerabilities to adversarial attacks. This survey focuses on the intersection of Adversarial Machine Learning (AML) and autonomous systems, with a specific focus on LiDAR-based systems. We comprehensively explore the threat landscape, encompassing cyber-attacks on sensors and adversarial perturbations. Additionally, we investigate defensive strategies employed in countering these threats. This paper endeavors to present a concise overview of the challenges and advances in securing autonomous driving systems against adversarial threats, emphasizing the need for robust defenses to ensure safety and security.

SECTION: IIntroduction

In the field of autonomous driving systems, the combination of Artificial Intelligence (AI) and vehicular technology has opened new possibilities. These advanced systems enable unmanned vehicles, including drones and other autonomous platforms, to not only perceive their surroundings but also make real-time decisions while navigating complex traffic scenarios. With the potential to revolutionize various sectors, autonomous systems promise heightened safety, streamlined logistics, and the capacity for multitude of beneficial operations.

However, beneath the promise of seamless automation lies a significant challenge: the vulnerability of these systems to adversarial attacks, which encompass a wide range of techniques, including those that share characteristics with Adversarial Machine Learning (AML) attacks. AML attacks, designed to manipulate machine learning models, typically involve the introduction of carefully crafted perturbations or alterations to input data. However, it is important to note that perturbing inputs represent just one facet of AML attacks[1]. The diverse AML landscape includes other techniques like backdoor data poisoning[2], where an adversary can inject a small number of poisoned samples with a backdoor trigger into the training data. When activated during deployment, these triggers manipulate the machine learning (ML) model. These alterations may be imperceptible to humans but can significantly disrupt the operation of the ML system, potentially causing malfunction.

The shared characteristics between adversarial threats and AML attacks include the ability to add noise or manipulate minor parts of inputs in ways unrecognizable by humans, with the ultimate target being the ML system, leading to its malfunction. By exploiting vulnerabilities in the system, adversarial attacks aim to create inputs that appear legitimate but are subtly altered to trick the system. This survey paper sets out to explore the intersection of adversarial attacks from an AML perspective and ML-based autonomous driving, addressing a significant subject in this domain.

The autonomous driving systems are categorized into six levels by the Society of Automotive Engineers[3], ranging from Level 0 indicating no automation to Level 5 representing complete automation, as illustrated in Figure1. While Level 5 automation is yet to be achieved, ongoing testing efforts are underway[4]. Legal constraints in numerous countries also limit the testing and deployment of Autonomous Vehicles (AV).

As we progress beyond Level 2 automation, the reliance on sensors like LiDAR (Light Detection and Ranging) radar, and cameras, coupled with machine learning algorithms becomes crucial[5]. Specifically, LiDAR’s capability for precise distance measurements and high-resolution 3D mapping capabilities plays a vital role in improving environmental perception and situational awareness[6,7,8,9,10]. Over the last decade, LiDAR has become the most popular AV sensor as it enhances various aspects of autonomous systems, including obstacle detection, mapping, localization, and object recognition. Moreover, LiDAR-based autonomous systems are expected to have a significant impact on the Defence industry, promising efficiency and security in challenging terrains. Figure2illustrates the pipeline of AV systems with sensors and the ML system, and potential points of attack.

However, like any technology, ML-based LiDAR systems are not immune to vulnerabilities. Various attacks are possible, and our survey paper first concentrates on adversarial attacks, specifically traditional AML attacks and certain cyber-attacks on sensors that can cause malfunctions in ML-based perception modules. Attackers can employ AML techniques or cyber-attack methods to deceive or manipulate the perception systems of autonomous devices. These attacks can disrupt sensor inputs, potentially resulting in incorrect decisions and compromising safety and security. Subsequently, we proceed to investigate the theoretical aspects of defensive techniques against these adversarial attacks and analyze their limitations.

This survey paper addresses the gap in the existing literature by providing a comprehensive overview of ML approaches, adversarial attacks, and defenses specifically applicable to LiDAR-based systems in the context of autonomous driving. While some existing survey papers explored ML in autonomous driving[11,12,13,14], they have primarily concentrated on ML functionality from a performance perspective, neglecting the importance of ensuring the robustness of the ML system against AML attacks or cyber-attacks on sensors targeting ML systems. In addition, unlike previous surveys that often focus on limited aspects of AML attacks, such as image spaces or specific attack methods[15]and/or defenses[12]without in-depth analysis of their limitations, our survey takes a broader approach, encompassing the diverse spectrum of adversary threats and defenses in LiDAR-based perception systems. Moreover, our survey places a significant emphasis on identifying and analyzing the limitations of existing AML defense strategies in this domain. To achieve this, we begin with a literature review, examining 3D LiDAR sensory data and Machine Learning (ML) approaches in autonomous driving. By analyzing the current state of research on adversarial attacks, we aim to identify research gaps, emerging trends, and advancements in securing autonomous driving systems against adversarial threats.

Our survey aims to make significant contributions to the field:

A Survey of 3D LiDAR-Based Machine Learning Models: Our survey paper investigates 3D LiDAR-based machine learning models in the context of autonomous driving, with a specific emphasis on widely recognized and highly cited models. By summarizing these prominent models in existing research, we provide readers with a clear overview of the state-of-the-art in this crucial area.

Analyzing Adversarial Attacks and Defensive Strategies in 3D Autonomous Driving Systems: A central objective of our survey paper is to shed light on the evolving threat landscape facing autonomous driving systems. AML attacks and cyber-attacks present a significant challenge, potentially compromising the safety and security of these systems. Consequently, we conduct a comprehensive analysis of existing AML attacks and cyber-attacks tailored to the realm of 3D autonomous driving, as well as explore and analyze defensive strategies to mitigate these threats.

Our survey covers a range of attacks, including cyber-attacks on sensors such as sensor spoofing, as well as physical attacks, and adversarial perturbations. We not only explain the methodologies behind these attacks but also explore potential defensive strategies and countermeasures. It is worth noting that existing defensive strategies often fall short of providing effective countermeasures. This paper highlights significant gaps in current research on autonomous system resilience against adversarial threats.

SECTION: IIAutonomous Vehicle (AV) System

The processing pipeline of an AV system, depicted in Figure2, comprises several stages that work together to enable the vehicle to operate autonomously. This pipeline includes sensors, preprocessing such as data pre-processing and sensor fusion, and ML modules like perception, decision-making, path planning, and control systems.

Sensors, such as cameras, LiDAR, GPS devices, etc., collect raw data from the environment. These sensors capture and relay information about the AV’s surroundings in which the AV operates, including road infrastructure, traffic dynamics, environmental conditions, etc. for the AV’s process. In this survey, we focus on AV systems using LiDAR sensors since LiDAR sensors offer a significant advantage over other sensors, such as radars and cameras, due to their higher resolution and precision. Additionally, LiDAR proves to be versatile, performing reliably under both daytime and night-time conditions[16,17].

Sensor data including LiDAR point cloud data requires pre-processing before being supplied to the ML algorithms. Data preprocessing plays a crucial role in preparing and refining the raw sensor data for further analysis. It involves data cleaning, filtering, and feature extraction, ensuring that the data input to the subsequent ML stages is of high quality and relevance. Sensor fusion, another vital part of pre-processing, combines data from multiple sensors to enhance perception accuracy. This fusion process is not necessary if the system has a single sensor.

The ML component of the pipeline interprets and extracts meaningful insights from the pre-processed and fused sensor data. This step involves a range of tasks, including perception, decision-making, and route planning. The ML algorithms are central to providing an autonomous driving capability.

The perception module is responsible for sensing and comprehending the vehicle’s environment. It processes data from an array of sensors, including LiDAR, cameras, GPS, and others, enabling the recognition of objects, identification of road features, and a holistic understanding of the environment. ML algorithms, specifically designed for object detection, semantic segmentation, object tracking, and scene comprehension, are integrated within this module. They work together to interpret sensor data, extract meaningful information, and create a representation of the environment that the AV can use for navigation.

Once the perception system has gathered and processed sensor data, the next key step is decision-making. This module is dedicated to making important decisions on how to interact with the environment, based on the perceived environment. Here, the ML algorithm determines the vehicle’s actions, including lane changes, yielding to other road users, and managing emergency scenarios. It heavily relies on the insights gained from the perception and ML components.

Path planning forms another integral part of the pipeline. It leverages map data and desired trajectory information to chart the optimal route for the AV. This component guides how the AV navigates from its current location to its destination, ensuring safe and efficient travel.

Finally, the control system executes the actions defined by the decision-making and path-planning stages. It manages the physical aspects of the AV, including steering control and velocity management, to enact the planned route accurately.

Throughout this intricate pipeline, there are various potential points of weakness, primarily at the interfaces between components and in communication with external entities. The ML perception typically handles the sensor data directly and processes it to understand the vehicle’s surroundings. On the other hand, ML decision-making or planning does not typically deal directly with sensor data but relies on the processed information from the perception module to make decisions about how the vehicle should act. Thus, from an adversarial attack perspective, the ML perception module is exposed to potential attacks, as it directly interfaces with sensor inputs. Adversarial attacks on the perception module can manipulate the way the vehicle perceives its environment, potentially causing it to make incorrect or dangerous decisions. The ML decision-making module or planning module relies on the accuracy of the perception data, so it can indirectly be affected by attacks on the perception module. We describe ML-targeted attacks in SectionIII-B. In addition, AVs often communicate with other vehicles and infrastructure through communication systems. These communication channels can be vulnerable to attacks such as typical cyber-attacks or cyber-attacks on sensors described in SectionIII-A. Adversaries can send false data, manipulate data, or disrupt legitimate communication between vehicles, potentially causing accidents or traffic congestion. Therefore, robust security measures and vigilant oversight over the AV system are essential for protecting the AV against potential adversarial threats, ensuring the reliability and safety of autonomous driving technology.

In this survey, our primary focus is the robustness of LiDAR-based autonomous driving systems. The LiDAR system generates data that reveals the presence of obstacles in the environment and the vehicle’s relative position to these obstacles. This data offers insights into the contours of roads, nearby infrastructure, and vegetation. In the following subsection, we investigate the LiDAR system, the characteristics of LiDAR data, and the machine learning approaches applied to analyze this data. We then provide a literature survey regarding the ML perception modules that are related to the robustness of AV systems.

SECTION: II-ALiDAR System

In a typical LiDAR system, a laser emits infrared light pulses at various angles onto target objects. The LiDAR sensor subsequently detects and processes the reflected echoes, creating a 3D point cloud. Each point in the cloud is represented by a 3-dimensional vector (x, y, z), providing spatial coordinates within the LiDAR coordinate system. Additional features like color or intensity can be integrated if needed. This point cloud is a fundamental element that can be further processed and analyzed for a wide array of applications, including environment and object perception, localization, and object recognition.

LiDAR, however, has limitations. It requires a direct line of sight of objects and may face challenges in environments with obstacles or occlusions[18,9]. A LiDAR can only see objects that reflect its signal. If the signal does not return, whether due to absorption, transparent materials, or reaching its range limits, LiDAR interprets it as an absence of objects. Reflective surfaces may introduce data inaccuracies or false readings in LiDAR measurements. Furthermore, adverse weather conditions such as heavy rain, fog, or snow can disrupt LiDAR data collection, diminishing its reliability under unfavorable weather conditions.

The inherent nature of LiDAR point cloud data is characterized by its sparsity and lack of structure, rendering the processing of LiDAR data a challenging endeavor. Primary tasks associated with point cloud data encompass 3D object detection, semantic/instance segmentation, motion prediction, multiple object tracking, localization, object detection and classification, scene segmentation, and scene understanding. Object detection systems, exemplified by PointPillars[19], VoxelNet[20], or SECOND[21], operate by taking a 3D point cloud as input and subsequently generating bounding boxes around objects within the environment. This functionality provides spatial awareness and enables AVs to make informed navigation and control decisions.

The processing of LiDAR point clouds necessitates the deployment of state-of-the-art models that heavily utilize Deep Neural Network (DNN) architectures. These DNNs, while powerful, are susceptible to adversarial attacks. This vulnerability is particularly pronounced in the perception component of ML models utilized in autonomous driving. Sensitivity to input variations makes these models vulnerable to adversarial perturbations, compromising their ability to accurately detect, segment, or map objects. These incorrect perceptions can then lead to erroneous decisions in the downstream decision-making component of the autonomous system. For example, the injection of a false object may lead to ML decision to apply emergency brake operations that may injure passengers, resulting in severe safety consequences.

SECTION: II-BLiDAR Point Cloud

Three-dimensional LiDAR provides high-resolution point clouds with accurate representations of the length, width, and height of objects, offering a comprehensive view of the environment. However, 3D LiDAR generates a substantial amount of data per scan due to its detailed output. The extraction and interpretation of geometric details from 3D range data are notably more intricate in comparison to 2D data. Moreover, 3D laser data introduces an additional complication as the lower layers of the scanner frequently capture ground or floor surfaces, further adding to the complexity of data analysis.

Reliable perception of the surrounding environment is typically achieved through two subtasks: simultaneous localization and mapping (SLAM) and detection and tracking of moving objects (DATMO)[22]. SLAM aims to create a map comprising static elements of the environment, providing the vehicle with knowledge of its surroundings. On the other hand, DATMO utilizes this map to detect and track dynamic objects in real-time.

Point clouds are characterized by several properties that make them challenging to work with:

Massive: Point clouds can be massive, especially when representing complex scenes or large environments. Each point in the point cloud requires storage for its 3D coordinates and potentially additional features like color or intensity.

Noise: Point clouds often contain noise, which refers to unwanted or random variations in the measured point coordinates or features. Noise can be caused by numerous factors, such as sensor inaccuracies, environmental conditions, or reflections.

Incomplete: In real-world scenarios, it is challenging to obtain complete and perfectly sampled point clouds. Incomplete point clouds arise when some parts of the 3D scene are occluded, not captured by the sensor, or simply missing due to limitations in data acquisition.

Irregular: Point clouds are considered irregular because there is no predefined structure or grid-like organization to the points. Unlike images, which have a fixed grid of pixels, points in a point cloud can be distributed arbitrarily in 3D space.

Unstructured: Point clouds lack inherent connectivity or spatial relationships between points. Each point is independent, with no knowledge of its neighbors or their arrangement. They are collected from laser reflections off surfaces, without a predefined pattern like images.

Unordered: The order of points in a point cloud is arbitrary, and there is no predefined sequence or arrangement. Different scans or data acquisition processes can result in different orderings of the points in the point cloud.

Sparse: Although LiDAR provides accurate distance measurements, the point clouds are sparse and have non-uniform densities across the scene. This sparsity is a result of factors such as the sensor’s range, resolution settings, and the geometry of the environment being scanned. It means that there are fewer points available to accurately capture the nuances of the environment, making it harder for ML algorithms to accurately understand and navigate their surroundings.

These properties make point cloud processing a challenge in the field of computer vision and 3D data analysis. Specialized algorithms and deep learning architectures, such as PointNet[23], have been developed to handle these properties and extract meaningful information.

SECTION: II-CMachine Learning for LiDAR Data

The primary focus of this paper is on the ML perception module, which is considered a central point of vulnerability due to its pivotal role in comprehending the environment. While decision-making is also a significant concern, it typically relies on the information processed by the perception module to guide the vehicle’s actions. Furthermore, communication vulnerabilities, while important, may have different implications, as they can impact the ML perception modules. Therefore, we prioritize our focus on ML perception, as it is directly impacted by adversarial threats.

As introduced earlier, 3D point cloud data holds a significant role in autonomous driving, serving as a vital component within the perception systems of self-driving vehicles. Processing LiDAR data can be challenging due to the characteristics of point clouds outlined in SectionII-B. Traditional deep learning techniques, such as Convolutional Neural Networks (CNNs), have primarily been designed to work with data organized on structured grids, like 2D images (composed of pixels) or 3D volumes (represented as voxels). In such grid-based structures, adjacent data points have well-defined relationships, enabling efficient application of convolutional operations. In contrast, point clouds possess inherent structural irregularity. They consist of individual points scattered throughout 3D space, lacking any predefined grid or regular arrangement. Notably, LiDAR-generated point clouds are less susceptible to adversarial attacks compared to images[24,25,26], making it more challenging to launch attacks on LiDAR-based AVs. Nevertheless, it is important to recognize that, while challenging, such attacks are not impossible and there has been a recent increase in their prevalence and sophistication as discussed in SectionIII.

There have been several survey papers on deep learning approaches using 3D LiDAR data[11,27,12,13,14]. In this section, we highlight the most popular approaches commonly targeted for AML attacks. We explore a range of popular deep learning models that differ in their approaches, especially regarding feature extraction, which is a principal factor in processing 3D point clouds.

PointNet[23]is a pioneering deep learning model that addresses the challenge of processing irregular and unstructured 3D point cloud data. PointNet’s main goal is to extract meaningful features and patterns from these point sets without relying on any predefined order or connectivity. It achieves this by utilizing continuous symmetric functions, approximated through shared Multi-Layer Perceptrons (MLPs), to process the 3D coordinates and additional features, such as colors, of each point independently. As a result, PointNet exhibits permutation invariance, enabling it to handle point clouds regardless of the order in which points are presented. Additionally, PointNet generates embeddings for each point within a point cloud, and these embeddings undergo transformation and aggregation to ensure invariance to geometric transformations, such as rotations or translations. This property ensures that the classification results remain unaffected by rotations of the input point clouds.

PointNet++[28]is an extension of PointNet that introduces a hierarchical feature learning approach. It organizes the points into nested sets and processes them hierarchically, enabling the model to capture both local patterns and global context in the point cloud data. PointNet++ is specifically designed for point set segmentation tasks. It achieves this by subsampling the point cloud into overlapping regions (query points) and processing each region using a ’Set Abstraction Layer’ to extract local features. These features are then interpolated and propagated back to the original points to capture global contextual information.

PointNet and PointNet++ serve as foundational architectures for processing raw 3D point cloud data directly. PointNet-based models are commonly employed in tasks such as object detection, segmentation, and scene understanding. Frustum PointNet[29]extends the PointNet architecture to fuse LiDAR and camera data for increased perception reliability. The Frustum PointNet approach begins by creating 3D bounding boxes called frustums around objects initially detected in 2D images. These frustums define regions of interest within the 3D point cloud data. Subsequently, PointNet is applied to process the point cloud data within these frustums, enabling tasks such as object detection and localization in 3D space. Similar to Frustum PointNet, Frustum ConvNet[30]uses PointNet operations at lower layers of its network architecture. However, Frustum ConvNet employs convolutional layers as part of its architecture, for capturing spatial relationships and aggregating local features, whereas Frustum PointNet relies on fully connected layers. At these lower layers, Frustum ConvNet may share similarities with Frustum PointNet in terms of processing individual points within frustums using shared MLPs. Frustum ConvNet extends beyond this by incorporating convolutional layers, which enable it to capture spatial relationships and context more effectively.

Voxel grids are used to convert point clouds into a 3D grid format, making it easier to apply 3D convolutions. VoxelNet[20]is a deep learning model that leverages 3D voxel grids to represent 3D data. It introduces a 3D detection network tailored for precise object detection in sparse LiDAR point clouds. The approach involves partitioning the point cloud into uniformly spaced 3D voxels, a random selection of a fixed number of points from each voxel, and utilizing a voxel feature encoding layer to construct a comprehensive volumetric representation. VoxelNet unifies the tasks of feature extraction and bounding box prediction within a single, end-to-end trainable deep network, eliminating the necessity for manual feature engineering. In 3D object detection workflows, PointNet can be utilized as a feature extractor to process individual points within the voxels generated by VoxelNet. This facilitates more detailed feature extraction at the point level within each voxel. It is important to note that PointNet is not an intrinsic component of the VoxelNet architecture; its integration depends on the specific implementation. Furthermore, VoxelNet organizes point cloud data into a 3D voxel grid, effectively establishing a Bird’s-Eye View (BEV) representation, which is particularly advantageous for object detection tasks.

SECOND[21]introduced sparsity-aware convolutional layers, which make it efficient in handling sparse LiDAR data without the need for voxelization. LiDAR sensors often produce sparse point cloud data, meaning that some regions may have no data points at all, and others may have varying point densities. SECOND employs sparsity-aware convolutional layers, which are specialized for processing sparse data efficiently. Instead of applying convolution operations to all points uniformly, they adaptively select and process only the relevant points, effectively ignoring empty regions with no points. In addition, when processing a point in a sparse region, the sparsity-aware layers consider their local neighborhood of points. This neighborhood may vary in size and shape depending on the point distribution. The layers extract features from this dynamic neighborhood.

PointPillars[19]initially transforms the original point cloud data into a top-down, 2D BEV representation of the 3D environment. This 2D perspective is further analyzed and feature extraction is performed using 2D convolutional layers. The BEV representation is then subdivided into a grid composed of ”pillar-like structures”. These pillar-like structures are essentially the grid cells used to organize the 3D point cloud data in the BEV representation. Within each of these pillars, PointPillars utilizes 2D convolutional layers to process the points and extract features. PointPillars operates in real-time for object detection, allowing it to predict object candidates belonging to multiple classes. It provides estimations of their 3D-oriented bounding boxes and associated class confidence values.

PIXOR[31]is another 3D object detection architecture that also has its feature extraction approach tailored to the task. PIXOR operates on 2D camera images, specifically focusing on LiDAR-camera fusion for 3D object detection from BEV. The model utilizes a 3D occupancy grid representation with accumulated reflectance and employs a classification heat map and regression features for object localization. The BEV representation is preferred due to its accuracy and avoidance of object overlap, enhancing computational efficiency. The top-down perspective in BEV eliminates depth ambiguity ensuring clear separation of objects at different distances. PIXOR is one of the fastest LiDAR object detection models and is further improved in PIXOR++[32].

PointRCNN[33]is an approach in 3D object detection compared to previously mentioned methods like PointNet, VoxelNet, PointPillars, and PIXOR, in terms of its feature extraction and overall approach. Unlike traditional CNNs designed for structured grids, PointRCNN operates directly on unstructured point cloud data, allowing it to capture intricate spatial information for precise object detection in 3D scenes. PointRCNN introduces a two-stage detection framework that first generates region proposals using a ‘Region Proposal Network’ and then refines these proposals using 3D CNNs. The proposals are often represented in a BEV for object detection. Both PointRCNN and PointNet are capable of directly handling unstructured 3D point cloud data, but PointRCNN is specifically designed for accurate 3D object detection and localization tasks, while PointNet is for a broader range of tasks beyond object detection, including segmentation, classification, and scene understanding due to the strengths of its permutation and transformation invariance.

MotionNet[34]presents a distinctive approach to motion prediction using 3D point cloud data. It achieves this by converting 3D point clouds into BEV maps, streamlining subsequent computations. The model encompasses various features, including the ability to generalize to unseen objects, integration of temporal information, the capture of multi-scale spatio-temporal features, etc. MotionNet’s architecture relies on standard 2D and pseudo-1D convolutions, rendering it well-suited for real-time operations in autonomous driving scenarios. However, its performance may exhibit variability based on the specific application.

Some studies focus on the fusion of multiple sensors with LiDAR. Ku et al.[35]introduce an approach for 3D object detection that can jointly generate 3D object proposals and perform object detection by aggregating information from multiple views or camera angles. This multi-view approach is designed to enhance the accuracy and robustness of 3D object detection, especially in situations where objects might be partially hidden or obstructed when viewed from a single perspective. EPNet[36]is also a system that combines information from 3D data sources with image data to enhance object detection capabilities. It integrates image semantics to provide additional context and information, which in turn improves the accuracy of object detection.

In addition to the above-mentioned approaches, various other deep learning approaches, including those proposed by Huang et al.[37]and Priya and Pankaj[38], have been developed to process 3D LiDAR point cloud data. Given the inherent vulnerabilities in deep learning, it is necessary to prioritize efforts aimed at identifying relevant adversarial attacks and defenses. In the following section, we will explore adversarial attacks.

SECTION: IIIAttacks

In the realm of computer science, an ‘adversary’ refers to those attempting unauthorized access or corruption of a network. Originating in 2004 for anti-spam filter robustness[39], adversarial machine learning has evolved to challenge the security of ML models. Autonomous vehicles, heavily reliant on a diverse network of sensors, including LiDAR, radar, cameras, and GPS, leverage advanced ML algorithms for processing multi-modal inputs. These algorithms play a pivotal role in environment perception and vital operational decisions. While sensors are traditionally deemed trusted components in AV control systems, any compromise to their integrity, resulting in falsified readings, introduces significant risks to both vehicle safety and security. These risks stem from a two-fold vulnerability: both sensors and ML algorithms are susceptible to adversarial attacks.

Sensors: The sensors themselves are susceptible to a range of conventional cyber-attacks, including authentication breaches, Denial-of-Service (DoS), jamming attempts, or even direct physical attacks[40,41,42,43]. Alongside these established threats, malicious actors can exploit these vulnerabilities by targeting the AV communication channel to execute various deception attacks, such as Sybil, spoofing, or replay attacks as elaborated in SectionIII-A. These deceptive tactics can result in the manipulation or corruption of sensor data, leading to erroneous perceptions and decisions by the autonomous vehicle.

ML Algorithms: Beyond sensor vulnerabilities, AVs face a distinct susceptibility to adversarial targeting in the realm of ML models. Attackers can exploit weaknesses in these algorithms, deceiving vehicles into making unsafe decisions. Such manipulations may include subtle alterations to the training data, injection of backdoor triggers, or the introduction of carefully crafted adversarial perturbations into the sensory inputs, challenging the ML model’s recognition capabilities. Notably, these perturbations do not alter the semantic meaning of the scene but wield a transformative influence on the ML model’s output. SectionIII-Bprovides a comprehensive exploration of adversarial attacks on ML algorithms.

In the context of LiDAR based AVs, attacks by adversaries encompass a range of tactics. These tactics include adversarial manipulation in the image domain, along with attacks involving manipulation of sensor inputs, introduction of fabricated data, or repetition of attacks, among other strategies. The overarching objective is to exploit weaknesses in the underlying ML algorithms, ultimately deceiving the vehicle’s perception and potentially influencing its driving decisions for malicious purposes.

SECTION: III-AAttacks on Sensors

LiDAR sensor systems are susceptible to attacks that can compromise their integrity, availability, and accuracy[44,45,46]. These attacks intend to mislead autonomous systems by altering data from LiDAR sensors, which can result in incorrect perceptions and unsafe decisions by autonomous vehicles.

Attackers can accomplish this by emitting deceptive signals to manipulate distance measurements or introducing false objects to the LiDAR perception system. We focus on the cyber-attacks aiming to disrupt or manipulate the LiDAR readings which eventually lead to disrupting the ML decision making. Since sensors are typically considered trusted components in an AV’s control system, falsified readings could lead to unforeseen consequences if the sensors are compromised.

Sensor attacks typically occur within the vehicle’s communication channel and have the potential to manipulate LiDAR sensor data in several ways, such as creating fake objects (Sybil attacks), injecting malicious points in LiDAR data (Spoofing attacks), or even replaying outdated point clouds (Replay attacks) to deceive the AV system.

Spoofing, a form of masquerading attack, severely impacts the trustworthiness of LiDAR systems. In spoofing attacks, a spoofing device emits laser pulses toward the victim LiDAR, which disrupts the timing of the laser reception events and consequently, alters the calculated 3D positions of objects. This manipulation results in the creation of ‘spoofed points’ within the LiDAR’s point cloud. These spoofed points can lead to object misdetection by the downstream object detector. For instance, the attack can relocate points originally associated with an object[47]or even render the object undetectable[48]. Alternatively, spoofed points clustered together can falsely trigger the detection of a non-existent object[49]. Spoofing attacks can be synchronized or asynchronized. The synchronized attacks require precise knowledge of the victim LiDAR’s scanning pattern beforehand to synchronize the malicious laser firing timing[50,51]. Asynchronized attacks do not need such knowledge and thus are more deployable[47,52].

Petit et al.[47]highlighted how attackers can manipulate a LiDAR system through an asynchronous attack, relaying laser signals from a different location to generate fake data points that appear farther away than their actual positions. Building on this, Shin et al.[52]further illustrated the potential to inject false data points, creating illusions that seem closer to the location of a spoofed device. These attacks distort perception and can disable the LiDAR’s ability to sense specific directions. The authors proposed a blinding attack wherein the LiDAR is exposed to an intense light source with the same wavelength as the LiDAR. As a result, the LiDAR failed to perceive objects from the direction of the light source. Additionally, Park et al.[53]demonstrated spoofing attacks on infrared sensors used in medical infusion pumps, resulting in the manipulation of medicine dosage.

Sato et al.[54]demonstrated an improved LiDAR spoofing capability tailored for contemporary LiDAR systems. The key idea is to fire many attack laser pulses at a higher frequency than the victim LiDAR’s laser-firing frequency to achieve the spoofing effect for every point in the scanning range. The attack’s effectiveness depends on the high frequency of the attack laser pulses.

Replay attacks have been extensively studied in the fields of estimation and control[55,40,56]. In a replay attack, a message is recorded and subsequently played back at a different time with malicious intent. The specific objective in the context of LiDAR systems is to mislead the perception system, causing a miscalculation of the target’s time and position[47,57]. For instance, a vehicle in front of the victim AV is moving forward at a speed of 110 km/h. The attacker captures the LiDAR data from the victim AV and stores it for later use. When the leading vehicle slows down, the adversary injects the old LiDAR data into the system periodically. The victim AV still believes that the leading vehicle is traveling at 110 km/h and may not decelerate appropriately, potentially causing an accident.

In a study by Stottelaar[58], a LiDAR replay attack was demonstrated wherein signals were recorded for later insertion of malware, which could lead to false detections of non-existent objects. Consequently, the vehicle’s control unit might erroneously perceive a significant obstacle and initiate an abrupt stop. Similarly, Petit et al.[47]employed a method where they captured, delayed, and then replayed the LiDAR signal, causing the LiDAR sensor to produce inaccurate measurements.

Traditionally employed in peer-to-peer networks, sensor networks, and vehicular ad hoc networks (VANET), Sybil attacks are now being extended for multimodal interconnected sensors and communication technologies within AV systems[59,60,61,15]. The term ‘Sybil attack’ originates from the book Sybil, which narrates the experiences of an individual diagnosed with dissociative identity disorder[62]. In a Sybil attack, adversaries exploit the vehicle communication infrastructure to generate and advertise multiple fake identities (Sybil nodes), disrupting the environmental perception of victim AVs[62]. This falsified information attack can be orchestrated through a malicious vehicle or without the involvement of an actual vehicle. The fake identities, whether stolen from inactive nodes or newly fabricated, can pose as non-existing objects or fake vehicles, violating the assumption of accurate traffic perception by AV sensors[63]. This subversion compromises object detection and tracking, leading to navigation errors and potential traffic chaos, particularly among LiDAR-based AVs[64]. For instance, an attacker can use Sybil nodes to issue false warnings, creating a fabricated traffic jam or road incidents, influencing victim AVs to alter their routes, while false object signatures exacerbate confusion for the LiDAR sensors. More advanced Sybil attacks can involve spoofing other sensors like GPS and LiDAR, potentially leading to disastrous traffic incidents[65]. Furthermore, Sybil nodes can disrupt LiDAR sensors via DoS attacks, overloading communication channels and compromising accurate surrounding detection and mapping.

LiDAR generates a point cloud frame of its surroundings, offering data on nearby objects, such as their distances and angles from the vehicle. In context of Sybil attacks, if fake objects are introduced into the surroundings, LiDAR will feed this misinformation into the backend ML algorithm, leading to confused or wrong perceptions of the environment. This misinformation may trigger the AV system to indicate traffic congestion, resulting in unnecessary slowdowns. In interconnected vehicle environments, it may force other vehicles to change their routing decisions, avoiding falsely congested or targeted areas. Discrepancies may arise if data from other sensors, such as GPS, radar, and cameras, do not align with the LiDAR-generated information. Lim et al.[66]conducted experiments on Sybil attacks in VANETs using multiple sensor sources, including LiDAR. They also proposed defenses as discussed in SectionIV-A.

It is important to note that Velodyne VLP-16 has been the standard choice for LiDAR robustness evaluation in most research. Studies have either exclusively assessed their attacks on the VLP-16 or used its attack susceptibility to validate their threat models. Sato et al.[54]have argued through their experiments that sensor attacks relevant to VLP-16 may not necessarily apply to more recent LiDAR systems referred to as ”next-generation” LiDARs[67]. The next-generation LiDARs incorporate advanced security features, including laser timing randomization and pulse fingerprinting. While prior works[52,50,48]have mentioned these features as potential defenses, none have thoroughly assessed their effectiveness against Sybil, spoofing, or replay attacks. By randomizing the timing of laser pulses, it becomes exceedingly difficult for an attacker to predict when a pulse will be emitted. This unpredictability disrupts the attacker’s ability to synchronize their malicious signals with the LiDAR system’s emissions, rendering pre-calibrated attack timings obsolete. Interestingly, we find that the attacker may still be able to inject some points if the randomization is not strong enough. Pulse fingerprinting assigns unique signatures to laser pulses, enabling the LiDAR system to authenticate data and prevent replay attacks. Digital signatures also offer authentication and non-repudiation for laser pulses. Using a nonce in laser beacons, generated uniquely each time, thwarts replay attacks by making intercepted data unusable in subsequent communications.

SECTION: III-BAttacks on ML

This section explores studies on attacks targeting ML models behind LiDAR-based perception and decision-making processes, aiming to understand the strategies employed by malicious actors and potential countermeasures in SectionIV. We also delve into the complex landscape of multi-modal attacks, which introduce a new layer of security challenges for autonomous vehicles equipped with diverse sensor modalities.