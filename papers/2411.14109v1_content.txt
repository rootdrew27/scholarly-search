SECTION: Global and Local Attention-Based Transformer for Hyperspectral Image Change Detection

Recently Transformer-based hyperspectral image (HSI) change detection methods have shown remarkable performance. Nevertheless, existing attention mechanisms in Transformers have limitations in local feature representation. To address this issue, we proposeGlobal andLocalAttention-based Transformer(GLAFormer), which incorporates a global and local attention module (GLAM) to combine high-frequency and low-frequency signals. Furthermore, we introduce a cross-gating mechanism, called cross-gated feed-forward network (CGFN), to emphasize salient features and suppress noise interference. Specifically, the GLAM splits attention heads into global and local attention components to capture comprehensive spatial-spectral features. The global attention component employs global attention on downsampled feature maps to capture low-frequency information, while the local attention component focuses on high-frequency details using non-overlapping window-based local attention. The CGFN enhances the feature representation via convolutions and cross-gating mechanism in parallel paths. The proposed GLAFormer is evaluated on three HSI datasets. The results demonstrate its superiority over state-of-the-art HSI change detection methods. The source code of GLAFormer is available athttps://github.com/summitgao/GLAFormer.

SECTION: IIntroduction

Hyperspectral image (HSI) change detection stands as a crucial task within the field of remote sensing, focusing on the identification of altered areas by comparing hyperspectral images obtained at different times. The exceptional spectral resolution of HSIs facilitates accurate detection of changes in ground objects[1]. As such, HSI change detection has been widely applied in various domains, including damage assessment[2], land cover analysis[3]and urban expansion monitoring[4].

Traditional methods in HSI change detection primarily employed techniques, such as change vector analysis[5]and Tucker decomposition[6], to analyze the spectral changes in multi-temporal images. Canty et al.[7]were the first to introduce the Multivariate Alteration Detection (MAD) method, which is based on Canonical Correlation Analysis and is designed for unsupervised change detection in vegetation using multi-temporal hyperspectral images. Later, Nielsen[8]enhanced this approach by developing the Iteratively Reweighted MAD (IR-MAD) algorithm. However, these methods encountered limitations in threshold selection and reduced robustness in complex scenarios[9]. Recently, convolutional neural networks (CNNs)[10]have been proven especially effective in extracting representative features from multi-temporal HSIs. Saha et al.[11]proposed a method called deep CVA by combining CNNs with change vector analysis (CVA).

More recently, Transformers, which rely entirely on self-attention, have gained popularity in computer vision tasks, such as image classification[12]and object detection[13]. Transformers have the advantage of capturing global dependencies and exhibit better performance in handling long-range dependencies compared to CNNs. This potential has prompted researchers to explore the attention mechanisms for HSI change detection. Song et al.[14]enhanced the feature representation of multi-temporal HSIs by introducing cross-temporal interaction symmetric attention. Furthermore, Ding et al.[1]introduced the Transformer encoder for HSI change detection, leveraging self-attention with a global receptive field to enhance the recognition of changes. In[15], a Transformer-based multi-scale feature fusion model was proposed for change detection.

Although existing Transformer-based methods for HSI change detection have achieved promising performance, they still suffer from two limitations: 1)Insufficient local-level representations modeling.Transformers tend to pay more attention to global features. However, global and local features serve distinct roles in encoding HSI patterns. The emphasis on global features in Transformers leads to the loss of certain local features, which results in a degradation of change detection performance. 2)Limited non-linear feature transformation.Feed-Forward Network (FFN) is commonly used to process the output from the attention layer in Transformer, enabling non-linear feature transformation for the input of the subsequent attention layer. However, existing methods are limited in non-linear feature representation and are susceptible to noise interference.

To overcome the above limitations, we propose aGlobal andLocalAttention-based Transformerfor HSI change detection, GLAFormer for short. Specifically, to enhance the local-level feature representations, we have designed a global and local attention module (GLAM) to encode both low-frequency and high-frequency signals. Furthermore, to augment the non-linear feature transformation, we propose the cross-gated feed-forward network (CGFN) to amplify the salient information while suppressing noise. Extensive experiments on three HSI change detection datasets demonstrate the superiority of our proposed GLAFormer.

Our main contributions can be summarized as follows:

We propose the GLAM as an enhancement to the self-attention mechanism. This module combines high-frequency and low-frequency signals to achieve a more comprehensive spatial-spectral feature representation for change detection.

We develop the CGFN to improve the non-linear feature transformation within Transformers. This network amplifies important information and mitigates noise interference.

Extensive experimental results demonstrate that the proposed GLAFormer outperforms state-of-the-art methods. The codes will be released to the remote sensing community.

SECTION: IIMethodology

The overall architecture of our proposed GLAFormer is shown in Fig.1. Two hyperspectral images (and) captured at different times are passed to the GLAFormer. Firstly, two patches from the multi-temporal HSIs of the same geographical area are extracted. Then, both patches are fed into two parallel GLAFormer encoders to extract informative and robust features. Next, the learned features from the two paths are fused. Finally, the fused features are transformed by several convolutional and fully connected layers for change detection.

As shown in the right part of Fig.1, the GLAFormer block consists of two key modules: GLAM and CGFN, which are detailed as below.

SECTION: II-AGlobal and Local Attention Module (GLAM)

As depicted in Fig.2, the GLAM consists of two branches: global attention and local attention. The global attention captures the global dependencies of the input, while the local attention branch computes the detailed local feature dependency. The global and local features are fused by concatenation.

Local attention.The local attention branch encodes high-frequency features via local window self-attention, which applies self-attention mechanism to local windows of feature maps. As shown in Fig2, a local window refers to aregion in the feature maps. These local windows are evenly partitioned in a non-overlapping manner.

The feature within each window is of size. Here,is the size of the window, andis the feature dimension. The feature within each window is reshaped into. Next, aconvolution is applied to enhance the input and obtain the query, key, and value. The local window attention is defined as:

whereis the output feature from the local attention branch.,, andare the tensors after theconvolutions specific to the local attention branch, andis the number of hidden dimensions for a single head in the local attention.

Global attention.The global attention branch captures low-frequency features by applying the attention mechanism over pooled feature maps. As illustrated in Fig.2, the input feature is evenly partitioned intowindows in a non-overlapping manner. To effectively capture global information, average pooling is employed on each window to obtain the average-pooled feature map. Next,is transformed to keyand value. To ensure complete and unchanged information access, the global attention uses queriesfrom the original feature map. This approach is consistent with that of local attention. To generate the output features, the standard self-attention is applied on,, and:

Channel splitting and merging.The input features are evenly split along the channel dimension before entering the global and local attention branches, reducing complexity and boosting GPU throughput. This splitting also decomposes the learnable parameters into smaller matrices, reducing the modelâ€™s parameter count. These two sets of features are separately fed into the local and global attention branches, respectively. To produce the output of GLAM, the output featuresfrom the local attention branch and the output featuresfrom the global attention branch are concatenated as:

SECTION: II-BCross-Gated Feed-Forward Network (CGFN)

To enhance the non-linear feature transformation in Transformers, the CGFN is proposed, which incorporates the gating mechanism and multi-scale convolution into the existing feed-forward network.

As shown in Fig.3, the proposed CGFN consists of two parallel paths. In each path, depth-wise convolutions with different sizes of kernels are employed to enhance the multi-scale feature extraction. Then, the gating mechanism is used to filter the less informative features in each path. The useful features passing through the gates are fused with the original features from another path. The fused features from the two paths are combined via element-wise summation. Given input, the CGFN can be defined as:

wheredenotes the output features,denotes the cross-gated mechanism,is the GELU activation function andrepresents the element-wise multiplication operation. The gating mechanism and the multi-scale convolutions amplify important information and mitigate noise interference.

SECTION: IIIExperimental Results and Analysis

SECTION: III-ADataset and Experimental Setting

We evaluate the performance of our GLAFormer through extensive experiments on three widely recognized multi-temporal hyperspectral datasets. These datasets were sourced from the Hyperion sensor onboard the EO-1 satellite. Specifically, the first dataset, referred to as the River dataset[16], comprises imagery of a river in Jiangsu Province, China. The second dataset is the Farmland dataset[17], which covers a farmland area in Yancheng City, Jiangsu Province, China. The third, known as the Hermiston dataset[9], captures irrigated farmland in Hermiston City, Umatilla County, Oregon, USA.

To demonstrate the effectiveness of the proposed GLAFormer, six state-of-the-art models are selected for comparison, i.e., IR-MAD[8], SSA-SimaNet[18], SSCNN-S[19], CDFormer[1], SSTFormer[20], CSDBF[21]and GTMSiam[22]. GLAFormer is configured with 4 blocks and 8 attention heads across all three datasets. The comparative analysis is grounded in two primary metrics: overall accuracy (OA) and the Kappa coefficient. OA provides a general assessment of change detection performance in terms of overall correctness. Kappa is a more robust measure that takes into account the agreement between the observed classification and what would be expected by chance.

All experiments are carried out by using the Pytorch framework. The training phase spanned over 100 epochs and was conducted on a single NVIDIA 4090 GPU. The Adam optimizer is utilized with a learning rate of 0.0006. The training batch size is set as 128. The input patch size for the proposed methods is, and the dimension of the embedded sequence is fixed at 256. For each of the three datasets, 3% of the samples are selected for training, 2% for validation, and the remaining samples are used for testing.

SECTION: III-BExperimental Results and Comparison

As presented in TableI, the quantitative comparison between the GLAFormer and other methods is conducted on three datasets. The results demonstrate that our proposed method consistently outperforms the compared methods across all three datasets in terms of OA and Kappa. Notably, in terms of the Kappa coefficient, GLAFormer achieves an average improvement of 2.77% across the three datasets compared to the previous state-of-the-art feature fusion method, GTMSiam. This signifies an accuracy boost of over 20% in regions that were challenging for previous models to identify.

To demonstrate the superior performance of our proposed GLAFormer, we also qualitatively compare the results of different methods on the three datasets. Fig.4shows the change detection result on the River dataset. Unlike other methods, the IR-MAD approach exhibits significant noise due to its lack of training information in change detection. In contrast, the detection results of GLAFormer are closer to the ground truth, particularly in the highlighted regions.

The change detection results of the Farmland dataset is shown in Fig.5. The regions in the red rectangle reveal that, only the GLAFormer and SSTFormer successfully identify the subtle alterations within the region. This observation aligns with the quantitative findings reported in TableI. It is worth noting that GLAFormer demonstrates an improvement of 1.58% and 3.11% in OA and Kappa coefficient, respectively, compared to the GTMSiam method. This performance gain can be attributed to the superior integration of global and local signals in GLAFormer.

The change detection results of Hermiston dataset are depicted in Fig.6. It shows the complex nature of the changes within this dataset, characterized by numerous irregular regions. A detailed analysis of the highlighted regions reveals that our proposed method produces a more accurate change map with clearer boundaries and reduced noise, underscoring its robust capability in detecting changes within complex backgrounds. This performance improvement can be attributed to the effectiveness of the dual-gated mechanism of CGFN in noise suppression. Quantitatively, GLAFormer achieves a 1.57% and 4.42% increase in OA and Kappa coefficient, respectively, compared to the GTMSiam method.

Both the qualitative and quantitative analysis demonstrates the robustness and accuracy of the proposed GLAFormer in handling complex change detection scenarios.

SECTION: III-CAblation Study

We conduct a series of ablation experiments on the three datasets to validate the effectiveness of the proposed GLAM and CGFN. Firstly, we design a Basic Transformer with the same structure as the GLAFormer, while the Basic Transformer uses traditional multi-head attention. In addition, we have two variants of GLAFormer, i.e., without the GLAM (w/o GLAM) and without the CGFN (w/o CGFN). These are replaced with standard self-attention and FFN, respectively. The results of the ablation study are shown in TableII. We find that GLAFormer and its variants beat the Basic Transformer in all cases. The GLAFormer always achieves better performance than its two variants on the three datasets. This demonstrates the necessity of the GLAM and CGFN designed in GLAFormer.

SECTION: IVConclusions

In this letter, we propose a novel GLAFormer for HSI change detection. The GLAFormer offers two enhancements over existing Transformer-based change detection methods. First, the designed GLAM leverages the abundant channel information intrinsic to hyperspectral images to combine both high-frequency and low-frequency signals. Furthermore, the designed CGFN is meticulously engineered to augment the extraction of pertinent information while concurrently mitigating noise interference, thereby enhancing the overall quality of the change detection process. Our comprehensive experiments conducted on three hyperspectral datasets, consistently demonstrate the superior performance of GLAFormer over the state-of-the-art methods.

SECTION: References