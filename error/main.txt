Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:  25%|██▌       | 1/4 [00:00<00:02,  1.10it/s]Loading checkpoint shards:  50%|█████     | 2/4 [00:02<00:02,  1.11s/it]Loading checkpoint shards:  75%|███████▌  | 3/4 [00:03<00:01,  1.22s/it]Loading checkpoint shards: 100%|██████████| 4/4 [00:03<00:00,  1.11it/s]Loading checkpoint shards: 100%|██████████| 4/4 [00:03<00:00,  1.02it/s]
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 109.24it/s]
Traceback (most recent call last):
  File "/data/groups/classes/2024/fall/cs426/group_5/SchSearch/scholarly-search/./py_code/main.py", line 109, in <module>
    top_paper_ids = embLib.search_papers(prompts[i], response, n_results=N_RESULTS)
  File "/data/groups/classes/2024/fall/cs426/group_5/SchSearch/scholarly-search/py_code/embedding_library.py", line 174, in search_papers
    scores = self.model.similarity(r_emb, self.paper_embs)
  File "/data/users/roota5351/.local/lib/python3.9/site-packages/sentence_transformers/util.py", line 142, in dot_score
    return torch.mm(a, b.transpose(0, 1))
RuntimeError: expected m1 and m2 to have the same dtype, but got: float != double
