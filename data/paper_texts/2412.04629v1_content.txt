SECTION: Argumentative Experience: Reducing Confirmation Bias on Controversial Issues through LLM-Generated Multi-Persona Debates

Large language models (LLMs) are enabling designers to give life to exciting new user experiences for information access. In this work, we present a system that generates LLM personas to debate a topic of interest from different perspectives. How might information seekers use and benefit from such a system? Can centering information access around diverse viewpoints help to mitigate thorny challenges likeconfirmation biasin which information seekers over-trust search results matching existing beliefs? How do potential biases and hallucinations in LLMs play out alongside human users who are also fallible and possibly biased?

Our study exposes participants to multiple viewpoints on controversial issues via a mixed-methods, within-subjects study. We use eye-tracking metrics to quantitatively assess cognitive engagement alongside qualitative feedback. Compared to a baseline search system, we see more creative interactions and diverse information-seeking with our multi-persona debate system, which more effectively reduces user confirmation bias and conviction toward their initial beliefs. Overall, our study contributes to the emerging design space of LLM-based information access systems, specifically investigating the potential of simulated personas to promote greater exposure to information diversity, emulate collective intelligence, and mitigate bias in information seeking.

SECTION: 1.Introduction

Large language models (LLMs) offer a novel design space to explore new ways to support human information seeking.
For instance, commercial search engines and services like ChatGPT and Perplexity can synthesize information from multiple sources to provide direct answers to user questions111ChatGPT:https://openai.com/index/chatgpt/, Perplexity:https://www.perplexity.ai/.. Recent work has also explored leveraging the internal knowledge and reasoning capabilities of LLMs to
simulate human personas with diverse perspectives(Prpa et al.,2024; Park et al.,2022; Chen et al.,2024; Khan et al.,2024). Imagine a user could generate a set of LLM personas on-demand to debate any topic of interest from multiple perspectives. How should we design such a system to maximize potential benefit to information seekers (e.g., information diversity) while also minimizing associated risks (e.g., LLM hallucination and biases interacting with human biases)?

In traditional information-seeking process, users retrieve facts, evidence, and other information from various sources, often guided by their pre-existing beliefs. This can lead toconfirmation bias(Berthet,2021), where users favor information that supports their prior assumptions. Such biases are prevalent not only in standard information access systems, like search engines, but also in conversational interactions, where users actively shape the direction of the discourse(Sharma et al.,2024; Khan et al.,2024). However, LLM-powered diverse information-seeking could be intentionally designed to provide broad coverage and present contrasting views, regardless of
prior user beliefs. Recent design explorations of multi-persona systems have been encouraging, with subjective or indirect user feedback suggesting mitigated confirmation bias(Park et al.,2023a; Chiang et al.,2024; Zhang et al.,2024).

In this work, we explore a novel information seeking experience: letting users launch a debate on any topic of interest in which generated LLM personas present diverse perspectives on the topic. We explore the active and autonomous nature of LLM agents in this setting as they present information and arguments, creating anargumentative experiencebetween humans and AI. In focusing the user experience on exposure to diverse perspectives, we particularly investigated whether exposure to diverse information via generated personas could help reduce user confirmation bias.

Participants in our study launched LLM debates on controversial topics spanning social issues (e.g., ”Should abortion bans be illegal?”) to imaginary scenarios (e.g., ”Should space be colonized?”) We first assessed initial user attitudes toward these topics, then asked users to engage with a baseline search system and our multi-persona debate system. We used a mixed-methods approach to capture participants’ cognitive perceptions, such as real-time eye-tracking metrics, behavioral data, such as user interactions, and qualitative feedback through retrospective think-aloud sessions.
These data not only help assess the relative performance of our multi-persona debate system, but also address limitations of other recent exploratory studies on LLM-persona systems, which primarily relied on self-reported metrics and subjective feedback(Park et al.,2023a; Zhang et al.,2024). Our study thus complements this prior work in moving toward a more comprehensive view of how use of LLM personas can impact user information consumption.

Our study investigates three key research questions:

What is the overall user experience when conceptualizing controversial topics through a multi-persona debate interaction simulated by LLM?

Compared to the retrieval-based system, how effective is the multi-persona debate system in mitigating confirmation bias?

Compared to the retrieval-based system, how does the multi-persona debate system finally influence user pre-existing beliefs?

Through a combined analysis of both quantitative and qualitative data, our findings
reveal that the argumentative experience powered by LLM personas helps foster constructive deliberation on contrasting viewpoints, making individuals more likely to consume content that challenges their pre-existing beliefs. This happens because persona-based debates present information in a more dynamic, appealing, and persuasive manner,
reducing user cognitive load and enhancing interactivity so that people are willing to engage with challenging content. In summary, our work investigates persona-based debate systems to gain deeper insights into human cognitive perceptions and behavioral patterns when interacting with them. We assess the effectiveness of these systems in reducing confirmation bias during information seeking and offer broader design implications to guide the future development of persona-based systems.

SECTION: 2.Related Work

SECTION: 2.1.The Social Simulation and Role-Play of LLM

Over the past five years, LLMs (e.g., GPT, Llama, Gemini, etc.) have rapidly advanced and today represent the state-of-the-art in performance across various natural language tasks222GPT:https://openai.com/index/gpt-4/, Llama:https://www.llama.com/, Gemini:https://gemini.google.com/. ThrAdditionally, by being trained on the increasing amounts of web data and computational resources(Kaplan et al.,2020), LLMs have developed strong reasoning and association abilities, as well as internal knowledge that captures social knowledge and cultural norms.

To instruct and tailor content generated by LLMs, prompting is a specific technique used by practitioners, providing initial inputs or cues to a language model(Liu et al.,2023).
Researchers have explored creative ways to assess and extend the human-like capabilities of LLMs through prompting(Wang et al.,2021; Wei et al.,2022; Yao et al.,2022). One novel application is the development of agent-based systems where LLMs are used to create highly autonomous agents. LLM personas (orSocial Simulacra) are a prominent example. Specifically, by incorporating different beliefs, desires, goals, and characteristics into the prompts, LLMs can role-play to simulate human reactions and behaviors(Shanahan et al.,2023; Park et al.,2022; Chen et al.,2024; Tseng et al.,2024).
This approach offers new opportunities for enhancing user experiences in Computer Supported Cooperative Work (CSCW) and other areas of Human-Computer Interaction (HCI). In these fields, generative agents can provide more dynamic, interactive, and autonomous user experiences(Park et al.,2023b). Researchers have explored different use cases, such as using social simulacra to conduct user studies(Argyle et al.,2022; Park et al.,2022), creating generative agents in an interactive sandbox environment(Park et al.,2023b), or directly using LLMs as judges to assist decision-making tasks(Pan et al.,2024), ranging from data annotation(Tan et al.,2024)to language evaluation(Wang et al.,2023).

However, researchers also highlight important challenges in the real-world experiments that employ LLM as the core technique to design persona systems, as well as agent-based systems in general. For example, in particular on the development of social simulacra, LLMs can reflect polarized human opinions regarding different social issues, including misinformation(Neumann et al.,2024), climate change(Santurkar et al.,2023), and politics(Taubenfeld et al.,2024). More importantly, the broad idea of agent-based systems also raises important ethical questions about the idea of replacing humans(Prpa et al.,2024). In summary, the development and implementation of LLM-based systems are still in their early stages. Ongoing research is needed to investigate both the advantages and challenges of applying these systems to different real-world scenarios.

SECTION: 2.2.Confirmation Biases in Information Seeking

Confirmation biasis one of the cognitive biases(Berthet,2021)which refers to the human tendency to seek and interpret evidence that supports their existing beliefs, expectations, or hypothesis(Nickerson,1998), regardless of the plausibility of those beliefs(Edwards and Smith,1996).
Confirmation bias consists of two aspects: the cognitive aspect (disposition) and the motivational aspect (manifestation)(Berthet et al.,2022).
The cognitive aspect of confirmation bias focuses on human tendencies(Berthet et al.,2022; Baron,2023).
It represents a stable psychological disposition that reflects an individual’s tendency toward confirmatory information seeking and evaluation, which can be reliably measured through validated psychometric instruments(Ardi and Pradiri,2021; Rassin,2008; Berthet,2021).
The motivational aspect focuses on the relationship with users’ prior beliefs(Baron,1995).
This aspect relates to users’ pre-existing beliefs within specific contexts and manifests dynamically during information-seeking activities, where individuals tend to select information aligning with their attitudes, allocate more attention to confirming content, and assign greater weight to belief-consistent evidence during evaluation(Vedejová and Čavojová,2022).

Previous research has shown that confirmation bias is widely manifested in seeking behavior, influencing how users interact with information.
Specifically, users may be more likely to select and spend more time reading attitude-consistent results(White,2013; Suzuki and Yamamoto,2020), while avoiding information that challenges their prior beliefs(El and Moussaoui,2022; Knobloch-Westerwick et al.,2015; Dickinson,2020).
This behavior may further result in filter bubble and echo chamber(Quattrociocchi,2017), where like-minded people gather, communicate and interact as an identified community, reinforcing shared beliefs and perspectives(Garrett,2017).

To mitigate such biases,
HCI and CSCW scholars have explored design strategies in visualization and recommendation systems to encourage user engagement with diverse content.
One established approach is to increase exposure to opposing viewpoints.
For instance,Lex et al.(2018)mixed tweets and hashtags from various partisan groups,Schweiger et al.(2014)used tag clouds to display opposing viewpoints, andHuang et al.(2012)presented counterarguments on a separate screen.
Another approach is to increase the system interactivity and user engagement.
For instance,Sude et al.(2021)added a ”voting” feature for search results, andRieger et al.(2021)applied warning labels like ”this search result may reinforce your opinion,” requiring users to click a button to view them.
These features help users to be more aware of their information seeking and decision framing process.
Additionally, developers created search systems to balance different search results by learning user existing information activities, such asSchwind et al.(2012)’s search system that highlights search result inconsistent with user preferences reflected on their search queries andJasim et al.(2022)’s bias mitigation recommendation model that suggests diverse sentiment review for online products, informed by user past browsing history.
Aforementioned studies suggest that presenting diverse information in a more vivid way can motivate users to engage with content that differs from their prior views.

However, it’s important to recognize that these design and system enhancements remain centered on a static, passive model of information consumption, characteristic of traditional search contexts where information is retrieved and displayed rather than dynamically presented. While increasing exposure to diverse information through external cognitive forcing functions can increase information diversity, this approach may not inherently enhance user engagement or persuasiveness. In contrast, LLM-powered information seeking presents a novel interaction paradigm that enables more diverse, interactive, and dynamic engagement, potentially reducing confirmation bias.

SECTION: 2.3.Opportunities of LLM Constructive Deliberation on Contrasting Viewpoints

Confirmation bias is often associated with polarization effects in which social divides serve to establish and/or reinforce certain viewpoints. While exposure to opposing views in a hostile setting can heighten polarization(Bail et al.,2018), constructive deliberation between opposing views can actually promote empathy, tolerance, and sharing ideas, and reduce polarization(Mutz,2002; Porter and Schumann,2018; Levendusky and Stecula,2021; Bächtiger and Parkinson,2019; Kim et al.,2021).

Researchers have explored how LLMs can facilitate constructive deliberation and enhance engagement with contrasting viewpoints through mediated discourse.

From the technical side,Tessler et al.(2024)develop the Habermas Machine, a system of LLMs based on Chinchilla which generates statements that express common ground amongst a set of opposing views.Kambhatla et al.(2024)operationalize receptiveness into a computational framework, and use an LLM in combination with the framework to reframe Reddit comments to be more receptive to other users’ comments.
Other work also studies grounding, or constructing a shared basis of understanding, in promoting positive discussions on opposing views by fine-tuning specific language model(Cho and May,2020; Shaikh et al.,2024b).

Researchers in social science and HCI also design LLM-powered tools to facilitate constructive deliberation. For example,Argyle et al.(2023)aim to improve conversation quality in divisive online political conversations using an AI chat assistant. Similarly,Zhang et al.(2024)designed a multi-agent dialogue system in social media conversations. Although no comparison was made with other baseline conditions, they found that participants were influenced either by their own interests or by the system itself to actively explore diverse perspectives, helping to reduce their filter bubbles.Chiang et al.(2024)directly use LLM to play devils’ advocate in AI-assisted group decision-making and found that participants were more likely to form an appropriate trust to adopt AI decisions.

Overall, we see LLMs increasingly being used to reduce polarization and intolerance in ways that might complement LLM-tooling to mitigate related biases. Notably, LLM could be designed to simulate personas that take more critical stances according to predefined roles and characters, which might challenge user prior beliefs. By presenting a new user experience built around diverse feedback and engagements than traditional search, this approach might help counteract the biased information-seeking behaviors commonly seen in traditional search systems.

Research Focus of this Study.Building on prior research, we aim to thoroughly and objectively assess the effectiveness of LLM-generated personas in reducing confirmation bias within an automated debate context. LLM-powered diverse information-seeking via personas demonstrates how LLM agents actively and autonomously can present information and arguments, creating anargumentative experiencebetween humans and AI.Unlike traditional information-seeking that is predominantly user-driven, this argumentative experience could foster a more interactive and collaborative exchange of information to reduce both motivational and cognitive confirmation bias.

While prior studies have examined LLM-generated personas for product recommendations(Park et al.,2023a), reducing filter bubbles through qualitative feedback(Zhang et al.,2024), and generating counterarguments in group decision-making(Chiang et al.,2024),
our study objective is to ground the hypotheses (as highlighted above) from a psychological cognitive perspective.

We designed a multi-persona debate system that presents diverse viewpoints through argumentative discourse on controversial issues. By comparing this system with a baseline retrieval-based approach that presents balanced content snippets from opposing perspectives, we evaluate how dynamic, argumentative information presentation influences confirmation bias and belief formation. Through eye-tracking analysis capturing users’ involuntary (bottom-up) and goal-directed (top-down) eye movements, we examine how this active, LLM-driven interaction paradigm shapes user engagement.

In the following sections, we present the system design for the multi-persona debate system (Section3) and detail the study procedure (Section4).

SECTION: 3.System Design

This section describes the design and development of our multi-persona debate system, which serves as the experimental interface for our study.
As an overview of the multi-persona debate system and how users may interact with it, we present a simplified user-system workflow in Figure1. Details are presented regarding the envisioned usage scenario (Section3.1), design objectives (Section3.2), interface features (Section3.3), and system architecture (Section3.4).

SECTION: 3.1.Envisioned Use Case

Controversial social issues, such as gun control, abortion, climate change, etc., often attract heightened media attention and public interest, where partisanship and political divisions can influence adopted stances. This suggests value in exploring new ways by which people might navigate complex and nuanced issues of divergent positions and ideologies. We assume users are at least somewhat curious and interested to explore diverse views (or they would not be using our system). Someone particularly firm their own beliefs may be curious about how anyone else could think otherwise.

Our multi-persona debate system offers a novel form of information access for such topics, using LLM personas to generate diverse and, possibly, contrasting perspectives. A user begins by entering a topic of interest, similar in spirit to a traditional search query. The system then generates suggested personas to provide broad coverage of differing views. The user can freely keep these generated personas, revise them, or add others. Following this, the user
initiates as many rounds of debate as they find valuable, further revising the set of personas at any time to explore additional perspectives. By simulating a debate between personas, each advocating for a distinct perspective, users are exposed to a rich array of arguments, counterarguments, and the complex interplay of ideas that characterize real-world discussions.

For example, when debating a topic such as ”Should space be colonized?”, the system presents perspectives from diverse stakeholders such as scientists, environmentalists, and economists, each offering unique insights on the matter. In the debate, personas generated by LLMs present their arguments in a conversational setting. A simulated “space scientist” may argue that colonizing space is crucial for humanity’s survival, while a simulated “environmentalist” might oppose this stance, raising concerns about the potential environmental and ethical implications.

As users observe the debate, some arguments may naturally resonate with them more than others. To promote more active engagement and information retention, users can bookmark any argument of particular interest they would like to review later, as well as to record their agreement or disagreement with it (via thumbs up or down buttons) to remind themselves later when they review bookmarked content. Users can review their bookmarked content at any time during or after the debate. This interactive experience – customizing the debate and bookmarking arguments of interest – seeks to help users organize and track the main points of each perspective in order to foster a deeper, more critical engagement with the topic at hand.

SECTION: 3.2.Design Objectives

Motivated by the aforementioned usage scenario, our design goals are as follows:

Broad Representation: We generate LLM personas that provide comprehensive coverage of major viewpoints on each topic. This development requires a deliberate and balanced approach to perspective generation to ensure balanced representation while maintaining a calibrated spectrum from opinion-based to factual discourse.

Dynamic Debate Interactions: We strive to create dynamic debate interactions among personas.
This includes the ability for personas to respond to each other’s arguments, pose questions, and provide rebuttals, mirroring the fluid nature of human dialogue.

User Engagement and Interactivity: We seek to promote user engagement by enabling users to save salient responses, modify persona parameters, and initiate successive debate rounds. This interaction design fosters active participation in dialectical exchanges rather than passive observation.

SECTION: 3.3.Interface Features

Figure2presents the user interface of our LLM debate system. We describe the major interactive features below.

At the start, users can either enter a topic, possibly controversial, in the search bar or choose one from the list of suggested topicsA. The system then begins generating LLM-personas relevant to that topic.

As displayed inB, each persona is represented by a title and description, along with automatically assigned colors and icons to help users easily identify and differentiate between them (which emerged as a need during early pilot testing).
We set a predefined number of personas at the beginning (N=5), but users are free to generate or manually create as many personas as they want. The specific prompt instructions (described in Section3.4.1) aim to generate diverse LLM personas that represent a range of viewpoints and social roles on the selected topic. This approach aligns with our primary design goal of comprehensive representation.

During the design of this interface, we addressed a critical design consideration regarding the optimal level of inter-persona interaction within each debate round.

In a structured human debate333https://debatingmatters.com/debate-timing-structure/where debaters are separated into two teams holding opposing views, responses may either focus on arguments presented by a specific debater or address all previously discussed points made by members from the opposing team. Additionally, arguments may unfold sequentially under the guidance of a moderator or occur simultaneously, with debaters from different teams engaging back-and-forth in animated exchanges.

Given our second design goal of fostering dynamic debate interaction while preventing the user from being overload, we have the personas engage in a round-robin (sequential) discussion. The debated content is displayed in a traditional conversational formatC, making it easier for users to follow the debate. The prompt instructions (Section3.4.2) encourage each persona to sequentially formulate their arguments by referring to the entire debate history.

A debate round concludes once all personas have (in order) presented their arguments. Afterward, users can select, deselect, add, or edit personas, and start a new round of debate by clicking the “Start Debate” button. Each time an additional round of debate is initiated, a new tab is created in the interface. This enables users to navigate back-and-forth across different rounds of the debate in reviewing the arguments presented. It is motivated by our third design goal of fostering user engagement and interactivity.

With multiple personas presenting arguments over several rounds of debate, the number of arguments can quickly grow, which risks overwhelming the user. To help keep the set of arguments presented more manageable, we introduce bookmarking in our interfaceD, allowing the user to save arguments of particular note for later review. By clicking up/down thumb icons, users can further record whether or not a given argument resonated with their own thinking. These user bookmarks are collected and shown in the main interface’s ‘Summary’ tab, to the right of the latest debate round, as displayed inC. Users can review their bookmarked content at any time during or after the debate.

SECTION: 3.4.System Architecture

This section describes the architecture of our system, detailing the prompt instructions to support each interactive feature, including persona creation (Section3.4.1) and debate generation (Section3.4.2), language model choices (Section3.4.3), and the web develop framework (Section3.4.4).

In creating personas for our multi-persona debate system, prior studies have pointed out several limitations inherent to LLMs(Park et al.,2022,2023b), such as inconsistent persona generation and formatting. While LLMs can generate personas that clearly express their stances on controversial topics, determining how to effectively prompt the LLM to achieve this may not always be straightforward.

One problem is that assigning specific names to personas, real or fictional, can be problematic because readers may mistakenly believe the persona represents an actual person, as evidenced by prior studies that LLMs would inadvertently reveal real names from their training data(Huang et al.,2022). To mitigate misrepresentation and potential ethical concerns, we prompt the LLM to ”generate a title for the persona, not a name”, while enabling users to override this default setting through customization. In generating persona descriptions,
the LLM may include detailed background information without explicitly clarifying the persona’s stance on the topic, yet explicitly linking persona background to specific stance risks perpetuating stereotypes or creating caricatures of those backgrounds.
To address this, we first prompt the LLM to “describe background (instead of their stance)” and then separately prompt it to “start the debate by briefly presenting an argument in support of its stance on the topic.”

We generate an initial set of personas to cover key perspectives on the issue. To enhance perspectival diversity, we incorporate existing personas as context when generating additional ones. Our prompt design includes specific instructions to maintain consistency across persona professions and descriptions (see AppendixAfor prompt details).

To facilitate the debate, we developed two prompts: one to initiate the debate and another to continue it based on prior debate conversations (see AppendixAfor prompts details). However, it is important to note that LLMs are constrained by a maximum input length, known as the ‘context window’(Wang et al.,2024)after which they may start to lose track of earlier portions of the input. This limitation can be problematic in our system, as personas need to reference the entire debate history to provide meaningful responses.

To overcome this challenge, inspired byPark et al.(2023b)’s work, when the debate history exceeds the LLM’s context window, we employ an extractive summarizer that compresses the transcript to fit within the required length while preserving the key points of the discussion. Specifically, we use theBERTExtractiveSummarizer(Miller,2019), which provides a good balance between summarization performance and latency.
To make the responses more concise, readable, and suitable, we also include prompt instructions “Generate at most 200 words” and “Use bullet points (in markdown format)”. This helps to reduce verbose, unstructured LLM generations and mitigate information overload.

While the landscape of LLMs is vast and rapidly changing, OpenAI’s GPT models have thus far remained at the forefront, with
GPT-4444GPT-4:https://openai.com/index/gpt-4/being among the most capable LLMs today. Its
128K token context window also allows it to perform well in long range tasks like ours. We thus adopted GPT-4 for the study presented here, though we note our system architecture is largely agnostic and could easily support other LLMs as well.

We developed the system UI using Streamlit555https://streamlit.io/, a popular machine learning web development framework that allows development with an emphasis on interactivity and ease of use. It also promotes rapid prototyping, which made it easy to iterate on the interface design based on user feedback or emerging requirements.

SECTION: 4.Methods

To explore how users might engage with the multi-persona debate system and the system effectiveness of reducing confirmation bias, we conducted a controlled, within-subjects study by comparing the multi-persona debate system with a baseline retrieval-based system. In this section, we describe our formal evaluation protocol, including the experimental procedure and tasks (Section4.1), participant recruitment (Section4.2), the selection of controversial topics (Section4.3), and data collection and analysis.

SECTION: 4.1.Experimental Procedure and Tasks

As illustrated in Figure3, the within-subject experiment started with eye calibration and task instructions. Participants were then randomly assigned to one of two study blocks, Block A or Block B. InBlock A, participants utilized the baseline system to engage with the topic. We adopted ArgumentSearch666https://argumentsearch.com/(Daxenberger et al.,2020)as the baseline for our A/B experiments. ArgumentSearch is a retrieval-based search engine that identifies articles from the open web and organizes content snippets according to their stance on the user query (detailed description is provided in AppendixC).

InBlock B, participants interacted with our multi-persona debate system as the experimental condition to explore and generate debate content with the given topic. Each block included a training task to first familiarize participants with the assigned system.
Within each block, participants completed four randomized trials assigned with different controversial topics. Once they completed the trials in one block, they moved on to the other block and used the alternate system, ensuring they interacted both systems.

Each trial consisted of three parts:(i)Pre-task Questions(ii)Exploring the given topic with the assigned interface, and(iii)Post-task Questions.
In the pre-task questions, we asked participants to explicitly rate their topic familiarity, pre-existing belief (i.e., stance) to the topic, and the confidence for their stance.
For each trial, participants were presented with a controversial issue to explore the interface. After participants completing the task, we again evaluate their current stance to the topic and the confidence score, similar to the pre-task questions.

Upon completion of all eight trials across both systems, participants were required to complete a post-test questionnaire to assess their propensity for confirmation bias.
Following this, a semi-structured interview was conducted to gain insight into the users’ interactions with the systems, their perception, as well as the usability and feedback. Details of the pre-, post-task questionnaires and interview questions are presented in AppendixB. The entire experimental study took approximately 1.5 to 2 hours to complete. This included 60 to 80 minutes for the experimental portion and an additional 15 to 25 minutes for the interview.

SECTION: 4.2.Participant recruitment

The study was conducted in a usability lab at a university, withparticipants (19 females, 18 males, and 3 non-binary identity). Particpants were recruited using convenience sampling, and were aged between 18 and 34 years (view demographic details in AppendixD). They came from a variety of academic disciplines, ranging from applied sciences, natural sciences, engineering, to social sciences, bringing diverse educational backgrounds. Participants were pre-screened for native-level English familiarity, 20/20 vision (uncorrected or corrected). Upon completion of the study, each participant was compensated.

In the data analysis, a total of 156 trials, derived from 39 participants each completing 4 tasks within the multi-persona debate system, were utilized for behavioral (Section5.1) and eye-tracking analysis (Section5.2). One participant data point was excluded due to the missing eye-tracking data during collection. All 40 participants were included in the user belief change analysis (Section5.3).

SECTION: 4.3.Selection of Controversial Topics

These topics were sourced from procon.org777ProCon.org_2024covered a diverse range of categories, including health, science and technology, economics, and entertainment. These topics are formulated as yes/no proposed actions, such as ”Should abortion bans be illegal?” or ”Should space be colonized?”. The topic itself thus embeds a “pro” stance supporting the action vs. the “con” stance against it.
We select topic categories to cover a range of important issues with broad societal relevance. Each topic was selected to ensure active public discussion, involvement from various groups, reliable information from credible sources, and a balanced view of arguments, without needing much specialized knowledge (view topic details in Appendix9).
In each block, one topic was selected for each category, resulting in four tasks per block and a total of eight tasks.

SECTION: 4.4.Data Collection and Analysis

Data collection during the experimental procedure incorporated multiple sources: pre-task questions, user interaction logs, post-task questions, system evaluation questionnaires, and interview recordings. Eye-tracking data were gathered using the Tobii TX-300 eye-tracker and processed through Tobii Pro Lab888https://www.tobii.com/products/software/behavior-research-software/tobii-pro-lab, a commercial usability and eye-tracking software that enabled raw gaze data collection, user interaction recording, and preliminary data cleaning for subsequent analysis.”

Further details about our analysis are provided below.

To categorize user interaction patterns with our LLM debate system, we conducted a clustering analysis using the following behavioral data:

The average number of rounds of debate generated.

The average number of personas adopting pro/con stances over the course of the debate for a given topic.

The average time (in seconds) duration for each round of debate.

The average number of new personas generated for each round.

The average number of personas edited by participants for each round.

The average number of times participants visited the summary tab for each round.

The average number of thumbs (up or down) clicked for each round.

Following the initial clustering analysis, we performed thematic coding to summarize the qualitative feedback provided. Since we compare user experience between two different interfaces, our qualitative themes focus on factors influencing participant comparisons between the A/B systems used.
We present these findings in Section5.1.

A primary research objective is to evaluate the system’s effectiveness in mitigating confirmation bias in information behavior, particularly in reducing selective exposure to attitude-consistent information. Through eye-tracking data analysis, we examine engagement patterns with content that diverges from users’ prior beliefs. Drawing on confirmation bias literature (described in Section2.2), we hypothesize that increased temporal engagement with reading opposing viewpoints may indicate reduced confirmation bias through enhanced exposure to differing perspectives.

Additionally, we incorporate two key factors in evaluating the above hypothesis based on our study design. First, we considered the impact of users’ general tendency toward confirmation bias as a psychological disposition (described in Section2.2), to understand how this human factor may affect the system’s effectiveness.
The second factor is user topic familiarity, since we intentionally selected different social topics (described in Section4.3).
We thus formulate two further sub-questions regarding how users’ eye movements might differ based on these factors.

How do varying levels of topic familiarity and confirmation bias tendency influence user engagement with content?

How does use of our LLM debate system vs. the baseline system impact user engagement with content? Does this effect differ based on user levels of topic familiarity and their confirmation bias tendency?

The user topic familiarity and confirmation bias tendency were measured in the pre-task questions. We also measured two types of eye-tracking metrics (ET) and defined areas of interest (AOIs) to understand user engagement with the content. These measures are defined as follows:

Users are categorized into five levels of familiarity based on a 5-point Likert scale, as collected in the pre-survey.

Participant levels of confirmation bias were measured usingBerthet (2021)’s questionnaire. The final collected scores ranged from 0.34 to 0.88, with a median of 0.6. To categorize participant confirmation bias tendencies, we divided the scores into three equal groups, classifying them into low, medium, and high.

Two metrics, including total fixation duration and fixation counts, were utilized to understand user engagement. Fixations were filtered to include only good-quality fixations, lasting between 100ms and 2000ms. Additionally, both fixation duration and counts were normalized relative to the length of the content.

We also label AOIs to identify participant selective exposure to attitude-consistent versus attitude-inconsistent information.
For example, if the content supports the given topic and the participant also holds a supportive view, then the content would be labeled as attitude-consistent information. Fixations falling into these AOIs represent how user engage with the attitude-consistent information. Table1presents how we annotate attitude-consistent and attitude-inconsistent AOIs based on user pre-task belief and the stance of the content.

We present the results for RQ2 in Section5.2, focusing on user engagement of the content.

We adopt a similar approach as with RQ2. Correspondingly, we formulate two sub-research questions relevant to topic familiarity and user confirmation bias tendency:

How do different levels of topic familiarity and confirmation bias tendency influence user belief changes?

How does our LLM debate system, compared to the baseline system, impact user final belief changes? Additionally, does this effect differ based on user levels of topic familiarity and their confirmation bias tendency?

User pre- and post- belief were collected separately in the pre- and post-task questions. We calculated three types of belief changes, including non-directional, bi-directional, and weighted belief changes based on user confidence, defined as follows:

Users are categorized into two groups of belief changes — changed vs. unchanged — based on the difference of belief measurement for each topic. User belief is measured based on a 5-point Likert scale (i.e., very supportive, somehow supportive, neutral, somehow opposed, and very opposed), collected in the pre- and post-task questions.

Users are categorized into three groups of belief changes — less supportive, more supportive, and unchanged — showing the directional belief change for each topic, as calculated based on the previous 5-point Likert scale.

We calculate the stance shift weighted by the average confidence level before and after using each system (Equation1)999In prior behavioral studies byNorman and Price (2015), relative confidence of people’s subjective responses were evaluated using average measures. Building on this, we evaluate participants’ relative confidence in their beliefs about the topics by calculating the average confidence level before and after the intervention.. This score reflects both the direction and strength of the belief change. User belief confidence is also measured by a 5-point Likert scale in the pre- and post-task questions.

Results for RQ3 are detailed in Section5.3, which discusses belief changes.

SECTION: 5.Results

SECTION: 5.1.RQ1: User Experience in Conceptualizing Controversial Topics through Multi-Persona Debate

From the behavioral data collected in the debate system (as described in Section4.4), users generated an average of 1.865 debate rounds per topic.
For each round, an average of 1.734 personas supporting the topic and 1.972 personas opposing the topic were selected. Users made minimal edits (0.187 personas), clicked thumbs up/down 2.628 times to bookmark content, and accessed the bookmark tab only 0.121 times on average. Full descriptive data are provided in Table6.
As we recognized notable variations in the behavior data among participants, we performed a clustering analysis to better understand users’ engagement patterns and their relationship to both the system design and the topics explored.

We first applied K-means clustering to categorize participant behaviors while they used the debate system. Recognizing that participants might display different usage patterns across various topics, we treated each participant’s interaction with each topic in the system as a separate unit of analysis.
This resulted in a total of 156 units of analysis, since 39 participants each engaged with 4 topics.
In the K-means clustering process, features were standardized using Z-scores to normalize the data, ensuring that each feature contributed equally to the clustering algorithm and improving the comparability across different scales.
As shown in Table2, the clustering result yielded three distinct groups with anvalue of 0.255 and silhouette coefficient of 0.170.

The smallest cluster (N= 25, Group 0) was characterized by their exceptionally high scores in bookmark tab visits (Z= 2.091) and thumb clicks (Z= 0.788), while showing average usage in other behavior measures. Group 1 (N= 75) exhibited positive scores in the number of debate rounds (Z= 0.381) and the selection of supportive personas (Z= 0.320), but notable negative scores in debate duration (Z= -0.451) and the selection of opposed personas (Z= -0.631). Group 2 (N= 56) was distinguished by high scores in debate duration (Z= 0.576) and the selection of opposed personas (Z= 0.893). This group also showed moderate positive scores in new personas generated (Z= 0.349) and personas edits (Z= 0.166). By carefully reviewing the participant screen recordings and qualitative feedback during their use of the debate system and correlating these understandings with the clustering statistics, we identified and conceptualized three distinct types of usage behaviors.We characterize a usage pattern for each group as follows:

Participants in this group frequently used thumbs up / down features to express their opinions while observing the debate, and often reviewed the bookmarked content. They typically engaged in more than two debate rounds and showed moderate involvement in selecting and editing personas, balancing supportive and opposing viewpoints. For example, during the debate topic of “Should humans colonize space?”, P14 remarked “I think there’s a lot of good points made. Mainly it comes down to the tangibility of it and the fact that it kind of does feel like we’d be abandoning the mess that we made here [the Earth].” Because P14 found it feasible for space colonization, this participant often gave thumbs-up to compelling arguments and thumbs-down to weaker ones. Similarly, others in this group proactively express their opinions using the thumbs features and spent more time on the bookmarked tabs. We see this pattern reflected in our envisioned use case (Section3.1). It is marked by frequent use of feedback features, revisiting bookmarked content, and a balanced consideration of both supportive and opposing perspectives.

Participants in this group were inclined to generate more rounds of debate (up to five) but spend less time reading and digesting arguments presented. Notably, we observed a preference for selecting personas that agreed with the given topic.
From qualitative feedback, it appears that this may stem from the uncertainty about the topic. By initially choosing supportive personas, participants began to familiarize themselves with the subject matter. For example, in the debate over “Should humans colonize space?” P17 admitted a lack of knowledge in that area. The participant first selected two supportive personas, an aerospace engineer and a resource economist, to gain insights into the potential benefits of space colonization. As the debate progressed, P17 gradually included personas with different perspectives. This pattern reflects a strategy of building understanding through repetition and confirmation, with a gradual move toward considering alternative viewpoints as participant knowledge grows throughout the debate.

Participants in this group exhibited the highest level of engagement with the system. Compared to other two groups, they experienced the longest debate durations, selected more new personas, and frequently edited these personas. A notable characteristic was to actively seek out personas that disagreed with the topic.
These behaviors suggest significant mental effort invested in generating, evaluating, refining personas, and reading content to gain a comprehensive understanding of the topic.
This behavior might stem from participant propensity for critical thinking, as indicated from their qualitative interviews.
For example, in the debate topic of “Should abortion be legal?” P14 initially supported the legalization of abortion, felt that they hadn’t explored the topic deeply enough “[Although] I’m kind of familiar, but I haven’t really delved in deep to all the different sides so I don’t want to take a side on it [quickly].” Despite holding a pro stance, this participant sought out opposite opinions to gain a more comprehensive view of the controversial issue. This pattern exemplifies how some participants, even with initial stances, actively engage with conflicting perspectives to ensure a balanced understanding of the topic.

In addition to identifying three general behavioral patterns, we found that topic-specific factors influence participants’ engagement with the debate system. Participants were also attentive to the expertise and backgrounds of personas, which affected their use behaviors. We present these findings, along with further analysis in the AppendixE.

SECTION: 5.2.RQ2: Comparison of User Engagement between Retrieval-based and Multi-persona Debate System

In this section, we analyzed participants’ eye movements within attitude-consistent vs. inconsistent AOIs to understand how they engaged with the two systems.
We begin by analyzing the system differences then diving into how variations of eye movements between systems were influenced by two human factors, including topical familiarity and confirmation bias tendency (Section5.2.1).
Next, we present the analysis of the variance of eye movement across different behavioral groups (Section5.2.2). As the eye movement data follows a normal distribution, our statistical analysis primarily applies parametric test.

Table3shows the analysis of ET metrics (i.e., total fixation counts and duration) between baseline and debate systems in how participants read the attitude-consistent vs. attitude-inconsistent information. Figure4shows total fixation duration on attitude-consistent vs. attitude-inconsistent information in both systems across different levels of topic familiarity and confirmation bias tendency. We introduce our statistical results as follows.

System comparison.As shown in Table3, our paired t-test revealed no significant difference in eye fixation counts and duration between attitude-consistent and attitude-inconsistent content in the baseline system, but a significant difference was observed with the debate system. Additionally, as both fixation counts and duration were statistically significant higher in the attitude-inconsistent information for the debate system, this indicates
participants’ greater willingness to engage with diverse perspectives in the debate system than the baseline.

Topic familiarity.By conducting a two-way ANOVA, we examined the effects of the topic familiarity and the content-belief consistency (i.e., whether user read information consistent with their beliefs) on ET metrics. We found that, there is no effect of topic familiarity influencing user eye movements in both systems. Content-belief consistency had a significant main effect on both total fixation counts (,) and duration (,), but it was only shown in the debate system not the baseline. Additionally, no interaction effects were shown in both systems.

Confirmation bias tendency.Another two-way ANOVA was conducted to examine the effects of the confirmation bias tendency and the content-belief consistency on ET metrics. We found that, unlike topic familiarity, the confirmation bias tendency had a significant main effect on both total fixation counts (,) and duration (,) in the baseline but no effect found in the debate system. Additionally, the content-belief consistency had a significant main effect on both total fixation counts (,) and duration (,) in the debate system but no effect in the baseline. This is similar to the previous ANOVA results. No interaction effects were shown in both systems.

The ANOVA analysis conducted above on content-belief consistency but separately with topic familiarity and confirmation bias tendency reveal a consistent result: there is a clear difference on whether participants reading content consistent or inconsistent with their attitude when using the debate system, as reflected in their eye movements, but no difference found in the baseline. While topic familiarity yields no difference in both systems, confirmation bias tendency resulted in significant difference on the baseline but not the debate system. In combined with the system comparison results shown in the paired t-test (Table3), we can conclude that the debate system effectively reduces selective exposure and increases user engagement with attitude-inconsistent content, while the baseline system activates confirmation bias tendencies, as evidenced by distinct eye movement patterns.

We also visualized participants’ eye movements across different behavior clusters in Figure5, separated into two systems.
A two-way ANOVA was conducted to examine the effects of the behavioral clusters and the content-belief consistency on ET metrics, specifically in debate system. We found that, for total fixation counts, the behavior clusters had a significant main effect (,), while the content-belief consistency did not. The interaction effects of behavior clustering and content-belief consistency were not significant.
Post hoc comparisons using the Tukey HSD test indicated that mean total fixation counts were significantly higher in cluster 2 (,) compared to cluster 0 (,) and cluster 1 (,).

These results suggest that there is significant difference in the eye movements between behavior clusters within the debate system,
As content-belief consistency did not significantly influence fixation counts, this suggests that user engagement levels were more closely tied to their behavior patterns when using the debate system rather than whether participants would read content associated with their prior beliefs. Additionally, as post-hoc analysis revealed thatCritical Readers(group 2) had significantly higher fixation counts compared to the other groups, this suggests thatCritical Readerswere more visually engaged with the content.
By associating with qualitative results, describing howCritical Readersactively engaged with various personas and generated content (Section5.1), we can conclude that certain behavioral pattern, i.e.,Critical Readers, show a clear sign of engagement demonstrated in their eye movement data.

SECTION: 5.3.RQ3: Comparison of User Belief Changes between Retrieval-based and Multi-persona Debate System

In this section, we first examine whether participant belief changed or remained unchanged across two systems and the influence of topic familiarity and confirmation bias tendency (Section5.3.1, similar to our approach for RQ2). Afterward, we explore in greater depth in terms of bidirectional belief changes, i.e., whether participants became more or less supportive, because this helps suggest whether there is a shift toward increased or decreased polarization (Section5.3.2). As the belief change data does not follow a normal distribution, we applies non-parametric test for analysis.

By visually presenting participant belief changes based on their topic familiarity (Figure6, the two plots on the left) and confirmation bias tendency (Figure6, the two plots on the right), we observed a clear trend indicating that participants with higher familiarity with the topic were less likely to change their beliefs. However, there is a less obvious trend shown in confirmation bias tendency. We conducted a generalized linear mixed-effects model analysis to quantify the statistical effects (model details were presented in AppendixF.2). The overall result demonstrates that there is a statistically significant difference across the various levels of topic familiarity and confirmation bias tendency on whether participants changed belief or remained unchanged, while the difference is not shown in interface conditions.
We briefly describe the mixed effects for each variable in details as follows.

System comparison:The system variable has an estimated positive coefficient of(,,). This suggests that participants using the debate system would slightly change their beliefs. However, this likelihood is very small and not statistically significant.

Topic familiarity:Topic familiarity has a statistically significant negative impact on belief change, with an estimated coefficient of(,,). This suggests that as participant familiarity with a topic increases, they become significantly less likely to change their beliefs.

Confirmation bias tendencyConfirmation bias tendency shows a statistically significant positive effect on belief change with an estimated coefficient of(,,). This means that participants with higher levels of confirmation bias tendency are more likely change their beliefs, which is counterintuitive to our understanding. By examining the different proportions of belief changes across CB groups, we found that the low tendency group had the highest individual percentage of belief change (25.6%), but the combined belief change percentages of the medium and high tendency groups (19.1% + 20.6% = 39.7%) were greater than that. This cumulative effect may indicate that participant belief changes might not operate neatly into a three-level continuum of confirmation bias tendency.

Correlation among three variables:As parts of the generalized fixed-effect results,
there is no moderate correlation among group interface, topic familiarity, and confirmation bias tendency, reflecting that these variables operated relatively independently in influencing belief change.

We examined how system conditions influence participant bi-directional belief changes, weighted by their confidence level, and explored this variance on topic familiarity and confirmation bias tendency.

System comparison:By mapping bi-directional belief changes — less supportive, more supportive, and unchanged — on both systems (Table4), we found that although many participants did not change their beliefs (=,=), more participants became less supportive after using the debate than the baseline (=¿=). Additionally, by conducting Wilcoxon sign-ranked test on the weighted belief change (in Table4, the last row, where the mean value ¡0 indicates becoming less supportive and ¿0 indicates becoming more supportive), the weighted belief change for the debate was significantly lower than that of the baseline (=¡=,,).

Topic familiarity:By visualizing participant weighted score for belief change across different levels of topic familiarity (Figure7, the two plots on the left), we found many participants did not alter their beliefs, which reduced the overall magnitude of changes shown in the box plots. However, among participants who did change their beliefs, there is a lowered central tendency (median and the interquartile range) in the experiment compared to the baseline. This expands on earlier findings of significant difference across levels of topic familiarity (Section5.3.1), demonstrating that, for participants who finally changed their belief, the debate system led them to become less supportive across different familiarity levels. Additionally, we also found the weighted belief change vary depending on different topics (additional analysis and findings are presented in AppendixF.3).

Confirmation bias tendency:By visually presenting participants’ bidirectional belief changes across different levels of confirmation bias tendency, we found a similar trend observed in the topic familiarity (Figure7, the two plots on the right). While many participants did not change their beliefs, reducing the overall magnitude changes as presented in the box plot, for participants who did changed their beliefs, the debate system made user less supportive across three levels of confirmation bias tendency, whereas the baseline tended to increase it.

By combining the statistical results in both Section5.3.1and5.3.2, we learned that while the system conditions did not yield a statistically significant difference on participant non-directional belief changes (i.e., whether participant belief changed or remained unchanged), for directional belief changes, there was a clear distinction. The debate system was more likely to cause participants to become less supportive of their initial stance, whereas the baseline tended to reinforce prior beliefs, making them more supportive. Additionally, user belief changes exhibited a statistically significant increase as topic familiarity decreased. While a statistically significant difference was also observed with confirmation bias tendencies, the trend did not fully align with our hypothesis. This discrepancy may be due to the three-level classification of bias tendency scores, indicating a need for further investigation in future studies.

SECTION: 6.Discussion

SECTION: 6.1.Enhancing Interaction

While our LLM debate system supports several forms of user interaction (e.g., topic selection, persona revision or creation, argument bookmarking, and controlling debate duration), participants offered several ideas to further increase interaction and engagement. Specifically, they sought greater ability to actively participate in and influence the debate.

For example, some participants suggested use of the search bar to allow them to inject their own opinions into an ongoing debate (P2-3). Similarly, some participants misunderstood the thumbs up and down bookmarking icons as allowing them to influence the ongoing debate and expressed a desire for this feature when realizing it was not supported (P26). Others requested the ability to highlight specific quotes from a persona content and prompt the persona to provide further information or supporting evidence (P25-26, 28, 39). A fact-checking feature was suggested to show the most recent evidence from the web for user-highlighted content, aiding in verification of arguments (P39).

SECTION: 6.2.Balancing Divergent Viewpoints and Convergent Solutions

While participants appreciated the system for broadening their understanding of controversial topics through multiple viewpoints, many expressed a desire for more concrete solutions to address the social issues being debated.

For example, some participants preferred concrete answers over the exchange of opinions. P13 noted personas“tend to stop at potential angles for the topic, but they don’t dive much deeper into more specific details.” P29 said “the chat didn’t address specific concerns and I couldn’t find a clear solution.” This led us to further reflect on
when a system should offer diverse perspectives vs. more concrete answers. Providing convergent viewpoints can help spur decision-making but may also lead toautomation biasin users too readily accepting system answers, something we sought specifically to avoid in our design. Bearing a more critical and constructive stance, we consider there are different design opportunities to balance divergent viewpoints with convergent solutions effectively.

First, convergent solutions could be presented when debate becomes congruent during the debate. For example, our participants noted that in the later rounds, the debate became less meaningful or began to repeat similar comments (P21, 26, 35, 40). Previous studies have reported similar findings, noting that LLMs tend to stop generating novel thoughts once they have established confidence in their responses — a phenomenon known as the “degeneration-of-thought” problem(Liang et al.,2023). While novel prompting techniques could be developed to help LLM continue generating new thoughts(Chen et al.,2023), or to allow participant inputs to illicit new generations, this might also be a sign for prompting convergent solutions instead of continued divergent brainstorming. Additionally, it may be necessary to distinguish between points of agreement and disagreement, and then generate solutions tailored to each(Shaikh et al.,2024a). Implementing this functionality could help transform the debate system for divergent thinking into more of a practical problem-solving tool. A practical feature would be automatically detecting when to wrap-up the debate and signal this to the user, improving our current design, which lacks guidance to the user when continued debate is unlikely to yield additional insights.

Second, while some contentious topics have little consensus (and so are very suitable for public debate), other topics have clearer scientific answers, such as whether climate change exists or the Earth is flat. In such cases, it can be not only misleading but harmful to present (and give standing) to arguments that continue to dispute well-accepted scientific facts. For example, fact-checking agencies often choose not to fact-check highly sensational claims for which the simple act of fact-checking would lend more credence and visibility to these claims than they merit(Phillips,2018; Procter et al.,2023).

Additionally, integrated fact-checking support might not be needed if the system automatically showed the (detected) reliability of all statements presented, such as based on evidentiary support. This could enable users to better calibrate their assessment of arguments presented with low vs. strong reliability indicators. Alternatively, we could further constrain and filter the debate (personas and/or arguments) to only include arguments meeting a minimum reliability bar. In this case, the “debate” may present diverse personas and evidence supporting a given stance rather than arguing for different positions.

All that said, one can still imagine cases where fringe opinions might be very valuable to include. A science educator might want to know why flat-Earthers believe what they do so that their beliefs may be effectively countered. A scientist operating at the frontier of their field may wish to explore a new idea that challenges accepted knowledge(Liu et al.,2024). A writer may be seeking assistance in generating dialogue for a fictional story or script(Wan et al.,2024). As in so many things, context matters. Therefore, design should strive to flexibly support such different contexts and needs so that the debate includes appropriate, responsible, and accurate presentation of information that is fit for purpose.

SECTION: 6.3.Addressing Potential Bias in LLM-generated Personas

LLM simulation may exhibit many inaccuracies vs. reality due to hallucination, random errors, and consistent biases. Approximation of diversity in the real world may over- or under-representing certain groups and perspectives. Such bias often stems from the limitations of training data that incorporate existing social inequalities, stereotypes, or incomplete views of the population(Christian,2020). Recent work has examined these misalignment across misinformation(Neumann et al.,2024), climate change(Santurkar et al.,2023), and politics(Taubenfeld et al.,2024).

In our study, we found that participants intentionally assessed whether LLM simulations accurately reflected the roles they represented (P19, 29, 31, 34, 38-39) and revised the descriptions if they considered simulations might be biased (P29, 34). Additionally, some participants even challenged the limits of LLM simulations by creating unconventional personas. For example, P34 created the persona of a foreigner with no ties to America to evaluate whether the LLM responses were both realistic and relevant to the federal corporate tax issue. P2 took on the persona of an animal to test if the LLM could effectively respond from an animal perspective on animal testing “I am surprised by the cat persona, it actually understands the description, hates dogs, and says things less logically.

Of course, users may hold their own biases toward certain social roles which could further reinforce their confirmation biases. The very flexibility our system enables users to customize the LLM personas and correct biases they find also means that they have the power to customize personas that reaffirm their existing beliefs. We cannot objectively evaluate how well participant customization reflects social roles within the demographic groups embodied by those personas. Future work should involve systematic socio-demographic studies to better understand, align, and compare user interpretations of personas with the biases present in LLM-generated personas(Kirk et al.,2024). Additionally, HCI research might consider how to balance giving users control over customization with ensuring representational diversity and fairness in LLM-generated personas.

SECTION: 6.4.Reducing Automation Bias in AI-Assisted Decision-Making

Although we did not explicitly assess the system’s impact onautomation bias(Bertrand et al.,2022)(i.e., whether participants would automatically follow AI suggestions or engage in deliberate decision-making), the debate format of arguing opposing positions directly avoids providing simple answers to users that might be accepted without deliberate engagement. The debate format, with high customization, forces users to think critically and objectively assess the different arguments presented. This contrasts with the more passive role users typically take in traditional AI-assisted decision-making scenarios, where they might simply accept AI decisions(Buçinca et al.,2021; Lai et al.,2023).

Many participants intentionally structured a robust debate by selecting or customizing personas with different stances on the question (P14, 22, 24). P22 stated, “I felt like the descriptions that it gave would give a good debate” P24 added, “I’d probably change these personas a little more into what I feel like would really structure a good debate.” Although asking people to grapple with uncertainty may be uncomfortable, this encourages users to engage with multiple viewpoints and think critically to promote more deliberate decision-making. We were inspired in part by prior work using cognitive forcing functions to mitigate user over-reliance on AI decisions(Buçinca et al.,2021; Gajos and Mamykina,2022). The debate system also offers this opportunity to help provide potential opposing viewpoints, fostering appropriate reliance in AI-assisted group decision-making(Chiang et al.,2024).

In general, participant comments suggested that they found it engaging and enjoyable to engage in this way (P12, 24, 32, 38), reflecting on their prior stances on social issues and becoming aware of their own biases (P33). P38 remarked, “It was interesting and nuanced to control an LLM, something I’ve never experienced before.” P33 noted, “I think I still have some personal bias in terms of what I look for more.” We aim to combine increasing exposure to diverse views — with an interface that promotes this rather than ignoring perspectives users might dislike — and avoiding spoon-fed answers that can be accepted without thought. By doing so, we hope to foster critical thinking and reduce reliance on automation, ultimately enhancing the decision-making process.

SECTION: 6.5.Limitations

The discussion above highlights several key limitations of our study. In this section, we outline these limitations concerning system design and development (Section6.5.1), sampling and test time (Section6.5.2).

As described in Section6.1, our current multi-persona debate system lacks some interactive features to increase user engagement, such as the ability to nudge debate conversations by incorporating user feedback and new inputs. Additionally, system improvements are needed to enhance debate quality (Section6.2), such as integrating RAG to reduce potential hallucination problems, refining prompting techniques to minimize repetitive responses from personas, and facilitating a natural closure in the debate (e.g., “I have nothing new to add”).

Additionally, because the system has not been evaluated for potential biases in its representations across topics and the persona, it is highly likely that biases in the LLM could impact the results of our user testing. Thus, in terms of system design, future studies could incorporate these interactive features to enhance user engagement and integrate more robust techniques to address potential biases within the system.

We also recognize that our findings are limited by the participant pool, which primarily consisted of college students. This focus restricts the generalizability of our results to a broader population. College students often lack real-world experience with certain controversial topics, which may affect their level of engagement and reduce the diversity of perspectives represented in the study. Expanding participant diversity in future research could not only broaden the range of perspectives for evaluating system effectiveness, enhancing generalizability, but also inspire new usage behaviors or scenarios for the debate system.

Additionally, our study restricted participant task time in the lab, which may have limited their ability to fully explore long-term interaction patterns with the system. Extended use of the system could potentially reveal different engagement behaviors and belief changes that were not captured within the current study time constraints. Therefore, both sampling and time limitations suggest that future studies should consider diverse samples and longer engagement periods to capture a more comprehensive understanding of the debate interface impact across varied user groups.

SECTION: 7.Conclusion

This study introduces and evaluates an LLM-powered multi-persona debate system designed to mitigate confirmation bias in information access.

The system presents diverse viewpoints through an interactive, persona-based interface where users engage with simulated debates across multiple perspectives on controversial topics. Through an in-depth, within-subject, mixed-method user study, we demonstrate that the multi-persona debate system significantly reduces confirmation bias by encouraging users to invest more attention in content that challenges their initial beliefs, as evidenced by the eye-tracking data and behavioral measures.

Our results provide valuable insights for designing future LLM-based systems to foster open-minded engagement with diverse viewpoints, encouraging unbiased information processing on complex or controversial topics.

SECTION: 8.Acknowledgments

This research is funded in part by Microsoft and by Good Systems101010https://goodsystems.utexas.edu, a UT Austin Grand Challenge dedicated to developing responsible AI technologies, as well as by the UT Austin School of Information. We extend our special thanks to Gauri Kambhatla for her assistance regarding polarization research, and to Anubrata Das and Sooyong Lee for their valuable feedback and insights. We are also grateful to our participants, without whom this research would not have been possible. The statements made herein are solely the opinions of the authors and do not reflect the views of the sponsoring agencies.

SECTION: References

SECTION: Appendix

SECTION: Appendix APrompts

SECTION: A.1.Prompt Placeholders

Throughout our prompts, we use placeholders, which are automatically replaced by their corresponding value as defined in our initial configuration. For all our current version of the system these values are:

[TOPIC]: The user-input topic to focus persona generation and debate discussion around.

[NUM_PERSONAS]: Initial requested number of personas

[CURRENT_PERSONAS]: Current personas in JSON format

[NAME]: Name of the persona

[DESC]: Description of the persona

[HISTORY]: Transcript of the debate in JSON format

[LIMITER]: Sentence telling the LLM how long their response should be (ie. Limit your response to 5 sentences).

SECTION: A.2.Persona Generation

Given the topic, [TOPIC], create a roundtable debate of different personas to show key perspectives of it. Output the personas as a list of JSON objects. Each JSON object should have the following structure:{ "title": <title of the Persona>,"description": <Brief Description of the Persona, only describing their background (rather than their stance)>,"emoji": <Single emoji representation of the perspective the persona represents>}.Ensure that the output is formatted as a valid JSON.Please generate exactly [NUM_PERSONAS] personas.

Given the topic, [TOPIC], we are creating a roundtable debate of different personas to show key perspectives of it.Currently, we have personas as follows: [CURRENT_PERSONAS]
Please output exactly one additional persona. Your output should have the following JSON structure:{"title": <title of the Persona>,"description": <Brief Description of the Persona, only describing their background (rather than their stance)>,"emoji": <Single emoji representation of the perspective the persona represents>}.Ensure that the output is formatted as a valid JSON.

SECTION: A.3.Persona Response

You are in an roundtable debate on the topic [TOPIC].You are [NAME], who is [DESC].Please start the debate by concisely presenting your
argument for your stance on the topic. [LIMITER]

You are in a continuing roundtable debate on the topic [TOPIC].You are [NAME], who is [DESC].Here is the transcript of the debate so far  [HISTORY]Please continue to debate the others, concisely supporting your stance on
the topic. [LIMITER]

SECTION: Appendix BMeasurements for data collection

SECTION: B.1.Pre task questionnaire

Please indicate your current stance on the given topic? [Supportive; Neutral/ Undecided; Opposed]

How confidence are you for your stance and reason? [Very low; Slightly low; Moderate; Slightly high; Very high]

How familiar are you with the topic? [Not familiar; Slightly familiar; Moderately familiar; Familiar; Very familiar]

SECTION: B.2.Post task questionnaire

Please indicate your current stance on the given topic? [Supportive; Neutral/ Undecided; Opposed]

How confidence are you for your stance and reason? [Very low; Slightly low; Moderate; Slightly high; Very high]

SECTION: B.3.Interview questions

When you were using the retrieval-based system,

what kind of information interested you most?

What document did you decide to read?

What were you looking for in the document page?

Which interface did you find most useful?

Did you find the content trustful/ useful? Why?

When you were using the multi-persona debate system,

How did you decide which persona to select to engage in the debate?

How did you decide how to switch agents between debate rounds?

Why did you change (not change) the personas between rounds?

How did you decide which persona to change/ keep between rounds?

How many rounds of debate did you usually read? Why did you want to proceed to the next round? When would you stop generating next round?

What kind of content interested you most/ helped you to explore the topic and make decision?

Did you find the bookmark function useful? Why?

How did you decide which information to save in the bookmark?

Did you find the LLM-generated information useful and trustful?

In general, how did you use these two systems to explore the diverse perspectives for the given topics? Where did you found most useful for your exploration?

For the two systems you used in this study,

Were you satisfied with the experience when using the systems?

Were you overloaded by information?

Was the design effective?

which one do you prefer?

Do you think your prior knowledge would influence how you use the systems?

When you were familiar with the topic, how would you use the systems?

when you were unfamiliar with the topic, how would you use the systems?

When exploring with the system, what factors/ information would make you shift your perspective?

SECTION: Appendix CBaseline Retrieval-based System

ArgumentSearch is a retrieval-based search engine that identifies articles from the open web and organizes content snippets according to their stance on the user query. We chose ArgumentSearch over standard search like Google or conversational search tools like Perplexity because it specifically organizes articles by stance (supportive or opposed), aligning with the core idea of presenting content from both sides of an issue to mitigate confirmation biases (as described in Section2.2). By comparing this system with the multi-persona debate system, we can more effectively evaluate the mere impact of personas while mitigating the common design effect of one-dimensional ranking in search results, which tends to naturally cause a reinforcement of user confirmation bias and echo chambers during the traditional information-seeking process.

SECTION: Appendix DParticipant Demographics

SECTION: Appendix EAdditional Findings regarding User Behavior Patterns

Beyond the main behavior clusters outlined in Section5.1, in this section, we provide additional analysis, describing the topical differences within these groups (SectionE.1) and additional qualitative findings regarding how our participants select and revise personas (SectionE.2).

SECTION: E.1.Topical differences among user behavioral clusters

Additionally, when we separated these behavioral groups across different topics, we observed significant differences. As shown in Figure9, for several topics, such as “Is vaping with E-cigarettes safe?” “Should the Federal corporate income tax rate be raised?” “Should TikTok be banned in
school?” and “Do violent video games contribute
to youth violence?”, the distribution of all three groups share a similar pattern111111The distribution of behavior patterns in the topic of “Should animals be used for scientific or commercial testing?” is similar to that of previous topics, but with a variation: there is a higher numberMulti-round explorerscompared toCritical readers. Among these topics, theCritical readersemerged as the majority group, followed by a smaller number ofMulti-round explorers, and thenActive observers. For other topics, including “Should humans colonize space?” “Should abortion be legal?”, and “Should the United States implement a universal basic income?”, theMulti-round explorerswere overwhelmingly the dominant group, with only a few participants classified asActive observersorMulti-round explorers. It is important to note that there was a significant shift of participants fromCritical readerstoMulti-round explorerswithin these two topic groups. This change indicates that participants began allocating more of their time to generating new rounds of debate and relatively less time to reading and analyzing the content. This shift may have happened because participants sought more in-depth or novel insights on these specific topics, encouraging them to generate more rounds of debate. Overall, these results suggest that topic-specific factors do influence
participant engagement patterns in using the debate system.

SECTION: E.2.Persona expertise, individuality, and diversity in selecting and revising personas

From the post-task interviews, we found three additional factors that participants frequently mentioned in selecting and revising personas, including personaexpertise,individuality, and the overalldiversityof personas when selecting and editing them to construct the debate. These factors were closely tied to how participants conceptualized the controversial topics being discussed.

First, many participants preferred selecting both expert and individual personas. Expert personas were more trusted to provide factual information, evidence, and other logical and reliable arguments to the controversial topic (P11, 14-15, 22, 24, 33, 36, 38-39). P39 explained that for the topic of “TikTok ban,” experts could provide opinions rather than emotional responses “Parents who are concerned about their kid is great, but I don’t expect them to have all of the data necessary to make an informed decision. I thought there would be experts discussing things logically and providing evidence-based information, as opposed to information driven by emotions.” In contrast, individual personas could provide direct and authentic arguments (P11, 22, 24-25, 33, 38). For example, P38 said “Whether TikTok should be banned from school. I really want from people who are in the school specifically because it’s important to see the people who are actually being affected to know their pain points. So that’s why I picked the teacher, the student, and the administrator.”

Additionally, as participants were aware that potential bias could underlie different personas,
participants aimed to create a balanced representation of opinions by selecting personas that supported different sides of the topic. On one hand, this approach could be an effective strategy for generating counterarguments (P14, 24, 26, 28, 33, 35-36), as P36 explained, “I tried to balance the number of people who supported the topic with those who opposed it, to sort of weigh which perspective truly aligns with my own thinking and against it.”
On the other hand, some would deliberately balance opinions that might be disproportionately represented on one side in real-world discussions (P22, 24, 33). P33 pointed out that“If I’ve been hearing a lot of one point of view, I’ll try to keep generating a persona until I find one that opposes it.”

SECTION: Appendix FAdditional Statistical Results

SECTION: F.1.Descriptive user behavior data in debate system

SECTION: F.2.Generalized linear mixed-effects model analysis

We conducted a generalized linear mixed-effects model to analyze whether participant belief changed or remained unchanged varies on participant topic familiarity and confirmation bias tendency across two systems (Section5.3.1). In this model, belief changes were treated as a binomial outcome (changed vs. unchanged), with user and topic included as random effects. The fixed effects included user confirmation bias tendency (CB), topic familiarity (TF), and the user interface (UI). We used the glmer function of the R package lme4121212https://cran.r-project.org/web/packages/lme4/index.htmlwith the formula:. We code higher value for each variable: a higher score on CB and TF reflects increased tendency on confirmation bias and topic familiarity; the experiment condition is coded with a higher value than the baseline.

SECTION: F.3.Distribution of bi-directional belief changes across topics

By mapping participant bidirectional belief changes across different topics (Table9), we found that the yielded system effects on weighted belief changes also vary on the topic. For example, in topics “Should animals be used for scientific or commercial testing?” and “Should humans colonize space?” (highlighted as orange) participants became more supportive of their previous stances after using the baseline. In contrast, for topics “Should the Federal corporate income tax rate be raised?” and “Do violent video games contribute to youth violence?” (highlighted as blue) participants became less supportive of their previous stance after using the experiment. This suggests that user belief changes differ depending on the topic, with some topics being particularly sensitive.