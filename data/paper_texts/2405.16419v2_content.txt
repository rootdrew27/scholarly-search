SECTION: Enhancing Feature Diversity Boosts Channel-Adaptive Vision Transformers
Multi-Channel Imaging (MCI) contains an array of challenges for encoding useful feature representations not present in traditional images. For example, images from two different satellites may both contain RGB channels, but the remaining channels can be different for each imaging source. Thus, MCI models must support a variety of channel configurations at test time. Recent work has extended traditional visual encoders for MCI, such as Vision Transformers (ViT), by supplementing pixel information with an encoding representing the channel configuration. However, these methods treat each channel equally,i.e., they do not consider the unique properties of each channel type, which can result in needless and potentially harmful redundancies in the learned features. For example, if RGB channels are always present, the other channels can focus on extracting information that cannot be captured by the RGB channels. To this end, we propose DiChaViT, which aims to enhance the diversity in the learned features of MCI-ViT models. This is achieved through a novel channel sampling strategy that encourages the selection of more distinct channel sets for training. Additionally, we employ regularization and initialization techniques to increase the likelihood that new information is learned from each channel. Many of our improvements are architecture agnostic and can be incorporated into new architectures as they are developed. Experiments on both satellite and cell microscopy datasets, CHAMMI, JUMP-CP, and So2Sat, report DiChaViT yields again over the state-of-the-art. Our code is publicly available at.

SECTION: Introduction
Most visual encoders assume they are provided with a fixed-channel representation as input (e.g., they take RGB inputs as input at train and test time). However, many applications find a variety of imaging techniques beyond just the traditional RGB channels beneficial. For example, satellite images or sensors onboard a robot often contain an infrared camera in addition to traditional RGB, and microscopes can also host a significant range of potential imaging channels. Thus, Multi-Channel Imaging (MCI) models aim to learn good feature representations from datasets with heterogeneous channels, where the number and type of channels can vary for each input at test time. Training a model that is robust to changes in channel configurations can save time and resources as only a single model needs to be learned, while also helping to prevent overfitting in small datasets through transfer learning. Prior work proposed methods to make MCI models robust to missing channels by randomly masking them during training. As shown in Fig.(a) left and (b) top, this results in redundancies being learned across channels during training rather than encoding new information. A consequence of this repetition is a model focused on learning strong cues that are easy to identify, making it less capable of learning unique and/or challenging cues within each channel.

To address this limitation, we propose aversennelsionransformer (DiChaViT) that aims
to balance the robustness in different MCI configurations, which may cause redundancy, with a need to learning diverse and informative features.
First, we include a Channel Diversification Loss (CDL), a regularization term that encourages a special channel token, which represents the presence of a channel in the input data, to be distinct from the other channel tokens. As shown in Fig.(a) right, this reduces repeated information across our model’s channels. However, this can still result in similar features being encoded for each image patch. Thus, our Token Diversification Loss (TDL) aims to directly diversify the features learned for each patch token as shown in the bottom of Fig.(b) by encouraging that each patch token is orthogonal to the others. Finally, rather than a uniform random channel masking strategy as used in prior work, we introduce Diverse Channel Sampling (DCS), in which we select channels based on their dissimilarity, further promoting feature diversity. We observe that promoting a more diverse representation enables each channel to contribute more to the final prediction, leading to a performance boost of up to% in downstream MCI tasks. Fig.provides an overview of our approach.

The work that is closest in spirit to ours are methods that are designed to learn disentangled representations,e.g., learning features aligned to a given set of attributes. These methods have shown a trade-off between the strength of the disentanglement and the downstream tasks performance. This is due, in part, to the fact that many attributes these methods aim to disentangle are correlated with each other, making it challenging to know what features relate individually to each attribute. However, unlike these tasks, MCI methods do not focus only on disentangling features across channels. Instead, they must capture some redundant information to be robust to missing channels while simultaneously learning features that may only arise in a subset (or even a single) channel. In other words, in MCI some redundancy is desirable across channels even if we could learn perfectly disentangled representations. In addition, many methods in disentangled representation learning assume the attributes to separate are labeled, but there are no labeled attributes in MCI. Instead, DiChaViT must automatically decide what to capture in multiple channels while still learning important channel-specific information.

We summarize our contributions below:

We propose DiChaViT as a solution to enhance feature diversity and robustness in MCI-ViTs, boosting classification accuracy byover the state-of-the-art on three diverse MCI datasets: CHAMMI, JUMP-CP, and So2Sat.

We introduce a new channel sampling strategy to encourage the selection of more distinct channel sets during training, thereby enhancing feature diversity in MCI models.

We introduce regularization and initialization techniques that better balance robustness to different configurations in MCI and facilitate learning diverse and informative features.

SECTION: Related Work
Researchers have been developing convolutional-based models to keep pace with the evolving landscape of multi-channel imaging data. Bhattacharyyaet al.introduced IRFacExNet, which utilizes depth-wise convolutions to merge channel-wise features from infrared thermal images. Jianget al.introduced a double-channel CNN that takes into account the correlation between input channels in aerial images. This approach employs a separate sub-network for each group of channels and then performs feature fusion to aggregate features across channels. Siegismundet al.presented DCMIX to work with images with many channels based on imaging blending concepts. While these methods can be used for MCI, they are not designed to work on varying input channels.
In a recent study, Chenet al.introduced and adapted channel-adaptive models based Depthwise convolutions, TemplateMixing, and HyperNets. These models incorporate their adaptive interface in the first layer of an otherwise shared ConvNeXt model. While these methods provide a strong baseline, they find settings where some channels are missing during inference challenging.
In our work, we aim to improve MCI model robustness by improving the diversity of learned features.

. Vision transformers (ViT)have natural advantages when dealing with multiple channels, especially when the number of channels varies. ViTs treat image modeling as sequence-to-sequence problems, allowing them to be flexible in handling different numbers of image tokens. Nguyenet al.introducedand, in which they divided each input channel independently into patches and then aggregated the patch features across channels using learnable queries. Tarasiouet al.proposed TSViT, which incorporates a tokenization scheme and temporal position encodings to process Satellite Image Time Series. In a relevant work, Zhouet al.introduced FAN, a channel reweighting design aimed at adjusting channel features based on the observation that some channels capture more significant information than others. In the medical domain, Hatamizadehet al.proposed UNETR that utilized a transformer encoder followed by a skip-connected decoder for 3-D medical image segmentation.
Recently, Baoet al.proposed ChannelViT that processes each input channel independently via a shared linear projection and incorporates a learnable channel embedding for preserving channel-specific features. In addition, the authors proposed Hierarchical Channel Sampling (HCS), a regularization technique applied to the input channels to boost robustness and reduce training time. ChannelViT outperforms standard ViTs in classification tasks and demonstrates its generalization ability when only a subset of the trained channels is available during inference. In a similar work, Bourriezet al.introduced ChAda-ViT, a channel adaptive attention technique for handling heterogeneous microscope images. However, these methods do not adequately model the unique properties of each channel type, resulting in harmful redundancies, whereas we boost the diversity of features across channels to enhance the robustness of MCI-ViT models.

SECTION: Encouraging Diverse Representations in multi-channel ViTs
Given a multi-channel image (MCI)containing channels, our goal is to train a modelthat takes our input imageas input to make its predictions. Following, we consider the MCI setting wherehas seen all the channels we expect to see during inference,i.e.,.
We leave the exploration of handling novel channels during inference for future work, as it presents significant challenges, including establishing meaningful connections between existing and new channels, and identifying informative channel weights in the presence of domain shifts.
In our setting, since we do not know whatwe may see during inference, prior work has focused primarily on exploring methods that are robust to different choices ofby encouragingto redundancies across channels (e.g.,). Specifically, they begin with a base ViT encoderthat uses each channel-specific image patchas input. Each image patch is passed through a shared patch projection layer and concatenated with its corresponding channel token. Hierarchical Channel Sampling (HCS)encourages robustness to missing channels by randomly masking some channels during training to ensure key information can be captured in multiple channels. However, as noted in the Introduction, this can be harmful whendoes not balance this repetitive feature learning to also capture distinctive channel-specific information.

As illustrated in Fig., DiChaViT aims to better balance repetitive and distinct feature learning through three major components. First, we use a Channel Diversification Loss (CDL) to learn diverse representations to help prevent feature collapse in the channel tokens (Sec.). Second, our Token Diversification Loss (TDL) encourages patch tokens to also learn distinct features (Sec.). Finally, Diverse Channel Sampling (DCS) promotes robustness to missing channels while also encouraging that new features are also learned during training (Sec.). These components enable our approach to balance repetitive and channel-specific feature learning (overview in Fig.).

SECTION: Enhancing channel token separation
Recall that in Fig.(a), learned channel tokensfrom prior work show high mutual information, indicating these tokens are not well-separated. Following, we partly mitigate this issue by replacing the random initialization ofused by prior workwith an orthogonal initialization. To further encourage the diversity in the features, we introduce Channel Diversification Loss (CDL) for increased separation between the channel tokens (Fig.(a)). Inspired by ProxyNCA++, the idea is to use a learnable vector (i.e., an orthogonally initialized) to represent each channel in the input image during training. We promote diversity in the channel tokens by pulling channel features toward their corresponding anchors while pushing them away from all other anchors. A key benefit of this approach is that the anchors prevent channel tokens from collapsing while still allowing for flexibility in learning useful representations.

Formally, we denoteas the set of all channel anchors,as the temperature, andas the-Norm. We start by initializing the channel tokensand their channel anchors orthogonally. Then, we apply CDL as follows:

whereis a function that returns a corresponding channel anchor for channel token, andis the squared Euclidean distance between channel tokenand an anchor. In Eq., the numerator calculates the distance of a channel token to its anchor, while the denominator computes all these distance pairs of the channel token to all the channel anchors. When the temperature valueis set to, we get a standardfunction. Lowering the temperature can lead to a more focused and sharp probability distribution, but we found that the results are not very sensitive to the value of. Thus, we simply use a fixed temperatureof.

SECTION: Enhancing feature diversity for patch tokens
MCI-ViT models like ChannelViT, ChAda-ViTuse a shared linear projection to extract features independently from each input channel in the image rather than using separate projections for each channel.
With the shared projection, only the common features across channels are retained, while other channel-specific information is filtered out, which helps to reduce overfitting. However, this design can also produce similar representations for all patch tokens. This is not ideal because each patch may contain unique information that would be ignored. In our approach, we also leverage this shared projection, but we enhance it with Token Diversification Loss (TDL), a regularization applied to the patch token features to enhance the diversity of features learned by each patch in the input image (see Fig.(b) for an overview). Specifically, we enforce an orthogonality constraint on the tokens to ensure that each token is orthogonal to the others. Additionally, we take into account the token type information to differentiate between tokens from the same channels and across channels. The main idea is to make features from different channels more distinct while allowing for a certain level of similarity among features within the same channel.

Letbe the input patch at position, andbe the shared linear projection at the first layer. We denoteas the patch feature token of,as the set containing all patch feature tokens in the input image, andas a function that returns the corresponding channel for input patch. We devise a unified loss function for each input image as follows:

whererepresents the cosine similarity,denotes an absolute value, andare the numbers of patch token pairs in the two equations respectively. Eq.calculates the average cosine similarity of all feature token pairs in the same channels, while Eq.calculates the average of all feature token pairs from different channels. The two losses are combined with weightsandto balance the constraint of tokens belonging to the same channels (first term) and tokens belonging to different channels (second term), to form the final lossin Eq.. Our goal is to encourage each patch token to be orthogonal to each other to promote the diversity of patch tokens.

SECTION: Diverse Channel Sampling (DCS)
Baoet al.introduced HCS to reduce the training time and improve the robustness of the model. The main concept is to randomly drop some input channels and train the model only on the remaining channels. In the same spirit, we propose a novel method, Diverse Channel Sampling (DCS), to sample a more diverse subset of channels during training (Fig.(c)). Similar to HCS, we start by randomly sampling a number, which is the size of a subset of channels to train on. However, while HCS sampleschannels randomly, DCS first samples an anchor channel. Then, we select otherchannels that are dissimilar to the anchor channel. This idea shares similarity with Channel DropBlock, where a set of similar channels in a CNN layer is masked out to disrupt co-adapted features. However, instead of keeping a fixed number of feature map channels as in Channel DropBlock, DCS selects a flexible number of input channels for each sampling. The procedure of DCS is outlined in Algorithm.

In practice, Algorithmcan be applied to a batch of images for faster sampling. We use channel tokento represent the channel feature. Refer to Sec.and Tab.for more discussion on choices of. The temperaturecontrols the sharpness of the probability distribution. With a large, DCS reduces to HCS, while with a small, DCS selects a random subset of channels that are the least similar to the anchor channel.

SECTION: Training Objective
The final loss consists of the primary loss for the specific task (e.g., cross-entropy for classification), Channel Diversification Loss (CDL) applied to channel tokens, and Token Diversification Loss (TDL) used on patch tokens. These terms work together to promote diversity in channel and patch token features, resulting in a more robust model, as shown in Eq.:

whereis a weight to balance CDL. Note that TDL is balanced byandin Eq..

SECTION: Experiments
SECTION: Experimental Setup
We adopt the following baseline methods.

utilizes a depthwise convolution layer to independently filter each input channel. The resulting features are averaged to create a new feature representation, which is then fed into a ViT backbone.

generates weights for each channel by learning a linear combination of shared, learnable parameter templates. These weights are formed into a patch project layer, followed by a ViT backbone.

employs a neural network (e.g., MLP) to independently generate weights for each channel, which are then concatenated to form a patch projection layer. This patch projection layer is subsequently used in a ViT backbone.

uses a shared projection layer to extract features from each channel separately, then feeds these tokens, together with their corresponding positional embeddings and channel embeddings, into a ViT backbone.

is the same general architecture as ChAda-ViT, but also employs Hierarchical Channel Sampling (HCS) during training.

As HCS proves robust in multi-channel imaging, we incorporate this technique for DepthwiseViT, TemplateMixingViT, and HyperNetViT to ensure a fair comparison in these adaptive baselines used by Chenet al.. For ChannelViT and ChAda-ViT, due to their similarity (primarily a difference in whether HCS is included), we use the implementation fromfor both methods. All baselines utilize a ViT small architecture (M parameters) implemented in DINOv2as the backbone.
We use AdamW optimizerto train the models, minimizing cross-entropy loss on JUMP-CP and So2Sat, and proxy loss on CHAMMI. For the learning rate, we use a scheduler with linear warmup and cosine decay. Refer to Appendix Sec.for details.

We evaluated the methods by calculating their top-classification accuracy on the So2Satand JUMP-CPdatasets. For CHAMMI, we used the evaluation codeprovided by the authors, in which a 1-Nearest Neighbour classifier is used to predict the macro-average F1-score for each task separately. We report the average score on WTC and HPA, and present the detailed results in Tab.of the Appendix.

SECTION: Datasets
consists of varying-channel images from three sources: WTC-11 hiPSC dataset (WTC-11, three channels), Human Protein Atlas (HPA, four channels), and Cell Painting datasets (CP, five channels). The three sub-datasets contain a total ofK microscopy images, of whichK images are for training and the rest for testing across various tasks. The models are trained to learn feature representation and then evaluated on domain generalization tasks.

comprises images and profiles of cells that were individually perturbed using chemical and genetic methods. Our experiments focus on the compound perturbation plate BR00116991, which containsK training images,K validation images, andK test images. Each image has eight channels, with the first five beingand the remaining three containinginformation. The dataset consists ofclasses, includingperturbations and a control treatment.

contains synthetic aperture radar and multispectral optical image patches from remote sensing satellites. Each image in the dataset haschannels, of which eightandchannels. The dataset consists ofclasses, each representing a distinct climate zone. We use the city-split version of the dataset, which includesK training images andK test images.

SECTION: Results
Tab.shows that DiChaViT outperforms the state-of-the-art ChannelViT by up to% points on all three datasets: CHAMMI, JUMP-CP, and So2Sat.
For JUMP-CP and So2Sat, we consider two scenarios: tested on all training channels (denoted as "Full") and tested on a subset of channels (denoted as "Partial"). In the full channels setting, our model shows a% point improvement compared with other baselines on JUMP-CP and So2Sat. When tested on partial channels, DiChaViT demonstrates its robustness by achieving a% improvement compared with the baselines. This demonstrates that diversifying feature representations in MCI-ViT models boosts both performance and robustness.

Tab.presents a detailed evaluation of DiChaViT and the best baseline model, ChannelViT, when tested on partial channels of the JUMP-CP dataset (with a total of eight channels). For the partial channel evaluation, we exclude some of the channels that the models were trained on and only test the model on the remaining channels. Then, we calculate the average accuracy across all combinations,e.g., testing on seven channels, as shown in column "7", involves averaging the results ofcombinations (refer to Tab.in the Appendix for detailed results). Our findings consistently show that DiChaViT demonstrates improved robustness when some input channels are missing.

To provide more insight into the contribution of each component of DiChaViT, Tab.presents the model’s performance when a component is removed. The results highlight the critical role of the DCS component, as its removal has the most detrimental effect
on performance, particularly in thesetting, with a decrease of% and% points on JUMP-CP and So2Sat, respectively. The absence of CDL and TDL results in similar performance drops across all datasets. The highest scores are achieved when all components are integrated, indicating that each component plays a
crucial role in the model’s design. Refer to Tab.in the Appendix for a comprehensive analysis.

SECTION: Analysis and Discussion
In MCI-ViT models such as ChannelViTand ChAda-ViT, channel tokens play a crucial role in learning channel-specific features, particularly when dealing with multiple channels where each contains unique information.
To assess the impact of channel tokens, we compared the performance of DiChaViT on JUMP-CP and CHAMMI(orange bars) andchannel tokens (blue bars), as shown in Fig.. The results indicate that DiChaViT demonstrates significant improvements with channel tokens, resulting in% and% point increases on JUMP-CP and CHAMMI, respectively, highlighting their importance.

As shown in Fig., using orthogonal initialization (green) provides a% gain on JUMP-CP and CHAMMI. This may suggest that by initializing the weights orthogonally, the model can more effectively capture diverse patterns within the data, resulting in boosting its overall performance.

Fig.(a) and (b) show the performance of DiChaViT (and) across different values ofon So2Sat and CHAMMI datasets. We can observe that selecting a value that is too large is not beneficial to the performance. It is worth finding a suitable value for. On the So2Sat, the best performance is achieved with, while the suitable value for CHAMMI is.

Fig.(c) reports the performance of our model across different ratios ofandin TDL. We set a fixed value ofatand vary. We observe that using a largercompared withleads to better performance for DiChaViT. This suggests that knowing which channel a token comes from,i.e., theorchannel, is necessary. The results indicate imposing stricter constraints on tokens from different channels compared with tokens from the same channel obtains the best performance.
Tab.shows the impact of each component in TDL. We see that considering only tokens within the same channels (denoted by "Only") is insufficient, resulting in a significant drop in performance. In contrast, using bothandin TDL yields the best performance of DiChaViT.

. Tab.compares the performance of using channel tokens () and patch tokens (i.e., image patches after passing through the projection layer) to compute the similarity score for sampling in Algorithm(line 3). We observe that using channel tokens gains better performance on So2Sat and CHAMMI datasets. Note that while channel tokens are shared across all input images, patch tokens differ for each input image.

Tab.shows the effect of temperatureused in Algorithmon DCS. Whenis set to a very small value, as reported in the first column (denoted as ""), DCS selects channels with the lowest similarity scores to the anchor channel. Conversely, whenis assigned a large value, denoted as "HCS" in the last column, DCS is reduced to HCS, meaning that it selects the subset of channels randomly. We find that always selecting the lowest similar channels () does not yield the best performance. Instead, setting the temperature toproduces favorable results for both So2Sat and CHAMMI.

Fig.compares the number of times each channel is sampled during training with
DCS (blue bars) and HCS(red dashed line). DCS offers a different distribution for its channels compared with HCS, with some channels receiving more training than others. For example,() in the last bar, is sampled twice as frequently aschannel (first bar).

SECTION: Conclusion
In this paper, we present DiChaViT, a model aimed at enhancing feature diversity and robustness in Multi-Channel Imaging (MCI) ViTs. First, we introduce Diverse Channel Sampling, a novel channel sampling strategy that encourages the selection of more distinct channel sets during training, thereby promoting feature diversity. Additionally, DiChaViT incorporates Token Diversification Loss on the patch tokens and Channel Diversification Loss for channel tokens to further diversify the features learned in MCI-ViTs. Our experiments demonstrate a% point improvement over state-of-the-art methods on satellite and microscopy imaging datasets. Many of our enhancements are not tied to any specific architecture and can be incorporated into new architectures as they are developed. DiChaViT represents a promising advancement in addressing the challenges associated with MCI, paving the way for more effective MCI-ViT models.

The development of DiChaViT represents an advancement in MCI, with potential positive impacts such as improved medical diagnosis and accelerated healthcare research. Additionally, its versatility in satellite imaging holds promise for environmental monitoring. However, there are also potential negative impacts, including the risk of bad actors using this research to develop harmful applications, such as invasive surveillance systems. This highlights the importance of ethical considerations and responsible deployment.
One of the limitations of our work is that it is not designed to handle novel channels. Generalizing to unseen channels is challenging because it requires establishing a connection between existing and new channels. This is further complicated in the presence of domain shifts, which makes finding the informative channel weights even more difficult. Thus, investigating techniques to adapt to new channels at test time is a promising research direction in MCI. In addition, our approach requires extra hyperparameter tuning, which may necessitate additional compute resources.

SECTION: Acknowledgments and Disclosure of Funding
This material is based upon work supported, in part, by the National Science Foundation under award DBI-2134696. Any opinions, findings, and conclusions or recommendations are those of the author(s) and do not necessarily reflect the views of the supporting agencies.

SECTION: References
SECTION: Implementation details
We utilize a ViT small architecture (M parameters) implemented in DINOv2as the backbone for all the baselines. Specifically, we use ViT-S/16 (patch size of) on CHAMMI and JUMP-CP, and ViT-S/8 (patch size of) on So2Sat. The AdamW optimizeris used to train the models, minimizing cross-entropy loss on JUMP-CP and So2Sat, and proxy loss on CHAMMI.

The goal of CHAMMI is to train a model to learn the feature representation for the input image. Thus, we use thetoken at the final layer as the feature representation and train the model to minimize the proxy loss. We then evaluate the model on various tasks following the evaluation code provided by the authors, in which a-Nearest Neighbour classifier is used to predict the macro-average F1-score for each task separately. The channel-adaptive interfaces are adapted from the author’s implementation code. Besides the model, we incorporate the same data augmentation as introduced by the authors, such as thin-plate-spline (TPS) transformations. We train each model forepochs with a learning rate of, and a batch size of.

. Following Baoet al., the learning rate is warmed up for the initialepochs, peaking atafter which it will gradually decay tofollowing a cosine scheduler. We also apply a weight decay ofto the weight parameters, excluding the bias and normalization terms to mitigate overfitting. Additionally, we use the same data augmentation as used in the code provided by the authors. To get the final prediction, we pass the Transformer encoder’s representation for thetoken into a classifier head to predict the probability of each class. We train each model forepochs, with a batch size ofon JUMP-CP, andon So2Sat. We adapt the code provided by the authorsfor the baselines in our work.

In this study, experiments were conducted on So2Sat and CHAMMI using a single NVIDIA RTX (48GB RAM) and three Intel(R) Xeon(R) Gold 6226R CPUs @ 2.90GHz. For experiments on JUMP-CP, two NVIDIA RTX A6000 GPUs and six Intel(R) Xeon(R) Gold 6226R CPUs @ 2.90GHz were utilized.

SECTION: Additional experimental results
. Tab.shows an extension of the main resulting table in the main paper (Tab.), where we include CNN-based (ConvNeXt backbone) models from. To ensure a fair comparison, we adjust the number of layers in these CNN-based models so that all models in Tab.have approximatelyM parameters. We can observe that in general, DiChaViT outperforms CNN-based and ViT-based models on the three datasets.

.
Tab.extends Tab.in the main paper to have a better understanding of the individual effects and contributions of each of the losses. We observe that adding DCS helps improve the performance (e.g., by% on CHAMMI), and robustness of the model, especially when tested on partial channels (a boost of% on So2Sat Partial). Similarly, TDL and CDL also show improvement across the three datasets. For example, TDL improves the performance by% on CHAMMI and% on So2Sat on full channels.

Fig.illustrates the distributions of channel tokens(blue) and(red) CDL. Each subplot presents the distribution of a trained channel token on the CHAMMI dataset. We observe that CDL results in more flattened distributions with more non-zero values in the channel tokens.

Fig.shows an extended version of Fig.(b) in the main paper, where we calculate the attention scores of thetoken to the patch tokens at layers,, and(the penultimate layer), and then aggregate them by channel. This indicates that ChannelViT (top) relies more heavily on specific channels (e.g.,and) for making predictions, while other channels (e.g.,and) are less considered. In contrast, DiChaViT (bottom) displays more evenly distributed attention scores across channels, indicating that each channel contributes more significantly to the model’s predictions.

In Tab., we provide individual channel combination results when using seven channels (of eight) of the JUMP-CP dataset for inference. This corresponds to the details in column "7" from Tab.in the main paper, representingdifferent channel combinations. For each combination, we report theandof the models computed over three runs. Our results demonstrate that DiChaViT gets% better performance for each combination while also providing more stable results (i.e., smaller model variance) than baseline ChannelViT.