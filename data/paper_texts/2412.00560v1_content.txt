SECTION: Friend or Foe? Harnessing Controllable Overfitting for Anomaly Detection

Overfitting has long been stigmatized as detrimental to model performance, especially in the context of anomaly detection. Our work challenges this conventional view by introducing a paradigm shift—recasting overfitting as a controllable and strategic mechanism for enhancing model discrimination capabilities. In this paper, we present Controllable Overfitting-based Anomaly Detection (COAD), a novel framework designed to leverage overfitting for optimized anomaly detection. We propose the Aberrance Retention Quotient (ARQ), a novel metric that systematically quantifies the extent of overfitting, enabling the identification of an optimal ”golden overfitting interval”. Within this interval, overfitting is leveraged to significantly amplify the model’s sensitivity to anomalous patterns, while preserving generalization to normal samples. Additionally, we present the Relative Anomaly Distribution Index (RADI), an innovative metric designed to complement AUROC-pixel by providing a more versatile and theoretically robust framework for assessing model performance. RADI leverages ARQ to track and evaluate how overfitting impacts anomaly detection, offering an integrated approach to understanding the relationship between overfitting dynamics and model efficacy. Our theoretical work also rigorously validates the use of Gaussian noise in pseudo-anomaly synthesis, providing the foundation for its broader applicability across diverse domains. Empirical evaluations demonstrate that our controllable overfitting method not only achieves State-Of-The-Art(SOTA) performance in both one-class and multi-class anomaly detection tasks but also redefines overfitting from a modeling challenge into a powerful tool for optimizing anomaly detection.

SECTION: 1Introduction

In the traditional context of machine learning, overfitting has long been perceived as an undesirable phenomenon, just like[3,8,10,20], traditionally viewed as the result of a model excessively memorizing training data, leading to compromised generalization capabilities. However, we challenge this conventional wisdom by extending the concept beyond the domain of anomaly detection, positioning controllable overfitting as a versatile mechanism for enhancing model sensitivity across a wide range of applications. This leads us to the central question that underpins our work: can overfitting be a friend rather than a foe in the domain of anomaly detection?

The conventional understanding of overfitting necessitates a significant paradigm shift. Historically stigmatized as inherently detrimental to machine learning models, overfitting, as our research demonstrates, can under specific controlled conditions be repurposed as a powerful mechanism for enhancing model performance. In scenarios where training data consists solely of normal samples, we show that allowing the model to comprehensively memorize these features enhances its sensitivity to deviations—namely, anomalies—during testing. This reframing positions overfitting not as an inherent flaw to be avoided, but as a strategic asset to be leveraged effectively.

Anomaly detection in visual domains is a crucial task that aims to identify patterns that do not conform to expected behavior. Traditionally, anomaly detection relies on the notion of learning the distribution of normal data and distinguishing anomalies by identifying outliers. Various methods have been proposed to achieve this, including reconstruction-based approaches[31,15,30], embedding-based models[25,32,13,9], and anomaly synthesis technique[4,28,17,23].

We advance the notion of controllable overfitting, suggesting that a calculated and moderate degree of overfitting enables the model to capture intricate and subtle characteristics of the data. This heightened focus allows for a pronounced contrast when confronted with previously unseen deviations—precisely what is required for successful detection tasks, as opposed to a simplistic pursuit of generalization. This approach provides an opportunity to redefine how we evaluate model capabilities in environments devoid of training data that represents the full spectrum of possible scenarios. In this paper, we presentControllable Overfitting-based Anomaly Detection, calledCOAD.

Our theoretical framework and empirical validation jointly support this proposition. We demonstrate that, as the degree of overfitting increases, the score distribution for normal samples evolves accordingly, while the score distribution for anomalous samples remains stable. By introducing theAberrance Retention Quotient, calledARQ, as an overfitting parameter, coupled with a noise loss term to finely control the degree of overfitting, we have identified an optimal ”Golden Overfitting Interval”that maximizes detection efficacy without compromising model reliability. This strategic balance enables robust differentiation between normal and anomalous samples, providing a substantial performance boost.

We also introduce a novel metric, the Relative Anomaly Distribution Index, calledRADI, to differentiate from traditionalAUROC-pixelmeasures. UnlikeAUROC-pixel,RADIis derived from the cumulative distribution function (CDF) of the normal and anomalous pixel prediction score distributions. WhileRADIprovides an indirect reflection of detection performance and maintains a similar trend toAUROC-pixel, it also offers a more versatile framework for theoretical modeling and practical discussion of model capabilities. This distinction underscores its value as a complementary tool, adding a new layer of analytical depth to our approach.

Moreover, we substantiate the rationale for employing Gaussian noise in pseudo-anomaly detection modules. Through calculating the Total Variation Distance (TVD) between actual anomaly data and a Gaussian distribution across the entire dataset, we obtain a fair result. This outcome indicates a high level of similarity between true anomalies and a Gaussian distribution, thereby providing a theoretical validation for the common practice of using Gaussian noise as an effective pseudo-anomaly generator in previous works likeGLASS[4]andSimpleNet[17]. This insight not only strengthens our methodology but also offers a theoretical foundation for broader applications in anomaly detection frameworks.

To summarize, the key contributions of our work are as follows:

We challenge and transcend the conventional understanding of overfitting, positioning it as a controllable and transformative mechanism capable of unlocking model capabilities beyond traditional boundaries.

We introduce theARQto precisely regulate the overfitting degree and theRADIas a complementary metric toAUROC-pixel, providing a more adaptable tool for mathematical modeling and facilitatingDual Control Mechanismwith the
use ofCOAD.

Our approach dismantles the demonization of overfitting, repurposing it as a generalizable module and achieving SOTA results in bothone-classandmulti-classanomaly detection tasks. We also provide a theoretical foundation for utilizingGaussian noiseas a preliminarily pseudo-anomaly generator.

SECTION: 2Related Work

SECTION: 2.1Overview of Anomaly Detection

Reconstruction-based methods are founded on the hypothesis that models trained exclusively on normal data can successfully reconstruct normal instances while failing to do so for anomalies, thereby using reconstruction error as a measure of abnormality. Notable reconstruction-based approaches include Autoencoders (AE)[29,33], Generative Adversarial Networks (GANs)[7,15], and Reverse Distillation (RD)[6,23]. Specific methods under these categories, such asDSR[31],RealNet[32], andDRAEM[30], attempt to learn the representation of normal data and generate accurate reconstructions for normal samples but tend to produce significant residuals for anomalous inputs.

Recent developments have seen the use of embedding-based methods, besides reconstruction-based methods. These models leverage pre-trained networks to extract features from input images, aiming to separate anomalies from normal samples within the feature space. Anomalies are identified based on the distance between their embeddings and those of normal samples. Techniques such asDouble-MMD RGP[25],RealNet[32],PyramidFlow[13], andCFlowAD[9]utilize this paradigm, some of which employ a memory bank to store representative features and apply distance metrics to detect anomalies. Embedding-based methods are particularly valuable in high-dimensional feature spaces, where the intricate relationships between different regions of the data can be better captured using a pre-trained model’s learned representations.

Another line of research focuses on synthetic anomaly generation, a strategy that involves creating pseudo-anomalies to augment training data and improve detection performance. These synthetic anomalies are used to provide explicit anomaly labels in the training set, converting the unsupervised task into a form of supervised learning. Notable techniques includeCutPaste[14], which pastes cut-out normal patches in different positions, and methods such asGLASS[4],UniAD[28],SimpleNet[17],RealNet[32],andDDPM[12], all of which employ Gaussian noise to generate synthetic anomalies at both feature and image levels. These approaches help in training the model to differentiate between normal and abnormal samples, thus improving its ability to detect true anomalies. By contrast, methods such asDRAEM[30]andDMDD[16]employ Berlin noise or other forms of noise, which have not demonstrated the same level of effectiveness in anomaly detection tasks. In subsequent sections, we will theoretically justify the use of Gaussian noise in these pseudo-anomaly generation modules, establishing its effectiveness and reasonableness as an anomaly synthesis strategy.

SECTION: 2.2One-classvs.Multi-class

Our method builds on existing frameworks in anomaly detection and requires a deep understanding of these foundational models. Without a comprehensive grasp of their structure and mechanisms, our method may be misapplied, leading to suboptimal outcomes. Hence, we will conduct demonstrative experiments from bothone-classandmulti-classperspectives.

One-classanomaly detection focuses on modeling the distribution of normal data to identify deviations. Methods such asRD[6]andRD++[23]are foundational in this area.RDemploys a pretrain model for feature extraction, whileRD++further enhances this process for improved robustness.

Multi-classanomaly detection handles diverse object categories and intra-class variations. Notable approaches likeUniAD[28]andHVQ-Trans[18]effectively generalize across multiple classes.

SECTION: 2.3Non-Diffusionvs.Diffusion-Based

For the purpose of making our method easier for readers to understand and apply, we have also supplemented it with the diffusion-based framework.

Non-diffusion methods, such asUniAD[28], have been effective for anomaly detection but often face limitations in preserving the semantic consistency of anomalous regions, especially in complex settings.

Diffusion-based methods have recently gained traction due to their exceptional reconstruction capabilities, as evidenced byDiAD[11], which stands out among contemporary methods.DiADemploys a diffusion framework for generating anomalies while maintaining semantic information.

SECTION: 3Method

SECTION: 3.1Overview

AsFig.2shows, our works provides an overview of our proposed framework for enhancing anomaly detection through controllable overfitting. We introduceControllableOverfitting-basedAnomalyDetection, calledCOAD. We systematically integrate novel elements such asARQfor quantifying overfitting andRADIas a complementary metric for AUROC-pixel. These components collectively facilitate the monitoring, control, and optimization of the overfitting process to maximize model sensitivity while preserving generalization capabilities.

SECTION: 3.2Quantifying Overfitting withAberrance Retention Quotient

The exploration of overfitting has largely been confined to its avoidance, and there has been a conspicuous lack of systematic studies on how to control or even beneficially leverage overfitting for enhancing model capabilities. Moreover, existing research lacks a quantitative metric that accurately reflects the extent of overfitting, which is critical for understanding its implications and finding the ”sweet spot” in model training. To fill this gap, we introduce theAberranceRetentionQuotient, calledARQ, a novel metric designed to quantify the degree of overfitting by capturing the model’s divergence from true data representation during training.

TheARQis formally defined as follows:

where N represents the total number of instances,represents the predicted output at theinstance, anddenotes the corresponding original ground truth value. The numerator captures the aggregate prediction deviation from the true labels across all data points, while the denominator represents the totality of the predicted target values, normalizing the aberrance in the context of the entire dataset.

ARQis a core metric in our framework that quantifies the progression of overfitting during model training. By trackingARQ, we identify thegolden overfitting interval, where the model’s sensitivity to anomalous patterns is maximized without compromising generalization. Specifically, we denote the interval of optimalARQas:

whereis the baseline value around which the optimal range is established,is a quantity of the same order of magnitude as, representing the permissible deviation from the baselinewithin the optimal range, which indicates the region in which the overfitting is leveraged most effectively.

As overfitting progresses,helps us mitigate false positives while reducing false negatives,Fig.1(a)andFig.1(b)illustrate some cases. By effectively usingARQ, we transform overfitting into a controlled mechanism that enhances model robustness and discriminative power for anomaly detection.

SECTION: 3.3Bridging Theoretical Modeling and Practical Anomaly Detection withRelative Anomaly Distribution Index

To facilitate the mathematical treatment later, we made the following two assumptions, which were verified in subsequent experiments, please seeSec.4.

At anAberrance Retention Quotientof, the prediction scores of normal pixelsfollow a normal distribution dependent on:

where the meanand variancevary withARQ. As theARQincreases, the model’s memory of normal samples is enhanced, potentially resulting in:

The meanbecoming closer to the average value of the training data.

The variancedecreasing due to the model’s predictions on normal samples becoming more stable.

The variance of normal pixel prediction scores decreases exponentially with increasingARQ, expressed as:

whereis the initial variance (without overfitting), andis a positive constant representing the rate at which variance decreases. This relationship shows that as the model overfits, its prediction on normal samples becomes more stable.

The prediction scores of anomalous pixelsfollow a fixed normal distribution that does not change withARQ:

since anomalous pixels are not present during training, and the model cannot memorize them.

After these assumptions, we introduce theRelativeAnomalyDistributionIndex, calledRADI, a novel metric designed to bridge theoretical modeling and practical anomaly detection. Unlike traditional metrics such asAUROC, which are often used to evaluate model performance in anomaly detection tasks,RADIprovides an indirect yet insightful measure of the model’s capacity to differentiate between normal and anomalous samples. This makes it particularly valuable for theoretical analyses, while also retaining practical utility in assessing model effectiveness.

TheRADIquantifies the overlap between normal and anomalous score distributions, akin to theWilcoxon rank-sum[24]andMann-Whitney U tests[19].RADIis calculated using the cumulative distribution function (CDF) of the score distributions:

whereandrepresent the scores of anomalous and normal pixels, respectively.

It might seem counterintuitive why usingRADIas an indicator would enhance model performance, as one might think that maximizing this value would lead to the model predicting everything as anomalous. However,RADIitself is not directly used for model optimization; rather, it serves as a metric to reflect the optimization outcome and help identify the extent to which normal and anomalous distributions are distinguishable. The goal is to ensure that anomalies receive consistently higher scores compared to normal samples, which allows the model to achieve better discrimination.

Moreover, the relationship between overfitting and variance is controlled byEq.8, which ensures that the variance of normal pixel predictions () does not decrease to zero due to the noise term. This prevents the variance from collapsing entirely, maintaining a distinction between normal and anomalous scores. Thus,RADIcan increase without the model predicting all samples as anomalous, as variability in normal predictions remains above a non-zero threshold, sustaining a balance between sensitivity to anomalies and generalization.

RADIprovides a probabilistic assessment of whether anomalous scores exceed normal scores, offering insights into model discrimination. While similar toAUROCin reflecting a model’s ability to distinguish between normal and anomalous samples,RADIcalculates this directly through distribution comparison rather than at multiple thresholds. It is particularly useful for quick theoretical assessments, whereasAUROCis better suited for comprehensive performance evaluations across thresholds.

Overall,RADIcomplementsAUROCby providing a simplified measure of the model’s discriminative power, effectively reflecting its trend without requiring threshold-based evaluations.

For our case, where bothandfollow normal distributions,RADIcan be further expressed in a simplified analytical form:

whereis theCDFof the standard normal distribution. In this case,andare the means of the anomaly and normal pixel score distributions, respectively, whileandare their respective standard deviations, withrepresenting theAberrance Retention Quotient.

Eq.7highlights the dependence ofRADIon the statistical properties of the score distributions. Asincreases, the standard deviationof the normal scores will decrease due to the model’s increasing ability to memorize normal patterns, which results in a more stable distribution for normal scores. This reduction in variance directly affects the value ofRADI, increasing the probability that the anomalous scores are distinguished from normal scores, thereby enhancing the detection capability of the model.

However, when overfitting is excessive, the model may start to memorize noise, leading to instability in prediction scores, and the variancewill no longer decrease and could even increase. To describe this phenomenon, we introduce a noise term:

whererepresents the noise impact induced by overfitting and can be expressed as:

whereis the maximum noise variance,controls the rate of increase of noise variance, andis the threshold ofARQwhere noise starts to appear. When,.

To find the optimalAberrance Retention Quotientofthat maximizesRADI, we calculate the derivative ofand set it to zero.

The derivative is as below and we set the derivative to zero:

whereis the probability density function of the standard normal distribution.

This implies either(unrealistic as variance cannot be zero) or. Thus, solving yields:

We defineAberrance Retention Quotientof, adjusted to optimize thepixel-level AUROC. The mathematical relationship betweenARQandAUROCis established by monitoring the gradient, We call itGradient-Guided Overfitting Control.

We integrateinEq.2andGradient-Guided Overfitting ControlinEq.13and call this combined control mechanism theDual Control Mechanism:

IfDual Control Mechanismfails, theDual Control MechanismtriggersFreeze Command Signals, which prompt whether freeze certain network layers, beginning with lower-level feature extraction layers and moving upwards.

The rationale for progressively freezing certain layers while overfitting the other parts lies in the architecture’s functional partitioning. Lower layers are responsible for extracting fundamental features, which are common across both normal and anomalous data. Freezing these layers early preserves their ability to extract generalizable features, preventing degradation due to overfitting. Conversely, keeping deeper layers unfrozen during the overfitting stage enables the model to specialize in identifying unique, high-level features that are more discriminative between normal and anomalous samples. This approach helps maintain generalization while enhancing sensitivity to rare patterns, ultimately boosting anomaly detection performance without succumbing to the pitfalls of overfitting the entire model.

SECTION: 4Experiments

SECTION: 4.1Dataset

We evaluate our method using the MVTec AD dataset[1], which is a comprehensive, real-world dataset for unsupervised anomaly detection tasks. The MVTec AD dataset includes 15 categories, comprising 3629 images for training and 1725 images for testing. The dataset provides pixel-level annotations for each anomaly, making it suitable for evaluating both image-level classification and pixel-level segmentation tasks.

SECTION: 4.2Comparison with SOTAs

In this section, we compare the performance of our proposed method with several SOTA anomaly detection methods in both one-class and multi-class tasks.

Using the optimalARQvaluederived from theas indicated byEq.12, we setARQto 0.006 forone-classtasks and 0.06 formulti-classtasks.is defined asforone-classtasks andformulti-classtasks, where the balance between overfitting and generalization is optimal for anomaly detection. We saved model states within these intervals and evaluated their performance across respective benchmarks to ensure robust detection.

Furthermore, during model training, we adopted aDual Control Mechanismfor Optimal Detection Performance approach in our frameworkCOAD, as detailed inEq.14, and whenDual Control Mechanismfails, it triggersFreeze Command Signals, prompting the selective freezing of certain network layers in the traditional
framework.

Our method builds upon existing anomaly detection frameworks. Initially, we perform standard training on the original model. Following this, we transition into the controllable overfitting stage, during which the model is further trained using ourCOADframework. This stage utilizesDual Control MechanisminEq.14. All pseudo-anomaly generation in this stage is performed using Gaussian noise to introduce controlled variability, which aids in refining the model’s sensitivity to anomalies. Additionally, the learning rate is reduced toof that used in the normal training stage, allowing the model to make finer adjustments.

After training, the inference of the model proceeds in the same manner as the baseline anomaly detection frameworks, ensuring that the enhancements provided byCOADintegrate seamlessly.

The results of ourone-classandmulti-classexperiments are summarized inTabs.1and2. It can be observed that our enhanced method outperforms the original methods, achieving newSOTAresults. The enhancement in pixel-level AUROC is especially significant, which is crucial for fine-grained anomaly detection.

These results confirm that the introduction of controllable overfitting, regulated byARQandRADI, enhances the model’s sensitivity and stability, leading to robust anomaly detection abilities that outperform existingSOTAmethods.

SECTION: 4.3Ablation Study

We conduct an ablation study comparing our enhanced framework with its corresponding basic versions inTabs.3and4. The results demonstrate consistent and notable improvements in both image-level and pixel-level AUROC across all evaluated frameworks.

In particular, the performance gains observed in image-level anomaly detection emphasize the strength of ourCOAD, which effectively captures subtle differences between normal and anomalous regions. Specifically, our enhancements yielded an increase of up to1.9in theDiADframework, as seen in image-level AUROC, and similar significant improvements in other frameworks.

For pixel-level AUROC, a similar pattern of improvement was observed, with gains of up to1.2seen in multiple frameworks, as shown inTab.4. This underscores the strength of ourCOAD, which not only optimizes image-level detection but also provides enhanced granularity in distinguishing pixel-level abnormalities.

Furthermore, the versatility of our method is evident in its applicability to different anomaly detection paradigms. Whether inone-classormulti-classanomaly detection tasks, or even in settings employingdiffusion-basedmodels versusnon-diffusionframeworks, our method has consistently demonstrated superior performance, showcasing our method’s robustness and generalizability.

In this section, we compare the performance of different models under distinctARQranges to validate the impact of controllable overfitting on anomaly detection. We evaluated methods such asRD,RD++,UniAD, andDiADacross variousARQlevels. AsTabs.5and6show, the results demonstrate that, by appropriately regulating theARQ, which is in, model detection performance can be significantly enhanced. It is evident that our controllable overfitting strategy not only yields consistent improvements across different models but also helps in striking the optimal balance between overfitting and generalization.

Overall, these results demonstrate that our controllable overfitting strategy consistently yields significant performance gains across various models and tasks. By leveraging theARQwithin the identified optimal range, we successfully enhance the models’ discriminative abilities while maintaining a balanced relationship between overfitting and generalization.

SECTION: 4.4Validation of Distribution Assumptions and Theoretical Validation ofGaussian NoiseUsage

In this section, we firstly validate the assumptions introduced inSec.3.3.1by employing the Total Variation Distance (TVD) metric. We leveraging multiple models at different stages of overfitting, characterized by distinctARQvalues. For each model state, corresponding to differentARQ=, we calculate the prediction scores for both normal and anomalous pixels across the dataset. Subsequently, we evaluate their proximity to a Gaussian distribution using TVD, ensuring a robust assessment of the normality of these distributions. The partial results of this validation are summarized inTab.7. Moreover, we model the variance of the normal pixel prediction scoresas an exponential function of theARQ=, given byEq.4.

To validate the suitability of Gaussian noise as a pseudo-anomaly generator, we employ the TVD metric to quantitatively compare the distribution of real anomaly scores with that of Gaussian-distributed pseudo-anomalies. We can seeTab.7, the resulting TVD value was about0.08, suggesting that the Gaussian-distributed pseudo-anomalies exhibit a significant overlap with the actual anomalies. This supports the assumptions that Gaussian noise can be effectively used to preliminarily simulate anomalous behavior in training models for anomaly detection, which is usually used byGLASS[4],SimpleNet[17],RealNet[32],andDDPM[12].

SECTION: 5Conclusion

In this work, we reenvisioned overfitting as a controllable and transformative mechanism, usingCOADto enhance model capabilities beyond conventional boundaries. We introducedARQto precisely regulate overfitting, as well asRADI, which leveragesto provide a more versatile metric compared toAUROC-pixel, facilitating both theoretical modeling andDual Control Mechanism. By repurposing overfitting as a generalizable module, our approach not only dismantles its demonization but also enables us to achieve SOTA results in bothone-classandmulti-classanomaly detection tasks. Furthermore, we provide a robust theoretical foundation for employing Gaussian noise as a preliminary pseudo-anomaly generator, extending the applicability of ourCOAD.

SECTION: References

Supplementary Material

SECTION: 6Dual Control Mechanism Design Concept

Overfitting has traditionally been viewed as a problem that hampers generalization—where the model memorizes noise and specific details of the training data, leading to poor performance on unseen examples. However, in the context of anomaly detection, we posit that overfitting can be harnessed as afeature, not a flaw. The key lies in the concept ofcontrollable overfitting—managing overfitting in a way that makes the model more sensitive to subtle differences between normal and anomalous data.

In practical terms, overfitting can amplify the sensitivity of the model to slight deviations, which is particularly useful in anomaly detection scenarios, where anomalies are often defined by subtle discrepancies from the norm. Our approach aims to leverage this characteristic to enhance detection capability while avoiding the negative consequences of overfitting, such as loss of generalization. This balancing act necessitates a carefully designed mechanism, which we call theDual Control MechanisminEq.14.

TheDual Control Mechanismis comprised of two complementary components:inEq.2andGradient-Guided Overfitting ControlinEq.13. These components work together to ensure that overfitting remains within beneficial bounds, ultimately enhancing anomaly detection without sacrificing the ability to generalize effectively.

TheARQquantifies the degree of overfitting by capturing the relationship between the model’s fit to the training data and its potential for retaining useful deviations that indicate anomalies. We define an optimal interval for ARQ, denoted asARQoptimal, which represents the range where overfitting is beneficial—significantly enhancing sensitivity to anomalies without compromising generalization.

During training,ARQis continuously monitored to ensure it remains within this optimal interval. IfARQmoves outside the defined range, corrective actions are taken to bring it back. The optimal interval allows the model to exploit overfitting in a targeted manner, enhancing the model’s sensitivity towards subtle anomalies while minimizing the risk of memorizing noise.

AlongsideARQoptimal, theGradient-Guided Overfitting Controlis employed to supervise how overfitting impacts anomaly detection performance directly. This component utilizes theRelative Anomaly Distribution Index (RADI)to quantify the overlap between normal and anomalous score distributions. By keeping track of the gradient ofRADI, we can ensure that the anomaly detection performance is on an upward trajectory during overfitting.

Specifically, we require that the gradient ofRADIwith respect toARQis non-negative, which indicates that the model’s ability to distinguish anomalies from normal data is improving as overfitting increases. If the gradient condition is violated, indicating that overfitting is leading to a decline in detection performance, additional measures are triggered.

In situations where theDual Control Mechanismfails—meaning both theARQexceeds the optimal range and theGradient-Guided Overfitting Controlshows deteriorating performance—we initiateFreeze Command Signalsin. These signals are the model’s way of mitigating excessive overfitting by progressively freezing network layers.

Freeze Command Signalsbegin by selectively freezing the lower-level feature extraction layers, which are primarily responsible for capturing fundamental visual features such as edges, textures, and basic shapes. These foundational features are generally invariant across different images and therefore require less flexibility once they are well-trained. By freezing these lower-level layers, we stabilize the feature extraction process, reducing the risk of the model overfitting to noise and minute variations in the training set. As training progresses and overfitting persists beyond the optimal range, additional higher-level layers are frozen progressively in a staged manner. This gradual freezing strategy ensures that while the foundational layers remain stable, the more abstract, task-specific layers retain flexibility long enough to refine their understanding of anomalies.

By progressively freezing layers, the model maintains stable low-level feature extraction while allowing the higher-level layers to refine their understanding of anomalies. This approach ensures that the model retains a balance between maintaining its basic feature extraction capabilities and enhancing its discriminative power for anomaly detection.

TheDual Control Mechanismthus provides a comprehensive way to manage overfitting during training. By monitoring bothARQand theRADIgradient, and employingFreeze Command Signalswhen necessary, our framework transforms overfitting from a challenge into an asset—amplifying the model’s ability to detect anomalies while maintaining robustness and generalization.

SECTION: 7Main Functional Pseudocode

SECTION: 8Extended Discussion of Gaussian Noise Validation

SECTION: 8.1Theoretical Rationale for Gaussian Noise

In this work, we chose to use Gaussian noise as a preliminarily pseudo-anomaly generator due to its statistical properties and simplicity. Gaussian noise, characterized by its mean and variance, serves as an ideal candidate for generating random deviations that can mimic unexpected patterns in normal data.

From a theoretical standpoint, Gaussian noise exhibits a distribution that is both isotropic and well-defined in high-dimensional space, making it suitable for approximating unstructured, irregular anomalies. The Central Limit Theorem (CLT) supports the use of Gaussian distributions as approximations for many naturally occurring random processes. In particular, when adding minor perturbations to an image, we aim to simulate unforeseen deviations from the underlying structure of normal samples, which Gaussian noise effectively captures.

Additionally, Gaussian noise serves as a zero-mean stochastic process, allowing us to avoid introducing any specific directional bias, which could potentially interfere with the model’s capacity to learn anomalous versus normal regions. By employing Gaussian noise, we ensure that our model does not overfit to particular anomaly patterns but instead gains a generalized sensitivity to any divergence from the normal data distribution. This universality underpins our approach to controllable overfitting within theCOADframework.

SECTION: 8.2Validation Through Total Variation Distance (TVD)

To validate the suitability of Gaussian noise as a pseudo-anomaly generator, we conducted an empirical analysis using theTotal Variation Distance (TVD)metric. TVD is a standard measure used in probability theory to quantify the dissimilarity between two distributions. We calculated TVD to evaluate how closely Gaussian noise could mimic true anomalies in both spatial and intensity domains.

The calculation of TVD involves estimating the difference between the empirical distributions of Gaussian noise and the true normal and anomaly pixel intensities:

whererepresents the empirical distribution of the true anomalies, andrepresents the empirical distribution of Gaussian noise. TVD measures the extent of overlap between the two distributions, where a smaller TVD implies a closer approximation between the pseudo-anomalies and real anomalies.

We conducted experiments on our dataset using both generated Gaussian noise and real anomalies. presents a comparison of the TVD values for different classes. The results indicate that the Gaussian distribution closely matches the distribution of real normal and anomalies across a range of classes. Specifically, it can be seen inSec.4.4.

SECTION: 8.3Experimental Results and Qualitative Study

The experimental results demonstrate that the model trained using Gaussian noise exhibits a better anomaly detection performance to models trained with other pseudo-anomaly generator.

To further validate the results, we present detailed histograms for the anomaly detection scores obtained across 15 individual categories as well as the overall dataset. These histograms were generated under the condition where theAnomaly Rate Quotient (ARQ)is set to 0.006, usingRD++as our baseline framework. Each histogram inFigs.3and4provides a clear visualization of the distribution of detection scores, overlaid with a Gaussian fitting curve for enhanced interpretability. This fitting curve highlights the distribution, allowing for a more effective comparison of the model’s performance across different categories and the overall dataset, further solidifying the reliability of our evaluation metrics.

SECTION: 8.4Future Directions with GLASS-like Pseudo-Anomaly Generators

While Gaussian noise has proven effective as a preliminary pseudo-anomaly generator, future work could explore more advanced methods inspired by theGLASSapproach[4]. TheGLASSmethod introduces a structured way to generate pseudo-anomalies by leveraging geometric transformations and localized pattern synthesis, providing greater control over anomaly characteristics.

By incorporating concepts fromGLASS, we envision aGaussian Noise-Enhanced GLASS-like Generator, where Gaussian noise could act as the foundational perturbation, and additional constraints or transformations could be applied to shape the pseudo-anomalies in a contextually relevant manner. For instance, augmenting Gaussian noise with spatial or intensity correlations reflective of real anomalies could enhance its realism and improve model robustness in detecting diverse anomalies.

Such an approach would align well with ourCOADframework, enabling a more versatile training process that accounts for both unstructured and structured anomaly patterns. By systematically integrating these future developments, we aim to refine our anomaly detection strategy, bridging the gap between theoretical advancements and practical applications.

SECTION: 9Qualitative Comparison of Anomaly Detection between Different Baselines and COAD

To further validate the effectiveness of our methods, we provide a qualitative comparison of anomaly detection results across 15 distinct categories using baselines such asRD,RD++,UniAD,DiAD, and the proposedCOADframework inFigs.5,6,7and8. Each subfigure demonstrates: (from left to right) the original image, the ground truth anomaly mask, the result from the baseline method, and the result after applyingCOAD.

The comparison shows thatCOADeffectively reduces both false positive rates (FPR) and false negative rates (FNR), accurately capturing anomaly regions while minimizing misclassifications. These results are consistent with the improvements reflected in the earlier quantitative data inTabs.3and4, whereCOADconsistently outperforms its counterparts in image-level and pixel-level AUROC metrics, highlightingCOAD’s capability to outperform the baselines.

By leveraging controllable overfitting,COADenhances the model’s sensitivity to true anomalies while maintaining its generalization capabilities. The reduction in FPR minimizes the misclassification of normal regions as anomalies, while the decreased FNR highlights the model’s ability to capture subtle anomalies that baseline methods often miss. These qualitative and quantitative improvements collectively demonstrate the robustness and effectiveness ofCOADin advancing anomaly detection tasks. Additionally, the sharper distinction between normal and anomalous regions demonstrates the framework’s capacity to refine boundary precision, further enhancing detection reliability.

SECTION: 10Future Work

In future work, we plan to refine our pseudo-anomaly generators by incorporating advanced methods inSec.8.4, enabling the generation of more structured and domain-relevant pseudo-anomalies.

Moreover, we intend to explore the application of theCOADframework in other domains, particularly in areas such as medical imaging, autonomous driving, and forgery detection. Forgery detection, for instance, highlights an opportunity to utilizeCOAD’s enhanced sensitivity to subtle anomalies, such as fine-grained pattern inconsistencies or texture deviations. Furthermore, we aim to generalize and modularize theCOADframework into a plug-and-play component that can be seamlessly integrated into similar tasks across various fields. Ultimately, we aspire to redefine the concept of overfitting itself, transforming it from a perceived limitation into a powerful tool that drives innovation.