SECTION: Transportation Marketplace Rate Forecast Using Signature Transform
Freight transportation marketplace rates are typically challenging to forecast accurately. In this work, we have developed a novel statistical technique based on signature transforms and have built a predictive and adaptive model to forecast these marketplace rates. Our technique is based on two key elements of the signature transform: one being its universal nonlinearity property, which linearizes the feature space and hence translates the forecasting problem into linear regression, and the other being the signature kernel, which allows for comparing computationally efficiently similarities between time series data. Combined, it allows for efficient feature generation and precise identification of seasonality and regime switching in the forecasting process.

An algorithm based on our technique has been deployed by Amazon trucking operations, with far superior forecast accuracy and better interpretability versus commercially available industry models, even during the COVID-19 pandemic and the Ukraine conflict. Furthermore, our technique is able to capture the influence of business cycles and the heterogeneity of the marketplace, improving prediction accuracy by more than fivefold, with an estimated annualized saving of $50 million.

SECTION: Introduction
Linehaul freight transportation costs make up a significant portion of overall Amazon transportation costs. To manage these costs, Amazon has developed a variety of tools to manage linehaul capacity mix and procurement. One key input to all of these models is a forecast of transportation freight marketplace rates, which however are notoriously difficult to forecast – they are driven by a number of factors: the ever-changing network of tens of thousands of drivers, shippers of all sizes with a mix of occasional, seasonal, and regular demands, a huge set of brokers, traditional and digital exchanges, and local, regional, national, and international economic factors of all kinds. In addition, the transportation marketplace frequently goes through fundamental shifts – either because of wars, pandemics, fuel prices, or due to shifting international trade patterns.

Although Amazon has purchased externally created forecasts for some time, these forecasts are neither explainable nor sufficiently accurate to meet specific Amazon needs. To address this challenge, we have built a forecasting model based on time series data to predict weekly freight marketplace rates for the North America market, at both the national and the regional levels. Our approach incorporates an innovative signature-based statistical technique capable of efficiently capturing significant fluctuations in transportation marketplace rates.

Time series data consists of sequential observations recorded over time and is ubiquitous: finance, economics, transportation, weather, and energy prices. Given time series data, forecasting additional data points is critical for informed decision-making and process optimization in almost every organization and industry.

Time series prediction models such as Autoregressive Integrated Moving Average (ARIMA)and Exponential Smoothingassume that the time series are stationary, which is not the case for freight marketplace rates. Moreover,
ARIMA has limited ability to capture seasonality and long-term trends, and Exponential Smoothing may be insufficient for abrupt changes or outliers and produce unstable forecasts. Furthermore, these methods rely solely on historical data from the time series, which is inadequate in capturing the causal relation between the economic factors and the marketplace rates. Meanwhile, machine learning algorithms such as Long Short-Term Memory Neural Networksand Gated Recurrent Units, though capable of capturing nonlinear relationship and complex patterns in time series data, will require substantially more training data which is not available in our case.

Indeed, one of the main challenges in analyzing time series data is their ever-changing statistical properties, due to factors including changes in business and economic cycles, shifts in policy, or changes in market conditions. In our case, the market itself has recently experienced shifts inand, in terms of volatility, trends, and cyclical patterns, partly due to the COVID-19 pandemic and the Ukraine conflict.

Much of statistical learning theory relies on finding a feature map that embeds the data (for instance, samples of time series) into a high-dimensional feature space. Two requirements for an ideal feature map are, meaning that non-linear functions of the data are approximated by linear functionals in the feature space; and, meaning that the expected value of the feature map characterizes the law of the random variable. It is shown that with the technique of the signature transform these two properties are in duality and therefore often equivalent. This is the primary inspiration for our proposed signature-based forecasting technique for our forecast models.

Originally introduced and studied in algebraic topology, the, sometimes referred to as theor simply, has been further developed in rough path theory, introduced for financial applicationsand machine learning, and most recently to time series data analysis. Given any continuous or discrete time series, their signature transform produces a vector of real-valued features that extract information such as order and area, and explicitly considers combinations of different channels. The signature of time series uniquely determines the time series, and does so in a computationally efficient way. Most importantly, every continuous function of a time series data may be asymptotically approximated by a linear functional of its signature. In other words, signature transform linearizes the otherwise complicated feature space, and thus is a powerful tool for feature generation and pattern identification in machine learning.

We
propose a novel signature-based statistical technique for the time series forecasting problem. This is based on two key elements of the signature transform.
The first is the universal nonlinearity property of the signature transform, which linearizes the feature space of the time series data and hence translates the forecasting problem into a linear regression. The second is the signature kernel which allows for computationally efficient comparison of similarities between time series data. Technically, this is to identify different “signature feature maps”, the statistical counterpart of identifying different distributions for a given time series data, albeit in the linearized feature space from the signature transform.

Our approach starts by collecting data including a hundred of market supply and demand factors, and runs a correlation test between the marketplace rate and the factors to remove non-significant factors and to identify factors that may be colinear. We then exploit the universal nonlinearity property of signature transform to construct signature features as suitable candidates for the “internal” features. To avoid issues of overfitting and co-linearity between the signature
feature and the external factors, and to improve the forecast accuracy, we adopt the two-step LASSO for the regression analysis.
Finally, this two-step LASSO is enhanced with adaptive weight using a signature kernel, which enables capturing changes in regimes or seasonality.
Combined, this leads to our signature-based adaptive two-step LASSO approach. This novel signature-transform-based technique for data analysis allows for efficient feature generation and more precise identification of seasonality and regime switching embedded in the data.

This signature-based adaptive two-step LASSO algorithm has been implemented for the trucking operations in Amazon since November 2022. Performance analysis shows that our forecast model presents superior performance than commercially available forecast models, while providing significantly better interpretability. Despite the onset of COVID-19 and the Ukraine conflict,
it captures the influence of business cycles and heterogeneity of the marketplace, improves prediction accuracy by more than fivefold, and has an estimated annualized saving of approximatelymillion.

SECTION: Technical Background
SECTION: Signatures of Continuous Paths
We begin with the definition of signatures of continuous piecewise smooth paths.

Letdenote the space of all real tensors with shape. Define a binary operation called, denoted by, which maps a tensor of shapeand a tensor of shapeto a tensor of shapevia. When applied to two vectors, it reduces to the outer product. Let, andfor, in each case withmany.

Exampleshows that the signature for a one-dimensional path only depends on its total increment. In general, it implies that the signature of a path itself may not carry sufficient information to fully characterize the path. Nevertheless, this problem may be resolved by considering theversion of the original path (see Definition, Theoremandbelow).

SECTION: Signature of Discrete Data
To define and compute signatures of discrete data streams, one can simply do linear interpolations and then apply signature transforms.

SECTION: Key Properties of Signature
In fact, the signature not only determines a path uniquely up to translation, but alsoany continuous functions of the path, as stated in the next theorem.

Thisis the key property of the signature transform and is important for our model, and in general for applications in feature augmentations. See,,for examples.

Note that the signature by definition is an infinite-dimensional tensor. In practice, one can only compute the truncated signaturein () up to some depth. The next result guarantees that reminder terms in the truncation decay factorially.

The next property about signatures, Theorem, is the. It implies that the signature encodes the data by its arrival order and independently of its arrival time. This is a desired property in many applications such as hand-writing recognition,. Meanwhile, there is an interesting interplay between Theoremand Theorem: in a problem where time parameterizations are irrelevant, it suffices to compute the signature ofby Theorem; However, if time parameterization is important, then according to Theorem, applying the signature transform to the time-augmented pathensures that parameterization-dependent features are still learned.

Note that by Theorem, the signature of a stream of data is independent of the choice ofin a linear interpolation in (). Meanwhile, by Theorem, in order to learn parameterization-dependent features, one can apply the signature transform to the time-augmented data stream, where, andis the time when the data pointarrives.

Letbe a data stream of lengthinThenhas

components. In particular, the number of components does not depend on the length of the data stream. The truncated signature maps the infinite-dimensional space of streams of datainto a finite-dimensional space of dimension. Thus the signature is an efficient way to tackle long streams of data, or streams of variable length.

SECTION: Computation of Signature Transform
The signature transform of a data stream can be computed in an efficient and tractable way, with the help of Chen’s identity. It starts by introducing the followingoperation:
with, defineby

Chen’s identitystates that the image of the signature transform forms a group structure with respect to. That is, given a sequence of dataand some,

Furthermore, from Example, the signature of a sequence of length two can be computed explicitly from the definition. Letting

then

Chen’s identity further implies that the signature transform can be computed by

() implies that computing the signature of an incoming stream of data is efficient and scalable. Indeed, suppose one has obtained a stream of data and computed its signature. Then after the arrival of some more data, in order to compute the signature of the entire signal, one only needs to compute the signature of the new piece of information, which is then computed via the tensor product with the previously-computed signature.

Recall from () that the signature may be computed by evaluating severalin () andin (). We begin by noticing that the key component in the computation is to evaluate

Instead of computingconventionally through the composition ofand,suggests to speed up the computation by Horner’s method. More specifically, it is to expand

so that the-th term can be computed by

As proved in, this method has uniformly (over) fewer scalar multiplications than the conventional approach, and reduces the asymptotic complexity of this operation fromto. Furthermore, this rate is asymptotically optimal, since the size of the result (an element of), is itself of size.

SECTION: A Generic Framework for Linear Statistical Models with Signature Transform
The universal nonlinearity of the signature transform (cf. Theorem) suggests that linear models can effectively capture complex non-linear relationships between factors and targets. This section introduces a generic framework for time series forecasting that integrates linear statistical models with the signature transform, utilizing its capacity to encode intricate temporal patterns. Additionally, a weighting technique based on signature kernelsis incorporated into the linear models to enable adaptive weighting and regime switching.

SECTION: Forecasting Problem
Consider a time series forecasting problem involving two time series,and. Here,is a-dimensional vector representing the factor values available at time. The objective is to predict the value offor a given time interval.
Thus, the goal is to find a (possibly nonlinear) modelsuch that, whereis the class of all admissible models.

More specifically, given data up to time,, the goal is to predict. A standard approach for findingis to solve the following optimization problem:

whereis a loss function that quantifies the discrepancy between the model predictionand the actual value.
Onceis obtained, the prediction foris given by.

SECTION: Our Approach
We present a generic framework that integrates linear statistical models, signature transform, and signature kernels.

For any time stepand time window size, denoteas the slice of the time seriesfrom timeto.
Letbe the depth of the truncated signature andbe the depth-signature transform of the truncated pathfrom timeto.

Letdenote a class of linear models that mapto. Given a training dataset, the optimal predictoris determined by minimizing the empirical loss:

whereis the loss function, whose form depends on the specific choice of the linear statistical model.
For example, in the case of ordinary least squares (OLS), the loss functionis defined as the squared error between the actual and predicted values, i.e.,

For Lasso regression, the loss function is augmented with an-regularization term to promote sparsity in the parameters, resulting in

whereis the regularization parameter. Similarly, Ridge regression incorporates an-regularization term to penalize large parameter values, leading to the loss

The choice of the specific linear model and its associated loss function depends on the characteristics of the data and the desired trade-off between prediction accuracy and model parameter sparsity.

In the classical approach of linear statistical models in (), each historical sample is given equal weight in the optimization problem to obtain the model at time. However, this equal-weight scheme may fail to account for changes of regime or seasonality.
Instead, a more effective approach would be to dynamically assign weights based on their similarity to the current period. This is precisely what we propose, as elaborated below.

First, recall the signature feature map (Theorem),

is a universal feature map from the path space to the linear space of signatures.
To avoid computation over a large space of functions, we kernelize the signature feature mapin (), and define the signature kernel,
for any discrete time seriesandas suggested in.
Hereis the inner product on the linear space of signatures.

Next, to measure the similarity between two discrete time seriesand, consider the distance induced by the signature kernel,

Smallimplies a higher similarity between patterns inand, which suggests thatandcome from the same regime and share the similar seasonality. In practice, one may truncate the signature to depthwhen computing (), and we denote the distance computed from the depth-truncated signature by.

Finally, we adapt the weights in the linear models according to the signature kernel, this is called. It takes five hyper-parameters: a forecast horizon, a window size, a signature depth, a temperature parameter, and the distance metric.
More precisely,
definefor any;
for anyand, denoteas a slice of the time seriesfrom timeto.
At each time,takes the historical samplesas input, and outputs an adaptive weight vector

with. That is,will assign a higher weightto the sampleif the seasonality pattern near timeis more similar to the current seasonality pattern embedded in the sample.
Thus, when a new data sample arrives,
the weight vectorwill be recomputed by themodule, to adapt to changes in the recent data samples.

Measuring similarity via signature kernel leads to a novel linear modeling approach, in which we propose to adapt weights according to the similarities between time series data to capture seasonality and regime switching embedded in the data.
In the case of forecasting models with signature transforms, comparing similarities of data translates to identifying “signature feature maps”. This is the statistical equivalence of identifying different distributions for a given set of data, albeit in the linearized features space from the signature transform.
Algorithmsummarizes this
approach of adaptive linear models via signature kernel, by integratingoutlined in Algorithmwith the linear modeling in ().

SECTION: Forecasting Problem of Transportation Marketplace rate
The freight marketplace rate forecast problem involves two time seriesand. Here,is a-dimensional vector representing values of the key economic factors that drive the supply and demand in the freight marketplace at time.
Factors from the market supply side include information regarding the supply of drivers and trucks and fuel/oil prices. Market demand factors include imports, agriculture information, manufacturing activities, housing indexes, and railway transport. Additionally,is the freight marketplace rate at time.
Previously, Amazon relied on a commercial service to obtain forecasts for future marketplace rates. However, those forecasts lacked accuracy and transparency. To address these, we consider the following forecast problem.

SECTION: Our Approach
We will present a signature-based adaptive two-step LASSO approach that we have developed and implemented in Amazon, which has demonstrated excellent performance in solving this problem.

Our approach and experiment start by collecting data involving over a hundred of national and regional market supply and demand factors, downloaded from the governmental public websites, including Federal Reserve Bank and Bureau of Labor Statistics, as well as industrial databases such as Logistic Manager. The time range for the data is from 2018 to 2022.

We first run a correlation test between the marketplace rate and the factors to remove non-significant factors, with further correlation analysis to identify factors that may be colinear. After this round of elimination, over forty factors remain, including consumer price index, housing index, oil and gas drilling, logistic managers’ index, employment information, weather, and other market benchmarks.

Besides the “external” factors, most time series forecasting approaches, such as ARIMA, also construct “internal” features from the history of. Those “internal” features may help to characterize the trend, momentum, and stationarity of. We, instead, exploit the universal nonlinearity property of signature transform (Theorem), and construct signature features as suitable candidates for the “internal” features. In the application to transportation rates, given the extensive dataset of external factors, preliminary experiments indicate that it is sufficient to consider the signature transform ofalone, rather than incorporating bothand, as in ().

More specifically, for any time stepand time window size, denoteas the slice of the time seriesfrom timeto. The feature vector for predictingconsists of both the economic factorsand the depth-signature features. We denote the concatenation of those two sets of features as, whose dimension is denoted by.

The universal nonlinearity property of the signature transform linearizes the feature space, hence translating the forecasting problem into a linear regression analysis.
Since the dimensionof the feature vector may be relatively large compared to the number of historical samples, especially when the time stepis small, we adopt the approach of two-step LASSO to avoid overfitting and the issue of co-linearity especially between the signature feature and the external factors.
The first step is to select the factors by solving the standard LASSO regression,,. This is to add an-regularization to model coefficients in the ordinary least square objective. This-regularization will encourage the sparsity of model coefficients, and prevent the over-fitting problem. In the second step, an OLS with only the selected factors is applied.
This two-step LASSO estimation procedure has been shown to produce a smaller bias than standard LASSO for a range of models,.

More precisely, letdenote the adaptive weight vector in (), which is the output of Algorithm. The adaptive LASSO regression is to solve the following optimization problem:

Here the constant, called the regularization parameter, controls the sparsity of coefficients:
a higher value ofleads to a smaller number of nonzero coefficients in.
In the two-step LASSO, the first step is to select the factors by solving the LASSO regression in (), and get. In the second step,
the subsequent OLS refitting is to findsuch that

Figureillustrates the overall workflow for predicting transportation marketplace rates using Algorithmwith the two-step LASSO model.

SECTION: Real-time performance
Our signature-based adaptive two-step LASSO algorithm has been implemented for the trucking operations in Amazon since November 2022. Performance analysis shows that our forecast model presents superior performance than commercially available forecast models, with prediction accuracy improvement by more than fivefold, and has an estimated annualized savings of $50 million.

Below we will present the real-time performance using data from April 2021 to July 2022. While this timeframe precedes the model’s actual implementation due to confidentiality restrictions, it represents a particularly challenging period marked by both the COVID-19 pandemic and the Ukraine conflict, and allows us to demonstrate the model’s effectiveness in volatile market conditions.

We will showcase the national-level prediction in North America (N.A.) along with five representative regions within North America, designated A, B, C, D, and E to protect proprietary information. We apply the relative error to measure model performances where

We compare the performance of our model at the national-level predictions with the standard industry predictions for the April 2021 - November 2021 time period. Both our model predictions and industry predictions are made three months (twelve weeks) ahead of time, with monthly predictions obtained by aggregating weekly predictions. The detailed results are listed in Table.
In particular, our predictions (with a relative error of around 2%) are far superior to standard industry predictions (with a relative error of around 20%). The prediction accuracy is improved by more than fivefold.

Tablereports the relative prediction error of our model for the national level and five regional predictions (A, B, C, D, and E), up to a twelve-week horizon. The prediction error moderately increases from aroundfor the one-week prediction to approximatelyfor the twelve-week prediction, remaining significantly lower than the industry standard of.

To demonstrate the necessity of the adaptive signature kernel, the key and novel component of our model, we compare the predictions from Algorithmwith and without the signature kernel in (). The results are reported in Table. The predictions presented here are for one representative region in North America on October 24, 2021. Evidently from Table, the errors without the signature kernel are larger () even for short-term predictions. In contrast, the signature kernel method captures better the seasonality, and obtains a smaller relative error () for short-term predictions.
This table shows the effectiveness of incorporating the signature kernel in the forecast model.

Tablereports the relative prediction error of our model for the national level and five regional predictions (A, B, C, D, and E), for a five-week horizon, with model predictions made on June 25, 2022. Most of the prediction errors are shown to be less than.

SECTION: Conclusion
This work presents a novel, highly accurate signature-based adaptive two-step LASSO forecasting model for transportation marketplace rates. Deployed at Amazon since November 2022, it delivers more than fivefold forecast accuracy improvements compared to industry models even amidst major market disruptions, with significant cost savings.

SECTION: References