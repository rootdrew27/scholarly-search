SECTION: Time-Series K-means in Causal Inference and Mechanism Clustering for Financial Data

This paper investigates the application of Time Series-means (TS--means) within the context of causal inference and mechanism clustering of financial time series data. Traditional clustering approaches like K-means often rely on static distance metrics, such as Euclidean distance, which inadequately capture the temporal dependencies intrinsic to financial returns. By incorporating Dynamic Time Warping (DTW) as a distance metric, TS-K-means addresses this limitation, improving the robustness of clustering in time-dependent financial data. This study extends the Additive Noise Model Mixture Model (ANM-MM) framework by integrating TS--means, facilitating more accurate causal inference and mechanism clustering. The approach is validated through simulations and applied to real-world financial data, demonstrating its effectiveness in enhancing the analysis of complex financial time series, particularly in identifying causal relationships and clustering data based on underlying generative mechanisms. The results show that TS--means outperforms traditional-means, especially with smaller datasets, while maintaining robust causal direction detection as the dataset size changes.

SECTION: IIntroduction

The inference of causal relationships between observed variables is a fundamental challenge across many scientific domains, such as finance, social science and supply chain[1]. Especially, understanding the underlying mechanisms and causal relationship of financial data is crucial for tasks such as risk management, portfolio optimization, and anomaly detection. Traditionally, clustering methods like-means are utilized for grouping financial assets based on return patterns. However, these methods typically rely on static distance metrics such as Euclidean distance, which are inadequate for capturing the temporal dependencies inherent in financial time series data. Some use deep learning based method[2,3], but the temporal dependences of financial data still can not be properly taken into account. Financial returns are not merely independent observations but are characterized by trends, seasonality, and varying volatility, making it imperative to adopt methods that respect the sequential nature of the data. Some machine learning methods, such as LightGMB[4]and regression tree are also static and can not deal with the time-series data appropriately.

Traditional approaches, such as LiNGAM[5], PNL[6]and IGCI[7], often assume that all observations are generated from a single, homogeneous causal model, which simplifies analysis but overlooks the complexity of real-world data. In practice, data is frequently collected from multiple environments or sources, each governed by distinct mechanisms that lead to heterogeneous causal relationships. This heterogeneity can render standard causal inference methods ineffective, as they fail to capture the underlying mixture of causal models. Recognizing this limitation,[8]propose a novel approach by extending the Additive Noise Model[9](ANM),, into a Mixture Model (ANM-MM)[8]. This model comprises multiple ANMs, each characterized by different functional forms and noise distributions, enabling the identification of diverse causal mechanisms within the data.

Their proposed framework incorporates a Gaussian Process Partially Observable Model (GPPOM), which is a variant of well-known GP-LVM[10], to estimate the latent parameters associated with each observation, thereby allowing for the identification of different causal mechanisms within the data and to answer two questions:causal inferenceandmechnism clustering. The first is to infer the causal direction between two random variables, and the second is to answer a question, how can we cluster the observations generated from the same data generating mechnism together.

In this work, we extend the ANM-MM framework to address the specific challenges posed by financial time series data. Traditional K-means clustering, commonly used for grouping financial assets, is limited by its reliance on Euclidean distance, which fails to capture the sequential dependencies in time series data. Financial returns, characterized by trends, volatility, and temporal patterns, require a more nuanced approach. To this end, we proposed TS--means based ANM-MM framework for financial transaction data, by replacing the static-means algorithm with Time Series-means, incorporating Dynamic Time Warping (DTW) as a distance metric. DTW enables the alignment of time series that may exhibit similar patterns with temporal shifts, thereby improving the robustness of clustering for time-dependent financial data. By integrating Time Series-means into the ANM-MM framework, we enhance its applicability to finance, facilitating more accurate causal inference and mechanism clustering in markets where timing and sequence are critical.

In SectionII, we clarify the notations and provide background and preliminaries of this paper. In SectionIII, we introduce a TS--means based framework for financial time series. In SectionIV, we validate our approach via simulation study and real world financial data.

SECTION: IIPreliminaries

An ANM Mixture Model (ANM-MM) consists of multiple causal models that share the same causal direction between two continuous random variables,and. Each causal model is represented by the following ANM:

whererepresents the cause,represents the effect,is a nonlinear function parameterized by, and the noiseis independent of. The distinct causal models within the ANM-MM differ only in their function parameter, which is drawn from a discrete distribution over a finite set. Specifically,, where,, andis the indicator function associated with. All observations are thus generated by a set of processes that share the same functionbut differ in their parameter. This variation reflects the influence of external factors on the generating process in each independent trial. The data-generating mechanism of the ANM-MM is depicted in Fig.(1).

In causal inference using ANM-MM,[8]demonstrates that the causal direction within an ANM-MM can be determined by assessing the independence between the hypothetical cause and the associated function parameter. According to Theorem 1 of[8], if these two are independent in the causal direction, they are likely to be dependent in the anticausal direction. Consequently, in practical applications, the causal direction is inferred as the one that exhibits stronger evidence of independence. The identifiability of the ANM-MM is also discussed in[8].

SECTION: IIIMethodology

In ANM-MM, the parameter, which represents the function parameters, can be directly utilized to identify different data-generating mechanisms since each value ofcorresponds to a specific mechanism. In other words, observations generated by the same mechanism would share the same, assuming that the statistical model is identifiable with respect to[8]. Letdenote the parameter associated with each observation.[8]proposed a more practical inherent clustering structure within ANM-MM by assigning eachto one of thecomponents, with each component following a normal distribution. They also demonstrated that minimizing the likelihood-based loss function is equivalent to applying the K-means algorithm to all. Thus, the objective of clustering data consistent with the generating mechanisms in ANM-MM can be achieved by first estimating the parameters associated with each observation and then applying-means directly on those parameters. Considering the temporal nature of financial time series data, we hypothesize that for financial return time series, a time-series-means (TS--means) algorithm based on the Dynamic Time Warping (DTW) algorithm[11,12], as proposed by[13], would be a more suitable alternative to the plain-means algorithm.

Consider two time serieswith length,, andwith length,. The implementation of the DTW method can be described in the following[11,12], we first construct the distance matrix. At the second step, we construct the transformation matrix, where each element is determined by

The final step is to build the optimal transformation path and DTW distance. The transformation pathis a set of ontiguous elements of thematrix that matches the seriesandandminimizes the total distance between these time series. Thus, the last step is to build the optimaltransformation path and DTW distance. The path betweenandis determined by the formula[11]:

whereis the length of the path.. Then DTW the distance between two time series is determined by the formula[11,12],

The mathematical appropriateness under the setting proposed by[8]for our method will be provided in the futher work.

SECTION: III-AAlgorithms

[8]propose Gaussian process partially observable model (GPPOM) and incorporate Hilbert-Schmidt independence criterion (HSIC)[14]enforcement into GPPOM to estimate the model parameter. Then we summarize algorithms for causal inference and mechanism clustering of ANM-MM.

TheGaussian Process Partially Observable Model (GPPOM)is an extension of the Gaussian Process Latent Variable Model[15](GP-LVM) designed to handle partially observable variables within the ANM Mixture Model framework. Based on kernel methods, GPPOM employs a nonlinear mapping from the latent space to the observed data space using Gaussian Processes, allowing it to capture complex relationships between variables. Additionally, GPPOM incorporates the Hilbert-Schmidt Independence Criterion (HSIC) to enforce independence between latent variables and observed causes, which is crucial for accurate causal inference and mechanism clustering. Through joint optimization, GPPOM effectively estimates latent parameters that represent the underlying generative mechanisms, making it a powerful tool for analyzing data generated by multiple causal processes.

HSIC[14], based on reproducing kernel Hilbert space (RKHS) theory, is a widely used method for measuring the dependence between random variables (r.v.s). Letbe a sample of sizedrawn independently and identically from the distribution. HSIC addresses the question of whether. Formally, letandbe RKHSs with universal kernelsandon the compact domainsand, respectively. HSIC is defined as, whereis the cross-covariance operator from RKHSto, anddenotes the Hilbert-Schmidt norm[14][16].[14]proved that, under the conditions specified in[17],if and only if. In practice, a biased empirical estimator of HSIC based on the sampleis often used:

where,,, andis avector of ones. Finally, by incorporating the HSIC term into the negative log-likelihood of GPPOM, the optimization objective becomes

wherecontrols the importance of the HSIC term andrepresents all hyperparameters, includingand the kernel parameters. For more technical details on GPPOM, as well as model and parameter estimation, see[8]. The next algorithm1details our approach for causal inference and mechanism clustering using time-series-means. In Step 2, we implement time-series-based-means utilizing DTW.

SECTION: IVExperiments

SECTION: IV-ASimulation

We first evaluated the performance of our TS--means appraoch through simulation study. We refer the setting in[8],

The performance is evaluated using average adjusted Rand index[18](avgARI), which is mean ARI over 100 trials. ARI is a measure of the similarity between two data clusterings, which corrects for the chance grouping of elements. The ARI is given by:

Whereis the number of elements that are in clusterin the clustering and in clusterin the ground truth,is the sum of all elements in cluster,is the sum of all elements in cluster,is the total number of possible pairs. Highimplies good match between clustering results and the ground truth.

The Tab. (I) presents a comparison between ANM-MM K-means and Time Series-means (TS--means) on simulated data across different sample sizes (n = 50, 100, 150, 200, and 252). The performance is evaluated using avgARI and the Hilbert-Schmidt Independence Criterion (HSIC) for causal inference. The avgARI results indicate that TS--means consistently outperforms-means, particularly for smaller sample sizes, demonstrating its better ability to handle simulated data. However, as the sample size increases, the TS--means may not be as good as the-means. Additionally, the HSIC values, used to determine the causal direction between variables, consistently identify the correct direction (X → Y) across all sample sizes, even as the data size increases.

SECTION: IV-BFinancial Data

The dataset used in this work comprises daily stock returns of two prominent Hong Kong-listed companies: Cheung Kong (0001.HK) and Sun Hung Kai Properties (0016.HK), covering the period from January 4, 2000, to June 17, 2005. The data was sourced from the cause-effect pairs database by[19], with prices adjusted for dividends and stock splits. For days when the closing price was missing, linear interpolation was used to estimate the price, ensuring that the two time series remained aligned. The daily returns for each stock were calculated using the formula, whererepresents the closing price on day. This dataset provides a realistic context for analyzing causal relationships and time-dependent patterns in financial returns, as Sun Hung Kai Properties, a key stock in the Hang Seng Property Subindex, is believed to be influenced by other major stocks in the index. The Fig. (2) shows the linearly clustered stock returns (we manually linearly clustered the data byline). Obviously, there is positive correlation between two stock returns. By accurately classifying the returns into more meaningful clusters, we could improve risk assessment, and identify more precise causal relationships between the stocks. This refined classification would allow for better decision-making in financial strategies.

Tab. (II) presents the performance on real financial data across varying sample sizes, with the smallest sample (n = 50) representing the first 50 trading days. When the sample size is small (n = 50), TS--means shows a noticeable improvement in avgARI compared to-means, this also can be seen in Fig. (3) , suggesting that even with limited data, accounting for temporal patterns leads to better clustering results. However, the HSIC values for causal inference indicate a strong preference for the incorrect direction (Y → X), which will change as the sample size increases. We can see that as the sample size increases, the avgARI for both methods improves, but more importantly, the HSIC values gradually shift, indicating a correction in the inferred causal direction. By n = 150, the direction (X → Y) is consistently identified, underscoring how a larger window provides infoormation on both clustering and causal inference. This shift highlights the causal relationship between two stocks may change as we expand the trading window.

SECTION: VConclusion

In this paper, we extended the traditional-means clustering approach by integrating Time Series-means (TS--means) within the ANM Mixture Model (ANM-MM) framework, specifically targeting financial time series data. Our approach leverages Dynamic Time Warping (DTW) to better account for the temporal dependencies inherent in financial returns, which are typically overlooked by static clustering methods. Through both simulation studies and real-world financial data analysis, we demonstrated that TS--means consistently outperforms traditional-means in terms of clustering accuracy, particularly with smaller datasets. Moreover, our method maintains robust performance in causal inference, consistently identifying the correct causal direction as the dataset size changes. The findings highlight the effectiveness of TS--means in capturing time-dependent patterns and improving both clustering and causal inference in financial time series. We also notice that the causal relationship betweenmay change as the change in the trading window.

SECTION: References