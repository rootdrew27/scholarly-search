SECTION: Redes Neurais com LSTM e GRU na Modelagem de Focos Ativos na Amazônia

This study presents a comprehensive methodology for modeling and forecasting the historical time series of active fire spots detected by the AQUA_M-T satellite in the Amazon, Brazil. The approach employs a mixed Recurrent Neural Network (RNN) model, combining Long Short-Term Memory (LSTM) and Gated Recurrent Unit (GRU) architectures to predict the monthly accumulations of daily detected active fire spots. Data analysis revealed a consistent seasonality over time, with annual maximum and minimum values tending to repeat at the same periods each year. The primary objective is to verify whether the forecasts capture this inherent seasonality through machine learning techniques. The methodology involved careful data preparation, model configuration, and training using cross-validation with two seeds, ensuring that the data generalizes well to both the test and validation sets for both seeds. The results indicate that the combined LSTM and GRU model delivers excellent forecasting performance, demonstrating its effectiveness in capturing complex temporal patterns and modeling the observed time series. This research significantly contributes to the application of deep learning techniques in environmental monitoring, specifically in forecasting active fire spots. The proposed approach highlights the potential for adaptation to other time series forecasting challenges, opening new opportunities for research and development in machine learning and prediction of natural phenomena.

Keywords:Time Series Forecasting; Recurrent Neural Networks; Deep Learning.

Resumo

Este estudo apresenta uma metodologia abrangente para modelagem e previsão da série temporal histórica de focos ativos detectados pelo satéliteAQUA_M-Tna Amazônia, Brasil. A abordagem utiliza um modelo misto de Redes Neurais Recorrentes (RNN), combinando as arquiteturasLong Short-Term Memory(LSTM) eGated Recurrent Unit(GRU) para prever os acumulados mensais de focos ativos detectados diariamente. A análise dos dados revelou uma sazonalidade consistente ao longo do tempo, com os valores máximos e mínimos anuais tendendo a se repetir nos mesmos períodos a cada ano. O objetivo principal é verificar se as previsões capturam essa sazonalidade inerente por meio de técnicas de aprendizado de máquina. A metodologia envolveu uma cuidadosa preparação dos dados, configuração do modelo e treinamento utilizando validação cruzada com duas sementes, garantindo que os dados se generalizem bem para os conjuntos de teste e validação para ambas as sementes. Os resultados apontam que o modelo combinado de LSTM e GRU oferece excelentes resultados nas previsões, demonstrando sua eficácia na captura de padrões temporais complexos e na modelagem da série temporal observada. Esta pesquisa contribui significativamente para a aplicação de técnicas de aprendizado profundo no monitoramento ambiental, especificamente na previsão de focos ativos. A abordagem proposta destaca o potencial de adaptação para outros desafios de previsão em séries temporais, abrindo novas oportunidades para pesquisa e desenvolvimento em aprendizado de máquina e previsão de fenômenos naturais.

Palavras-chave:Previsão de Séries Temporais; Redes Neurais Recorrentes; Aprendizado Profundo.

SECTION: 1Introdução

Séries temporais são amplamente utilizadas em diversas áreas, como economia, climatologia, e monitoramento ambiental, e contam com grandes referências como[BoxJenkins1976],[JamesHamilton1994], e[PeterBrockwell2002]. De maneira geral, uma série temporal pode ser definida como um conjunto de informações fixadas no tempo e/ou no espaço de forma padronizada ou não. Quando tratamos de séries temporais de dados quantitativos discretos, onde o tempo é o principal fator de interesse, podemos entender essa série como um conjunto de observações que representam quantidades específicas, registradas ao longo do tempo. No contexto deste trabalho, focamos na série temporal dos focos ativos detectados pelo satéliteAQUA_M-Tna Amazônia, Brasil. Os focos ativos são detectados com base em anomalias de temperatura em pixels observados pelo satélite. Quando a temperatura de um pixel (representa uma área de 1m²) atinge níveis significativamente elevados, como, por exemplo, acima de 47°C — valor que, segundo o Sistema Estadual de Informações Ambientais e Recursos Hídricos[SEIA2024], caracteriza um foco de calor — o satélite registra a ocorrência de um foco ativo. Esses dados, disponibilizados mensalmente pelo Instituto Nacional de Pesquisas Espaciais (INPE), oferecem uma visão histórica importante, embora seja sabido que os satélites como oAQUA_M-Tpossuem limitações em termos de precisão, devido à sua idade e tecnologia. Entretanto, mesmo com essas limitações, os dados são valiosos para a identificação de padrões sazonais e anomalias ao longo dos anos. Futuramente, espera-se que esses dados sejam atualizados com a entrada em operação de novos satélites, o que permitirá um monitoramento ainda mais preciso. Neste trabalho, utilizamos modelos de Redes Neurais Recorrentes (RNNs), especificamente as arquiteturasLong Short-Term Memory(LSTM) propostas por[Schmidhuber1997]eGated Recurrent Unit(GRU) propostas por[JunyoungChung2014], para modelar e prever a quantidade de focos ativos na Amazônia. A LSTM é conhecida por sua capacidade de lidar com problemas de retenção de longo prazo, enquanto a GRU simplifica a estrutura da LSTM, aumentando a eficiência do modelo. A combinação dessas duas arquiteturas em um modelo misto oferece a robustez necessária para capturar os padrões complexos presentes na série temporal analisada. O lado positivo das redes neurais é a capacidade de um modelo bem treinado aprender padrões independentemente da escala dos dados. No caso dos focos ativos, a série temporal varia de um mínimo de 70 focos registrados em abril de 1999 a um máximo de 73.141 focos em setembro de 2007. Esse intervalo expressivo demonstra a importância de desenvolver uma arquitetura robusta e bem configurada para garantir que o modelo consiga aprender essas variações e realizar previsões com menores erros em comparação aos valores reais observados. Neste artigo, além de explorar a aplicação das RNNs, LSTM e GRU, você encontrará uma visão detalhada de como foi estruturado e treinado o modelo, quantos neurônios e épocas de treinamento foram utilizados, e como as previsões foram realizadas. Discutiremos a fundamentação teórica por trás das redes neurais recorrentes, analisaremos os dados históricos, identificando a sazonalidade dos focos ativos na Amazônia, e apresentaremos os resultados das previsões geradas pelo modelo treinado. Por fim, serão discutidas as implicações dessas previsões e as conclusões deste estudo. Dito isso, seguimos adiante com este estudo, detalhando cada etapa do processo de modelagem, treinamento, validação e previsão, para demonstrar a eficácia das redes neurais recorrentes na análise de séries temporais ambientais.

SECTION: 2Referencial Teórico

De acordo com[Graves2013], as Redes Neurais RecorrentesRecurrent Neural Networks(RNNs) são modelos poderosos para dados sequenciais. Elas são capazes de lidar com problemas de rotulagem de sequências onde o alinhamento entre entrada e saída é desconhecido. Esses modelos são construídos para aprender dependências temporais em dados sequenciais e mantêm uma memória interna para processar informações anteriores.

SECTION: 2.1Unidade RNN

Dada uma sequência de entrada, uma Rede Neural Recorrente padrão computa a sequência de vetores ocultose a sequência de vetores de saída.

em queWé a matriz de pesos ebé o viés, e o operadorrepresenta a multiplicação elemento a elemento; o estado de saídagerado no tempoé determinado pela informação de entradae pelo estado oculto anteriorno tempo.

A Equação (1) mostra como o estado oculto atualé calculado usando uma função de ativação, pesose viéscorrespondentes. Esse modelo de unidade de Redes Neurais Recorrentes é fundamental para compreender a propagação de informações ao longo do tempo em uma Rede Neural Recorrente. A estrutura interna da unidade RNN é exibida na Figura1.

Fonte: Elaborado pelo autor, adaptado de[Greff2017].

SECTION: 2.2Unidade LSTM

No artigoSpeech Recognition with Deep Recurrent Neural Networks[Graves2013], os autores enfatizam que a arquitetura das Redes de Memória de Longo e Curto Prazo (Long Short-Term Memory, LSTM) é particularmente eficaz para tarefas que requerem o processamento de sequências temporais longas. As LSTMs se destacam pela capacidade de superar as limitações das Redes Neurais Recorrentes (RNNs) tradicionais, permitindo que informações relevantes sejam retidas por períodos mais prolongados. Isso é primordial para lidar com dependências temporais extensas. Enquanto as RNNs funcionam em sequências temporais mantendo uma memória interna, as LSTMs aprimoram essa capacidade ao utilizargates“portões”para controlar o fluxo de informações. Esses portões facilitam uma retenção mais eficaz das informações a longo prazo, comparado às RNNs tradicionais, que enfrentam dificuldades em manter dependências temporais mais longas. Dessa forma, as LSTMs demonstram uma capacidade superior de generalização e previsão quando confrontadas com dados de entrada que se estendem por longos períodos de tempo.

A arquiteturaLong Short-Term Memory(LSTM), conforme descrito por[Greff2017], é projetada para lidar com as limitações das Redes Neurais Recorrentes tradicionais em tarefas de aprendizado de sequências temporais. O bloco LSTM é composto por três componentes principais, como ilustrado na Figura2:

Portão de Entrada:Este portão regula a quantidade de nova informação que será incorporada na célula de memória. Ele determina quais informações devem ser adicionadas ao estado da célula.

Portão de Esquecimento:Este portão decide quais informações presentes na célula de memória devem ser descartadas. Ele ajuda a manter a relevância dos dados ao longo do tempo, removendo informações que não são mais necessárias.

Portão de Saída:Este portão controla a quantidade de informação da célula de memória que será utilizada na saída do bloco LSTM. Ele decide quais informações da célula de memória serão passadas para a próxima etapa na sequência.

Esses portões são responsáveis por regular o fluxo de informações dentro do bloco LSTM, permitindo a retenção e atualização eficaz de dados relevantes por longos períodos. A estrutura interna do LSTM permite que o modelo capture dependências temporais extensas e mantenha a precisão em tarefas que envolvem sequências longas e complexas.

Sejao vetor de entrada no tempo,o número de unidades LSTM na camada eo número de entradas (aquirepresenta a dimensão da matriz de pesos). Então, obtemos os seguintes pesos para uma camada LSTM:

Pesos de entrada:;

Pesos recorrentes:;

Pesos de viés:.

Então, de acordo com[Greff2017], as fórmulas vetoriais para uma passagem direta em uma camada LSTM podem ser escritas como:

Em que,esão funções de ativação não lineares ponto a ponto. A função sigmoide () é usada como função de ativação da porta, e a tangente hiperbólica () é comumente usada como função de ativação de entrada e saída do bloco. A multiplicação ponto a ponto de dois vetores é denotada por.

Fonte: Elaborado pelo autor, adaptado de[Greff2017].

SECTION: 2.3Unidade GRU

As Unidades Recorrentes com PortasGated Recurrent Units(GRU), introduzidas por[JunyoungChung2014], são uma variação das LSTM. Enquanto as LSTM possuem três portões e uma célula de memória, as GRU simplificam essa estrutura ao fundir os portões de entrada e esquecimento em um único portão de atualização. Essa simplificação tem como objetivo tornar o treinamento mais eficiente e reduzir o número de parâmetros, mantendo um desempenho comparável às LSTM.

As fórmulas vetoriais para uma passagem direta em uma camada GRU foram encontradas no artigo de[Cheng2024]de uma forma mais simplista que são:

em queWeRsão matrizes de pesos;bsão vetores de viés;é a função de ativação sigmoide e odenota a multiplicação ponto a ponto.

A figura3mostra um esquema das Unidades Recorrentes com Portas (GRU) e a arquitetura típica dessa rede.

Fonte: Elaborado pelo autor, adaptado de[Cheng2024].

SECTION: 2.4Funções de Ativação

As funções de ativação são componentes fundamentais em redes neurais, responsáveis por introduzir não-linearidades nas saídas das camadas, o que permite às redes neurais aprender e modelar relações complexas nos dados. Essas funções não possuem parâmetros ajustáveis e são fixas, usadas especificamente para introduzir não-linearidade nas redes neurais conforme[Goodfellow2016]. A Figura4ilustra a transformação linear e a ativação linear em uma camada densa final de uma rede neural.

Fonte: Elaborado pelo autor

SECTION: 2.5Entendendo o Funcionamento das Camadas Densas em Redes Neurais Recorrentes

Os neurônios em redes neurais recorrentes (RNNs) são unidades fundamentais que processam informações ao longo do tempo. Eles são responsáveis por realizar operações matemáticas nos dados de entrada e nos estados ocultos anteriores (previsão do bloco anterior) para gerar saídas e atualizar seus próprios estados. Uma camada densa é uma camada comumente usada em redes neurais, em que cada neurônio na camada está totalmente conectado a todos os neurônios na camada anterior. Os cálculos realizados em uma camada densa envolvem multiplicação de matriz entre a entrada dos dados e os pesos (parâmetros) da camada, seguida por uma função de ativação. Aqui estão os cálculos para uma camada densa: Sejaa matriz de entrada de dimensão, em queé o número de amostras eé o número de características. Sejaa matriz de pesos da camada densa de dimensão, comsendo o número de neurônios na camada densa. Além disso, sejao vetor de viés da camada densa de dimensão.
A saída da camada densaé calculada da seguinte forma:

aqui,representa a multiplicação de matriz entre a entrada e os pesos da camada densa, eé o viés adicionado para produzir a saída final.
É importante notar que após essa operação, geralmente é aplicada uma função de ativação aos elementos depara introduzir não linearidade na camada densa conforme[Goodfellow2016].

SECTION: 2.6Algoritmo de Otimização Adam: Uma Visão Geral

O algoritmo Adam, desenvolvido por[Kingma2014], utiliza médias móveis exponenciais dos gradientes para atualizar os parâmetros, acelerando a convergência e evitando que o modelo fique preso em mínimos locais. O Adam incorpora estimativas de primeira e segunda ordens com correções de viés para melhorar a eficácia da otimização.
As configurações padrão para os problemas de aprendizado de máquina testados são,,e. Todas as operações em vetores são realizadas elemento a elemento (matricialmente). Comedenotados comoeelevados à potência.

De acordo com[Kingma2014], o algoritmo Adam é considerado uma técnica avançadda de otimização que calcula taxas de aprendizado adaptativas para cada parâmetro. Ele combina características dos métodos Adagrad e RMSprop, mantendo médias móveis exponenciais dos gradientes e dos gradientes ao quadrado para ajustar as taxas de aprendizado.

esão estimativas do primeiro momento (a média) e do segundo momento (a variância não centralizada) dos gradientes, respectivamente, daí o nome do método. Comoesão inicializados como vetores de zeros, os autores do Adam observam que eles são tendenciosos a valores próximos de zero, especialmente durante os passos iniciais, e particularmente quando as taxas de decaimento são pequenas […].[Ruder2016, p. 7].

Eles contrabalançam esses vieses calculando estimativas corrigidas de viés para o primeiro e segundo momentos:

Aqui,representa a estimativa da média dos gradientes ea estimativa da variância não centralizada. Para corrigir o viés de inicialização dessas estimativas, são calculadas as correções de viés:

Com essas estimativas corrigidas, a atualização dos parâmetros é dada por:

Reiterando o que foi afirmado no início desta seção, os valores padrão sugeridos para os hiperparâmetros são,, e. O otimizador Adam é conhecido por sua eficácia em uma ampla gama de problemas de aprendizado de máquina, proporcionando uma atualização eficiente e eficaz dos parâmetros durante o treinamento de redes neurais.

SECTION: 3Metodologia

Nesta seção, descrevemos o procedimento adotado para modelar e prever séries temporais utilizando redes neurais recorrentes. Utilizamos dados de contagem dos focos ativos detectados pelo satéliteAQUA_M-Tno bioma da Amazônia, abrangendo uma série histórica registrada desde junho de 1998 até 31 de agosto de 2024. Esses dados estão disponíveis no[INPE2024]. O processo metodológico para modelar e prever essa série temporal segue práticas estabelecidas na literatura de séries temporais e aprendizado de máquina. Inicialmente, dividimos os dados em conjuntos de treino e teste para avaliar a performance do modelo, aplicando técnicas como validação cruzada para assegurar a robustez do modelo. Após garantir que o modelo apresentava uma boa capacidade de generalização, optamos por treinar o modelo final utilizando 100% dos dados disponíveis. Essa abordagem visa maximizar a precisão das previsões, especialmente em cenários de passos à frente da última observação treinada, como indicado por[Geron2017]. No contexto dedeep learning, onde ajustes finos (fine-tuning) são comuns, o uso do conjunto completo de dados após validação é uma prática justificada para aprimorar o desempenho, conforme discutido por[Goodfellow2016]. Dessa forma, utilizamos o modelo treinado com 100% dos dados para realizar previsões depassos à frente, garantindo que as previsões fossem baseadas na maior quantidade de informações possível.

SECTION: 3.1Preparação dos Dados

Na preparação dos dados, adotamos uma abordagem de treino, validação e teste adaptada para séries temporais contínuas. Para garantir a eficácia da avaliação do modelo, seguimos o processo de divisão dos dados de frente para trás. Primeiramente, removemos os últimos 12lags(meses) da série para o conjunto de teste, considerando a série completa menos esses 12lags. Em seguida, removemos 24lagsadicionais para o conjunto de validação, o que deixou a série completa menos 36lagspara o treinamento. Embora tenhamos seguido a abordagem de divisão de dados, utilizamos validação cruzada com duas sementes para avaliar a performance do modelo. Conforme descrito por[Geron2017], a validação cruzada é essencial para garantir que o modelo generalize bem para novos dados. Foram utilizadas duas sementes distintas para criar dois modelos diferentes, o que permitiu avaliar a robustez e a estabilidade do modelo. A divisão final dos dados foi a seguinte:

Conjunto de Treino: Junho de 1998 até agosto de 2021;

Conjunto de Validação: Setembro de 2021 até agosto de 2023;

Conjunto de Teste: Setembro de 2023 até agosto de 2024.

Essa abordagem, combinada com o uso de sementes fixas, garantiu a replicabilidade dos resultados e confirmou a consistência das generalizações para os conjuntos de treino, validação e teste.

SECTION: 3.2Configuração dos Modelos

Foi utilizado a combinação dos modelos de redes neurais recorrentes LSTM+GRU essa arquitetura consiste em:

Camada de Entrada: Recebe os dados da série temporal em janelas fixadas previamente, que na nossa arquitetura escolhemos tamanho de 12 para que a partir de 12 meses se tenha a primeira previsão no 13° ponto.

Camada Recorrente: Para o modelo LSTM+GRU, foi configurada uma camada LSTM seguida por uma camada GRU, ambas com 256 neurônios.

Camada Densa: Uma camada densa com 256 neurônios e função de ativação ReLU.

Camada de Saída: Uma camada densa com 1 neurônio e ativação linear, fornecendo a previsão final para cada janela de entrada.

Veja a figura5que melhor ilustra essa configuração.

Fonte: Elaborado pelo autor

A Figura5ilustra uma arquitetura de rede neural que inclui as seguintes camadas:

Camada LSTM com 256 neurônios;

Camada GRU com 256 neurônios;

Camada densa com 256 neurônios;

Camada densa de saída com 1 neurônio.

A figura5ilustra a transmissão de informações entre as camadas até a saída final e não aborda o funcionamento de dropout ou funções de ativação. A explicação da arquitetura é a seguinte:

Cada entradano tempoé inicialmente processada pela camada LSTM composta por 256 neurônios. A saída dessa camada LSTM, com dimensão— considerando que nosso trabalho envolve uma única variável ao longo do tempo (focos ativos) — resulta em um vetor de dimensão. Essa saída é então utilizada como entrada para a camada GRU, que também possui 256 neurônios. A saída da camada GRU é processada por outra camada densa com 256 neurônios, mantendo a dimensão. Finalmente, essa saída é alimentada na camada densa de saída com 1 neurônio, resultando em uma previsão única para o próximo ponto da série temporal. Para ilustrar o funcionamento, considere um bloco de dados com 12 valores, em que a entradaé o vetor de valores de 1 a 12. A previsão é feita para o 13º valor. Esse processo é repetido ao mover a janela de entrada, de modo que o segundo bloco será de 2 a 13, e a previsão será para o 14º ponto, e assim por diante até o final da série. Esta ilustração é de apenas um bloco, mas ao configurar a série com blocos de tamanho 12, o modelo recebe os dados configurados previamente. Assim, se eu tenho valores de 1 a, os dados são configurados emarraysde tamanho 12, sendode 1 a 12,de 2 a 13, e assim por diante até o final da série. Portanto, essa ilustração é de apenas um bloco, mas no funcionamento completo da rede, o modelo computa todos os blocos pré-definidos e resulta em previsões para cadade acordo com o tamanho da série.

SECTION: 3.3Treinamento e Avaliação dos Modelos

Os modelos foram treinados utilizando a linguagem de programação[Python2024], com as bibliotecasScikit-learn[ScikitLearn2011]e[FrançoisChollet2024]. Cada modelo foi treinado por 1000 épocas, e as métricas Erro Absoluto Médio (MAE) e Raiz do Erro Quadrático Médio (RMSE) foram utilizadas para avaliar o desempenho.
Para cada época, o modelo gerou previsões utilizando uma técnica conhecida como janela/bloco deslizante (ousliding window). Este procedimento funciona da seguinte forma:

1.Janela de Entrada: Definimos uma janela de 12lags, ou seja, o modelo usa os dados dos 12 períodos anteriores para prever o valor do próximo período. Por exemplo, se temos dados mensais e a janela é de 12lags, o modelo usa os dados dos últimos 12 meses para prever o valor do mês seguinte.
2.Deslizamento da Janela: Após gerar uma previsão para o próximo período (o 13º), a janela é deslocada uma posição para frente. Isso significa que a previsão é feita usando os dados dos períodos de 2 a 13 para prever o 14º período. Esse processo é repetido até que todas as previsões sejam feitas para o restante da série temporal.
3.Avaliação das Previsões: As previsões geradas para cada época são comparadas com os dados reais da série temporal. Para avaliar a precisão das previsões, utilizamos as métricas MAE e RMSE. O MAE calcula a média dos erros absolutos das previsões, enquanto o RMSE calcula a raiz quadrada da média dos erros quadráticos. Os parâmetros iniciais dos modelos foram definidos utilizando uma distribuição de probabilidade específica, a distribuição normal de He (He normal). Essa distribuição é definida com média zero e desvio padrão, ondeé o número de unidades na camada de entrada. A escolha dessa distribuição ajuda a garantir uma inicialização adequada dos pesos, facilitando o treinamento eficaz de redes neurais profundas, conforme os desenvolvedores[KerasDevelopers2024].

Os dados foram divididos da seguinte forma:

Treino: Junho de 1998 até agosto de 2021;

Validação: Setembro de 2021 até agosto de 2023;

Teste: Setembro de 2023 até agosto de 2024.

Utilizamos duas sementes distintas para garantir a replicabilidade dos resultados e a estabilidade das métricas de desempenho. O modelo que apresentou o menor erro médio nas métricas MAE e RMSE durante o treinamento foi selecionado como o modelo final.

SECTION: 3.4Como as Previsões são Calculadas?

As previsões foram realizadas após o treinamento completo dos dados de focos ativos registrados na região da Amazônia, Brasil, disponíveis no[INPE2024], abrangendo o período de junho de 1998 até agosto de 2024. Após o treinamento, utilizamos a funçãopredictdo pacote[FrançoisChollet2024], para gerar as previsões. O processo envolveu o uso do modelo treinado, que já contém todos os parâmetros otimizados e ajustados. O modelo, armazenado e salvo como o melhor obtido durante o treinamento, é utilizado com a funçãopredict, que é chamada comomodelo.predict(). Este modelo foi treinado com uma variável e um bloco de tamanho 12. A funçãopredictsegue a sequência dos dados, incorporando as previsões anteriores para gerar novos resultados, adicionando esses resultados à série temporal e prevendo o próximo ponto. Para detalhar o processo: a funçãopredictutiliza as últimas 12 observações da série temporal (o tamanho da janela deslizante), que vão de setembro de 2023 a agosto de 2024, para prever o 13º ponto, que corresponde a setembro de 2024. A abordagem de“janela deslizante”é usada, permitindo que após a primeira previsão para setembro de 2024, o modelo integre essa previsão e gere uma nova previsão para o próximo mês. No segundo passo, por exemplo, ele utiliza as observações de outubro de 2023 a setembro de 2024, agora incluindo a previsão anterior (de setembro), para prever outubro de 2024 (um dado que ainda não existe na série temporal). No terceiro passo, o modelo usa os dados de novembro de 2023 a outubro de 2024, incluindo as previsões obtidas de setembro e outubro à série temporal, e assim por diante. Esse processo continua até que todas as previsões dos 12 meses sejam realizadas. Essa abordagem assegura que cada previsão mensal se baseie nos dados históricos mais recentes, juntamente com as previsões feitas nos passos anteriores, resultando em uma modelagem robusta para séries temporais de dados de contagem, conforme descrito na literatura e referenciado nesta seção. A ilustração detalhada desse processo está apresentada na Figura5.

SECTION: 4Resultados da Análise Estatística

Nesta seção, apresentamos uma análise descritiva da série temporal de focos ativos na Amazônia, com ênfase na média, desvio padrão, variância e nos valores máximos e mínimos registrados ao longo dos anos, veja a Tabela1.

Fonte: Autor, baseado nos dados da base de dados fornecida peloInstituto Nacional de Pesquisas Espaciais (INPE)

A análise foi realizada cuidadosamente, aplicando técnicas de análise de dados para identificar os pontos mais extremos de cada ano. Nosso objetivo é oferecer uma visão clara e direta desses valores, evitando a complexidade que seria introduzida por uma tabela detalhada. Ao invés disso, optamos por uma representação gráfica que facilita a visualização e compreensão dessas estatísticas importantes.

A série temporal de junho de 1998 até agosto de 2024 apresenta dados mensais do total de focos ativos registrados pelo satélite de referência a cada mês. Como vemos na Figura6, os meses de agosto e setembro foram consistentemente registrados como aqueles com o maior número de focos ativos durante esse período de mais de 20 anos.

Fonte: Autor, baseado nos dados doInstituto Nacional de Pesquisas Espaciais (INPE).

Fonte: Autor, baseado nos dadosInstituto Nacional de Estudos e Pesquisas Espaciais (INPE).

A figura7apresenta os pontos extremos de focos ativos de cada ano, enfatizando a sazonalidade existente na série temporal da Amazônia. Desde 1998 até 2024, observa-se que os maiores índices de focos ativos ocorrem consistentemente nos meses de agosto e setembro, enquanto os menores índices são registrados no primeiro semestre, principalmente nos meses de janeiro, fevereiro, maio e abril.

Fonte: Elaborado pelo autor

Para explorar gráficos detalhados e obter uma visualização interativa da série histórica de focos ativos na Amazônia, você pode escanear o QR code da Figura8. Este QR Code direcionará para uma aplicação desenvolvida na linguagem de programação[RCoreTeam2024]e[shiny2024].

SECTION: 5Resultados da Análise de Treinamento do Modelo de Aprendizado de Máquina

Nesta seção, apresentamos e discutimos os resultados obtidos para os modelos de redes neurais recorrentes avaliados, especificamente a abordagem mista que combina LSTM e GRU. Vamos explorar o desempenho do modelo, utilizando métricas de avaliação, como Raiz do Erro Quadrático Médio (RMSE) e Erro Absoluto Médio (MAE), tanto para os conjuntos de treino quanto para os de teste. Cada modelo foi avaliado isoladamente, e os resultados obtidos serão apresentados em tabelas detalhadas. Utilizaremos essas métricas para comparar o desempenho dos modelos e determinar qual deles apresenta os menores valores de erro. O modelo que demonstrar melhor desempenho, com os menores valores de erro, será selecionado como o mais eficaz para a tarefa de previsão em questão. As implicações dos resultados serão discutidas, incluindo a análise da variação das métricas com diferentes sementes e configurações. Esta análise fornecerá uma visão abrangente da eficácia de cada modelo, permitindo a escolha do modelo mais adequado para realizar as previsões necessárias com base nos critérios estabelecidos.

SECTION: 6Resultados do Modelo LSTM+GRU

A Tabela2e a Figura9relacionadas ilustram o desempenho do modelo LSTM+GRU para os conjuntos de treino e teste, utilizando diferentes sementes de inicialização. As métricas de Erro Quadrático Médio (RMSE) e Erro Absoluto Médio (MAE) são fundamentais para avaliar a precisão das previsões do modelo.

Fonte: Autor, baseado nos resultados das métricas

O Erro Absoluto Médio (MAE) mede a média das diferenças absolutas entre os valores reais e as previsões, e é definido pela seguinte fórmula:

em queé o número total de meses,são os valores reais de cada mês, esão as previsões do modelo para cada mês. Nesse contexto, conseguimos obter para cada época todas as diferenças entre os valores mensais reais e o que o modelo LSTM+GRU prevê para cada um desses meses. Depois, extraímos a média dessas diferenças, que nada mais é do que a soma dessas diferenças absolutas dividida pelo total de meses (). Já o Erro Quadrático Médio (RMSE) leva em consideração o quadrado dessas diferenças, penalizando erros maiores de forma mais severa, e é dado por:

em queé o número total de meses,são os valores reais de cada mês, esão as previsões do modelo para cada mês. O RMSE calcula a raiz quadrada da média dos quadrados das diferenças entre os valores reais e as previsões. Isso penaliza erros maiores de forma mais intensa, fornecendo uma medida que reflete a magnitude dos erros em um nível mais severo do que o MAE.
Essas métricas são utilizadas para selecionar o melhor modelo entre os 1000 treinamentos realizados. Em cada época, a diferença entre os valores reais e as previsões é calculada, e o modelo que apresenta a menor diferença média é escolhido como o melhor. Observa-se que, embora haja uma diferença significativa nas previsões, especialmente no RMSE, o MAE nos fornece uma diferença média de pouco mais de 3700 focos ativos, em comparação a uma média histórica de 9000 focos. Isso sugere que, apesar de não ser extremamente preciso, o modelo ainda consegue capturar a tendência sazonal geral, com um erro que representa menos de 50% da média histórica.

A Figura10ilustra a validação cruzada realizada com duas sementes distintas, 2024 e 2025, comparando dois conjuntos de treino e teste. Esta abordagem é fundamental para avaliar a capacidade de generalização do modelo em séries temporais, onde a sequência dos dados é extremamente importante. Ao utilizar sementes diferentes para os conjuntos de treino, teste e validação, garantimos que a validação cruzada considere variações na inicialização do modelo e na estimação dos parâmetros, permitindo uma avaliação mais robusta da generalização.

A Figura11mostra a comparação da perda (Loss) dos conjuntos de treinamento e validação para duas sementes diferentes: 2024 e 2025. A perda (Loss) é uma métrica que representa o erro médio entre os valores reais e as previsões do modelo em cada época durante o treinamento. A fórmula da perda (Loss) é diretamente relacionada às métricas de erro absoluto médio (MAE) e raiz do erro quadrático médio (RMSE), discutidas nas Equações19e20. Esses gráficos são fundamentais para a análise do desempenho do modelo. A perda (Loss) demonstra como os parâmetros do modelo são ajustados ao longo do tempo para minimizar o erro. O ponto onde a perda é minimizada indica a melhor configuração dos parâmetros do modelo para a previsão. A análise detalhada da perda nos conjuntos de treinamento e validação, conforme descrito na Seção3.3, revela a eficácia do ajuste do modelo. Observando a perda ao longo das 1000 épocas, é possível avaliar se o modelo está generalizando bem para novos dados, o que é essencial para prever a tendência dos dados. Portanto, esses gráficos ilustram a evolução da perda e fornecem detalhes sobre a capacidade da convergência dos parâmetros a cada modelo de se ajustar aos dados, refletindo diretamente na qualidade das previsões e na efetividade do treinamento realizado.

SECTION: 6.1Treinamento para os dados completos

Fonte: Autor, baseado nos resultados das métricas

A Figura12apresenta o treinamento do modelo utilizando o conjunto completo de dados, abrangendo o período de junho de 1998 até agosto de 2024. Esta abordagem permite avaliar a performance do modelo em toda a série histórica, seguindo as melhores práticas para séries temporais em machine learning, onde é crucial treinar o modelo com todos os dados disponíveis para realizar previsões futuras. Os gráficos12(a)e12(b)mostram a comparação entre os dados reais e as previsões para o conjunto de treino, utilizando as sementes 2024 e 2025, respectivamente. Estes gráficos ilustram a capacidade do modelo em capturar a tendência geral dos dados ao longo do tempo. Os gráficos12(c)e12(d)apresentam as métricas de desempenho do modelo para as sementes 2024 e 2025, com a raiz do erro quadrático médio (RMSE) e o erro absoluto médio (MAE), respectivamente. Essas métricas são fundamentais para avaliar a precisão das previsões do modelo, com o RMSE fornecendo uma medida penalizada dos erros maiores e o MAE oferecendo uma visão geral das diferenças médias. Finalmente, os gráficos12(e)e12(f)ilustram a evolução da perda (Loss) durante o treinamento para as sementes 2024 e 2025. A perda (Loss) é uma métrica importante que representa o erro médio entre os valores reais e as previsões do modelo em cada época de treinamento. Esses gráficos mostram como a perda varia ao longo das épocas, refletindo o ajuste contínuo dos parâmetros do modelo para minimizar o erro. A combinação dessas análises permite uma visão abrangente do desempenho do modelo treinado com o conjunto completo de dados, confirmando a eficácia da abordagem adotada e a capacidade do modelo de generalizar bem para previsões futuras.

SECTION: 6.2Previsão

Então, a partir do modelo treinado e identificando obest model— o ponto com o menor valor de métrica, como ilustrado nas Figuras12(e)e12(f)— podemos observar que esse ponto representa a configuração de parâmetros que resultou nos menores valores de erro absoluto médio (MAE) e erro quadrático médio (RMSE). Esse modelo otimizado foi utilizado para realizar previsões de 12 meses à frente. A Figura13mostra a série temporal desde junho de 1999 até agosto de 2024, e as previsões geradas se estendem de setembro de 2024 até agosto de 2025. Para detalhes adicionais sobre o processo de previsão e a implementação, consulte a seção3.4desse material.

SECTION: 7Conclusão

Este estudo avaliou o desempenho de redes neurais recorrentes, combinando as arquiteturasLong Short-Term Memory(LSTM) eGated Recurrent Unit(GRU), na previsão de focos ativos detectados pelo satéliteAQUA_M-Tna Amazônia. A análise demonstrou que essa combinação é eficaz na captura de padrões temporais complexos, com a escolha final do modelo baseada no Erro Absoluto Médio (MAE). As previsões geradas pelos modelos combinados apresentaram um desempenho elevado, especialmente em séries temporais com forte sazonalidade, como é o caso da série histórica dos focos ativos na Amazônia. Além disso, o estudo destacou a importância da configuração meticulosa dos modelos e do treinamento com validação cruzada para garantir boas práticas de modelagem. A simplificação da compreensão das redes neurais e do processo de aprendizado torna o tema mais acessível a alunos e pesquisadores sem experiência prévia no assunto. A análise descritiva identificou os meses de máxima e mínima incidência de focos ativos de 1998 a 2024, oferecendo percepções estratégicas sobre esses eventos. A semente escolhida para treinar o modelo completo e realizar previsões futuras, entre as sementes de número 2024 e 2025, foi a 2025. Esta semente apresentou um erro absoluto médio de aproximadamente 2.500 focos ativos. O modelo previu que o mês de novembro de 2024 será o maior pico registrado, com 41.791,5 mil focos ativos na região da Amazônia. Esta previsão indica uma anomalia em relação à série histórica completa, que tradicionalmente registra picos mais altos em agosto ou setembro. A previsão de novembro sugere uma mudança na tendência de pico de focos ativos, enquanto os menores registros permanecem consistentes com o padrão histórico, tipicamente observados no primeiro semestre. Foi observado que, ao modelar dados de contagem, a utilização de técnicas apropriadas e referências confiáveis permite estruturar uma base de dados com grande assimetria e treinar modelos que convergem para previsões que seguem a tendência geral da série temporal, independentemente da escala dos dados.

[title=Referências]