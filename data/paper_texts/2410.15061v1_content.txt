SECTION: Classifying extended, localized and critical states in quasiperiodic lattices via unsupervised learning

Classification of quantum phases is one of the most important areas of research in condensed matter physics. In this work, we obtain the phase diagram of one-dimensional quasiperiodic models via unsupervised learning. Firstly, we choose two advanced unsupervised learning algorithms, Density-Based Spatial Clustering of Applications with Noise (DBSCAN) and Ordering Points To Identify the Clustering Structure (OPTICS), to explore the distinct phases of Aubry-André-Harper model and quasiperiodic p-wave model. The unsupervised learning results match well with traditional numerical diagonalization. Finally, we compare the similarity of different algorithms and find that the highest similarity between the results of unsupervised learning algorithms and those of traditional algorithms has exceeded 98%. Our work sheds light on applications of unsupervised learning for phase classification.

Keywords:quantum phase, quasiperiodic, machine learning

PACS:71.23.Ft, 71.10.Fd, 71.23.An

SECTION: IINTRODUCTION

Anderson localizationr1, the suppression of wave diffusion in disordered media, is ubiquitous across many areas of classical and quantum physics. Numerous experimental demonstrations have been reported in various systems, such as photonic systemsr2;r3and ultracold atomsr4. Currently, the theoretical framework of Anderson localization is well established. The scaling theory predicts no delocalization in one- and two-dimensional systems, while three-dimensional (3D) systems can exhibit a localization-delocalization transitionr5. A threshold energy that separates extended from localized eigenstates is referred to as the mobility edge (ME)r6.

Quasicrystals also display novel localized phenomenar7;r8. Unlike random systems, quasiperiodic systems exhibit localization transitions even in one dimension. A paradigmatic model is provided by the well-known Aubry-André-Harper (AAH) modelr9;r10, where the localization-delocalization transition can be derived from a simple self-duality argument. Recently, significant interest has focused on finding low-dimensional quasicrystals that, analogous to the 3D Anderson model, display MEs separating extended and localized statesr11;r12;r13;r14;r61;r62;r63;r64;r65;r66;r67;r68;r69;r70;r71;r72;r73.

Traditional methods for distinguishing extended, localized, and critical states across these various models involve calculating a typical physical quantity, the inverse participation ratio (IPR)r15;r16;r17. For a normalized wave function, the IPR of an extended state scales linearly as, vanishing in the thermodynamic limit; the critical state approaches zero at a slower (power-law) rate, while the IPR of a localized state remains finite. Another method involves calculating the Lyapunov exponent, which is defined as the divergence rate between neighboring lattice points. For an extended state, the amplitude between neighboring lattice points remains equal in the thermodynamic limit, resulting in; conversely, for a localized state, the amplitude decays exponentially, leading to. However, the single Lyapunov exponent cannot distinguish the extended state from the critical state, hence the numerical results of critical states are often ambiguous, and a exact definition of critical states is lacking.

Remarkablely, a recent workr18proposes an explicit criterion for precisely characterizing critical states, asserting that the Lyapunov exponents of critical states should simultaneously be zero in both position space and momentum space. In more physically-based language, critical states should exhibit anomalous delocalization transport and multifractal structure (non-extended and non-localized) in both position space and momentum space.

An interesting question arises: Are there alternative methods to distinguish different quantum states in disordered systems? The rise of machine learningr19;r20research seems to answer this question, which has numerous applications in physical contexts, such as photonic structure designr24, quantum many-body physicsr25;r26;r27, quantum computing, and chemical and material physicsr28, as well as topological phase classificationr29;r30;r31;r32. Unsupervised learningr33, a significant branch of machine learning, can facilitate the data-driven construction of quantum states without prior knowledge.

In previous works, supervised learning methodsr36;r37have been employed to detect classical and quantum phase transitionsr38;r40, predict the phase diagrams of the long-range Harper model and the AAH modelr41, and address the edge learning problem of single event migrationr42;r43. However, many questions remain unresolved. For example, prior works have yet to derive eigenstates as markers through supervised learning. Notably, unsupervised learning algorithms do not require a training set; rather, the algorithms independently search for features within the data. This implies that phase diagrams can be obtained without traditional methods. Furthermore, previous algorithmsr36;r37have not effectively distinguished critical states from extended and localized states. In this work, we demonstrate the capacity of the unsupervised classification of three typical eigenstates in one-dimensional quasiperiodic models.

SECTION: IIDBSCAN AND OPTICS ALGORITHM

First, let’s introduce the principle of unsupervised learning algorithm. In practical calculations, we employ two widely-used algorithms, Density-Based Spatial Clustering of Applications with Noise (DBSCAN)r80;r33and Ordering Points To Identify the Clustering Structure (OPTICS)r81;r33,
due to their robustness in handling complex data. DBSCAN, introduced by Martin Ester et al. in 1996, is capable of identifying clusters of arbitrary shapes without requiring the pre-specified clusters, making it particularly suitable for distinguishing localized states (high density) and extended states (low density). OPTICS, developed by Ankerst et al. in 1999, orders points based on their density reachability, allowing for a more detailed analysis of clustering structures, which is useful for detecting transitions between extended, localized, and critical states.

The inputs for both algorithms are n-dimensional vectors, which are treated as coordinate points in an n-dimensional space. The output consists of labels of these points. The algorithms rely on the distance between two points, commonly defined by the Euclidean distance, which is given by the formula:

whereandrepresent the coordinates of two points in the-th dimension, respectively.

SECTION: II.1DBSCAN algorithm

The DBSCANr80;r33is effective for clustering data of arbitrary shapes, as its process is illustrated in Fig.1. DBSCAN categorizes data points into distinct clusters based on the distances between them, which is calculated using the Euclidean distance Eq. (1).

The core idea of the DBSCAN algorithm is to group together points that are density-connected—that is, connected with sufficient density—while marking those that are not part of any cluster as noise. The concept of "density-connected" is defined by two parameters:(the neighborhood radius) and(the minimum number of points required to form a cluster). A point is classified as a core point if it has at leastneighbors within itsradius. If a pointlies within theradius of a core point, thenis considered directly density-reachable. Subsequently a pointis said to be density-connected withif there exists a chain of directly density-reachable points connecting them.

An intuitive example is illustrated in Fig.1, the parameters are set toand. In Fig.1(b), pointhas points,, andwithin itsradius, while pointhas points,, andin its neighborhood, making bothandcore points. These core points and their neighbors form a cluster. Sinceandare density-connected, their clusters merge in Fig.1(c). Pointdoes not belong to any cluster and is classified as noise.

SECTION: II.2OPTICS algorithm

In contrast to DBSCAN, which only classifies points that exceed a fixed density threshold into clusters, OPTICSr81;r33is capable of identifying clusters with varying density levels, grouping points with similar densities into the same cluster. Fig.2illustrates its process.

The core idea of the OPTICS is to generate a sequence that reflects the positional relationship between data points, and cluster the data points based on this sequence. Each data point in the sequence has two attributes: the core distance (), defined as the distance to its-th nearest neighbor, representing the density around the point, and the reachability distance (), which reflects the distance between the point and preceding points in the sequence.

The specific sequence generation process is as follows. Initially, the algorithm computes thefor each point and sets allvalues to infinity. A point is then randomly selected as the first core point [Fig.2(a)]. In each iteration, the newvalue is calculated as the larger between the distance from pointto the current core pointand theof. If this new value is smaller than the previous, it is updated accordingly. The point with the smallestis chosen as the next core point, while the previous core point is added to the result sequence and excluded from further calculations [Fig.2(b)].

After the iterations, clusters are determined based on the result sequence and the threshold[Fig.2(c) and (d)]. If a point’sis smaller than, it is grouped with the previous point in the same cluster. If itsis greater thanbut itsis smaller than, it starts a new cluster. Otherwise, it is classified as noise.

For instance, Fig.2illustrates seven points withand. Initially, pointis chosen as the core point [Fig.2(a)], and after the first round ofcalculations, pointis selected as the next core point, withbeing added to the result sequence [Fig.2(b)]. The process continues until all points are classified. Pointforms a new cluster, and points,,, andare included in’s cluster, while pointsandform a separate cluster [Fig.2(c) and (d)].

SECTION: IIITWO TYPICAL MODELS

In various quasiperiodic systems, the AAH model and the quasiperiodic p-wave model are two representative models due to their display of rich quantum states: extended, localized, and critical states.

SECTION: III.1Aubry-André-Harper model

Quasiperiodic systemsr44;r45;r46;r47;r48;r51exhibit quasiperiodic structures rather than random distributions, such as the Fibonacci lattice model, the Thue-Morse lattice model, and the well-known AAH model. The lattice Hamiltonian for the AAH model is given by:

Here,andrepresent the fermion creation and annihilation operators, respectively;is the particle number operator; anddenotes the total number of lattice points. The termrepresents the quasiperiodic potential field. The parameteris an irrational number. Without loss of generality, we choose the phase factorand setas the energy unit for numerical calculations.

In quantum disordered systems, the inverse participation ratio (IPR) is a quantity typically used to characterize the localized and extended properties of eigenstates. The variation of IPR in the AAH model with respect to the disorder potential strengthwithin the range (0, 3) is shown in Fig.3(a1). The brightness of the color represents the value of the IPR, indicating that brighter colors correspond to larger IPR values. This analysis clearly reveals a sudden change at, where all eigenstates of the Hamiltonian become critical states. Moreover, all eigenstates of the Hamiltonian are extended when, whereas they are localized when.

SECTION: III.2Quasiperiodic p-wave model

The Hamiltonian for a one-dimensional p-wave superconducting pairing model in a quasiperiodic lattice is given by:

where. When, the model in Eq. (3) reduces to the AAH model in Eq. (2). Whenandincreases, this model exhibits a transition from a topological superconducting phase to an Anderson localized phase at. Moreover, the model in Eq. (3) exhibits a large number of critical states.

The numerical phase diagram of IPR for this modelr52;r60is shown in Fig.3(a2). In the region where, all eigenstates of the system are extended states; in the region, all eigenstates are critical states; and in the region, all eigenstates are localized states.

SECTION: III.3Simulation results

By applying the DBSCAN and OPTICS algorithms, We perform numerical simulations on these two models. For the AAH model (Eq.2), we set the total number of lattice pointsto obtain the eigenvector of the Hamiltonian. Similarly, for the quasiperiodic p-wave model (Eq.3), we set. These eigenvectors are put into the two algorithms separately, where the parametersandare adjusted. The output is a list of clustering labels, indicating the category to which each eigenvector belongs.

The clustering results for the AAH and quasiperiodic p-wave models are shown in Fig.3(b1), (b2), (c1) and (c2), respectively. The horizontal axis of each figure represents the disorder potential strength, while the vertical axis represents the index of eigenvalues for a given. Each point corresponds to an eigenvector, and different colors represent the distinct categories produced by the clustering.

As shown in Fig.3, the classification of eigenstates is clearly visible. In Fig.3(b1) and (c1), the region whereis darker, representing the extended state;corresponds to the localized state, andmarks the critical transition point between two phases. In Fig.3(b2) and (c2),indicates the extended state,represents the localized state, and the regioncorresponds to the critical state. Notably, the OPTICS algorithm distinctly identifies the critical state of the AAH model atin Fig.3(c1).

To explain more specifically how DBSCAN and OPTICS algorithms classify extended and localized states, we demonstrate their frameworks for quantum disordered systems. DBSCAN groups together eigenstates with high-density, while marking those in lower-density regions as outliers. Hence DBSCAN can identify extended states, which are more uniformly spread across the lattice, by forming large and continuous clusters. On the other hand, localized states, where the wave function is confined to a smaller region, result in more compact and isolated clusters. OPTICS, similar to DBSCAN, focuses on ordering eigenstates based on the density reach-ability. This approach allows OPTICS to detect more subtle transitions in quantum systems, such as critical states, as the density structure captured by OPTICS reflects the gradual transition from localized to extended states, and critical states lie at the boundary between these phases.

The primary advantage of machine learning methods like DBSCAN and OPTICS over traditional methods lies in the data-driven nature. Machine learning algorithms can automatically detect patterns and classify states without requiring prior knowledge of the system. This capability makes them particularly effective for identifying complex phase transitions, including critical states, which are challenging by the IPR simulation. Moreover, machine learning methods react well for larger data-sets, allowing for more efficient classification in systems with a large number of eigenstates.

SECTION: IVSIMILARITY

In this section, we employ the difference hash algorithm to calculate the similarity between traditional methods [Fig.3(a)] and machine learning methods [Fig.3(b) and (c)], namely the similarity between the IPR results and the clustering results.

The difference hash algorithm treats a figure as a two-dimensional signal composed of various frequency components. High-frequency components correspond to regions with significant brightness variations between adjacent pixels, providing detailed information about the image. In contrast, low-frequency components represent areas with minor brightness variations, capturing the general structure of the image. The algorithm reduces the image size to filter out high-frequency components and computes the hash values by focusing on the low-frequency components. If a pixel is brighter than the following pixel, the corresponding hash bit is set to 1; otherwise, it is set to 0. The similarity between two images is then determined by comparing their hash values. The similarityis given by the formula:

whereis the number of pixels in the image, andandare the-th bits of hash values, respectively.

Similarity results for different algorithms are illustrated in Table1, which indicate that the DBSCAN algorithm significantly surpasses the OPTICS algorithm. For both the AAH model and the quasiperiodic p-wave model, the DBSCAN algorithm achieves a similarity of over 95% compared to traditional methods, with a peak value of 98.4%. In contrast, the OPTICS algorithm only attains approximately 90% and 62% similarity for the two models, respectively. Additionally, the unsupervised learning results for the AAH model are notably better than those for the quasiperiodic p-wave model. This is reasonable, as the AAH model deals with a single-particle problem, while the quasiperiodic p-wave model is a mean-field approximation of a strongly correlated system. The latter’s increased complexity and reduced robustness to machine learning algorithms explain the lower performance.

SECTION: VCONCLUSION

In this work, we investigate the capability of unsupervised learning algorithms to extract information about distinct phases in various quasiperiodic systems. Specifically, we employ two unsupervised learning algorithms, DBSCAN and OPTICS, to classify the extended, localized, and critical states in the AAH model and the quasiperiodic p-wave model. While previous studies have focused on supervised learning algorithms, we demonstrate that unsupervised learning algorithms can accurately reproduce phase diagrams in close agreement with traditional numerical methods. Furthermore, we apply the difference hash algorithm to quantify the similarity between the unsupervised learning phase diagrams and the traditional numerical phase diagrams. Our results show that the DBSCAN algorithm is particularly effective for exploring quasiperiodic systems. Additionally, DBSCAN is not only applied to single-particle problems but also effectively describes the mean-field approximation of strongly correlated systems. Thus, a potential extension of DBSCAN is to distinguish many-body wave functions across various phases in many-body interacting systems. This work provides a valuable demonstration of unsupervised learning in classifying different states of matter and highlights its potential for phase classification.

SECTION: References