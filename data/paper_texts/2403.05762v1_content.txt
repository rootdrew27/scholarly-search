SECTION: Lateral Control of Brain-Controlled Vehicle Based on SVM Probability Output Model

The non-stationary characteristics of EEG signal and the individual differences of brain-computer interfaces (BCIs) lead to poor performance in the control process of the brain-controlled vehicles (BCVs). In this paper, by combining steady-state visual evoked potential (SSVEP) interactive interface, brain instructions generation module and vehicle lateral control module, a probabilistic output model based on support vector machine (SVM) is proposed for BCV lateral control to improve the driving performance. Firstly, a filter bank common spatial pattern (FBCSP) algorithm is introduced into the brain instructions generation module, which can improve the off-line decoding performance. Secondly, a sigmod-fitting SVM (SF-SVM) is trained based on the sigmod-fitting method and the lateral control module is developed, which can produce all commands in the form of probability instead of specific single command. Finally, a pre-experiment and two road-keeping experiments are conducted. In the pre-experiment, the experiment results show that, the average highest off-line accuracy among subjects is 95.64%, while for those in the online stage, the average accuracy is only 84.44%. In the road-keeping experiments, the task completion rate in the two designed scenes increased by 25.6% and 20%, respectively.

This work was jointly supported by the National Natural Science Foundation of China under Grant No.U1964202, 61603295, Qin Chuangyuan “Scientists + Engineers” Team Construction in Shaanxi Province under Grant No. 2022KXJ-38, and Xi’an Science and Technology Program under Grant No.2022JH-RGZN-0041.

Hongguang Pan, Xinyu Yu and Yong Yang are with College of Electrical and Control Engineering, Xi’an University of Science and Technology, Xi’an 710054, China, and Xi’an Key Laboratory of Electrical Equipment Condition Monitoring and Power Supply Security. Xi’an 710054 (e-mail: hongguangpan@163.com, 15035804802@163.com, yongy@xust.edu.cn, llliuzesheng@163.com)

SECTION: IIntroduction

Brain-controlled vehicle (BCV) is a vehicle controlled by the human brain rather than limbs through brain-computer interface, which can convert Electroencephalogram (EEG) signals into control instructions and establish direct control channels between human intentions and external devices[1,2,3,4]. On the one hand, for the disabled persons, BCVs may help them recover their ability to drive, expand their range of activities, and improve their quality of life. On the other hand, for the healthy individuals, BCV can liberate their limbs and enhance their driving experience by providing a new driving style[5].

EEG signal has become the most commonly used technology in the brain-computer interface (BCI) system because of its high time resolution, high signal-to-noise ratio (SNR) and easy access. At present, BCI system based on EEG signal is used to control robots directly in most kinds of work through users’ minds[6,7,8,9,10]. It has significant advantages in rehabilitation fields, such as rehabilitation for the disabled and nursing care for the elderly[11,12]. Steady-state visual evoked potential (SSVEP) is a periodic nerve response induced by repeated visual stimuli, which usually generates EEG signals with the same frequency modulation as the target. In this paper, we choose SSVEP as an experimental paradigm, because it is suitable for the steering system of BCVs[13,14].

Biet al.[13]used SSVEP-BCI based on HUD for lateral control of vehicle. In the experiment part, the subjects completed the task on the U-shaped road. The experimental results verify the possibility of using EEG to carry out vehicle lateral control at low speed. However, due to the degradation of the online BCI system performance, some subjects overall experimental results are not very ideal. Lu and Bi proposed an EEG-based longitudinal control system for brain-controlled vehicles[14]. This method is tested in the virtual scene of the laboratory by simulating experiments on vehicles. The average accuracy of the off-line BCI system is more than 90%. But it shows relatively poor driving performance for some subjects in the online stage, and the longitudinal control module can only output three fixed commands, considerably reducing the performance of the BCV. Given the constraints of the limited of all existing BCI systems, it is very important to finding ways to enhance and ensure the overall driving performance.

At present, some work used auxiliary controllers and shared control strategies[15,16,17]to improve the BCVs driving. Zhuet al.[18]established a BCI system using the motion imagination to control the simulated vehicle using a shared control strategy. Luet al.[19]used model predictive control (MPC) as an auxiliary controller to control the lateral direction of the vehicle. The simulation results showed that the method makes it possible to test road-keeping and avoid obstacles while maintaining the user’s control authority. However, as we all know, introducing MPC as an auxiliary controller will change the control system structure and bring a lot of computation. In addition to the above methods, Khanet al.[20]designed a brain-driven intelligent wheelchair based on a vision-based sensor network, which can be controlled by SSVEP brain signal. In off-line training stage, the accuracy was up to 96%, meanwhile the 95% accuracy was achieved for online control.

In this paper, we introduced FBCSP algorithm into the brain instructions generation module, which can improve the off-line decoding performance. On this basis, lateral control module based on the SF-SVM method was developed to improve driving performance. The contributions of this paper consists of the following three parts:

Improve the SNR of the EEG signals and the off-line decoding performance of the brain instructions generation module, through designing and introducing the filter bank common spatial pattern (FBCSP) algorithm.

Improve the driving performance of BCV, sigmod-fitting SVM (SF-SVM) is trained based on the sigmod-fitting method. Based on the SF-SVM, the vehicle lateral control module is designed, this module can convert output instructions into probability values.

Verify the effectiveness of the proposed overall scheme. In the pre-experiment, the experiment results show that the average highest off-line accuracy among subjects is 95.64%, the average online accuracy is only 84.44%. In the road-keeping test, the lateral control module based on the SF-SVM has better BCV driving performance.

SECTION: IILateral Control System Design

As shown in Fig.1, the vehicle lateral control system proposed in this paper is made up of two parts, i.e., brain instructions generation module and lateral control module. The working process is as follows. The driver makes a decision based on the feedback from the surroundings to generate a steering command. At the same time, the driver needs to look at the corresponding stimulus on the user interaction interface, and then decodes the collected EEG signal into a control command. Finally, the lateral control module converts the command into the corresponding control signal and transmits it to control the vehicle.

SECTION: II-AInteraction Interface Design

This study is based on brain vision, and uses the steady state motion reversal visual stimulation paradigm with low flicker and the tireless user to induce periodic steady state potentials. It mainly consists of two chessboards, with the reversal frequency of 13Hz and 11Hz, respectively. Each chessboard is coded as 1125 cells (white and black), each size is 25 pixels. The reasons for choosing the frequency of this paradigm are as follows. Firstly, low-frequency stimulation is not easy to cause brain fatigue. Then, the spectral peak generated by the SSVEP is around 10 Hz, and the amplitude reaches the maximum at 15 Hz and 12Hz[21]. Fig.1presents the checkerboard pattern.

The left and right chessboards are used for lateral control of the vehicle. When users want to turn right, they need to look at the right chessboard, inducing the brain to generate EEG signals of the corresponding frequency. When they want to turn left, they need to watch the left chessboard. When the user wants to maintain the current driving state, there is no need to look at any stimulus.

SECTION: II-BBrain Instructions Generation Module

The signal flow diagram of the brain instructions generation module is shown in Fig.2, which consists of off-line and online stages. The off-line phase is used to decode the EEG signal, and the key parameters and models are trained for subsequent use in the online stage. Key parameters include the length of the time window, the projection matrix generated by the FBCSP, and the key parameters in the SF-SVM model. In the online phase, EEG is collected in real time, and the signal is decoded by off-line model to generate the corresponding instructions. These two parts are mainly divided into the following three steps: signal acquisition and preprocessing, feature extraction, and classification.

The signal acquisition equipment is the EPOC Flex-32 Channel Wireless EEG Headset of Emotiv company, and the electrode placement position is Cz, Fz, O1, O2, Oz, P3, P4, P7, P8, and Pz. The electrode position is shown in Fig.3. The reference potential corresponds to the average potential of the left and right earlobes. The sampling frequency is 128 Hz, the contact impedance between the electrode and scalp is calibrated to be less than 10 k. The collected signal needs to be band-pass filtered (4-49Hz).

EEG signal is converted into a corresponding instruction for each time window length. The length of time windows is one of the key parameters, which determines the decoding performance. Therefore, in the training phase, this study tests the decoding performance by defining different time window lengths to ensure that the brain instructions generation module has the best decoding performance. It should be pointed out that in order to increase the training dataset, we set the step size of the time window to 0.5s at the training stage.

The spatial filter is used to improve the resolution of multi-channel EEG signals and the SNR of EEG signals. In this section, in order to take into account the interaction between different sub-bands of EEG signals, we apply one-versus-rest FBCSP algorithm to generate spatial filters. The overall algorithm of the FBCSP is shown in Fig.4.

For two classification tasks, a multi-channel EEG epochwith dimensions, whereNis the number of channels, andSis the sample points number of EEG epoch per channel, the normalized covariance matrixcan be expressed as:

whererepresents the transposition of matrix,represents the summation of elements on the diagonal of the matrix. Then covariance matrixof mixed spaces can be factorized as:

whereandare the average covariance matrix by averaging over all the trials of each classification task,is the matrix of eigenvectors andis the diagonal matrix of eigenvalues. The whitening characteristic matrixis shown in (3):

The average covariance matrices,can be transformed by:

whereandhave same eigenvector. By performing principal component decomposition for two matrices, it can be obtained that:

Therefore, the projection matrixis denoted as:

In this section, for multi-class problems, we apply one-versus-rest algorithm to generate spatial filters. Firstly, we filter the EEG signal of different frequency bands. Then,is obtained by taking the average of the projection matrix of each frequency band:

whereis the number of frequency sub-bands,is whitening matrix of the-th frequency band,is the feature vector of the-th frequency band.is the EEG signal obtained by filtering the-th average projection matrix through spatial filtering:

whereis-th CSP average projection matrix.

The frequency information of the EEG epoch is obtained by using the Pwelch algorithm which uses a short sliding window, continuing intercept the signalin sections, and then perform fourier transform on the windowed intercepted signal:

whereis the angular frequency, the Hanning window is selected as a window functionand the window function is:

And the expression for the signal power spectrum is:

In this section, we extract the power spectrum of each channel as the characteristics. The power spectrum extraction for each channel of the EEG epoch at the specific frequency of half frequency0.5Hz, basic frequency0.5Hz, double frequency0.5Hz. So we can get 60 features for each EEG epoch, the feature extraction is shown in (14):

wheredenotes the-th power spectrum feature of EEG epoch filtered by the-th CSP projection matrix.

We adopted a one-versus-rest classification strategy to achieve multi-classification. The one-versus-rest classification strategy needs to buildbinary classifiers for theclassification problem. Compared with traditional learning methods, the final decision function of support vector machine is only determined by a few support vectors, thus avoiding the disaster of dimensionality. In this paper, SVM with RBF as kernel function is used to construct classifier. For-th EEG epoch,is-th SVM output without threshold, which can be depicted in (15):

wheredenotes the number of the support vector of the-th classifier. For-th EEG epoch,is the-th support vector of-th classifier,is the weight of the-th support vector of-th classifier, andis the bias of the-th classifier.

The sigmod-fitting algorithm proposed by Platt is used to train the one-versus-rest SVM probability output value model. This method transforms the output of the classification model into probability values based on the distribution of categories. The classification model output of the training set is filtered by the sigmoid function, the probability output value of the-th SVM model is shown in (16):

whereare the coefficient matrix of probability value output model, which can be obtained by optimizing the loss function:

whereis the-th label of-th classifier.

After sigmod-fitting, each EEG epoch can be express as three corresponding three probability values, and the maximum probability value will be selected as the decoding result of this EEG epoch. We identify that a probability value greater than 0.9 indicates that the classification result is correct.

SECTION: II-CLateral Control Module

In sectionII-B, the sigmod-fitting method is used to obtain the SF-SVM classification model, which converts the output instructions into probability values. Theis the steering wheel angle by-th update can be represented as in (18):

whereis the steering command output by the brain instructions generation module at the-th update,is the probability value obtained by the SF-SVM.andare the maximum and minimum value range of steering wheel angle, respectively. The unit ofis deg.

SECTION: IIIPre-Expriment

In this section, the subjects are required to complete the pre-experiment so as to train and test the decoding performance of the brain instructions generation module. We select the subjects who performed both well in the off-line and online test because the BCVs cannot work for all users. At the same time, we consider that those well-behaved subjects were able to use brain signals to drive, thus allowing them to participate in the road-keeping experiment.

SECTION: III-AExperiment Subjects and Platform

Four subjects, aged from 22 to 25 years old (average age 23.8 years old), participate in this pre-experiment in this study. These subjects have no history of brain illness and have normal or adjusted vision.

The experimental platform is made up of EEG signal acquisition equipment, SSVEP stimulation interface, Carsim vehicle and lateral control module. The hardware environment of simulation experiment includes: the processor of Inter(R) Core(TM) i7-8750H, the graphics card of NVIDIA GeForce GTX 1050, and DDR4 16G of RAM. Emotiv’s EPOC Flex-32 Channel Wireless EEG Headset is used to collect EEG signals and the SSVEP visual stimulation written in C Code. CarSim provides a simulation vehicle, and its lateral control module is built in the simulink of MATLAB. The communication system between the EEG signal acquisition equipment and Carsim is built by using Simulink.

SECTION: III-BExperiment Process

The experiment includes the off-line and online stages. In the off-line stage, first, the subjects are asked to complete the EEG signals acquisition; then, the five-fold cross-validations for the accuracy of each subject is adopted to take the average results as the off-line accuracy. EEG acquisition is divided into the following two steps. First, participants are required to complete two groups of EEG signal acquisition, which are used to acquire the EEG signals at two frequencies. The two different frequencies represent the control commands for turning left and right respectively. For each frequency, the subjects are required to conduct four sessions, four trials for each session, each trial lasts for 12 seconds. Then, the subjects completed the test without any stimulation to acquire the EEG data related to the command of keeping straight driving. At this group, subjects need to conduct two sessions of collection, and each session carries out eight trials, each trial lasts for 12 seconds.

In the online stage, the subjects, who perform well in the off-line stage, are also required to complete the online performance test. We select the time window length corresponding to the highest accuracy for off-line test, and the accuracy of three commands (turning right, turning left, gonging forward) will be tested, respectively.

SECTION: III-CExperiment Results

The experiment results in the off-line stage are shown in Figs.5, where Fig.5and Fig.5show the average accuracy and information translate rate (ITR) of the subjects under different time window lengths. For subject one, two and three, the average highest off-line accuracy is 95.64%. Subject one exhibits the best decoding performance, and subject four presents the worst decoding performance who highest off-line accuracy is 89.72%.Therefore, subject four won’t participate in the subsequent experiments.

TableIshows the average online accuracy of the other three subjects. This result is obtained under the time window length corresponding to the highest accuracy for each subject. Compared with their off-line performance, all three subjects show a certain decline in the performance of the online test and the average classification accuracy is only 84.44%.

SECTION: IVRoad-Keeping Experiment

The road-keeping experiments are conducted separately in the scenes 1 and 2. The task scenes are shown in Figs.6. The road parameters are shown in TableII. The goal of the road-keeping test is to keep the vehicle running along the road centerline.

SECTION: IV-AExperimental Process

In the road-keeping experiments, the subjects are asked to conduct fifteen trials of road-keeping experiments in two class scenes with the SVM and the SF-SVM, respectively. The characteristics of the road in the scene 1 is long distance and small curvature, so the driving difficulty is low, but the average completion distance is large. The characteristics of the road in the scene 2 is short distance and the curve is large, so the driving task is more difficult, but the average completion time is short.

We apply the task completion rate, the lateral errorand the yaw angleas metrics to evaluate the performance of the BCVs. A trial is considered successful if the task completion distanceis shorter than the limit set to be two times the nominal distance[13].is defined as the distance from the vehicle center of gravity to the road centerline, andis defined as the orientation error of the vehicle frame relative to the road. In this experiment,,,, the vehicle rotation ratio is 19. Subject one selects a time window length of 4s in the scene 1 and 3s in the scene 2.

The selection of the time window length is a compromise after taking accuracy and ITR into account. Generally, we will choose the length of the time window with the highest ITR, but more must be considered in practice. The road-keeping experiment in the scene 1, it takes more time to complete due to the long distance. As a result, subjects needs to send more classification instructions and error instructions will also increase. Therefore, subject one choose to use the longest time window length to improve the accuracy of the experiment and ensure the completion of the experiment.

SECTION: IV-BExperiment Results and Analysis

This section shows the experimental results for subject one. We choose one of trials to display the results. The green rectangle in figures represent the straight section, and the orange represents the turning section. For convenience, we have made the following notations: maximum lateral error, mean lateral error, maximum yaw angle, mean yaw angle.

Subject one successfully completed 11 trials and 7 trials with SF-SVM and SVM, respectively. Fig.7shows input steer angle can only be an integer multiple ofwith the SVM. By contract, with the SF-SVM, the control module can flexibly output various steer angle. Fig.7shows the output probability value with the SF-SVM, and there are 65 instructions in this trial, with 9 probability values below 0.90. It can be seen that the online classification accuracy of this trial is 86.15%.

Fig.9,9,9show the position,andof the brain vehicle, respectively. Fig.9shows theand. As shown in TableIII, compared with the SVM, the SF-SVM generates the smaller average of lateral error and yaw angle error, the smaller maximum of lateral error and yaw angle error and the shorter task competition distance. Specifically, the task completion rate increased by 25.6%, the average of lateral error is reduced by 10.15%, and the average of yaw angle error is reduced by 16.88%.

Subject one successfully completed 9 trials and 6 trials with SF-SVM and SVM, respectively. Fig.8shows the input angle. Fig.8shows the output probability value with the SF-SVM. There are 32 instructions in this trial, with 4 probability values below 0.90. It can be seen that the online classification accuracy is 87.50%.

Fig.10,10,10show the position,andof the brain vehicle, respectively. Fig.10shows theand. As shown in TableIV, the SF-SVM model produces better performance. Specifically, the task completion rate increased by 20.0%, the average of lateral error is reduced by 36.90%, and the average of yaw angle error is reduced by 15.95%.

In the scene 1, even if with the SF-SVM control module, the lateral error is large in the range of coordinates (250,250)-(350,150). Meanwhile, in the scene 2, the overall lateral error is low, but the yaw angle error is large. It should be noted that the SF-SVM lateral control module only can weaken the wrong commands for the whole driving and play a certain corrective role, but it cannot avoid wrong commands. For incorrect instructions, SF-SVM requires less correct instructions to correct them. Hence, before applying to BCV in the real environment, the key technique is to improve the performance of the brain instructions generation module
(including higher precision of signal acquisition, the increase in the number of output commands, etc.).

SECTION: VConclusions

This paper has proposed a vehicle lateral control module based on the SF-SVM to improve the BCVs’ driving performance. The FBCSP algorithm is introduced in the brain instructions generation moudle which improves the SNR of EEG signals and ensures better decoding performance. In the case of poor performance of driving BCVs, the SF-SVM based on the sigmod-fitting method is trained. Based on this model, the control module with the SF-SVM is developed, which it not only can make the control instructions more flexible, but also can weaken the instructions in the case of incorrect classification. What’s more, experiments in the two road-keeping scenes are conducted, and results show that the control module with SF-SVM improves the driving performance of BCVs.
This study provides some insights on how to enhance the online implementation performance of the brain control dynamic system.

SECTION: References