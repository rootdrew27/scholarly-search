SECTION: RespDiff: An End-to-End Multi-scale RNN Diffusion Model for Respiratory Waveform Estimation from PPG Signals††thanks:* Co-first Author†Corresponding Author ym520@ic.ac.ukThis project is open sourcehttps://github.com/MYY311/RespDiff

Respiratory rate (RR) is a critical health indicator often monitored under inconvenient scenarios, limiting its practicality for continuous monitoring. Photoplethysmography (PPG) sensors, increasingly integrated into wearable devices, offer a chance to continuously estimate RR in a portable manner. In this paper, we propose RespDiff, an end-to-end multi-scale RNN diffusion model for respiratory waveform estimation from PPG signals. RespDiff does not require hand-crafted features or the exclusion of low-quality signal segments, making it suitable for real-world scenarios. The model employs multi-scale encoders, to extract features at different resolutions, and a bidirectional RNN to process PPG signals and extract respiratory waveform. Additionally, a spectral loss term is introduced to optimize the model further. Experiments conducted on the BIDMC dataset demonstrate that RespDiff outperforms notable previous works, achieving a mean absolute error (MAE) of 1.18 bpm for RR estimation while others range from 1.66 to 2.15 bpm, showing its potential for robust and accurate respiratory monitoring in real-world applications.

SECTION: IIntroduction

Respiratory waveform monitoring is vital in clinical as it is important to indicate the health condition of patients. Respiratory rate (RR) is informative to several fatal diseases within the respiratory and cardiovascular systems[1,2]. Hence, the methods to accurately measure RR in a convenient manner are gaining increasing attention

Usually, respiratory signal is measured with methods such as impedance pneumography, capnography and spirometry. However, these methods require bulky machines, which are not portable and restrict the scenarios for measuring RR. Furthermore, in clinical settings, manually counting is still considered the primary technique to estimate respiratory rates. This is inconvenient for the widespread respiratory rate estimation. Thus, there is a need to extract respiratory rates or estimate respiratory waveform in a convenient and human-labour-free manner. Meanwhile, Photoplethysmography (PPG) signals have gained broad interest and have been widely integrated into wearable devices recently. PPG sensor measures the blood volume change in the microvascular bed of tissue. The PPG signals are modulated by the respiratory signals, including frequency, amplitude and baseline modulations[3]. Then it will be beneficial to extract respiratory information from PPG signals, utilizing the portable nature of PPG sensors leading to continuous and portable RR estimation.

However, previous works show limited performance in RR estimation using deterministic mapping methods and hand-crafted features. Meanwhile diffusion model has gained tremendous interest recently due to its powerful iteratively optimizing ability[4]. The diffusion model has shown its prominent performance in various domains, including speech generation[5,6], time series generation[7,8,9], time series imputation[10]and biomedical signal denoising[11]. Thus we leverage the diffusion model and introduce the diffusion model to the respiratory waveform estimation task for the first time. We also propose multi-scale encoders under the assumption that the modulation of breathing activities on PPG signals scatters over different frequency ranges. Besides, we aid the optimization of the diffusion model by adding a spectral loss term, directly measuring the sampling quality in the frequency domain. With the diffusion model’s strong modelling capacity, we utilize the whole dataset without deleting signal segments due to low signal quality, which better mimics real-world scenarios.

In summary, we propose RespDiff, an end-to-end multi-scaled RNN based diffusion model giving the key contributions

We have applied the diffusion model on the respiratory waveform extraction task for the first time, manifesting the robust performance of the diffusion model in this new field.

We propose multi-scale encoders extracting spatial features at various resolutions.

We integrate spectral loss into the training scheme, which significantly increases the performance of the model.

We validated our method on the BIDMC dataset[12]and outperformed several well-established previous works, resulting in a new record in RR estimation.

SECTION: IIRelated Works

Various works have been proposed to estimate RR from PPG signals. Donget al.first applied classical signal processing techniques to extract multiple respiratory waveforms and remove trials with low signal quality indexes. Then they fused the extracted signals using sequence processing deep learning algorithms[13]. Iqbalet al.removed low-quality signals and combined preprocessing, filtering and postprocessing techniques to give the final RR estimation[14]. Osathitpornet al.proposed RRWaveNet, a U-net structure Network with Convolutional Neural Networks (CNN) layers as encoders and decoders. The proposed RRWaveNet works on a processed dataset with low signal quality segments deleted to give the final RR estimation[15]. Aqajariet al.reformulated the respiratory waveform generation task as a conditional generation task and chose cycle GAN as the generation model[16].

SECTION: IIIMethods

In this work, we have introduced a conditional diffusion model to the task of respiratory waveform estimation task. Under the backbone of the bidirectional RNN model, we propose novel multi-scale encoders which help extract features at different resolutions. Also, in addition to the diffusion loss in the distribution domain, we bring in a spectral loss term, optimizing the model regarding of signal quality in the frequency domain.

SECTION: III-AConditional Diffusion Models

Conditional diffusion models are composed of two processes: a forward process to corrupt the clean data to a known prior distribution,e.g., standard Gaussian noise, and a reverse process to iteratively recover the data distribution from the prior under the guidance of condition information.

In this work, given respiratory waveformand corresponding PPG signal, we develop a waveform-domain diffusion model to generateconditioned on.
In the forward process, we progressively corrupt the clean respiratory waveforminto a standard Gaussian noisewith a predefined noise schedule, where the transition probability can be written as:

With the property of isotropic Gaussian noise, we can efficiently calculate the noisy representation at time stepwith:

whereandindicate noise level anddenotes the Gaussian noise injected to corrupt the clean signal.

In reverse process, we start the denoising process from, and gradually removes the noise added to the clean signalat each time step:

The training objective of diffusion models is to maximize the variation lower bound (ELBO) of the likelihood of[4]. In practice, we adopt a re-weighted loss function from previous works[4,17,18]as follows:

In bio-electrical signal processing, several previous works have established strong diffusion baselines for EMG synthesis[19]and denoising[11], EEG imagine speech decoding[20], and ECG imputation and forecasting[21,22]. However, none of the previous studies explored the performance of diffusion models for respiratory waveform, which is a vital sign of health conditions in clinical.

SECTION: III-BNetwork Architecture

CNN is known for its powerful potential in feature extraction. The size of the kernel of CNN decides the spatial resolution of the extracted features. It is considered to be difficult to carefully design kernel sizes without any prior knowledge. To cope with this challenge, we propose the encoderwhich aims to extract characteristics from PPG at multiple scales. Theis composed of a stack ofconvolutional layers with varying resolution sizes. Multi-scale fine-grained feature extractor can be formulated as:

Breathing activities can generate slow-varying components in PPG signals, such as baseline modulation. Even a large kernel size is hard to capture such information. Thus we need feature extraction methods with large receptive fields. We propose the dilated multi-scale encoder, which aims to capture coarse-grained spatial features from the PPG signal and uses a similar multi-resolution design withwithlayers. However, the convolutional layer is replaced by dilated convolutions, which significantly helps increasing the receptive field:

During the respiratory estimation process, the beginning of the sequence usually suffers from bad quality due to the lack of context before it. Thus, we utilize bidirectional RNN, which leverages both past and future context to improve the quality of predictions even at the beginning of the sequence.
To make better use of the information in the input signal, firstly, the multi-scale PPG featurewith feature fusion ratiocan be formulated as:

The bidirectional RNN processes the input featureand aims to estimate the noise illustrated in4. Through training, the timestep for the diffusion process is uniformly sampled with. Instead of directly sending the noised inputinto the noise predictor, we extract its fine-grained featureand concat it withalong the channel.
The fused input, denoted as, is sent to a bidirectional RNN to predict the noise at state. The hidden state of the forward (fd) and backward (bd) RNN process is created as:

where the weights in RNN are,,,,and, andis the activation function.and, are the forward and backward hidden features at signal positionand diffusion timestep. The concatenation of themwill go through output head to give the estimated noise.

SECTION: III-CSpectral Loss

The training objective of diffusion models shown in (4) is to faithfully recover the data distribution from the prior distribution, while it may not guarantee the optimal sample quality in RR estimation.
Hence, to strengthen the sample quality of our proposed RespDiff, we further investigate the function of auxiliary loss functions which highlights the RR information in synthesized respiratory signals.
Specifically, we introduce a spectral loss into the original training objective of diffusion models.
At each training iteration, given the noisy representation, the network predicts the added noiseand then we can estimate a coarse respiratory waveformwith a single step:

Then, we apply the Fourier transform magnitude extractorto both estimatedand the ground-truth signal, and calculate a distance between them with:

whereis the number of frequency bins. Hence, during the training process, we employ both the diffusion loss shown in (4) and a weighted, where the weightis set as 0.01 in our experiments.
In inference, at each sampling step, the generation of diffusion models has been strengthened by our proposed auxiliary loss, leading to a final improvement in RR estimation after iterative sampling steps.

SECTION: IVExperiments

SECTION: IV-AExperimental Setup

Our conduct experiments on the BIDMC dataset[12], a widely-used benchmark dataset containing 53 recordings of ECG, PPG, and impedance pneumography signals, each of which has a length of 8 minutes.
The PPG signal and respiratory waveform are first downsampled to 30Hz since the breathing activity predominantly happens in the low frequency domain. Then, the breathing and PPG signals are further low-pass filtered with a cutoff frequency of 1Hz, segmented into lengths of 5 seconds, and normalized to a range of [-1, 1] and [0, 1] respectively. To mimic the real-world scenarios, we retain each processed sample, rather than deleting low-quality ones[15,14]. Leave-one-subject-out method is chosen as the training scheme for a comprehensive evaluation.

At the inference stage, we employ both DDPM[4]and DDIM[23]sampler to generate 5-second samples and concatenate the samples to obtain 8-minute results. RR estimation error and waveform estimation error are calculated on a window size of 60 seconds, where RR is calculated by applying a Fourier transform on the waveform and then finding the maximum non-zero frequency component. Following previous works[16,14,15], Mean absolute error (MAE) is used as the evaluation metric for both tasks.

SECTION: IV-BResults Analysis

As shown in tableI, we compare our works with three previous works, where our RespDiff outperforms other methods in RR estimation by a large margin.
Especially, compared with RRWaveNet[15]and the work from Iqbalet al.[14]which only estimate RR, our work generates the whole respiratory waveform. We perform a more complex task but achieve stronger performance.
Moreover, our end-to-end network does not require laborious task-specific tuning,e.g., the threshold selection process required by the baseline Iqbalet al.[14].

Also, our work utilizes the whole dataset without removing any segments. This approach better mimics the real-world scenario, where a clean recording environment is not a guarantee. The waveform MAE estimation results for RespDiff with and without spectral loss are 0.307 and 0.316. All mentioned works did not mention waveform estimation loss.

SECTION: IV-CAblation Study on Spectral Loss

We test the function of our proposed spectral loss under diverse inference processes of diffusion models,i.e., numerous-step sampling and few-step sampling.
As shown in TableII, in 50-step synthesis, the RR estimation error has distinctively decreased because of spectral loss.
When reducing the number of sampling steps to, our proposed spectral loss still plays an important role in improving RR estimation accuracy. Notably, the spectral loss makes 6-step sampling outperform the 50-step RespDiff without this auxiliary loss, considerably improving the inference speed of RespDiff.
In our observation, with 6 inference steps, RespDiff could generate an 8-minute respiratory waveform in 7 seconds. Figure2gives an example of respiratory waveform estimation under different settings. It is manifest that when the spectral loss is not employed, the estimated respiratory waveform gives the wrong RR by generating one more peak indicated by grey shades.

SECTION: IV-DAblation Study on Multi-Scale Encoder

To further justify the idea of applying a multi-scale encoder to extract features with different spatial resolutions. We set the kernel sizes to be all 3 instead of 1, 3, 5, 7, 9 and 11 in the multi-scale setting. Under the same training setup, the RR error increases from 1.44 bpm to 1.53 bpm, manifesting the effects of the multi-scale encoder.

SECTION: VConclusion

In this work, we have introduced RespDiff, a novel multi-scale diffusion model designed for the challenging task of respiratory waveform estimation from PPG signals. Our model leverages a bidirectional RNN as its backbone, coupled with multi-scale encoders that effectively capture features across various temporal resolutions. RespDiff has demonstrated promising results, outperforming several recent approaches in terms of both respiratory rate (RR) estimation and waveform reconstruction accuracy.

Furthermore, we have empirically shown that incorporating a spectral loss term significantly enhances the model’s RR estimation capabilities, regardless of whether DDPM or DDIM sampling is employed. This highlights the importance of considering both time-domain and frequency-domain information for accurate RR estimation.

To the best of our knowledge, this is the first application of diffusion models to the problem of respiratory waveform estimation from PPG signals. Our results underscore the powerful modelling capacity of diffusion models in this new domain, opening up exciting possibilities for future research.

SECTION: References