SECTION: Vision Transformer-based Semantic Communications with Importance-Aware Quantization
Semantic communications provide significant performance gains over traditional communications by transmitting task-relevant semantic features through wireless channels. However, most existing studies rely on end-to-end (E2E) training of neural-type encoders and decoders to ensure effective transmission of these semantic features. To enable semantic communications without relying on E2E training, this paper presents a vision transformer (ViT)-based semantic communication system with importance-aware quantization (IAQ) for wireless image transmission. The core idea of the presented system is to leverage the attention scores of a pretrained ViT model to quantify the importance levels of image patches. Based on this idea, our IAQ framework assigns different quantization bits to image patches based on their importance levels. This is achieved by formulating a weighted quantization error minimization problem, where the weight is set to be an increasing function of the attention score. Then, an optimal incremental allocation method and a low-complexity water-filling method are devised to solve the formulated problem. Our framework is further extended for realistic digital communication systems by modifying the bit allocation problem and the corresponding allocation methods based on an equivalent binary symmetric channel (BSC) model. Simulations on single-view and multi-view image classification tasks show that our IAQ framework outperforms conventional image compression methods in both error-free and realistic communication scenarios.

SECTION: 
Traditional communication systems primarily focus on encoding messages into bit sequences to ensure accurate reconstruction of transmitted bit sequences with minimal bit errors. However, recent advancements have shifted attention toward a more goal-oriented approach known as semantic communications, which prioritizes the transmission of intended meaning over the precise recovery of bits. A typical goal of semantic communications is to maximize task performance by ensuring that the conveyed message facilitates effective task execution, even if the bit sequence is not perfectly reconstructed. This approach has gained considerable traction in resource-demanding scenarios, such as Internet of Things (IoT) wireless networks or low-latency communications, which require high data efficiency or low latency while operating under limited communication resources.

The most widely adopted approach in semantic communication systems is to employ joint source-channel coding (JSCC) to transmit task-related semantic features directly over wireless channels. In this approach, source and channel encoders/decoders are integrated into a single neural model, and the unified encoder and decoder models are jointly trained under wireless channel environments such as additive white Gaussian noise (AWGN) and Rayleigh fading channels. This approach has demonstrated significant performance gains over traditional separate source and channel coding methods in various applications, including image transmission,
text transmission, and speech transmission. Despite its success in various applications, the analog transmission assumed in the JSCC approach poses challenges for integration with existing digital communication systems, which use hardware components and processing units specifically designed for digital symbol transmission. Additionally, analog transmission has inherent drawbacks compared to digital transmission, including vulnerability to noise and limited flexibility and scalability.

To address the limitations of the analog JSCC approach, digital semantic communication systems have been developed, focusing on efficiently representing semantic features with finite values that can be easily converted into digital symbols. For example, in, explicit or implicit quantization of individual semantic feature elements was employed to represent these elements as bit sequences of the same length. However, such fixed-level quantization often fails to account for feature importance, thereby limiting the system’s ability to maximize task performance when communication resources are highly constrained.
To tackle this challenge, adaptive quantization for digital semantic communications has been studied on the basis of entropy codingand importance-aware quantization. The key idea of entropy coding is to reduce the bit overhead in an average sense, by assigning shorter bit sequences to more frequent elements and longer bit sequences to less frequent ones. Based on this idea, in, learning-based source coders were considered to determine the optimal transmission rate of semantic features. Unlike the entropy coding which focuses on theof the semantic features, the importance-aware quantization focuses on theof each semantic feature in the context of task performance.
For instance, in, a reinforcement learning (RL)-based bit allocation scheme was proposed for orthogonal frequency division multiplexing systems.
In, a masking strategy was considered to mask noise-related image patches to suppress feature activations and reduce communication overhead. Both methods necessitate the use a dedicated module to compute feature importance, which needs to be carefully designed for each task.

A common limitation of all the aforementioned studies is their reliance on end-to-end (E2E) training, where various modules in semantic communication systems are jointly trained using large amounts of training data. However, the E2E training approach does not guarantee the effectiveness of the trained modules in mismatched training and testing environments, which may arise from dynamic and unpredictable wireless environments. Moreover, E2E training becomes increasingly impractical in complex scenarios such as collaborative inference, multi-modal, and multi-task settings. In these cases, the modules may need to be trained for all possible combinations of scenarios or, at least, re-trained for any changes in training scenarios. These requirements not only limit the scalability of these methods but also reduce their applicability in cellular or IoT sensor networks.

To address this limitation, semantic communication systems that do not rely on the E2E training under specific communication environments have been studied in some prior works. In, the training process involved random sampling of signal-to-noise ratio (SNR) values to ensure the JSCC model could adapt to diverse channel conditions.
Furthermore, in, a digital JSCC encoder-decoder pair was trained based on a parametric-model-based training environment. Then, during inference, communication systems adapt to this training environment by adjusting modulation levels according to the parametric model. This approach significantly enhances the adaptability and flexibility of the semantic communications, but still relies on a predefined parametric model.
To overcome this limitation, training-free semantic communications have been suggested in, which do not rely on the E2E training or the parametric-model-based training.
Specifically, in, a pretrained vision transformer (ViT) encoderwas used to select image patches relevant to the classification task instead of employing the E2E training. While this method effectively reduces communication overhead, the selective transmission of patches offers limited flexibility in managing communication overhead. Consequently, this approach may suffer from performance degradation when communication resources are highly constrained (e.g., IoT sensor networks).
More importantly, the method inoverlooks the impact of communication errors, which are inevitable due to channel fading and noise effects. This limitation restricts the broader applicability of this method in practical wireless networks.

To take a step toward realizing training-free and practical digital semantic communications, in this paper, we present a ViT-based semantic communication system with importance-aware quantization (IAQ) for wireless image transmission. In the presented system, the importance levels of image patches are quantified using attention scores extracted from a pretrained ViT model which does not rely on the E2E training. We then adaptively assign different quantization bits to image patches based on their importance levels. This is achieved by formulating a weighted quantization error minimization problem, where the weight is defined as an increasing function of the attention score. To solve this problem, we develop two methods: (i) an optimal incremental bit allocation method and (ii) a low-complexity water-filling bit allocation method. We further adapt our framework for realistic digital communication systems by modifying the bit allocation problem and the corresponding bit allocation methods based on an equivalent binary symmetric channel (BSC) model. Simulation results on single-view and multi-view image classification tasks demonstrate the superiority of the proposed IAQ method over existing quantization approaches. The main contributions of this paper are summarized as follows:

We present a novel IAQ framework for training-free semantic communication systems. To the best of our knowledge, this is the first work that incorporates adaptive quantization into the training-free semantic communication systems. Our framework provides an enhanced flexibility in controlling communication overhead compared to a selective transmission method considered in.

We formulate an importance-aware bit allocation problem for semantic communications. To this end, we consider a weighted quantization error minimization problem by determining a weight as an increasing function of the importance level. Our problem formulation can be generalized with any choice of the weight and importance measure. Therefore, our formulation provides an optimization framework for importance-aware bit allocation that can be applied in various semantic communication systems.

We devise importance-aware bit allocation methods to solve the formulated problem. By characterizing the property of the formulated problem, we show that an incremental allocation methodprovides the optimal solution of the formulated problem. To reduce the computational complexity required to solve this problem, we also develop a low-complexity method based on a simple relaxation strategy and the water-filling algorithm.

We extend our IAQ framework to operate under practical digital semantic communications, where the transmission of the bit sequence may contain errors due to channel fading and noise effects. To this end, we model the combined effects of digital communications using parallel BSCs, as done in. We then reformulate the importance-aware bit allocation problem based on distortion analysis that takes into account both quantization and communication errors. We also modify the incremental allocation and water-filling methods to solve the reformulated problem.

Using simulations, we demonstrate the superiority of our IAQ framework over the existing quantization methods for single-view and multi-view image classification tasks using the CIFAR-100, MIRO, and MVP-Ndatasets. Our results show that the proposed framework provides significant gains in the performance-overhead tradeoff for the considered tasks, compared to the existing approaches.

SECTION: 
In this work, we consider a ViT-based semantic communication system for wireless image transmission, where a device transmits an image to a server performing a dedicated machine learning task (e.g., image classification). In our system, the device employs a lightweight ViT encoder, and the server uses a more complex one, reflecting the resource constraints of IoT devices and the computational capacity of servers.
We assume that both the encoders are pre-trained using large datasets.

The ViT encoder equipped at the device is denoted by the function, parameterized by weights. Given input data, where,, andrepresent the height, width, and number of channels, respectively, we first reshapeinto a sequence of flattened 2D patches, denoted by. Here,is the patch size, andis the total number of patches. By using a projection matrix, these patches are linearly transformed to a-dimensional vectors, i.e.,

whereis the-th row of,is the output of linear projection, anddenotes the learnable position embedding.
To facilitate the classification process, a class tokenis added at the beginning of the embedded patch sequence. This class token is crucial for gathering information from the entire sequence, ultimately contributing to the final classification result.
The overall forwarding mechanism of the ViT encoder, described in, can be summarized as

where,, andis the number of layers.,andrepresent the multi-head self-attention, multi-layer perceptron and layer normalization, respectively. The final class tokenis obtained from the encoder’s output and then used as input to the classifier, defined by the functionwith parameters.

To determine the significance of each patch, we leverage the attention scores produced by the MSA mechanism. The-th single-head attention scoreis calculated as

whereandis the total number of heads.represents the query for the class token at the-th head and the-th layer, whiledenotes the keys corresponding to the image patches in the same head and layer. Finally, the mean attention scoreis obtained as

After extracting the mean attention scores, these scores are utilized as an input for a quantization process applied to the input image. This process yields a quantized imageand the corresponding bit sequence, whererepresents the total length of bit sequence anddenotes the quantization bit for the-th patch. Details of the quantization method will be introduced in Sec.and Sec..
The process of transmitting the bit sequenceto the server using digital communications can be equivalently modeled using BSCs, as will be explained in Sec.. Then, at the server, the received bit sequenceis transformed into a reconstructed imagethrough a dequantization process. After reconstructing the image, the ViT encoder at the server is applied to perform the dedicated machine learning task (e.g., image classification task). The overall transmission and reception process considered in our work is illustrated in Fig..

SECTION: 
In this section, we present a novel IAQ framework to enable an efficient image transmission for the digital semantic communication system. We begin by addressing a simple case under an error-free transmission scenario, where the BSC parameteris set to 0. An extension to an erroneous transmission scenario will be discussed in Sec..

SECTION: 
We start by explaining a patch-wise quantization approach adopted in our framework. Letbe the-th pixel value of the-th patch of the original image, whereand.
In this work, we simply adopt a uniform quantizer which is the most representative scalar quantization technique.
If the uniform quantizer with the quantization bitis assigned to the-th patch, the quantizer output foris expressed as

where,,, anddenote the minimum and maximum pixel values of an 8-bit image, respectively.
Onceis obtained, it can be equivalently represented using a binary sequence, given by

where the operatordenotes the binary representation of an integer.
An example of the uniform quantizer withunder error-free communications is shown in Fig.(a). In this scenario, if, we have, and the corresponding bit sequence is given by.

We now analyze the quantization error of our patch-wise quantization approach. For the-th patch, the quantization error of each pixel value is upper bounded by the maximum difference between the quantization outputand the input, as depicted in Fig.(a). Therefore, the upper bound of the quantization error betweenand the inputis given by

for alland. Consequently, the upper bound of the quantization error of the-th patch is expressed as

As shown in (), the quantization error of the-th patch exponentially decreases with the assigned quantization bit.

After the patch-wise quantization, a complete bit sequenceis constructed by concatenating eachacross alland.
Since we focus on the error-free transmission of the bit sequencein this section, the received sequenceat the server is identical to the transmitted sequence. Otherwise, as illustrated in Fig.(b), the received sequence differs from.
The received bit sequence is divided into patch-wise sequences, denoted by. Each patch-wise sequencethen undergoes dequantization to produce the-th pixel value of the-th patch, denoted by. Finally, a dequantized imageis constructed by rearranging the dequantized values into an image.

SECTION: 
Typically, each patch within the image exhibits significantly different mean attention scores, indicating that the patches have varying impacts on task performance. For example, Fig.visualizes the attention score map generated by the ViT encoder for an image classification task on the CIFAR-100 dataset. This figure shows that the attention scores are relatively high for critical pixels in the images, while they are relatively low for less important pixels. Inspired by this observation, in our IAQ framework, we adopt mean attention scores as an operationalof the importance level of each patch within the image. We then allocate varying quantization bits to patches based on their mean attention scores, assigning higher quantization bits to patches with higher mean attention scores.

Based on this idea, we formulate a weighted quantization error minimization problem by leveraging the mean attention score of the patch as a weight for the quantization error.
By utilizing the upper bound of the quantization error in (), our problem is formulated as

whereis a total bit constraint such that,is the maximum quantization bit of the uniform quantizer, andis afunction which can be any arbitrary increasing function of. Here,is the bit overhead required to transmit the quantizer information, defined as

whereis the ceiling function. The first term represents the bit overhead for, and the second term denotes the bit overhead for transmittingand. This quantizer information enables the server to perform dequantization. It should be noted that, in most cases, this additional overhead is negligible compared to the bit overhead ofrequired for transmitting the quantized pixel values of the image.

The problemis categorized as a discrete optimization problem. Since the objective function ofis convex and monotonically decreasing function of, it is well known that the optimal solution ofis obtained via an incremental allocation algorithm. This algorithm begins by initializing,, to start from the minimal bit overhead. Then, for each patch wherehas not yet reached, the algorithm iteratively increasesby 1 for the patch that leads to the largest decrease in the objective function as a response to the additionally assigned bit. This process continues until the total bit constraint in () is satisfied, progressively increasing the quantization bit for the selected patch. This algorithm offers an optimal allocation of the quantization bits.

SECTION: 
A major limitation of the incremental allocation method in Sec.is its substantial computational complexity, quantified as, where. In each iteration, the objective function given in () must be computed, resulting in a complexity of. This is further multiplied by the total number of iterations,.
To tackle this limitation, we develop a low-complexity bit allocation method based on the water-filling algorithm.
To this end, we reformulate the problemby substituting the quantization bitwith the quantization leveland also by relaxing the quantization levelfrom discrete values to continuous real values. Our reformulated problem is given by

where. The problemis categorized as a convex optimization problem, specifically a cave-filling problem within the family of water-filling problems. Consequently, the optimal solution ofcan be obtained by applying the Karush-Kuhn-Tucker (KKT) conditions.

The optimal quantization levelfor the-th patch is given in the following theorem:

See Appendix A.
∎

The optimal Lagrange multiplierin Theorem 1 can be easily obtained using various water-filling algorithms, such as the bisection search algorithmand the fast water-filling algorithm. Onceis acquired through the water-filling algorithm, the optimal quantization level is determined as shown in ().

Theorem 1 demonstrates that the optimal quantization level increases with the weightwhich is the increasing function of the mean attention score. Therefore, the quantization level allocation in () assigns a higher quantization level to patches with higher mean attention scores compared to those with lower scores. This indicates that our quantization framework with the optimal bit allocation effectively reduces overall quantization error by adaptively quantizing patches according to their importance.

It should be noted that the optimal quantization level in () may not be a power of two, which violates the assumption ofin our work. To address this issue, we introduce a simple adjustment step to satisfy the above assumption while utilizing the entire available bit budget. This step involves rounding the solutions in () (i.e.,), and then adjusting the quantization levels based onand the differences denoted by.
Then, ifand, one bit is incrementally added to the patch (i.e.,), with this adjustment performed in descending order of mean attention scores. Conversely, ifand, one bit is incrementally removed from the patch (i.e.,), with this adjustment carried out in ascending order of mean attention scores. This step ensures that the total bit constraint in () is satisfied with the adjusted quantization bits.

The problemhas the same objective function and bit overhead constraint as the problem, with the distinction thatassumes discrete quantization levels whileconsiders continuous ones.
As a result, () represents a relaxed feasible set of (), implying that the optimal solution ofis suboptimal for the original problem.
The computational complexity order required to solveis, wheredenotes the maximum number of iterations required by the water-filling algorithm.
In contrast, solvingrequires a computational complexity of.
Sincetypically holds due to the rapid convergence of the water-filling algorithm and the required minimum bit overhead,is computationally more efficient than.
Therefore, the water-filling algorithm demonstrates advantages in terms of computational complexity compared to the incremental allocation method.

SECTION: 
In this section, we extend our IAQ framework to operate under practical digital semantic communications, where the transmission of the bit sequence suffers from communication errors due to channel fading and noise effects.

SECTION: 
We start by describing a standard process to incorporate our IAQ framework into practical digital semantic communication systems. In this process, the bit sequence, corresponding to the quantized image, is modulated into digital symbols, wheredenotes the constellation set, and transmitted through fading channels.
Then a received signal at time slotis given by

whererepresents a channel gain at time slot, andis an AWGN distributed as.
At the server, channel estimation is performed to obtain an estimate of. Based on this, channel equalization is applied to compensate for the effects of fading, commonly using a zero-forcing (ZF) equalizer. The equalized signal is then passed through data detection, which determines the transmitted symbolfrom received signals. Following the data detection, symbol demapping is employed to recover the estimated bit sequence. Then this bit sequenceis applied as an input of the dequantization process, yielding a reconstructed image.

Our key strategy is to equivalently model the relationship between the inputand outputof the digital communication process by using parallel BSCs with certain bit-flip probabilities, as explained in.
Specifically, these BSCs have the same bit-flip probabilities when the same modulation is applied to all the bits in, and the channel remains constant within the transmission of the symbol sequence(i.e.,,).
Then, the relationship betweenandare equivalent to-parallel BSCs with a common bit-flip probability.
This implies that the conditional distribution offor a givenis represented as

A key advantage of our BSC modeling approach is that it can reflect various communication environments without explicitly considering digital modulation, fading channel, channel equalization, and digital demodulation processes; rather, the combined effect of these processes is implicitly captured by the parallel BSCs with a bit-flip probability. Note thatis equivalent to the bit error rate (BER) performance of the system and therefore characterized as a function of the channel, the SNR, and the constellation set.

In practical communication scenarios where bit-flip error is inevitable (i.e.,), the errors betweenandoccur before the dequantization process, leading to a degradation in task performance. This motivates us to devise a new quantization technique that minimizes the distortion between the input imageand the reconstructed image, taking into account both quantization and communication errors.

SECTION: 
We analyze the distortion of our patch-wise quantization approach, by taking into account both quantization and communication errors.
A key observation behind our analysis is that the length of abit sequence, given by, is very short because the maximum quantization bit is a small number (e.g.,) in general. Additionally, practical communication systems often operate in a small bit-error-rate regime (i.e.,). These facts imply that the probability of having more than two-bit error within each pixel-wise sequence is very small and therefore negligible. Motivated by this, we focus on characterizing the distortion under the following assumption:

The maximum number of the bit-flip errors occurred within each pixel-wise bit sequenceis limited to one, i.e.,,.

Based on, we characterize the upper bound of the expected distortion for the-th patch. This result is stated in the following theorem.

See Appendix B.
∎

Ifin (), it becomes equivalent to (). Therefore, () represents a generalized upper bound that encompasses both quantization and communication errors.

SECTION: 
On the basis of the distortion analysis in Sec., we modify the importance-aware bit allocation methods in Sec.and Sec.to incorporate them into the realistic digital semantic communications.

In this modification, we formulate a weighted distortion minimization problem by utilizing the distortion upper bound in () along with the weight function. Our bit allocation problem is given by

To solve the problem, we characterize the property of the distortion functionwith respect to, as given in the following proposition:

See Appendix C.
∎

Proposition 1 indicates that the problemhas the form of a well-known discrete optimization problem and therefore can be solved using an incremental allocation algorithm. For this reason, we refer to the above bit allocation method as a modified incremental allocation method. Note that if there is no communication error, our modified method is identical to the method in Sec.because the objective function of the problemwithis the same as that of, (i.e.,).

In this modification, we reformulate the weighted distortion minimization problemby substituting the quantization bit with a real-valued quantization level, as done in Sec.. The reformulated problem is given by

To solve the problem, we characterize the property of the distortion functionwith respect to. The result is stated in the following proposition:

See Appendix D.
∎

Since a positive weighted sum of convex functions is also convex, the problem () is a convex optimization problem. By utilizing the KKT conditions, we derive the optimal solution of the problemas given in the following theorem:

See Appendix A.
∎

Based on Theorem 3, we determine the optimal quantization levels as summarized in. In this method, the optimal Lagrange multiplierin Theorem 3 is iteratively determined using a bisection search algorithm in conjunction with the Newton-Raphson method, which is a representative root-finding algorithm, to determinethat satisfiesfor the given. As proved in Appendix A, the functionis a strictly decreasing function ofwhen. Therefore, the Newton-Raphson method yields a unique solution forthat satisfies () within a finite number of iterations. Note that if, the problembecomes equivalent to the problem(i.e.,), and the optimal quantization level can be explicitly derived in the same manner as in Sec.. Our modified water-filling method for determining the optimal quantization level in the problemis outlined in. After completing, we applied the method described in Sec.to fully utilize the available bit budget.

As discussed in Sec., the optimal solution ofis suboptimal for the original problem.
The computational complexity associated with solvingis, wheredenotes the number of iterations required by the Newton-Raphson method. This formulation yields a substantial advantage in comparison to thecomplexity of, as it holds that. Consequently, this demonstrates that water-filling algorithm is more computationally efficient than incremental allocation method.

SECTION: 
In this section, we evaluate the superiority of the proposed IAQ method through simulations. In these simulations, we consider the following tasks:

In this task, we consider single-view image classification using the CIFAR-100dataset.

In this task, we consider multi-view image classification using the MIROand MVP-Ndatasets. We assume that four devices send the images for the same object, but from different views. The server receives a single-view image from each device and classifies the image individually. The final classification result is determined by applying a majority rule to the four individual outcomes.

All datasets are normalized to zero mean and unit variance.
The ViT encoder model on the device is DeiT-Tiny, while DeiT-Small is used on the server, with 4.4 times more parameters than the device model. The DeiT-Tiny and DeiT-Small models are pretrained on the ImageNet-1k dataset, consisting of 1 million images and 1,000 classes. The classifiers of both models consist of a single fully connected layer. The pretrained ViT encoder models and classifiers are also fine-tuned according to our datasets. During the fine-tuning, we use the cross-entropy loss for both single-view and multi-view classification tasks.
The Adam optimizer is applied with a learning rate of, and the batch size is set toacross all datasets. The total number of epochs is set tofor MVP-N, andfor CIFAR-100 and MIRO. It should be noted that our fine-tuning process does not involve any communication process or channels.
The input image size for both device and server isacross all datasets. Both models are characterized by an embedding dimension of 768, a patch size of 16, 12 encoder layers, 196 patches, and 12 attention heads (i.e.,).
The compression ratio is defined as the ratio of the compressed bit overhead to the original bit overhead (i.e.,).
For performance comparison, we consider the following methods:

figure
Comparison of the classification accuracies of various quantization approaches for multi-view image classification tasks using the MIRO and MVP-N datasets.

: We consider four methods for the proposed IAQ framework: (i), which employs the incremental allocation method in Sec.to solve the problem; (ii), which employs the water-filling method in Sec.to solve the problem; (iii), which employs the modified incremental allocation method in Sec.to solve the problem; and (iv), which employs the modified water-filling method in Sec.to solve the problem. In all these methods, we set,,, and. Therefore, as highlighted inand, the water-filling method is more computationally efficient than the incremental allocation method.
A weight functionis chosen as

where,,is a factor that determines the shape of the weight, andis an arbitrary small value introduced to prevent the weight from becoming zero.
When, the weight function becomes convex, whereas for, it becomes concave. In the special case of, the weight function is linear with respect to the mean attention score.

: We consider the fixed-level quantization approach, which falls under the category of fixed-bit quantization. In this case, the compression ratio can be simplified to, asremains constant for all.

: We consider the attention-aware patch selection based quantization approach in. In this strategy, we allocate the highest quantization level,, to the topof patches based on their attention scores, while assigning the lowest quantization level,, to the remaining patches. In this case, the compression ratio can be simplified to. Therefore, the compression ratio can be determined based on the value of.

: We consider the attention-aware patch selection based quantization approach in. In this strategy, we allocate the highest quantization level,, to the patches whose attention scores exceed a certain threshold, while assigning the lowest quantization level,, to the remaining patches.
Since the precise relationship betweenand the compression ratio remains unclear, we numerically determine the optimalwithin the range oftofor each simulation setting.

: We consider the attention-aware patch selection based quantization approach in. In this strategy, we allocate the highest quantization level,, to patches in order of their attention scores, until the cumulative sum of these scores exceeds a specified threshold. The remaining patches are assigned the lowest quantization level,.
Since the precise relationship betweenand the compression ratio remains unclear, we numerically determine the optimalwithin the range oftofor each simulation setting.

SECTION: 
Fig.compares the classification accuracies of various quantization methods for the multi-view image classification tasks on the MIRO and MVP-N datasets.
Fig.shows that the proposed methods achieve a higher classification accuracy compared to the existing quantization methods, particularly when the target communication overhead is low.
Although existing attention-aware quantization methods (i.e.,,, and) consider mean attention scores, the proposed method offers additional performance gains over these methods by enabling optimal bit allocation beyond binary bit selection.
Additionally,andcan control the communication overhead effectively. For instance, it achieves task performance atand, which,, andcould not achieve. This demonstrates the flexibility ofandin controlling communication overhead.
The performance ofandis nearly identical. Sincerequires lower computational complexity than,becomes a more appealing solution, even though it relies on some relaxations to determine the optimal bit allocation.

figure
Comparison of the classification accuracy and communication overhead of various quantization approaches under different channel error levels for a multi-view image classification task on the MIRO dataset.

Fig.compares the classification accuracies of various quantization methods for the single-view image classification task on the CIFAR-100 dataset. In this simulation, we also examine the effect of the weight function design by comparing the performance ofwith different values ofin ().
Fig.shows that asincreases, the performance ofimproves for, while lowervalues yield better performance for.
Specifically, an exponential-like weight function (i.e.,) is preferred when the target communication overhead is low, while a root-like weight function (i.e.,) is preferred when the communication overhead is high.
This indicates that the performance ofcan be maximized by designing the weight function according to the target communication overhead. Nevertheless,consistently outperforms,,, andacross all values offor most cases.
These results demonstrate that the proposed method performs well with various choices of the weight function.

SECTION: 
Fig.compares the classification accuracy and communication overhead of various quantization methods under different bit-flip probabilities for the multi-view image classification task on the MIRO dataset.
Fig.(a) shows thatoutperformsandoutperforms. This indicates that our adaptive bit allocation by jointly considering both quantization and bit-flip errors offers robustness against communication errors. Furthermore, the superior performance ofcompared toand the better performance ofoversuggest that the low-complexity algorithms introduced in Sec.-B and Sec.-C exhibit even greater performance when.
Fig.(b) demonstrates that when, the proposed IAQ approaches maintain strong task performance compared to the baseline methods, particularly when the target communication overhead is low.

Fig.visualizes the attention score map and quantization level map ofunder error-free communications (i.e.), andunder BSCs withat, for the single-view image classification task on the CIFAR-100 dataset.
Fig.shows that patches with higher attention scores are assigned higher quantization levels, both whenand, which is consistent with the results derived in () and ().
Furthermore, a comparison between the dequantized images for different communication errors reveals that, asincreases, the quantization level for background patches decreases, whereas it increases for the object regions.
This allocation strategy helps ensure that crucial information for task performance remains robust under communication errors, while discarding less essential information.

SECTION: 
In this paper, we have proposed a novel IAQ framework for training-free ViT-based semantic communications. The key idea behind our framework is to utilize a pretrained ViT model to quantify the importance levels of different image patches. Based on this idea, we have devised the optimal bit allocation for different image patches by formulating a weighted quantization error minimization problem and also by developing the allocation methods to solve this problem. We have also extended our framework to consider communication errors in realistic digital communication systems. By adopting the BSC modeling approach, we have successfully modified our importance-aware bit allocation methods. Our simulation results demonstrate that our IAQ framework significantly improves the performance-overhead tradeoff of both single-view and multi-view image classification tasks.

An important direction for future research is to develop a tractable framework that characterizes the relationship between attention scores and task performance. Expanding the IAQ approach to realistic wireless channels, particularly through integration with classical Shannon communications, offers promising prospects. Additionally, extending this framework to support multi-task, multi-modal semantic communications could enable concurrent task execution across devices.

SECTION: Proof of Theorem 1 & 3
The Lagrangian function for () is given by

Then, the KKT conditions for () are represented by

Under the condition in (), we consider the following three cases:

(): In this case, we havefrom () and (). Therefore, the condition in () can be rewritten as

whereis given in (). In this case, the value ofcan be determined by finding the solution of the equation in () for a given value of.

(): In this case, we haveandfrom ()–(). Therefore, the condition in () implies that

This is equivalent to.

(): In this case, we haveandfrom ()–(). Therefore, the condition in () implies that

This is equivalent to.

Now, we prove thatis a strictly decreasing function of.
The first derivative ofwith respect tois given by

whereandis defined as

The functionsatisfy the following inequality:

wherefollows from the conditionand,is based on the fact that, andholds because.
Therefore,, indicating thatis a strictly decreasing function of. This also implies thatexists and is a strictly decreasing function of.

By combining all the above results, the optimal quantization levelthat satisfies the KKT conditions is given by

whereis set to satisfy the equality of.
The above expression can be rewritten as given in (), which completes the proof for Theorem 3.

We also prove Theorem 1 by settingin (). If, the functionin () is expressed as

Consequently, we have

Therefore, the optimal quantization levelis rewritten as

The above expression can be rewritten as given in (), which completes the proof for Theorem 1.

SECTION: Proof of Theorem 2
The upper bound of the expected distortion for the-th patch is presented in (). Specifically,follows from the property of memoryless BSCs,follows from the assumption of equiprobable bit outputs,denotes the exact upper bound of expected distortion of the-th patch under, wheredenoting the upper bound of the mean squared error (MSE) betweenandwhenundergoesbit errors, andfollows from the fact that.

SECTION: Proof of Proposition 1
By utilizing the distortion in (), the first derivative ofcan be obtained as () where.
The upper bound ofin () can be determined as follows:

wherefollows from the conditionand, andis based on the fact that.
Therefore, if, we have, implying thatis a monotonically decreasing function of.

Similarly, the second derivative ofis expressed in (). The lower bound ofin () can be determined as follows:

wherefollows from the conditionand, andis based on the fact that. Therefore, if, we have, implying thatis convex with respect to.
Aggregating the above results implies that if, the distortion functionis convex and a monotonically decreasing function of.

SECTION: Proof of Proposition 2
Letand, then the second derivative ofwith respect tois derived as

where. If, we haveandas shown in Appendix C. This directly implies that ifand, we have. This completes the proof.

SECTION: References