SECTION: Biological Brain Age Estimation using Sex-Aware Adversarial Variational Autoencoder with Multimodal Neuroimages
Brain aging involves structural and functional changes and therefore serves as a key biomarker for brain health. Combining structural magnetic resonance imaging (sMRI) and functional magnetic resonance imaging (fMRI) has the potential to improve brain age estimation by leveraging complementary data. However, fMRI data, being noisier than sMRI, complicates multimodal fusion. Traditional fusion methods often introduce more noise than useful information, which can reduce accuracy compared to using sMRI alone. In this paper, we propose a novel multimodal framework for biological brain age estimation, utilizing a sex-aware adversarial variational autoencoder (SA-AVAE). Our framework integrates adversarial and variational learning to effectively disentangle the latent features from both modalities. Specifically, we decompose the latent space into modality-specific codes and shared codes to represent complementary and common information across modalities, respectively. To enhance the disentanglement, we introduce cross-reconstruction and shared-distinct distance ratio loss as regularization terms. Importantly, we incorporate sex information into the learned latent code, enabling the model to capture sex-specific aging patterns for brain age estimation via an integrated regressor module. We evaluate our model using the publicly available OpenBHB dataset, a comprehensive multi-site dataset for brain age estimation. The results from ablation studies and comparisons with state-of-the-art methods demonstrate that our framework outperforms existing approaches and shows significant robustness across various age groups, highlighting its potential for real-time clinical applications in the early detection of neurodegenerative diseases.

SECTION: 
The aging population poses significant global challenges, profoundly affecting economic, medical, and societal systems. Among these challenges, declining brain function and neurodegenerative diseases in the elderly exacerbate the burden on healthcare and social structures. In the fields of life sciences and biomedicine, predicting and assessing age-related neurodegeneration, as well as developing treatments to mitigate or reverse its effects, remain critical research priorities. A key focus is the distinction between biological brain age and chronological age, which serves as an informative biomarker for neurological disorders such as Parkinson’s disease, vascular dementia, mild cognitive impairment (MCI), and Alzheimer’s disease (AD). Deviations from the typical brain aging trajectory are particularly significant, as they can predict an individual’s future risk of developing neurodegenerative conditions. Modeling brain aging patterns through neuroimaging data and tracking individual trajectories offers a promising approach to understanding brain aging dynamics and its implications for neurological health.

Despite the potential of multimodal neuroimaging, research on its use for brain age estimation, particularly in exploring anatomical and functional differences between male and female brains, has been limited. Our study aims to address this gap by estimating brain age using both fMRI and sMRI data, identifying potential indicators of brain development through various imaging modalities. The inherent differences between sMRI and fMRI, including noise levels, spatial resolution, and the dynamic nature of functional connectivity, highlight the need for innovative fusion techniques that leverage sMRI’s precision and reliability as biomarkers for age prediction.

Following are the key contributions of this study:

We propose a multimodal framework, named the Sex-Aware Adversarial Variational Autoencoder (SA-AVAE), to estimate brain age using multimodal MRI scans (sMRI and fMRI). This framework is the first to integrate sex information directly into the latent space, enhancing the model’s accuracy and robustness.

The proposed framework generates a disentangled latent space by enforcing distinct distributions through the simultaneous application of adversarial and variational autoencoder losses within a unified architecture.

We present a comprehensive strategy for fine-tuning loss weight parameters, providing valuable insights for optimizing architectures in broader applications.

Extensive experimentation on publicly available datasets demonstrates the accuracy and robustness of the SA-AVAE model, setting a new standard for brain age estimation techniques.

The remainder of the paper is organized as follows: Sectionpresents a comprehensive review of related studies, providing the context and background for our work. Sectiondetails the proposed framework, including its various components and the underlying principles. Sectionelaborates on the dataset specifications and preprocessing steps, as well as the architectural details and training strategy of the model. Sectionshowcases the experimental results, accompanied by an in-depth analysis. Finally, Sectionconcludes the paper by summarizing the key findings and discussing future research directions, with a focus on potential improvements and extensions to the proposed approach.

SECTION: 
Though recent advancements, traditional multimodal approaches often rely on simply concatenating features from different modalities without explicitly modeling their interactions. This limitation can overlook the potential synergies between sMRI and fMRI data that could enhance prediction accuracy. To address this, He et al.proposed a global-local transformer model that combines global and local features through an attention mechanism, significantly improving performance. Similarly, Armanious et al.incorporated both chronological and biological age information into CNN-based models, enhancing brain age prediction. Liu et al.further highlighted the importance of demographic factors, such as gender, in brain age prediction, using a support vector regression (SVR) approach. Dular et al.extended brain age estimation to multisite data, achieving an MAE of 3.25 ± 2.70 years, demonstrating the value of large-scale, heterogeneous datasets in improving prediction accuracy. Additionally, the concept of disentangled representation learning has gained attention, with Cai et al.employing a two-stream convolutional autoencoder to disentangle modality-specific features, improving upon traditional autoencoder designs. A concise summary of the existing literature is provided in Table, highlighting key methodologies such as modality integration, sex-aware modeling, adversarial learning, and disentangled autoencoders. Studies utilizing attention-based and transformer networks for improved segmentation, particularly in challenging modalities, have shown promise in advancing model-based approaches. Autoencoders (AE) have been widely explored for multimodal fusion, with early and late fusion. However, traditional AEs often struggle to differentiate between shared and complementary information, and noisy modalities can negatively impact latent representation learning across modalities.

Despite recent advancements, current approaches to brain age estimation still face significant challenges, particularly in fully exploiting the interactions between multimodal data and accounting for sex-specific aging patterns. To address these issues, the proposed framework in this paper integrates sMRI and fMRI data while incorporating sex-specific information into the latent space, capturing both modality-specific and shared features through disentangled representations. Our framework, the Sex-Aware Adversarial Variational Autoencoder (SA-AVAE), not only improves predictive accuracy but also enhances model interpretability by explicitly considering demographic factors such as sex. The key contributions of our work include: 1) the introduction of a novel framework that integrates sMRI and fMRI data with sex information to improve accuracy and robustness; 2) the use of disentangled latent representations, achieved by applying adversarial and variational autoencoder losses to ensure effective separation of modality-specific and shared features; 3) a new loss weighting strategy for fine-tuning model parameters, providing insights into optimizing architectures for broader applications; and 4) extensive evaluation showing that our framework outperforms state-of-the-art methods, establishing a new benchmark for brain age estimation. This work paves the way for more effective, interpretable models in neuroimaging and brain health assessment, emphasizing the importance of integrating multimodal data, disentangled representations, and demographic factors to improve both prediction accuracy and clinical applicability.

SECTION: 
We propose a multimodal framework, the Sex-Aware Adversarial Variational Autoencoder (SA-AVAE), which integrates adversarial and variational learning to disentangle features derived from sMRI and fMRI scans. These features are further combined with sex information to estimate biological brain age. While sMRI is more readily available, the framework is designed to function seamlessly even without the incorporation of fMRI, relying solely on sMRI when necessary. The components of the proposed framework are described in detail in the following subsections.

SECTION: 
SECTION: 
where,

and

SECTION: 
SECTION: 
SECTION: 
In our experiments, we utilized the OpenBHB dataset, a large-scale and comprehensive resource comprising 5330 3D brain MRI scans collected from 71 different sites. This diverse dataset includes scans from a wide range of demographics, ensuring broad genetic and geographical representation. Specifically, 3984 of the scans are publicly available, with 3227 scans allocated for training and 757 scans designated for validation. The validation set is further split into two subsets: 362 internal test samples and 390 external test samples, allowing for a comprehensive evaluation of the model’s performance on both internal and unseen data.

The OpenBHB dataset is organized into 10 distinct sub-datasets, which include subjects from varied ethnic backgrounds, including European-American, European, and Asian descent. This diversity ensures that our model is trained and evaluated on a broad spectrum of genetic backgrounds, enhancing its robustness and generalizability across different populations. The age range of the subjects spans from 16 to 86 years, and the dataset exhibits a balanced distribution of male and female subjects across different age groups, as shown in Figure. This balanced sex distribution is crucial for minimizing biases and ensuring that the trained model can generalize effectively across both male and female populations.

For the single-modality experiments with the SA-AVAE framework, we utilized the full publicly available OpenBHB dataset, which consists predominantly of structural MRI (sMRI) data. This extensive dataset enabled us to train the model effectively in single-modality settings, focusing exclusively on sMRI data. For multimodal experiments, we selected subsets of the dataset that include both sMRI and functional MRI (fMRI) data. Specifically, we incorporated two smaller datasets, referenced inand, which contain 66 and 315 scans, respectively. These two subsets were combined to create a unified multimodal dataset, resulting in a total of 381 scans. This approach allowed us to explore the impact of multimodal data integration on brain age estimation and assess the performance of our framework in leveraging both structural and functional brain information.

Overall, the diversity of the OpenBHB dataset, combined with its large size and rich multimodal data, provides a solid foundation for evaluating our proposed framework. The varied demographic representation and the inclusion of both single-modality and multimodal data ensure that our experiments are not only comprehensive but also robust across different populations and imaging modalities.

The high dimensionality of MRI scans, combined with the limited size of available datasets, poses significant computational challenges and increases the risk of overfitting when directly used in neural network training. To address these challenges, an initial feature selection step is essential. Feature selection methods are broadly categorized into three types based on their interaction with the learning model: filter methods, wrapper methods, and embedded methods. We adopted a filter method, due to its independence from specific models and computational efficiency, and its proven effectiveness.

For feature selection, we employed the Random Forest algorithm, which is well-suited for handling high-dimensional data with highly correlated features. This process results inandselected features from the first (sMRI) and second (fMRI) modalities, respectively. The dataset after feature selection can be mathematically represented as:

where:

represents the feature vector of the-th instance derived from the sMRI modality.

represents the feature vector of the-th instance derived from the fMRI modality.

corresponds to the target outputs (e.g., age and gender) for the-th instance.

denotes the total number of instances in the dataset.

The resulting feature vectorsand, along with the target outputs, form the basis for training and evaluating the proposed model.

SECTION: 
The architecture of the proposed Sex-Aware Adversarial Variational Autoencoder (SA-AVAE), employed in our experiments, is depicted in Figure. This architecture integrates encoders and decoders for both sMRI and fMRI modalities, alongside a shared regressor and a discriminator to facilitate adversarial learning. To ensure reproducibility and optimize the model’s performance, several key hyperparameters were carefully selected. First, the batch size was set to 20 during training to balance memory usage and model convergence. The latent space of the model was designed with a total dimensionality of 120, divided into a shared space of 50 dimensions and modality-specific spaces of 70 dimensions each. These dimensions were determined empirically, striking a balance between the representational capacity of the model and the computational efficiency required for large-scale experiments. For training, the Adam optimizer was used with an initial learning rate of 0.001, which was dynamically adjusted; if no improvement in validation performance was observed after nine epochs, the learning rate was reduced to a quarter of its current value to aid in convergence. Additionally, an early stopping mechanism was implemented to mitigate overfitting, halting the training process when no improvement was seen in the validation set after a predefined number of epochs. The training and evaluation of the SA-AVAE framework were conducted on an NVIDIA RTX 4090 GPU using the Keras library with a TensorFlow backend. The model had a total of 2.7 million trainable parameters. Training took approximately 12 hours to complete, while testing was conducted in about 1.5 hours, demonstrating the model’s computational efficiency, which makes it suitable for handling large-scale neuroimaging datasets.

Several implementation strategies were critical for optimizing the performance of the SA-AVAE framework. During training, the reconstruction losses for both sMRI and fMRI modalities were balanced to ensure that each modality contributed equally to the shared latent representations, preventing bias toward one modality. The adversarial and variational losses were carefully scaled using empirically derived trade-off parameters. This scaling ensured that the shared and distinct latent spaces were effectively disentangled, allowing the model to learn complementary features from both modalities. Furthermore, the regressor was jointly trained with both the encoder and decoder networks to ensure that the latent representations were tailored for accurate age prediction. Dropout and weight decay were employed to eliminate the possibility of overfitting and improve generalization ability. These measures, in combination with robust preprocessing and careful feature selection, enabled the SA-AVAE framework to achieve competitive performance in biological brain age prediction, effectively leveraging multimodal neuroimaging data.

SECTION: 
SECTION: 
SECTION: 
SECTION: 
To further illustrate the robustness of our proposed framework, Tablepresents a breakdown of the model’s performance across various age groups. Among all models, the proposed SA-AVAE consistently outperforms others in every age group, highlighting the advantages of sex-aware disentangled learning. Ultimately, the SA-AVAE model delivers the most consistent and accurate predictions, reinforcing the efficacy of our approach.

SECTION: 
SECTION: 
In this section, we analyze the impact of incorporating sex information into the brain age estimation model. Specifically, we compare the performance of the proposed adversarial variational autoencoder (AVAE) network with and without sex information. To expand our analysis, we explore two methods of incorporating sex information. The first method involves employing multitask learning, where the model is required to predict the subject’s sex along with biological brain age estimation. The second method, which we adopt in the proposed SA-AVAE framework, directly inputs the sex information into the regressor.

Tablesummarizes the results obtained from three different frameworks for brain age estimation, evaluating male, female, and overall groups, along with the number of trainable parameters. It can be observed that models incorporating sex information outperform the model without sex information across all groups, highlighting the significance of including sex information in the model. Furthermore, the inclusion of sex information via multitask learning significantly improves the network’s performance, although the improvement is slightly more pronounced in one gender group (female or male) than the other. On the other hand, the framework with direct inclusion of sex information not only improves brain age estimation performance but also does so with fewer trainable parameters. The reduction in parameters is due to the absence of the sex classifier required for multitask learning. Most importantly, the proposed SA-AVAE framework provides balanced performance across both male and female groups, demonstrating that the framework not only enhances brain age estimation but also improves robustness.

SECTION: 
SECTION: 
In this study, we introduced a novel framework for biological brain age estimation, leveraging the complementary information from structural magnetic resonance imaging (sMRI) and functional magnetic resonance imaging (fMRI) data. Our proposed Sex-Aware Adversarial Variational Autoencoder (SA-AVAE) combines adversarial and variational learning techniques to effectively disentangle latent features from both modalities. By decomposing the latent space into modality-specific and shared codes, our model captures both the unique and common aspects of brain aging, while also accounting for sex-specific aging patterns, further enhancing its performance. The results of our experiments, evaluated on the OpenBHB dataset, demonstrate that SA-AVAE outperforms existing state-of-the-art methods, showing significant robustness across various age groups. This highlights the potential of the framework for real-time clinical applications, particularly in the early detection and monitoring of neurodegenerative diseases. Future work will focus on enhancing the robustness of the framework to ensure effective performance with either modality independently. Additionally, we aim to conduct real-time evaluations using clinical data to assess the practical applicability of the SA-AVAE model in clinical settings.

SECTION: References