SECTION: Quantum Machine Learning Algorithms for Anomaly Detection: a Review

The advent of quantum computers has justified the development of quantum machine learning algorithms, based on the adaptation of the principles of machine learning to the formalism of qubits. Among such quantum algorithms, anomaly detection represents an important problem crossing several disciplines from cybersecurity, to fraud detection to particle physics.
We summarize the key concepts involved in quantum computing, introducing the formal concept of quantum speed up. The review provides a structured map of anomaly detection based on quantum machine learning. We have grouped existing algorithms according to the different learning methods, namely quantum supervised, quantum unsupervised and quantum reinforcement learning, respectively. We provide an estimate of the hardware resources to provide sufficient computational power in the future. The review provides a systematic and compact understanding of the techniques belonging to each category. We eventually provide a discussion on the computational complexity of the learning methods in real application domains.

SECTION: 1Introduction

Anomaly detection takes advantage from a wide range of artificial intelligence algorithms, which – combined with human supervision – may raise the degree of protection and of integrity of systems and data.
On the other hand, the advent of quantum computing has made possible to implement quantum algorithms on real prototypical – but already commercial – quantum hardware. Such algorithms include machine learning-related algorithms which may inherit the quantum speed-up typical of quantum algorithms.
The differentiation among quantum computing architectures (gate based[1,2], adiabatic[3,4], measurement based[5,6,7]), encoding (digital[8]versus continuous variables[9,10,11,12]), hardware (several substrates from solid state to trapped ions[13,14]to photons[15]), the diversity of the quantum algorithms and the unclear advantage carried by some of them in the field of quantum machine learning, and also the range of potential application domains and the different methods to achieve the same goal, call for a systematic review of what has been done and what is known in the field, in order to address more efficiently the investigation towards meaningful, feasible and relevant applications.
The quantum machine learning algorithms proposed in literature for anomaly detection purposes are updated to Q1 of 2024, and clustered by applying the criteria of training method. Indeed, the latter represents the criterion which drives the choice among a families of algorithms. Therefore, we classify the quantum algorithms for machine learning according to the same classification of classical algorithms, namely among supervised learning, unsupervised learning and reinforcement learning, respectively.
Despite its recent birth, the topic of quantum machine learning has been systematically reviewed in the time span 2015-2023[16,17,18,2,19,20]. We privileged the literature which includes a practical implementation on either an actual quantum computer or the simulator of some existing hardware. The literature reviewed by such sources is integrated by more recent articles not included there.
In the next sections we describe the summary of aims and AI algorithms used in anomaly detection, the basics of quantum computing and quantum advantage, the key quantum algorithms developed in the field which are relevant for anomaly detection purposes, and we systematically analyze the most recent advancements in the field of quantum machine learning applied to anomaly detection. In the second section, we summarize the application for quantum machine learning in the field of anomaly detection. In the third section, we introduce the concept of quantum advantage, along with a classification for the possible quantum speedups. In the fourth section, the groundings of quantum computing are introduced: from the definition of qubits, qudits and qumodes to the encoding of classical information into these units of computation. In the fifth section, different architectures of quantum computation (adiabatic and circuital models) are introduced, along with the support of classical computers. The sixth section is dedicated to focus on the role of HPC and classical computation to interface with quantum hardware and algorithms. Quantum neural networks and variational circuits, to translate on a quantum device the classical neural networks, are explained in section seven. In the remaining sections, a review on specific quantum algorithms for anomaly detection is provided, classified with respect to the categories of supervised, unsupervised and reinforcement learning. A summary of all the exposed algorithms can be found at Table3.In order to cover all of the classes of quantum algorithms and computational architectures in Figure1, we select and summarize a paramount paper for each of these classes. For instance, Killoran’s work[10]in 2019 defined how to build continuous variables neural networks for quantum computers, along with their employment for anomaly detection, while Tacchino in 2019[21]proposed a model of fully quantum neural perceptron. The other works we report are from Useche[22](2022) for performing classification tasks with qudits, Herr[23](2021) for introducing the QGAN in the field of anomaly detection, Moro[24](2023) to boost the performances on the Restricted Boltzmann Machine via an annealer, the Harrow, Hassidim, Lloyd paper[25](2009), which introduced the namesake HHL algorithm employed for the support vector machines (and beyond), and the paper by Albarràn-Arriagada[26](2018) for the quantum Reinforcement Learning.

SECTION: 2Application domains for quantum anomaly detection

As this review elaborates on the intersection of quantum machine learning methods with applications in the anomaly detection, we first briefly assess which classes of algorithms are related to such topic, from image recognition and data classification to clustering analysis. Moreover, another topic of interest is provided by the domain of applications: cybersecurity is a major focus for quantum machine learning[27,10,28,29,30](and for all–around machine learning), but a considerable interest arises on disparate topics such as big data for science, i.e. detecting Higgs–boson decay at LHC collider[31,32], geophysical analysis[33], detection of new particles at LHC[34,35]or even audio recognition[36,37].

Typically, cybersecurity is characterized as a collection of technologies and processes designed to protect computers, networks, programs, and data against malicious activities, attacks, harm, or unauthorized access. In the field of cybersecurity, anomaly detection is of paramount importance. Many datasets exist, including intrusion analysis, malware analysis, and spam analysis, which are used for different purposes[38].

All cybersecurity matter, while becoming increasingly crucial to all modern industrial and institutional activities, has also grown in the past decades in terms of complexity of the multiple bodies and structure which have been created to implement cyber defence functionalities.
SOCs (Security Operation Centers) are for example hugely complex cybersecurity systems, exploited to monitor infrastructures, to supervise networks, to detect threats also able to guarantee early warning and security awareness.
Once security incidents have been detected, they have also to be managed. The so called Computer Emergency Response Teams (CERTs) come into play.
Such complexity of cyber monitoring and countermeasure systems is strongly related to an equivalent rearrangement of the threat side, where more conventional private cyber crime groups and cyber terrorists or hacker sources were joined by government linked teams. Such groups carry out a so called cyber warfare by systematically implementing cyber attacks to national or institutional IT services[39].
Complexity grows together with continuous and rapid adaptations and modification of threats themselves. Ransomware groups and other malicious players, e.g., are changing their initial access vectors while the digital attack surface and vulnerabilities shift, also exploiting commercial tools to disguise their breaches and deploying new ransomware schemes.
Anomaly detection[40]is a fundamental tool for this task and such continuously evolving cyber threat landscape ultimately calls for actions by SOCs and CERTs to be largely become automated only asking for man-in-the-loop in few very critical steps; which on its turn naturally links to the use of machine learning[41,42,43,44], as a means of automated response.

The main purpose of such algorithms is to provide early warning of attack, possibly even before the attack is launched[45].
Cyber intelligence deals with amount of data, their heterogeneity and their high production rate. AI is believed[46]capable to enhance cyberspace security more effectively than conventional methods for three reasons, namely:

Discovery of new and sophisticated changes in attack flexibility, by better adaptation to detect anomalous, faster and more accurate operations.

Naturally handling high volumes of data

Learning over time to respond better to threats.

Moreover, between different AI methods such as neural networks, fuzzy logic, expert system, machine learning, and deep learning, the two latter bring the most achievements.
In the field of cybersecurity, the applications span mainly on malware detection, intrusion detection (ID), endpoint detection (ED), phishing detection and advanced persistent threat (APT). All of them take advantage of different methods based on a number of possible algorithms (or combinations of them): Naive Bayes method, Support Vector Machines (SVM), Decision Trees and, more recently deep Neural Networks[47,48,49,50]. One should keep in mind that since spurious transactions are far fewer than the normal ones, the highly imbalanced
data makes fraud detection very challenging and calls for ways to address it beyond the traditional
machine learning approach[28]. Furthermore, the development for instance of new fraud
detection methods is made more difficult due to the severe limitation of the exchange of ideas in fraud detection[51].
More recently, Reinforcement Learning proved to be a robust but flexible method to prevent cyber attacks[52,53,54], also thanks to a vast range of available algorithms, such as Deep Deterministic Policy Gradient (DDPG)[55], Trust Region Policy Optimization (TRPO)[56], Proximal Policy Optimization (PPO)[57], Generalized Advantage Estimation (GAE)[58].

In the broader field of anomaly detection, Neural Networks have also been successfully employed for medical and public health domain[59], fault detection for mechanical components and structural damage detection[60,61,62].
As for image and pattern recognition or data text analysis, along with detection of spurious elements in datasets from the corresponding domains, techniques such as Support Vector Machines[36,63], Neural Networks[64,65]and clustering based algorithms[66,67]have been deployed. Support Vector Machines have also been addressed to foil phishing attacks, achieving a rationale performance with 99.6% of True Positive Rate and 0.44% of False Positive Rate[68].
Finally, alsoadvanced persistent threatcan be performed by deep learning algorithms, such as dilated convolutional auto-encoders (DCAEs) algorithm[69].

Anomaly detection represents a major method in the field across these different purposes, and it turns out to be promisingly explored also in the field of quantum machine learning. In the next sections we therefore anticipate the key concepts of quantum information and quantum algorithms, so to consistently review anomaly detection from the perspective of the solution of security-related tasks, as outlined above.

SECTION: 3Quantum algorithms and quantum advantage

Quantum algorithms belong to computational classes defined by quantum Turing machines[70]instead of the conventional Turing machines.
In the complexity theory, for both classical and quantum computation, the runtime of an algorithm is measured in terms of number of elementary operationsinvolved[71]. In the circuit models for quantum computing, such operations match the application of native gates on the hardware for the gate-based architecture.
Therefore, the same problem can be mapped as NP but not P for classical machines while it can be of class BQP if defined on the Hilbert spaces on which quantum Turing machines rely[72]. Jager and Krems demonstrated that there exists a feature map and a quantum kernel that make variational quantum classifiers and quantum kernel support vector machines efficient solvers for any BQP problem. Therefore, some problems which are classically NP but BQP from a quantum approach, can be solved exponentially faster by using the appropriate quantum algorithm instead of a classical algorithm. Such property is called quantum speed-up. Different degrees of speed-up have been defined by a panel of experts in 2014[73], which can be summarized as follows:

there is a proof that there can be no classical algorithm that performs as well or better than the quantum algorithm. Example: Grover’s algorithm scales quadratically better than classical, provided there exist an oracle to mark the desired state;

the quantum algorithm performs better than
the best possible, not necessarily known explicitly, classical algorithm (i.e. lower bound to classical algorithm is not known)
Example: Shor’s quantum algorithm to factorize prime numbers (grows polynomially instead of exponentially with the number of digits of the prime number);

the quantum algorithm performs better than thebest availableclassical algorithm, as often the best available classical algorithm for strong quantum speed-up is not known;

if there is no consensus about which is the best available classical algorithm, it refers to the comparison with an arbitrary classical algorithm;

it refers to the benchmark of two corresponding algorithms. Example: classical and quantum annealing.

The landscape of quantum algorithms shows a range of possible speed-ups, which is even more difficult to systematize for the domain of quantum machine learning methods, where the (possible) speed-up is sometimes not quantified. The evaluation increases in difficulty as more architectures and more encoding methods are possible (see Section5and Figure1).

From the point of view of the implementation of quantum machine learning proposed in literature, three approaches are common. First, by the direct speed-up of machine learning techniques, by using algebra-related algorithms like those in the Table1, of which the HHL algorithm is paramount[17]. Secondly, by implementing variational quantum circuits and finally multilayer perceptron-based quantum neural networks. Recently, the competitiveness of quantum models based on variational circuits compared to classical models has been raised by the demonstration[20]that explicit models[74,75]outperform implicit models, and data re-uploading models exponentially outperforms simple explicit models. Explicit models rely on a parametric definition of the unitary operators,collecting the family of parameters. Such models therefore can be easily encoded into any variational quantum circuit. The QAOA algorithm is an example of explicit model.

SECTION: 4Encoding data with quantum systems

SECTION: 4.1From bits to qubits

The qubit is the fundamental unit of information encoded by a quantum computer. The qubit is a quantum state, defined by a vectorin a Hilbert space. It is the transposition of the classical bit, but instead of assuming two discrete values, formally, such values are transposed in a vector state[8]:

Thevectors form a orthonormal basis in thespace, therefore any qubit can be set in a linear combination as in the rightmost expression for[2, pag.94]. It follows immediately that, i.e. the state vectoris normalized. Theandcoefficients represent the probability for the state to be found either in theorstate. All the logic operations on a single qubit are implemented by operatorswhich transform such state fromto:. To preserve the normalization of the vector, the single-qubit operatorsare given by the unitary group. The most known single-qubits operators are the NOT gate, thegate and the Hadamard gate:

Thegate flips thestate into theand vice versa, acting in fact as the classical NOT gate. The Hadamard gate, instead, is an isomorphism onmapping the computational basisinto the conjugated oneone, where. For a comparison, see Table2.

It is possible to encode bits into qubits in several ways. The most vanilla method consists of a 1-to-1 encoding, making one bitto be encoded by one quantum state. In literature, such encoding is referred to as multi-register encoding[76], whereis the number of available qubits, andcan assume the values ofor. When all the qubits are initialized in thestate, to flip a single qubit it suffices to apply aNOT gate. Such operation can be performed simultaneously, yielding a circuit depth ofoperations to be performed.
However, an enhancement can be given by the superposition principle: in a register ofqubits, it is possible to encodebits, each permutation being given by the superposition of the different states. In fact, the analog encoding makes usage of all the possible permutations ofand. In the following line, the multi-register and the analog encoding are respectively shown[77]:

Therefore, within the analog encoding (rightmost expression) viaqubits it is possible to storeunits of memory, which meansbits requireavailable qubits. At this point, one should also notice that in the latter case the encoding process requires an exponential numberof steps[76], calling for methods or approximations to circumvent the issue. In the past, quantum RAM (qRAM) have been proposed to feed directly the register of qubits asked to load the data[78], but hitherto no example does exists[77,79,80].

One last family of data encoding is given by the Hamiltonian encoding. Within this frame, the data need to be formatted into a Hamiltonian operator, for instance the Ising Hamiltonian. Such a technique turns to be useful mainly in order to perform quantum annealing, see Section5.2, and it will be explored in details in Section4.4.

SECTION: 4.2Qudits

The qudit is a-dimension generalization of the qubit. Instead of a basis spanned byvectors, the space of qudits is generated byvectors. It is possible to choose a computational basis[81], therefore a vector in thisspace will given by

The state in Equation4must be normalized[82], so that. Referring to Section4.1.1, givenqudits it is possible to storeunits of binary memory. A feature comparison between qubits and qudits is provided in Table2.
The qubits operators from Equation (2) can be adapted in the qudits formalism as well. The phase Hadamard gate should be able to put anyelement from the computational basisinto a superposition over all the generators of such basis[83], along with a generalization for the NOT and theoperators[22,84]:

where the angleis defined as. The qudits in their conjugated basis, after a Hadamard transformation, are reported in Table2. Theis the sum modulo(for the qubits,). In[22], it is introduced the control gatesas a two-qudits operators. Here a target and a control qudits need to be specified: the operationholds on the target qudit only if the control one is set in thestate, otherwise it does not. The generalized control gate operator is: theunitary operator is applied on the target qudit when the control one is set in thestate.

SECTION: 4.3Qumodes (Continuous Variables)

In the frame of Continuous Variables (CV) for quantum computing, quantum information is encoded in continuous degrees of freedom such as the amplitudes of the electromagnetic field[10]. Specifically, the unit of information we described before as a qubit is substituted by the so-called qumode. In the phase space representation, the state of a single qumode is described by two real and conjugated variables such as, whetherqumodes are depicted by. Qumode states also have a representation as vectors or density matrices in the countably infinite Hilbert space spanned by the Fock states, which are the eigenstates of the photon number operator, whereandare the position and momentum operators. A comparison[9]between qubit, qudits and qumode architectures is provided in Table2.

Killoran et al.[10]report some possible operations to implement in the CV frame. First, the position and momentum operators are introduced:

Beinganddefined on the entire real line, the orthonormality relations hold:

The so-called Gaussian operators implement the linear transformations. On a set of a singlequmode, the rotation operatoracts between positions and momenta, while the displacement operatorperforms the translations over the qumodes:

Togetherandare able to implement affine transformations on a single qumode. Another Gaussian transformation is given by the beamsplitter, which is a 2-qumodes operator:

The last of the Gaussian operator is given by the squeezing one,:

Defining, it is straightforward to state the uncertainty relation in the CV frame:

SECTION: 4.4Embedding into QUBO problems

Adiabatic quantum computers can find the optimal solution to a specific class of optimization problems: Quadratic Unconstrained Binary Optimization (QUBO) problems. A QUBO problem is mathematically described as:

whereare the Pauli matrices that acting along the-direction, andandrepresent the parameters to the problem to be solved. We callcouplings or weights andbiases. Since the eigenvalues of the Hamiltonianrepresent the possible solution to the problem, the goal is to set the couplings and the biases so that the ground state ofrepresents the optimal solution to the optimization problem.

The QUBO problems can be represented as graphs, where nodes are associated with biases and edges with couplings. Ideally, we want to map the optimization problem graph directly into the quantum annealer QPU. However, in a quantum annealing system, the hardware graph topology, which represents the pattern of physical connections for qubits and the couplers between them, is fixed. Since we cannot modify the qubit connectivity of a specific quantum annealer, we must map the model parameters into the hardware topology by a suitable embedding to solve an optimization problem. The basic idea of embedding is to identify groups of qubits (chains) so that they form the topology of the QUBO problem under investigation by behaving as individual units. The connectivity of each group can be enhanced by creating strong ferromagnetic couplings between the qubits, which forces coupled qubits to stay in the same state.

SECTION: 5Processing quantum information with quantum computers

Three available architectures are provided in the field of quantum computing, see Figure1. Two out of three, the MBQC and the gate models, reproduce on a quantum device the classical Von Neumann-Zuse paradigm, i.e. processing the inputs into outputs via a sequence of commands. Such architectures can be labeled as circuital model, as both of them aim to install a circuit of logical, controlled and sequential operations on the qubits. On the contrary, the adiabatic computation provides a scheme of computation which is unedited for any classical device.

SECTION: 5.1Circuital model

In the gate model, the logic gates are given by certain physical operations on the qubits. Such gates, apart from being described by unitary matrices in an algebraic fashion, can just be taught as the classical logic gates (OR, AND, XOR and so on) transposed in the quantum frame. Such logic transformations can involve just one single qubit, or rather two as well as, see Figure2. Any logic gate can be built by composing a set of universal gates, generally given by two single-qubit and one two-qubit operators[1].

In the measurement-based model instead, such logic gates are built relying on quantum phenomena such as entanglement and measurement[7]. Nevertheless, the gate model can be mapped into the MBQC one[85,6], proving that the two models are able to yield the same output.

SECTION: 5.2Adiabatic quantum model

Quantum annealers are quantum computers capable of finding the optimal solution to a QUBO problem by measuring the ground state of the QPU, i.e., the qubit configuration corresponding to the minimum energy of the system. The basic idea of quantum annealing is to prepare the qubits in the ground state, an easy-to-build configuration described by a Hamiltonian, and then let the system evolve until it becomes equal to, as in Equation12. If the evolution is sufficiently slow, the adiabatic theorem[3,86]guarantees that the systems stay in the ground state. Therefore, it is possible to find the solution to the optimization problem by simply measuring the system.

Quantum annealers realize quantum annealing by introducing a time-dependant transverse field resulting in a total Hamiltonian:

whererepresents the time, and the functionsandcontrol the annealing evolution and are referred to as the annealing schedule. At the beginning of the annealing, the system is prepared in the ground state of(). At the end of the annealing, the system should be in the ground state of().

SECTION: 6Emulation of quantum computing resources by High-Performance Computing

Quantum computing is a potentially disruptive computational paradigm that will enable efficient solutions to problems that are inherently difficult for classical digital devices. Although large-scale, error-corrected quantum computers are not yet available, hardware technology is evolving at a rapid pace, and demonstrations of quantum supremacy have already been achieved on current noisy intermediate-scale quantum (NISQ) devices for selected problems of academic interest[87,88,89,90]. From the practical applications standpoint, however, NISQ devices still need to operate alongside classical digital hardware. Real-world applications are in fact characterized by complex computational workflows and large problem instances in which most of the computational burden is necessarily carried by traditional resources. For these reasons, NISQ computers are currently utilized as accelerators or co-processors embedded in hybrid quantum-classical computation.

The orchestration of hybrid hardware resources is currently implemented by means of a loose-integration paradigm, in which the classical and quantum processing is typically performed via local machines with consumer capacities and via remote quantum devices respectively. From an end-user perspective, this paradigm is considered the most effective as it allows the evaluation of alternative vendor solutions while limiting the risks associated with the experimentation of highly prototypical technologies which might suffer from rapid obsolescence. The main drawbacks of such an approach are instead related to the latency associated with the continuous data transfer, along with the additional concerns regarding the exchange with third-parties servers of sensitive or restricted data.

To mitigate these issues, the scientific community is also starting to investigate on-premises scenarios with the co-location of quantum and digital classical hardware. This is commonly considered as a first step that, in the long term, should yield to a tight-integration paradigm in which quantum and classical processors are both co-located and interconnected via dedicated high-speed, high-capacity links[91]. The first experimentations in this direction are being conducted in various high-performance computing (HPC) centers, see ateuroHPCJUandHPCQS.

Beyond providing the means for an effective exploration of hybrid quantum-classical integration paradigms,
HPC resources enable the emulation of quantum computers with up to the equivalent of 40 to 50 qubits, which is more than what most NISQ devices deliver today. Given that the current quantum hardware is still difficult and expensive to access, HPC emulators provide unique opportunities for conducting impactful R&D that would not be possible otherwise. Typical activities enabled by HPC emulators are test/development of new algorithms for real-world applications, evaluation of the solution quality and time-to-solution behavior when scaling up the size of the problem, and the investigation of co-design of quantum algorithms and hardware.

A variety of emulators are currently available that can be used to implement a range of quantum algorithms, including those that are presented in this review. Most of them target a qubit architecture that implements the gate-based computational setting, either with an exact quantum state representation (state-vector, density matrix) or with approximate/compressed state representation (tensor networks). Such emulating libraries implement standard linear algebra operations that emulate the behavior of physical gates operated on the qubits register. Some of the most known software development kits (SDKs) that provide emulator backends areQiskit(IBM),Cirq(Google), and Pennylane[92](Xanadu). The majority of such libraries, which have been initially written to run on local machines, are now capable to exploit distributed memory protocols and GPU acceleration, which enable the simulation of intermediate-size quantum states (30+ qubits) and the execution of deeper circuits with acceptable running times.

In addition, as most of the hybrid quantum machine learning algorithms currently under investigation rely on variational circuits (VQE[93], QAOA[198], Quantum NN), which are parameterized circuits trained by a classical computer through the optimization of a differentiable loss function, many of these SDKs have also been designed or integrated with state-of-the-art machine learning software packages such as PyTorch[95], TensorFlow[96],Paddle-Paddleto leverage automatic differentiation techniques such as backpropagation. These can take advantage of GPU acceleration to reduce the overall execution time but incur additional memory overhead due to the need to store partial derivatives of the forward pass. The utilization of premium, large-memory GPUs that are typically available in HPC centers can boost performances.

Within the qubit architecture, a few emulators have been developed to deal with the measurement-based computational setting. Examples are Parceval (Quandela)[97]andPaddle-Quantum(Baidu), the latter taking also advantage of backpropagation methods.
As for architectures based on qudits,Jet(Xanadu)[98]andCirq(Google) libraries are available. Emulators based on continuous variable architectures are also available.

SECTION: 7Generalization of neural networks in quantum circuits

The classes of Machine Learning and Deep Learning are often juxtaposed in literature and applications, but indeed the first includes the second as a special case based on neural networks. Deep learning exploits a deep hierarchy of layers of artificial rate neurons, resulting in a non-Von Neumann-Zuse architecture that is virtualized on standard digital CMOS hardware. A software tunes a set of hyperparameters of the NNs, called synaptic weights, to re-elaborate the inputs to outputs.

A ML approach based on traditional and classical computing is straightforward to be translated on a quantum hardware, as it suffices to encode the inputs and the prompts into a quantum circuit. The main bottleneck is the constraint on the current size of the hardware, but from a theoretical perspective the problem can be treated as any classical-to-quantum algorithm. In such a way, it is quite standard to benchmark the performances between any classical algorithm and its quantum counterpart. A comparison for some of the most known classical machine learning methods and routines is given in Table1. Instead, neural network may require a paradigm shift towards new architectures. In the following two subsections, we present the two main approaches to neural networks, namely the variational and the quantum perceptron approaches, respectively.

SECTION: 7.1Variational approach

As said, several algorithms rely on an Artificial Neural Network (ANN, or more simply NN). NNs allow to transform input data to outputs (labels, actions) encoding the inputs through various layers of artificial synapses. According to the Hornik’s theorem[99], a sufficiently complex NN can always approximate the label output given an input.

In quantum computing, many models have been proposed to replace the classical architecture of multiperceptron-based neural networks. The main feature consists of introducing a specific circuit model, able to process the input states of the system through a series of iterations. Of course, shallow circuits belong to this architecture, as well as one-layer classical neural networks.
In order to process the information, instead of layers of neurons, quantum circuits display a block of unitary operations to be performed. The angles, implemented by unitary operators such as rotations, substitute the synaptic weights. In this frame, a quantum neural network (QNN) can be implemented via a variational quantum circuit (VQC)[100,101].

However, a broad range of quantum neural networks models have been proposed[102,103,104,105,106]: hybrid quantum circuit-classical neural networks approaches[107], quantum neuron models[108]as an alternative for the classical activation functions and so on. A classical activation functionis defined as

whereis called the weight function, andbthe bias vector. There are several classes ofactivation functions, among them the perceptron, the sigmoid, the ReLu and others. The perceptron, in its classical description, given a set ofinputs acts as a step activation function[109][2, pag.49], i.e.is substituted by the Heaviside step function, or rather by a sign function. In Section8.1a model for a quantum perceptron is presented.

It must be noted that variational circuits are known for suffering the barren plateau effect[110]. As random circuits are often proposed as initial guesses for exploring the space of quantum states during optimization of the parameters, one discovers that the exponential dimension of Hilbert space and the gradient estimation complexity make such choice unsuitable on more than a few qubits. In general the probability that the gradient along reasonable directions is non-zero to some fixed precision is exponentially small as a function of the number of qubits. Mitigations to this issue have been proposed thanks to smart inizialization[111], also avoiding it thanks to quantum convolutional neural networks[112].

SECTION: 7.2Neurons into qubits

There are more options to encode neurons into a qubit. Nevertheless, given the definition of a qubit, few encoding options can be defined, bounded by the maximum encoding capability of a register of N qubits. The first option consists of the-to-encoding, where each and every input neuron of the network corresponds to one qubit[113,114,115,116,117]. The information is provided as a string of bits assigned to classical base states of the quantum state space.
Similarly, a 1-to-1 method consists of storing a
superposition of binary data as a series of bit strings in a multi-qubit state. Such
quantum neural networks refer to the concept of the quantum associative memory[118,119]. A different-to-option is
given by the quron (quantum neuron)[120]. A quron is a qubit whoseandstates stand for the resting and active neural firing state,
respectively[120].

Alternatively, a radically different encoding option consists of
storing the information as coefficients of a superposition of quantum states[121,21,122,123,109,124]. The
encoding efficiency becomes exponential as a-qubit state is an element of a-dimensional vector space, but one has to remember that also operations required to store the state increase exponentially. From one hand, loading a real image classification problem of few megabits in a quantum neural network makes the-to-option currently not viable[125], while the choice-to-allows to encode a
megabit image in a state by usingqubits only. In the latter case one should anyway deal with the difficulty of preparing such a state, unless it is for instance generated by a circuit which approximates some aimed distribution, or alternatively it comes directly from the physical conversion of flying qubits containing quantum data acquired by some quantum sensing system.

SECTION: 8Quantum supervised learning

Supervised Learning is the branch of Machine Learning which has been more transposed in a quantum formulation. Here we present the most significant quantum algorithms relevant for cybersecurity tasks, along with a description of their classical counterparts: activation functions for binary decisions[21,123,126], Support Vector Machine (SVM)[127,128,129,33,130,131,132]and kernel methods in general[74].
One should notice that while current cybersecurity data are fundamentally classical in nature, in the future incoming quantum data from either quantum sensors or quantum communication networks may carry quantum (entangled) data, which in turn can be classified for instance by quantum tensor networks, as demonstrated by one of the authors[133].

In the broader field of classical anomaly detection, a paramount role is played by image classification, e.g. to spot medical diseases[59,134,135]or mechanical defects in industrial processes[61,136,60], therefore a specific Section of our analysis is dedicated to their quantum counterpart.

Classification by quantum tensor network on reduced MNIST with 4 categories has shown to return the same performances as best supervised learning algorithms, but more interestingly, it was able to discriminate quantum ground states carrying entanglement.

In the following Section, we introduce a range of techniques which vary from the implementation of natively quantum perceptron to the employment of adiabatic computation to improve performances of the Restricted Boltzmann Machine. Moreover, we show how to encode quantum neural networks on the continuous variables and classification tasks on qudits. All of the aforementioned techniques performs well when dealing with sampling from probabilistic distributions. Eventually, we show how to achieve quantum advantage on the Support Vector Machines via the HHL algorithm.

SECTION: 8.1Quantum feed-forward Neural Network for binary decisions

Recently[123,126], a model of perceptron implemented by a quantum circuit has been proposed. This model features an input vectorand a weight vector, such that the activation response depends on theirscalar product. In such scenario, the components of the vectors. The vectors can be encoded into a quantum register by the following states:

where the statebelongs to. Being,all, andbeing the dimension of the input and weight vectors,andare real equally-weighted (REW) superpositions of all the computational basis states. The stateslive in aHilbert space, where.The inner product betweenandreturnstimes. To prepare the input state, the following transformation can be implemented as

wherecan be composed by anymatrix withon the first column[21]. To perform theinner product, it is possible to define a unitary operatorsuch that.
To do so, choose any unitarywithon the last row. The inner product betweenandcan thus be performed by

whereis simply. Therefore,yields the scalar product. The coefficientcan be obtained, in a circuital computation, by entanglingwith an ancilla, through a multi CNOT gate (i.e. a CNOT whose control qubits are given by thestate). The sole state on which such multi-CNOT operatoracts on is thestate, i.e. the last one ():

whereis the multi-qubits control state andthe target one. Measuring the ancilla qubit on thebasis, it is possible to activate the perceptron with probability. Such achievement reproduces the perceptron in a quantum circuit. One should notice that such activation function ends the circuit with the measurement process, so the quantum information cannot travel further to other nodes. The issue has been addressed by one of the Authors[137]by replacing the measurement process with a quantum circuit performing the Taylor series of the aimed activation function. Such method enables to program a multilayered perceptron.

SECTION: 8.2Quantum restricted Boltzmann Machine

Restricted Boltzmann Machines (RBMs) are neural network generative models first introduced by Hinton et al. in 1983 to improve upon the Hebbian learning method used in Hopfield networks. These models are designed to learn the underlying probability distributions of a dataset by using the Boltzmann distribution in their sampling function. A RBM consists of two layers: a layer of visible binary units (representing the input/output) and a layer of hidden binary units (which help the model mimic the dataset’s structure). The units are connected by real-weighted connections, as illustrated in Figure3. RBMs do not allow connections between units within the same layer, resulting in a bipartite system.

RBMs are flexible neural network models that can be used for various tasks, such as generating samples, making recommendations, or extracting features. They can also be used as classifiers by using different techniques, such as using them as feature extractors and appending a separate classifier or training them supervised with the label appended to the input data. These supervised RBMs are called discriminative restricted Boltzmann machines (DRBMs), which combine descriptive power with classification ability. The idea is to train the DRBM with a dataset where the label is appended to the input, then remove it from unseen inputs and reconstruct it using the RBM.

The RBM is an energy-based model where every specific configuration of visible and hidden units is associated with an energy, where,are biases andare the weights that represent the connection strength between units. Specifically, the joint probability of a configuration is given by the Boltzmann distribution

The objective of training an RBM is to adjust the model’s weights to increase the energy of states in the training dataset and lower the energy of all other configurations, allowing the model to learn how to generate and reconstruct the critical information encoded in the dataset. However, training an RBM can be challenging due to the large number of states that increases exponentially with the number of visible and hidden units, making it impractical to compute the partition function. Although an exact computation is not possible, several classical methods can be used to train the model, such as Contrastive Divergence[138](CD), Persistent Contrastive Divergence[139](PCD), and Lean Contrastive Divergence[140](LCD).

Although these methods are effective in practice, RBMs can be more difficult and costly to train than other models that rely on backpropagation techniques, such as neural networks. Their training is often unstable and requires significant computational resources, and the approximations made during training can affect overall performance. Quantum computers provide an alternative approach to training RBMs, allowing for faster computation and better gradient estimates by querying the quantum processing unit. D-Wave quantum annealers, which are commonly used to sample the ground state of a QUBO problem, can also be used to train RBMs, resulting in faster computation and a better gradient estimate. These RBMs trained on a quantum annealer are called Quantum Restricted Boltzmann Machines (QRBMs).

The basic idea to train a RBM on a quantum computer[141,142,143]is to extract a batch of samples from the quantum machine, which are dispersed according to the Boltzmann distribution associated to the RBM. If the computational cost of initializing the quantum computer is neglected, the quantum algorithm computational complexity to obtain a single sample scales as. The advantage of employing the D-Wave adiabatic quantum machine to exploit RBMs could emerge as an increase of performance metrics, such as the accuracy and the likelihood, or as a reduction in the computational complexity or computational times depending on the specific problem under consideration. The quantum RBM has been used to address anomaly detection of IP traffic data, performing 64x faster than classic hardware in the inference[24].
More general machines called Boltzmann machines, based on a complete (not bipartite) graph, have also been addressed on an adiabatic quantum computer[144].

SECTION: 8.3Neural networks in Continuous Variables

An architecture to set up a Neural Network (NN) by continuous variables (CV) has been provided by Killoran et al.[10]. It is shown that through the gates of CV encoding it is possible to reproduce the classical layer for a NN:

whereis the activation function,is the weight matrix andbis the bias vector. Such layer can be embedded in the CV formalism via the following sequence of operators/logic gates:

Here,, whereandare the Gaussian operators in Section4.3.1, while theoperators are given by a composition of beamsplitter. Instead,is a new non-Gaussian operation we are going to define in this Section.
To perform Machine Learning tasks in CV, is therefore possible to implement a variational circuit built by a set of layers such as in Equation21. In the following, it is shown how a quantum neural network has been built in ref.[10]. The first three operations can be decomposed into a direct sum of two blocks:

where the first block on the diagonal acts over thevariables, the second one over, in a similar fashion as the beamsplitter operator in Equation9. Afterwards, it is possible to apply the shifting by the displacement operator, so that the initial state, up to this point, is morphed into

where. The next step is to implement a non-linear transformation, which is given by the non-Gaussian operations. To build up such single-qumode gate, define a non-linear transformation, which can be written in a Taylor expansion offor a certain degree of approximation, thereafter implement the operation in the form

Now the unitary operation is nothing but a translation over the second qubit:

Eventually, a similar operation as from Equations14and20has been implemented in the framework of Continuous Variables, as stated in Equation (20):

where.

From the formalism in Section8.3, it is possible to develop a hybrid algorithm, where it is possible to alternate classical Neural Network with quantum circuits for Supervised Learning tasks. As both the hyperparameters from the classical NNs and the variational circuit need to be tuned, a backpropagation can be performed by training the data on a classical device. In Ref.[10], a mean square error (MSE) was introduced as loss function:

The model, when correctly trained, should return. In[10], such model of hybrid Supervised Learning was employed to detect fraudulent transactions. The performance of the training outputted a ROC curve with area, whereas the ideal curve should return a unitary area.

In the implementation of Killoran et al..[10], three potential advantages are proposed for employing the CV quantum neural networks. In the first place, CV neural networks can be performed on any photonic device, as the operation to implement them are universal in the photonic technology platform.

Secondly, Hornik’s theorem, as explained in Section7.1, guarantees that any Lebesgue measurable function can be reproduced by a neural network. Quantum neural networks embed this property along with effects such as superposition and entanglement, which are intrinsic of the quantum realm. Furthermore, dealing with qumodesit is possible to rely on both the positions and momenta representations,xandpbeing the Fourier transform of each other.

As the last point, quantum neural network in the CV framework can be employed for nonlinear transformations over distributions of probability. For instance, given a single-mode state, it is possible to encode its amplitude and transform it via a unitary transformation, due to the transformations acting inside the layers in Equation (26):

SECTION: 8.4Classification with qudits

Given a finite set of vectorsin, partitioned betweenclasses, the Density Matrix Kernel Density Classification method (DMKDC) is an algorithm developed by Useche et al.[22]which aims to reproduce the probability functionsfor an elementto belong to a certain class.

Given a system of qudits in aspace, suppose to have a number of classes. Thereafter, a collection of training datais provided, along with a feature map. Such a map can be set by a softmax encoding, see Ref.[145], rather than via random Fourier features (RFF), see Ref.[145,146]. Both of these encodings would provide a normalized vector such that,being encoded in the fashion of a qudit vector, as in Equation (4), whose coefficients are computed by the chosen encoding methods. In second place, the density matrix, associated to such states, is constructed as a maximally mixed state over all the samples, see the below Equation. At the same time, it is possible to define a specific density matrixcorresponding to each-th class:

being the cardinality of the entiredataset. The frequencyaccounts how many times a databelongs to the-th class,counting the number of samples into the-th class.
The posterior probability for a genericsample to belong to the-th class reads as[145]

The aim of the algorithm is to samplein order to get the probability.
As theare known from the data, andbeing a Hermitian operator, it is possible to diagonalize it via atransformation:

Theare the-th eigenvalues for theoperators,andranking fromto. For each operator, there exists a specificunitary transformation capable to diagonalize the density matrixinto the computational basis, where. The expectationcan therefore be written as

Afterwards, it is possible to introduce theoperator:

Before to show the qudit implementation of the DMKDC circuit, we sum up the pipeline for the training of the training process based on the density matrix estimation:

map the datainto a qudit vector, thanks to a RFF or a softmax encoding;

sample thefrequencies, thus estimating theprobability densities;

introduce theoperator able to diagonalize theobservables.

It is worthy to notice that such training procedure does not involve iterative operations. The training samples are solely employed to prepare thematrices, the time complexity of the algorithm scaling linearly on the size of training dataset. In fact, as remarked by Gonzalez[145], the complexity of the algorithm isfor the estimation of theelements,being again the cardinality of the dataset, andfor the diagonalization of the same probability densities.

To prepare the DMKDC register, in the first place a qudit with all the frequenciesis prepared as follows:

In the second place, a quditencodes the classical data to be classified, at last aancilla. The overall state, before to compute, results in

As a first step, apply agate on thequdit, which consists of a sum moduloover thegenerators, so that the new state reads

whereis the sum modulo. Afterwards, apply aand agates, with the first qudit as control and the second and third respectively as targets:

where the first controlled gate apply aon the second qudit, while the second c-gate morphs thequdit into. Applying back agate, the state turns to be

As a second step, from the above state apply theand thegates, which outputs

To iterate the process, apply thegate on the first qudit, thereafter theandgates, for. Eventually the circuit returns the following state:

The second and the third qudits can be rewritten as

where thecoefficients are. It is possible to recombine the tensor product coupling the diagonal terms and the off-diagonal apart:

Applying thegate using the second qudit as target and the third as control, it leads to

The probabilityin Equation30can be achieved by measuring the first qudit in the-th element and the second one in:

The second passage has made usage of Equation32. At the end of the process, in the phase of testing, it is possible to point out which class the databelongs to by maximizing the probability:

SECTION: 8.5Classical and Quantum Support Vector Machines

In the field of quantum machine learning, support vector machines (SVM) have been deployed for instance to distinguish anomalies from normal activities. More specifically, such algorithms has been employed to spot fraudulent credit card transactions or spurious bank loan[28], to address malware detection[147]or rather to prevent cyber attacks, such as DDoS attacks[27].
Support Vector Machines are a classical supervised learning algorithm which aims to learn from the training samplesin order to classify a new data sample into positive or negative class[148]. The data samples are given in the form, with say two possible classesandand a relation to satisfy given by[149]

The space where the dataare set is. In such a formulation, it is possible to define a new set of coordinateszsuch that. Theare called feature maps, mapping theto the space of thez, i.e., with.
The purpose is to set a hyper-plane, given by theequation, wherezare the generic coordinates in aspace anddefine the parameters for the hyperplane. The vectorwof parameters is defined as

whereare the data for the training, andtheir corresponding weights.For the classification to succeed, at the end of the trainingwandbshould be set such thatfor a training pointin the positive class, andfor a training pointin the negative class. Via the formulation in Equation47, the hyperplanecan be defined as[130]

whereis called kernel function.

In Equation48, the kernel function is defined as the inner product between feature maps, but many other definitions may arise. Linear kernels are defined as[132,150,34]

In such case,and, the dimensions of the data and the feature space, are equal.
Nevertheless, many models of different kernels may arise. Depending on the nature of the problem to be tackled, different kernels may induce different metrics for the classification tasks.
The polynomial kernel is defined as[131,33,34],
whereis the polynomial degree and,are constants to be tuned. Another class is given by the gaussian kernel[131,150,33],,
whereis again a constant to be tuned. The last kernel model frequently cited in literature is the the Radial Basis Function kernel (RBF)[34],.
Again,is a parameter to tune for best fitting the real model.

In any of these formulations,still remains a symmetric matrix.

Regardless of the choice for the kernel, the final goal of the algorithm should be to reproduce the function in Equation46and ref.[127]:

and therefore, the hyperparameters which need to be trained are now. A way to express the affiliation of adata to one of the two classes, for(thus being the identity map) is the following[18]:

With such a formulation, the closest datato the hyperplane yield an equation. In AppendixB, we proveto be the distance between such points, thus callingto be minimized for the classification to succeed at best.
However, some datamay fall into a so-called grey region, with distancewith respect to the corresponding hyperplane. Thecan be thought as errors, or soft-variables (because the margins of the hyperplanes are now “soft”). The condition in Equation51can be translated into an equality:

being. We will refer to this condition in the next steps. Beingwthe normal vector to the hyperplane with coordinatesx, the distance between the two separation hyperplanes for the two classes is given by, i.e. by the norm ofw. Choosing the direction ofw, it is possible to minimize the distance between the two regions in the phase space which define the two classes, reducing therefore the probability to find an error. The purpose is now to minimize such distance, so that any object falling in the between of the two planes can be classified with no ambiguity. Such geometrical deduction can be pursued in Figure6a. Nevertheless, when some outliers inevitably occur, as in Figure6b, we are even interested in reducing thetotal distance. Summing these conditions with the constraint in Equation52, the following system is provided:

whereis the sensitivity to the total amount of errors. This optimization problem can be formulated via the Lagrangian multipliers, where the conditionis given by the inner product ofwand the sum over the, while the constraintby the last equation of the system[129]:

Thecoefficients play the role for the Lagrangian multipliers. To get the best parameters, we derive the Lagrangianwith respect tow,,and:

Afterwards, substitute the first and the third equation in the fourth one, which yields

as. The same expression can be rewritten in terms of the kerneland with all the parameterson the left member:

Taking into account the constraintfrom Equation55, the same expression in Equation57can be reformulated into a matrix fashion as

The first row holds because of the third equation in the system from Equation55. The dimension of the kernel matrixand the identitywhich multipliesis, i.e. the number of data from the training. Therefore, it is possible to obtain the parametersby just inverting thematrix:

Thematrix can be expressed as, where

Back to Equation58, it is possible to encode the training parametersas

where the normalization constant is set to be. As in the classical case, there are many available definitions of kernels, the first one of which can be

Just for instance, in order to reproduce a polynomial kernel, it is possible to embed a state vectorin a higher dimensional space[127],,
and therefore the inner product. To invert the matrix in Equation58, it is possible to apply the HHL algorithm, achieving an exponential speed-up. An overall explanation for the HHL algorithm is provided in AppendixA. In the first place, the linear system in Equation58can be embedded into a quantum transformation as,
where the matrix(and consequently theoperator) is defined as. Thematrix has adimension, along with a norm(being its eigenvectors) because of the trace normalization. Thanks to the Lie-Trotter formula, it is possible to decompose the exponentiation ofas

whereis the trace normalization. In order to apply the HHL algorithm, the statemust be endowed with an ancillary qubit, in order to store the eigenvalues of, and decomposed into a basis for:

Thus, applying the HHL algorithm, thestate transforms into

SECTION: 8.6Natively quantum kernel methods

The kernel method consists of embedding a set of data into a higher-dimensional space (even infinite-dimensional) called feature space[74]. Given the space of data, the kernelis defined as a map.
Such a map can be considered as a metric in thespace of the data. In the previous section, the kernel functionhas been alternatively defined through the feature maps, where,
where. The feature mapis a map between the space of dataand the feature space,.
A visual representation for this encoding can be seen in Figure6c. Such method turns to be useful in quantum machine learning, where classical data need to be encoded into a Hilbert space to perform some computation. It follows that the kernel function, encoding the data into the quantum circuit, induces a norm on the Hilbert space, and therefore a distance in thespace. Such feature accomplishes the purpose for a classification algorithm: given a target, it is possible to compute the distancethanks to the embedding in the feature space. By this approach, the data can be directly analyzed into a Hilbert space of features, where it is possible to deploy linear classifiers, relying on the inner products between quantum states. Increasing the size of the Hilbert space, such kernels turn to be classically intractable.

A way to encode the information into qubits (i.e. in the Hilbert space) could be formulated by introducing an operator, acting as[34]. In such formulation, theoperator acts as a creator over the vacuum state. Thus the kernel can be estimated by confronting theoperators:

By such formulation, the kernel entry can be evaluated on a quantum computer by measuring thestate in the computational basis with repeated measurement shots and recording the probability of collapsing the output
into thestate.

SECTION: 9Quantum unsupervised learning

Recently, unsupervised learning gained wide success due to generative techniques, which allow to produce genuine new data mimicking the original dataset. Such techniques rely on sampling data from an unknown distribution, according to which the original ones are distributed. Quantum devices allow to generate samples from any distribution very efficiently, due to the intrinsic probabilistic nature of quantum mechanics. For instance, in[24]it has been proved that a Boltzmann Machine on an adiabatic quantum computer performs 64 times faster than its classical counterpart, involving tasks and data concerning the field of cybersecurity. In the next Section, we detail how classical generative-adversary techniques are designed and suited for quantum computers and anomaly detection purposes.

SECTION: 9.1QGAN for anomaly detection

Differently from the approach based on SVM mentioned in the previous section, another approach has been proposed by Herr et al.[23]relying on hybrid quantum GANs for the anomaly detection task.

GAN (Generative Adversary Network) is an unsupervised algorithm of machine learning. This algorithm is based on two agents, the discriminative and generative one. Given a distribution of dataand a set of labels to pairwith, the former model tries to fit the best conditional probability, the latter how to generate the joint probabilityfor the data distribution. It is possible to introduce some latent variables,z, to mimic the distribution for thexdata. Given a distributionfor the latent variablesz[151], the purpose for the generative model is to get the best parametersto build a function.
The data generated fromwill be distributed according to a probability distribution, while the true (unknown) distribution of data in thespace will be given by(standing for true). The purpose of the discriminative model, now that the hidden variableszare embedded in thespace, is to distinguish which variables are distributed according torather than:.
The problem can be reformulated as aminmaxone. In the WGAN (Wasserstrein GAN) formulation[23], given a set of dataxdistributed accordingly to(written as), and a set ofzwith adistribution, the purpose is to maximize the expectation function over, neutralizing at the same time the “fraudulent” action of:

whereis the class of all the-Lipschitz functions. A-Lipschitz functionis defined such that

where(for,is defined 1-Lipschitz),andare respectively the domain and codomain of the functionand are metric spaces endowed with a distance and a norm (expressed byin Equation68). Thereafter, it is possible to state the proposition by Gulrajani et al.[152]:

Letandtwo distributions in acompact metric space. Then, there is a-Lipschitz functionwhich is the optimal solution of.

As a corollary to the proposition, it is stated thathas gradient normalmost everywhere underand. Without entering the mathematical details and proof for such proposition, which we recommend to Gulrajani’s paper[152], it is possible to set the minmax problem in Equation67with Lagrangian multipliers:

where,being uniformly distributed in the range, i.e., whileandstill. The multiplier term is called gradient penalty term to the critic loss function.

The training for a WGAN consists of two steps: in the first one, given a set of generatedand truexinputs, the purpose is to find the global minimum for the Lagrangian loss function defined in Equation69, w.r.t.hyperparameters for themodel via a stochastic gradient descent technique.

In the second step, the purpose is instead to enhance the pursuit of the generator. The way to achieve such goal is to maximize the first Lagrangian term, w.r.t. both theandhyperparameters:

In its classical fashion, the generative modelis built up by a series oflayers. In the first place, the latent variablesare reshaped through a series of maps, so that the overall NN model results in

where. A set of activation functions can be applied for eachlayer: in[23]leaky ReLU were deployed. Secondly, the final form of the generator will be given by thefunction:

in Ref.[23]is set to be a sigmoid function on, withcollecting the corresponding hyperparameters of the weight matrixand the bias vectorb. To update the hyperparameters, it is possible to adopt any gradient descent method. The updating proceeds by the usual chain rule in the derivation process:

The discriminative modelis a NN endoewd with several hidden layers, mapping the data in aspace to the label space in.

Quantum circuits support the generative procedure of the model. In fact, quantum computers are expected to sample efficiently from distributions which are hard in a classical way[153,154,87,155,76]. On the contrary, the critic model needs lots of classical data, which requires too much time to be loaded and makes such transposition unfeasible in the NISQ era[156].

When implementing the generative model on a quantum device, thezlatent variables are given into a uniform distribution, whereas the encoded stateis given by the preparation layer. The operator, which implements such preparation layer, is composed as,being the X-rotation over theangle. After the state has been encoded, it follows a layer of rotationsin all thebasis, alternated to CNOT gates. Therefore, two hyperparameters are given:stores the basis on which to perform rotations,the angles. Whileencodes the architecture of the circuit, theangles are the variational parameters to optimize on. The multilayer generative functionin Equation70is transposed in an expectation value over:

where instead of composinglayers of activation functions, there is a sequence ofoperators. At the end, a classical activation functionis applied to compose the last layer for the generative model. Beside this difference, the gradient descent method is applied in the same manner as from Equation73, but instead the derivative ofis given by

SECTION: 9.2Other approaches to quantum anomaly detection by unsupervised learning methods

Generally speaking, quantum anomaly detection has been intensively explored in the past few years[29]. Anomaly detection for cybersecurity can take advantage of its development in other fields.
For instance, a field of application of anomaly detection is particle physics. There, a number of algorithms have been proposed.
For instance, Alve et al.[157]have applied QAD to an analysis characterized by a low statistics dataset. They have explored anomaly detection task in the four-lepton final state at the Large Hadron Collider that is limited by a small dataset, by a semi-supervised mode, without finding any evidence of speed-up. On the contrary, other examples sharing the unsupervised approach provided quantum speed-up, as follows.

Quantum auto-encoders have been assessed for unsupervised machine learning models based on artificial neural
networks. The aim consists of learning background distributions by quantum auto-encoders based on
variational quantum circuits, as problem of anomaly detection at the LHC collider. For representative signals, it turns out that a simple quantum auto-encoder outperforms classical auto-encoders[31]. There, a quantum auto-encoder has been developed, consisting of a circuit divided into three blocks, namely the state preparation that encodes classical inputs into quantum states, the unitary evolution circuit that evolves the input states, and the measurement and postprocessing part that measures the evolved state and processing the obtained observables.

An anomaly detection algorithm based on density estimation (ADDE) has been proposed by Liang et al.[158]to potentially express exponential speed-up, but it was later found not executing. Then, another group demonstrated such an exponential speed-up based on a modified version[159]. Such a new quantum ADDE algorithm is based on amplitude estimation. It is shown that such algorithm can achieve exponential speed-up on the number M of training data points compared with the classical counterpart.

In 2022, anomaly detection for credit card fraud detection have been demonstrated by quantum
kernels on 20 qubits by authors including HSBC Bank affiliation[160]. The benchmarks consist of kernel-based approaches, in particular unsupervised modeling
on one-class support vector machines (OC-SVM). Quantum
kernels are applied to different type of anomaly detection, leading to observe that quantum fraud detection challenges
the equivalent classical protocols at increasing number of features, which are equal to the number of qubits
for data embedding. The better precision has been achieved by combining quantum
kernels with re-uploading, with the advantage increasing with the size of the
system. The Authors claim that with 20 qubits the quantum-classical separation of average precision
is equal to 15%. The Authors estimate the computational cost to estimate the Gram matrix representing the kernel iswhereis the number of samples, while the continuous retraining to update on-the-fly the kernel is. Instead, the time needed for inference (to assign a label fraud or not) for detectingnew-coming samples is ofkernel evaluations. The report is of particular interest as an evaluation is made for what concerns such inference time for three different hardware platforms: 1) superconducting circuits, 2) trapped ions and 3) optical systems.
One can evaluate the training time for a dataset of 500 elements.
In superconducting qubits, operation happen at MHz speed. A reproducible kernel measurements may require at leastmeasurement shots. Withkernel evaluations, the training time is 100 s - 28 h training time at optimistic MHz
rate same cost of 28 hours. The inference time is significantly smaller down to 0.5 s in the case of reduced dataset.
Instead, for large datasets (100000 samples), it may raise to 16 weeks, which could only be reduced with partial inference of Gram matrix.
In trapped ions, for 10 kHz per shots, withkernel evaluations the training time andis 3 h - 17 weeks.
With photons on deterministic gates, which is currently still an open field of research, the expected time ranges between 10 ms and 10 s.

SECTION: 10Quantum Approximate Optimization Algorithm

Data clustering is the process of identifying natural groupings or clusters within multidimensional data based on some similarity measure. Clustering is a fundamental process in many different disciplines[161], for instance, it can be employed to divide the data set into a specified number of clusters, trying to minimize certain criteria (e.g. a square error function) falling into the class of optimization problems. Moreover, clustering algorithms are employed to perform network traffic identification[162]and for graph-based network security[163].

In literature, in fact, a common approach consists of representing the servers as nodes of a graph, and the flow of data between them as the edges of the graph itself[164]. By monitoring the topology of the graph, relying on a technique called graph similarity, any anomaly can be straightforwardly detected. In 2022, Li et al. proposed an algorithm of clustering in order to monitor the traffic flow on the web[162]. Nevertheless, despite the effectiveness of such approach, the graph encoding for anomaly detections turns the problem to an NP-hard one by scaling with the number of nodes – see[164,163]. Instead, quantum computation is able to tackle graph-based problems in a polynomial time. In the next Section, we provide a paramount example about how an NP-hard graph problem could be leveraged by a quantum machine learning approach.

SECTION: 10.1The MaxCut problem

The MaxCut algorithm is a NP-hard combinatorial problem[165,166]which can be set as follows. Given agraph,being the vertices of the graph andtheir connections, the weights of theconnections are given by the weight matrix. The purpose in the MaxCut problem is to find the best subsetof vertices and its complementto maximize the sum over the weights connecting the two subsets[165]:.
The MaxCut problem can be formulated as the following integer quadratic program[165,166]and therefore mapped into a Hamiltonian formulation, inspired by the Ising model:

The constraintholds, allowing to replace such classical variables with the third Pauli matrix fromalgebra, i.e. theoperator. Nonetheless, it holds that. The cut is defined by the condition, and it can be set by maximizing theobservable[167].
When two vertices belong to the same subsetor, it follows thatand the contribution tois null. Thus, the set ofandcan be thought as a partition of the system in up and down spins.

The MaxCut problem can be employed in the field of data mining and machine learning[168], with special regards to unsupervised learning[169]: it is possible to recreate unsupervised learning clustering of data by mapping the problem to a graph optimization problem and finding the minimum energy for a MaxCut problem formulation.

SECTION: 10.2QAOA formulation

The quantum approximate optimization algorithm (QAOA) has been many times applied to tackle the MaxCut problem[198,170,169,171]. Such algorithm consists of preparing a register of-qubits in the eigenstate of a Hamiltonian:

More specifically, the stateis the maximum for the Hamiltonian. The purpose is now makingevolve to the maximum eigenstate for theHamiltonian from Equation76via the adiabatic theorem, i.e. to the minimum eigenstate for. The next step is thus to encode a time-dependent Hamiltonianto make the stateevolve[4]:

The annealing schedules are set by theandterms, theHamiltonian is shaped on the form of theHamiltonian in Equation76, while the transverse field Hamiltonians (and) still keep the same form.
Via the adiabatic theorem, it is possible to makeevolve from the higher energy state ofto the higher energy state of(and therefore to the ground state of). As the Hamiltonian in Equation (78) depends on time, the corresponding time evolution is given by

where. It is possible to approximate the above evolution by splitting the continuous trajectory along(or) in a patchwork ofsmall, discrete steps of duration[4,172]. By applying the Trotter formula[173], the operator in the above equation can be approximated as

where. In the limit for, it is possible to involve again the Lie-Trotter formula[198,174]to split eachHamiltonian into theandterms:

The bigger is, the better both the approximations in Equations80and81work. It is possible to treat the terms in the round brackets as a set of angles,, to map the overall evolution into

In such formulation, the time evolution via a parameterhas been substituted byunitary transformations parameterized by a set ofangles. When implementing such operator on a circuit, the number of repetitions over thelayers stands for the depthof the circuit itself. The stateis therefore evolved naturally to the solution under the action of the following unitary operator:

Recall the cost functionin terms of the numberof layers which are inserted in the evolution from Equation83, e.g.:.
More layers are inserted (i.e. the higher is), the more the solution is supposed to be exact. Afterwards, it is possible to define the maximum value over the expectation of:.
Therefore, by the adiabatic theorem, it is possible to state that.
Eventually, it is possible to map the adiabatic process into an optimization for theparameters,, which can be achieved by a hybrid algorithm combining gradient descent methods on CPUs/GPUs with backpropagation on the quantum circuits. A useful metric, to assess how far the state is from the solution (i.e. the ground state of), is given by the approximation ratio parameter, formulated as[167,175,176,177,178,179,180,181,182,34].
Here, withbeing the actual state of the system andthe maximum eigenvalue of the Hamiltonian operator, whose corresponding eigenstate is the goal of the problem under consideration. Whentunes to, the exact solution is provided. The approximation ratio, by such definition, returns the cost function (in our case, the Hamiltonian spectrum) normalized in thecodomain.

Said this, some critical considerations have to be done. Once the QAOA was proposed for finding approximate solutions to combinatorial optimization problems[198], it was subsequently shown that QAOA solves the combinatorial problem Max E3LIN2 with better approximation ratio with respect to any polynomial-time classical algorithm known, at the time, but soon a better classical algorithm with better approximation ratio was found[183]. The assignment of a quantum algorithm to a class of speed-up may suggest the priority around the aspects which can be investigated.

SECTION: 11Quantum reinforcement learning

Reinforcement learning (RL) has been poorly explored in the field of quantum information, and just in the last years some interest has been raising towards this branch of Machine Learning[184,185,186].
For instance, Chen et al.[187]proposed a variational quantum reinforcement learning algorithm via evolutionary optimization with no evidence of quantum speed-up. Another variational implementation is due to Acuto et al.[188]. Dalla Pozza et al.[189]developed a quantum RL framework to solve a quantum maze with speed-up, and Cherrat et al.[190]show a quadratic speed-up under certain conditions for their quantum RL based on policy iteration.
The field looks currently less developed with respect to quantum supervised and unsupervised paradigms and more development should be expected before prospecting an evident impact on security related tasks. Nevertheless, for sake of completeness, this Section outlines some key aspects of quantum RL, which may inspire future research around its intersection with cybersecurity.

According to one of the first proposals, when transposing classical algorithms of reinforcement learning in the quantum domain, the actions and the states of the system can be described as elements spanning two different Hilbert spacesand, or even(wherestands for environment)[191,192]. Apart from the qubits belonging to these twoandsystems, an auxiliary system, called register, can be added[26,184,193]. In such case, when initializing the overall system, the state will be presented as

As from the classical RL algorithms, three functions are required: a policy function, a reward function (RF) and a value function (VF)[26,194]. The reward function is the criterion to evaluate the goodness of an action taken by the agent, with respect to the fixed task. The value function evaluates the general convergence of the algorithm to the goal it has to be achieved. The policy function defines which action to take with respect to the fixed purpose. However, due to the nature of quantum mechanics, even extracting information from the environment to the space of actions needs a decision problem, which task is relied to the policy function. The process of extracting information from the environment to the actions can be though as an interaction with the two systems.

The simplest case deals with one qubit for the environmentand one qubit for the action space. Depending on the RL protocol to implement, the register space can be endowed with one or two qubits. Generally, such states are initialized to, i.e..
In the first step, the data need to be uploaded into thespace:

In the second place, apply a set of CNOT gates withas control and theas targets:

SECTION: 11.1Quantum adaptation algorithm

The quantum adaptation algorithm, proposed by F. Albarrán-Arriagada et al.[26]and applied by Shang Yu et al. (including Albarrán-Arriagada himself) in a semiquantum way[193]has been tested to rebuild a quantum state, in order to describe a quantum system. It consists of the following steps: start from a system where all of the,andsubsystems take into account a single qubit. In the first place, encode the overall system in a similar fashion as in Equation85:

Therefore, apply aoperator (CNOT onas control,as target):

Afterwards, perform a measurement overin the computational basis, so that thestate is going to collapse inorwith probabilitiesor, respectively. If the superposition collapses to, the environmentand the actionshare the same state, otherwise the latter needs to be updated. To update, introduce the following operator:

Hereandstand for the elements from Pauli algebra, and the suffixshows that they are acting over the action space. The indexstands for the iteration over the process. The angles of rotation are defined in the following range:,
whereis the parameter to update per iteration. The operatoracts on thestate depending on the outcome from the measurement:

whereis the outcome from the-th measurement,if, otherwise. To update theparameter, the following rule has been proposed:

andare called the reward and punishment ratios, respectivelyand, so that every time the outcome isthe value ofis reduced, whenit is increased.is a hyperparameter to tune for every set of simulations, the better theparameter, the higher the fidelity between the simulated qubit and the initial state.

At the-th iteration, the system will be set in the state,
where theoperator accounts into memory all the previous actions over:

SECTION: 12Concluding remarks

Anomaly detection performed on quantum computers by quantum machine learning algorithms is at its infancy, but reveals high potential. At the same time, one may expect a transition for what concerns the kind of data and the applications to be managed. Indeed, quantum machine learning suffers of the bottleneck of the data loading issue. Given that no qRAM does still exist, theparallelized encoding of data in qubits is currently not viable because of its exponential data loading cost. Therefore, three options can be considered: (i) a robust but qubit-expensiveencoding of classical data to be loaded by the register used as input of the quantum algorithm, or, alternatively – in some special cases – (ii) to generate the data by a pre-trained quantum circuit returning an approximate probability distribution (derived from another probability distribution easier to generate) which can introduce entangled states as input, or (iii) to feed the quantum algorithms by quantum data – another option which potentially inputs an entangled state.
While it is still under investigation to which extent the quantum machine learning can be more precise and faster than classical machine learning methods on classical data, it is likely that the major advantage appears when quantum data are considered. Indeed, a quantum circuit naturally manages quantum states, while instead this is not straightforward in machine learning.
In several cases, there is no knowledge whether strong quantum advantage does hold or not. Algorithms withcommonquantum advantage should be better explored by looking at demonstrating some stronger quantum speed-up degree while empirically evaluating the trend of its performances when scaling for instance the number of qubits. One should be aware that the empirical search of asymptotic behavior may change the estimate of the trend as soon as larger number of qubits are achieved.
Cybersecurity inherits the algorithms from quantum machine learning, but carries the specificities of dealing with large datasets. Here, the mutually exclusive choice between kernel-based and variational learning shows the tradeoff: kernel-based guarantees optimal kernel can always be found, but it scales with, while for
variational learning it is possible in time.
Any decision concerning application of machine learning to real anomaly detection datasets should begin with a real problem based on the dataset, on which a direct benchmarking comparison with classical methods could be evaluated.

SECTION: Appendix AThe HHL algorithm

The Harrow, Hassidim and Lloyd (HHL) algorithm aims to solve a linear systemusing a quantum computer[17]. Such algorithm was proposed in[25]. The classical method known as the best scales roughlyoperations, versus asteps on a quantum computer, yielding an exponential speed-up in terms of number of operations[25]. The other parameters, in the time-scaling complexity, are the sparsityof the matrix, i.e. the most number of non-null entries from the rows of thematrix[77], the condition number, i.e. the ratio between the largest and smallest eigenvalues of[25]and eventually the error. Thus, the HHL algorithm, to be better performing than the best classical algorithms, requires some caveats, as thematrix to be sparse and to read out an expectation value overx, such as(being an observable), rather than outputting the exactstate. Nevertheless, such routines are quite common in quantum computation, and may pave the road to future applications in quantum machine learning.

In fact, the matrix inversion is a common routine for many computational processes. The HHL algorithm is a frequent subroutine for many machine learning methods. As in Fig. (7), the HHL algorithm consists of three main blocks:

encoding thebvector into a quantum state(or assumeto be already prepared);

perform a quantum phase estimation (QPE), apply a conditioned rotation on an auxiliary qubit by the achieved result and transform back the state by an inverse QPE;

measure the ancilla qubit.

Until the qRAM or other techniques of encoding will be leveraged, the first step could turn to be the main overhead[17], in terms of numberof operations, as the classical information, encoded inbits, needs to be compressed intoqubits.
Once such step has been accounted, the QPE algorithm takes as input a state, an ancillaand a unitary operationto perform on. Thevector must be eigenvector for, under which hypothesis the QPE works in the following manner:

withacting over. From, it is possible to get the binary encoding of. Therefore, to getit is mandatory to divide the result byand multiply by. Just for instance, suppose to apply agate on thequbit:

For, the QPE algorithm, applied on, returns, which is the binary encoding for. Thus, in order to get the correct phase, multiply byand divide by, obtaining.

To apply the QPE for the HHL algorithm, the unitary operatorcan be decomposed as the complex exponentiation of a Hermitian generator:

whereare the eigenvalues forandits eigenvectors. Secondly, as anyHermitian operator can generate a basis inby its eigenstates, thevector can be decomposed into itsgenerators:

being the coefficients forin thebasis. Afterwards, it is possible to apply the QPE transformation:

Up to this point, thebvector has been encoded into astate, on which a QPE routine has been acted. The next step is to introduce another ancilla qubit in thestate on which to perform a conditioned rotation, using theas control qubits:

with. Applying the inverse for the QPE yields

Measuring inthe ancillary qubit (otherwise the algorithm needs to be run again), the global output turns to be

Apart from a normalization factor, the final output is the state encoding(being the eigenvalues for). In casenot being Hermitian, it is always possible to fix it by building up the following matrix:

with the linear system turning to be

SECTION: Appendix BDistance between two hyperplanes

In the following, we prove the distance between thedata closest to the hyperplaneto be. For such points, it holds that. In the first place, we choose two points,such that,and their midpointto lie on the hyperplane, i.e., as pictured in Figure8for the 2D case. The distancebetween the two points is given by the sum of the distances between the points and the hyperplane, which we call:

Therefore, the overall distanceis set to be

for thecase, as stated in Equation (104). In such case, the hyperplane consists of a line.

SECTION: References