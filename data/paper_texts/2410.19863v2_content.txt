SECTION: Breaking the Illusion: Real-world Challengesfor Adversarial Patches in Object Detection

Adversarial attacks pose a significant threat to the robustness and reliability of machine learning systems, particularly in computer vision applications. This study investigates the performance of adversarial patches for the YOLO object detection network in the physical world. Two attacks were tested: a patch designed to be placed anywhere within the scene – global patch, and another patch intended to partially overlap with specific object targeted for removal from detection – local patch. Various factors such as patch size, position, rotation, brightness, and hue were analyzed to understand their impact on the effectiveness of the adversarial patches. The results reveal a notable dependency on these parameters, highlighting the challenges in maintaining attack efficacy in real-world conditions. Learning to align digitally applied transformation parameters with those measured in the real world still results in up to a 64% discrepancy in patch performance. These findings underscore the importance of understanding environmental influences on adversarial attacks, which can inform the development of more robust defenses for practical machine learning applications.

SECTION: 1Introduction

The rapid advancement of machine learning algorithms, particularly in computer vision domain, has revolutionized various applications, from autonomous driving to medical imaging and secure face recognition. However, the widespread adoption of these algorithms has brought to light significant security concerns, notably the susceptibility to adversarial attacks(Szegedy et al.,2014; Costa et al.,2024). These attacks involve deliberate modifications to input data to mislead machine learning models into producing incorrect outputs.

A prominent example of a computer vision system is the YOLO (You Only Look Once)(Terven et al.,2023)detection network, known for its high speed and accuracy. Despite its advantages, YOLO, like many other machine learning models, is vulnerable to adversarial attacks(Choi and Tian,2022). Highly effective in digital environments, these can also degrade the performance of detection networks in real-world scenarios.

In addition to adversarial attacks, the robustness of machine learning models, including YOLO, is also challenged by environmental conditions such as weather, lighting, camera location, and viewpoint changes(Ding and Luo,2024). Variations in lighting conditions can lead to overexposure or underexposure, which in turn can affect the model’s ability to correctly detect and classify objects. Similarly, changes in the camera’s location and viewpoint can introduce new perspectives and angles that the model may not have been trained on, further reducing its detection accuracy. Environmental conditions also affect the performance of adversarial patches(Hartnett et al.,2022).

This study focuses on the stability of adversarial patches in the physical world, aiming to understand how various environmental conditions and patch attributes affect their performance. Two types of adversarial patches were evaluated: a global patch designed to suppress all correct detections when placed anywhere in the scene, and a local patch targeting specific objects by partially overlapping them. The patches were tested on the same static scene with YOLOv3 and YOLOv5 serving as the detection networks, respectively. These versions were chosen due to the availability of pre-existing frameworks for generating adversarial patches tailored to them (Lee and Kolter (2019)andShrestha et al. (2023), respectively). The experimental setup included a controlled indoor environment with a standardized set of objects and lighting conditions. Performance was evaluated based on the mean average precision (mAP) for the global patch and detection confidence for the local patch. Key variables such as patch size, position, rotation, brightness, hue, blurriness and reduced color palette were systematically altered to assess their impact on patch efficacy. The experiments revealed significant dependencies between the performance of adversarial patches and these variables when applied in the digital and in the real worlds. While patch performance with respect to geometric transformation is consistent across both worlds, color transformations unveil substantial differences, which can’t be easily matched, and indicating a gap between these both worlds. An example in Figure1shows the same scene, where the hue parameter was altered using a RGB light source (top) and digitally using the best parameters to match a physical change (bottom). YOLOv3 performance differs significantly when hue is changed physically and when hue is changed digitally. These findings highlight the sensitivity of adversarial patches to real-world conditions. This work is the extension of study conducted byShack et al. (2024).

Contributions.Our study provides a comprehensive and systematic analysis of how adversarial patches perform under various physical-world conditions, including different lighting, patch sizes, and viewpoints. The findings underscore a significant impact of environmental conditions, such as lighting, on the effectiveness of adversarial patches. We show that the real-world effects are different from applying these transformations digitally using the best matching parameters. The study emphasizes the need for the development of advanced adversarial methods and improved defenses, contributing to the development of more resilient machine learning systems capable of withstanding real-world adversarial conditions.

SECTION: 2Related Work

Object detection models and their robustness.YOLO(Terven et al.,2023)is one of the most popular real-time object detection algorithms. Its high speed and good accuracy make it widely used in the community. The original YOLOv1 object detector was first released in 2016 byRedmon et al. (2016), and quickly became state-of-the-art. Over time, the algorithm was significantly improved, so different versions are now available(Redmon and Farhadi,2018; Bochkovskiy et al.,2020; Li et al.,2023; Wang et al.,2022; Jocher,2023). In order to achieve the optimal performance of the object detection model, each YOLO version was trained with geometric (perspective change, scaling, translation, flipping, and rotation), color (HSV), and more advanced(Wei et al.,2020; Yun et al.,2019; Ghiasi et al.,2021; Zhang et al.,2018)augmentations. This made YOLO models resilient to challenging environments.

Adversarial attacks and adversarial patches.Adversarial patches were first introduced in 2018 byBrown et al. (2018), demonstrating the ability to mislead image classifiers using round stickers(Wei et al.,2022). This concept was extended to object detection in 2019(Liu et al.,2019)with the Dpatch, although it was initially tested only in digital settings. Subsequent studies, such as the work byLee and Kolter (2019), adapted these patches for physical-world scenarios, highlighting challenges like maintaining attack efficacy across different environmental conditions. This type of attack is referred to as aglobal attackin this study, as it targets the entire image. The paper proposes a way to generate a global patch attack, by maximizing the YOLO loss function. This global adversarial patch is primarily used for the experiments in this study.
A different approach for attacking object detectors is proposed byShrestha et al. (2023). In this method, the patch must overlap the object that is intended to be hidden from the object detection network. This technique is referred to aslocal attackbecause it targets individual objects within the scene.
The current research builds on these works by systematically evaluating the performance of both global and local adversarial patches.

Defenses against adversarial patches.Adversarial attacks pose a substantial threat to object detection algorithms. Due to their disruptive potential of adversarial attacks, adversarial attacks have attracted considerable attention, with numerous researchers striving to devise innovative defense strategies(Saukh,2024; Choi and Tian,2022). A common approach involves the localization and subsequent neutralization or removal of the adversarial patches.Jing et al. (2024)propose PAD - a patch-agnostic defense mechanism that combines semantic independence localization and spatial heterogeneity localization;Xu et al. (2022)developed defense pipeline against white-box adversarial patches that zeros out
the patch region by repainting with mean pixel values;Naseer et al. (2018)proposed local gradient smoothing scheme that regulates gradients in the estimated noisy region of the image before inference;Scheurer et al. (2023)address defence against adversarial attacks in motion detection applications. In contrast to previous works, our carefully constructed experiments demonstrate that failure cases for existing adversarial patches can be deterministically constructed. These findings highlight the necessity for further research on more robust adversarial patches and stronger defense mechanisms.

SECTION: 3Methodology

Adversarial patch generation.The attack patches used in this work were generated byLee and Kolter (2019)andShrestha et al. (2023), using variants of local and global projected gradient descent running the following optimization:

whereis the distribution over samples, andis the patch application function. The functionapplies a transformationwith parametersto the patch during training to ensure robust patch performance (for example, the global patch was trained with rotation augmentation). The patch is then integrated into the imageat a desired location. The optimization is solved essentially by using gradient descent(Lee and Kolter,2019; Liu et al.,2019; Shrestha et al.,2023).

Global and local patches.This study evaluates two types of patches: a global patch and a local patch. The global patch, designed to attract the attention of the object detection network and suppress correct detections, can be placed anywhere in the image and was generated as described byLee and Kolter (2019)using YOLOv3(Redmon and Farhadi,2018). The local patch, which must overlap the target object, was generated according toShrestha et al. (2023)using YOLOv5(Jocher,2023). Both patch generation processes used the COCO2014 dataset(Lin et al.,2015). YOLOv3(Redmon and Farhadi,2018)was used to test the global patch, and YOLOv5(Jocher,2023)was used for the local patch, as these versions were originally used to generate the patches.
The generated patches (Figure2) are specific to their respective detection networks and are not transferable.
All physical patches were printed on regular paper using a standard printer.

Hypothesis.Following recent findings that adversarial patches may fail in the physical world(Hartnett et al.,2022), we conducted a dedicated set of experiments to better understand these failure cases. To achieve this, we (1) carefully constructed our experiments, and (2) investigated the differences between the effects observed in the physical world and their reproducibility through digital transformations. We used sensors, and two cameras operating in well-documented modes to run reproducible real-world experiments. Our main hypothesis is that failure cases of adversarial patches in the physical world in general differ significantly from similar experiments conducted digitally,i.e., by embedding the patch into an image and transforming the result using the same parameters as measured physically, or the best matching parameters computed by an optimization algorithm. We present this analysis next.

SECTION: 4Discovering Vulnerabilities of Adversarial Patches

SECTION: 4.1Experimental setup

Controlled real-world environment.We evaluated the performance of adversarial patches by conducting physical attacks in a controlled indoor setting and attempting to reproduce them digitally for comparison. This controlled environment allowed us to easily adjust testing conditions. Lighting control was managed using an IKEA®Tradfri LED1924G9 RGB light source. We primarily used the Microsoft LifeCam HD-3000 camera, which records 720p HD videos at up to 30 fps. To ensure results were not camera-specific, we repeated experiments involving brightness and hue with the Ausdom AF640 camera, which records 1080p HD videos at up to 30 fps.
Our scene setup is shown in Figure1. The test included a bottle, cup, small potted plant in a vase, tennis racket, spoon, and a picture of a person.
Occasionally, a dining table was detected with low confidence but excluded from consideration due to inconsistency.

Evaluation metrics.To evaluate the performance of the global patch, we primarily use the mean average precision (mAP) as the metric. mAP is calculated by generating precision-recall curves and then determining the area under these curves. This metric provides insights into the overall performance of an object detection system. In this study, a lower mAP of the detection algorithm indicates better performance of the patch in suppressing detections. For the local patch, we measure performance by the detection confidence of the targeted object. The detection confidence assigned to each detection describes the confidence or probability of a detected object belonging to a particular class. Lower detection confidence signifies higher patch effectiveness.

SECTION: 4.2Experimental variables

Following setups described in the literature(Chen et al.,2019; Eykholt et al.,2018; Thys et al.,2019; Braunegg et al.,2020), we varied key parameters that can also easily change in uncontrolled real-world settings: (1) geometry (patch size, observation angle, distance to the target), (2) color transformations (scene brightness and hue), and (3) information reduction (blurriness and limiting the number of colors in an image).

Geometric transformations.We first experimented with different patch sizes. For global attacks, patch sizes ranged from 10% to 30% of the image width to avoid object overlap. For local attacks, we tested patch sizes varied from 4cm x 4cm to 16cm x 16cm.
For all other experiments (geometric, color or information reduction), by default, we used a 25% image width-sized patch for global attacks and the smallest patch that significantly reduced object detection confidence for local attacks (11cm x 11cm for the tennis racket, 7cm x 7cm for the other objects). We explore patch rotations up to 90∘around X, Y, and Z axes (see Figure7).
We also explore the impact of the global patch position within the scene on its detection suppression ability depending on the distance from the target.

Color transformations.Ambient brightness was varied from 4 to 61 lux (measured with a light sensor). With automatic camera exposure, there is a trade-off between the image brightness and noise. To mitigate this, we fixed the exposure time, thereby enabling overexposure – a common problem in real-world applications like autonomous driving(Jatzkowski et al.,2018). The camera exposure was calibrated to produce a uniform, naturally looking image at a measured brightness of 15 nits. However, a discrepancy persists between the measured lux in the room and the illuminance calculated from the scene image.
To address this issue and facilitate comparisons with our digital experiments, we performed an illuminance scale correction based on the calculated image illuminace. This adjustment shifted the real-world range of 4 to 61 lux to an approximate range of 68 to 243 lux as measured in the images.
We varied the hue values of the scene with an IKEA Tradfri LED1924G9 RGB light source (see Figure1for an example). Note that this light source also influences the other colour properties of the environment (e.g., brightness).

Information reduction.We conducted a series of information reduction experiments in the digital domain to analyze the performance of a low-quality patch due to possible camera or printing effects. A low-pass filter is often used in digital image processing domain to smooth the image, soften the sharp regions, and remove the noise while preserving important image features. We varied the filter size from 0 to 500.
Color reduction filtering aims to enhance image compression, optimize storage efficiency, and decrease computational complexity in image analysis tasks by reducing the number of distinct colors in an image while maintaining its essential visual features. The number of reduced colors was varied from 2 to 600, whereas a natural-looking image of a scene contains more than 50’000 different colors.

SECTION: 4.3Exploration based on a fixed indoor scene

To get a better understanding of the stability of the attacks in the real world, we run comprehensives experiments and attempt to reproduce the results in the digital world. The observations below relate to the global patch, but most our findings also apply to the local patch, which is discussed in the appendix.

Distance dependence.The first stability issue is the patch’s effectiveness depending on its distance from the object. Experiments show an attack is successful only if the patch is within a reasonable distance from the target. Comparing Figure3(a) and Figure3(b) confirms the patch is more effective when closer to the object. The original paper(Lee and Kolter,2019)claims that while the patch is somewhat location-invariant, its influence weakens with distance. We further investigated the effect by digitally inserting the global patch at various positions. Figure4(left) displays tennis racket detection confidence, with the x and y positions indicating patch placement and confidence levels. The red rectangle is the ground truth bounding box. Results show the patch must be within a certain radius, dependent on the size of the patch, resolution of the scene, and the object itself, to suppress detection effectively. Figure4(right) illustrates detection confidence relative to the distance from the patch’s edge to the bounding box edge, showing the patch loses its adversarial properties when positioned too far away from the object (400px).

Rotation dependence.Due to the nature of physical experiments, the position of the patch relative to the camera is crucial in an adversarial attack. Figure3(d) illustrates a large rotation around the z-axis, resulting in a significant reduction in adversarial performance compared to Figure3(c).
Rotation is often included in training neural networks for computer vision as a data augmentation strategy(Cao and Saukh,2023). Rotation transformation was also applied in the global patch generation software(Shrestha et al.,2023; Zhang et al.,2023). Consequently, we expect the patch to exhibit some robustness to rotations. Figure5shows the mAP over rotation angles across the three axes in the real world (left) and digitally (right). The patch sizes were aligned across these two settings. In both cases, the patch shows robustness to rotations around x and y axes within40∘, yet loses its adversarial properties for rotations around z axis larger than 20∘. Adversarial effects of the patch in the digital domain is stronger.

Size dependence.The patch size positively correlates with its effectiveness. Figure3(e) and Figure3(f) show a significant difference in performance when scaling a global patch from 12% to 30% of the image. This trend is confirmed digitally, as Figure7(left) shows larger patches suppress more detections than smaller ones, with the effect being stronger in the digital domain.

Brightness dependence.Another issue with attack stability becomes apparent when lighting conditions change. If the camera’s exposure time is set to automatic, there is a trade-off between image brightness and noise. Setting this to manual removes this dynamic adaptation and enables us to emulate overexposure. The exposure time is fixed and calibrated to produce a uniform and naturally looking image for the baseline of the experiment at 15 nits. Figure3(g) shows an example of patch performance at reduced brightness, while Figure3(h) shows an example at increased brightness. Here, the adversarial patch loses effectiveness if the image becomes too bright and starts clipping. Conversely, decreasing brightness does not significantly impact the patch’s performance. Figure8clarifies how patch performance is affected by brightness. The digital patch shows consistent performance unaffected by lighting changes over the whole range of values. The physical patch, however, looses its effectiveness with higher brightness when clipping occurs, matching the mAP of a clean image without a patch.

Hue dependence.Here we investigate patch performance when changing hue lightning. Figure1provides examples of images with physically and digitally altered hue and the corresponding detection results. YOLO achieves a mAP of 0.4 in real-world (Figure1(b)), and a mAP of 0.14 in the digital world (Figure1(d)), resulting in approximately 64% discrepancy in patch performance. In the real world, we used a RGB light source to change hue. To get the hue value of the light source, the value reported in the companion app (IKEA®Home smart 1) to the LED was used. To digitally replicate physical world scene images as accurately as possible,i.e., to digitally generate the scene images that are the best match to the physical scene images, we train a small neural network.
Our neural network outputs suggest that color transformations alone do not fully capture the changes introduced by an additional hue light source. To support this, we present the performance of the patch across the complete hue range in Figure9. Figure9(left) shows the results from physical experiments, where the hue value is reported by the additional light source app. Figure9(right) displays results from digital experiments, where only the hue value of the image is digitally altered. Notably, YOLO performs consistently across all hue values in the physical world, whereas digital experiments exhibit some fluctuations in YOLO performance. Additionally, in the physical world, there is a clear range in the hue spectrum, between 200 and 300 degrees, where the patch fails to perform effectively. In contrast, digital experiments show only slight disturbances in patch performance between 150 and 200 degrees.

Information reduction.This set of experiments demonstrates that the patch requires a certain amount of information to become effective. In the low-pass filter experiments shown in Figure10(left), the detection efficiency for the scene without a patch and the scene with the simulated physical patch (labeled as "physical" patch) align closely up to a certain point –i.e., the presence of the patch has no influence on the detections.
Beyond this point, the presence of the patch decreases detection efficiency.
In the color reduction experiments shown in Figure10(right), there is almost perfect alignment between the scene with the simulated physical patch and the scene with the digital patch.
The detection algorithm also requires a certain amount of color details to achieve its full detection potential. While performing these experiments, we observed that the colors on the patch are quite diverse and mixed. Consequently, when a color reduction filter is applied, the patch retains a relatively large number of colors compared to the real-world environment. This allows the patch to maintain the maximum of it’s efficiency and remain as efficient as the original digital patch.

SECTION: 5Discussion, Limitations, and Outlook

Discussion.Our experiments reveal significant dependency of patch effectiveness on environmental variables, such as patch size, position, rotation, brightness, and hue, highlighting the challenges in maintaining attack efficacy in real-world scenarios. While some failure cases are intuitive (e.g., a positive correlation between the patch size and its effectiveness), many of our observations are not. Despite our best efforts to match the transformation parameters in the real world and in the digital domain, patch performance discrepancies remain, leaving many questions open. An interested reader is invited to check the outcome of our experiments for the local patch in the Appendix.

Lighting conditions, particularly brightness and hue, were found to be critical for patch performance. Changes in brightness, whether from natural or artificial lighting, can alter the patch’s appearance and its interaction with the detection model. Overexposure or underexposure can reduce patch’s effectiveness, as observed in our experiments. Variations in hue from different light sources also impact the patch’s ability to disrupt detection.
In the physical world, light interacts with different materials in complex ways, influencing the appearance of objects. Geometrical and physical optics, including reflection, scattering, interference, and absorption contribute to the perception of color(Tilley,2020). The color of an object is primarily determined by the energy of the light wave and material’s properties - the energy of the incident wave, surface roughness and texture. The light that is leaving the object is what is seen. Modeling these interactions digitally presents significant challenges, as highlighted byMusbach et al. (2013).

The impact of training data on performance of patches tailored for the specific detection algorithm is a critical consideration.
The COCO dataset’s 80 classes are highly imbalanced.Personis the most frequent class, occurring over 250’000 times, whilebottleandcupappear approximately 25’000 times each, andtennis racketonly about 5’000 times. Our experiments showed that concealing the tennis racket is challenging, often requiring larger and closer patches, likely due to the skewed distribution of training data.
Furthermore, patch behaviour under varying hue values may be attributed to the absence of red and violet images in the COCO dataset - most images are yellow and green hue.

Limitations.Our study has several limitations. Firstly, the experiments were conducted in a controlled indoor environment, which does not capture the variability of a real outdoor settings. Factors like weather, outdoor lighting, and movement dynamics were not considered. The physical patches were printed on standard paper and evaluated under specific conditions, without exploring variations in patch materials and printing quality.
Secondly, the study focused on a limited set of objects and scenes. While the selected objects provided a good baseline, a more diverse set of objects and scenes could reveal more insights. The experiments were limited to two types of adversarial patches and specific versions of the YOLO network. Exploring other types of patches and different object detection models could further generalize the findings.

Future Work.The findings call for a deeper understanding of the interplay between adversarial strategies and environmental factors.
Future research should focus on developing more sophisticated adversarial methods that can adapt to changing conditions, and on improving the robustness of detection models to withstand such attacks, thereby enhancing the security and reliability of machine learning applications in real-world settings. While adversarial patches are static, object detection models can take advantage of on-device adaptation and reconfiguration to improve their resilience to adversarial attacks,e.g.,Saukh (2024); Wang et al. (2024).

SECTION: Acknowledgments

We would like to thank Dr Ramona Marfievici for her valuable guidance and feedback as the shepherd of our paper for Workshop on Enabling Machine Learning Operations for next-Gen Embedded
Wireless Networked Devices (EMERGE 2024). Her comments and suggestions greatly improved the quality of this work.

SECTION: References

SECTION: Appendix

SECTION: Appendix AParameter Matching

SECTION: A.1Geometric Transformations

For geometric transformations, such as patch size and observation angle, we directly matched the parameters between the real-world and digital experiments. This alignment is feasible because, in both settings, patch size and observation angle are measured relative to the scene as captured by the camera.

SECTION: A.2Color Transformations

Matching parameters for color transformations proved to be more complex.

Brightness Transformations.For brightness transformations, ambient brightness was varied from 4 to 61 lux, as measured with a light sensor. However, due to various factors such as the camera’s exposure settings, light distribution in the room, and the light sensor’s position, the measured illumination did not correspond to the calculated illumination from the scene images. To match the physical and digital experiment parameters, we performed an illuminance scale correction based on the calculated image illuminance from the real-world experiment images. This adjustment shifted the real-world range of 4 to 61 lux to an approximate range of 68 to 243 lux.

Hue Transformations.For hue transformations, we initially conducted a direct matching of the real-world and digital parameters and the results are shown in Figure9. The results prompted further investigation, leading us to conclude that a hue light source in the real world affects not only the hue value that can be seen digitally, but also other colour properties of the environment visible digitally. To accurately replicate the physical world in the digital domain,i.e., to digitally generate the scene images that are the best match to their physical counterparts, we train a convolutional neural network.

The architecture of the neural network is illustrated in Figure11. It processes scene images (targets) of size 256x256x3 in the input layer. This is followed by two pairs of convolutional layers, each with ReLU activation and Max-Pooling layers. Subsequently, there is a fully connected layers with ReLU activation. The output layer splits into two branches: one with 3 nodes using the Sigmoid activation function for transformation parameters that are within a specific range (brightness factor, contrast factor, hue factor), and the another with 1 node using the Softplus activation function for transformation parameters that are positive values (saturation factor).

We utilized images of our scene, varying the hue and ambient brightness using an IKEA Tradfri LED1924G9 RGB light source and an additional light source. The dataset comprises 28 images: 23 for training, 4 for validation and 1 for testing. The input images are resized to 256x256 pixels and standardized using the target data’s mean and standard deviation, to being fed into the network. The output parameters are then applied digitally to the baseline scene image, taken under natural lighting conditions (without additional hue light or other light sources), to approximate the target image. We used mean squared error loss function and the Adam optimizer with a learning rate of 0.0001. The model was trained with a batch size of 4 over 500 epochs. To prevent overfitting, a dropout rate of 0.5 was applied after fully connected layers.

This task proved to be challenging. The addition of a hue light in the physical world significantly alters the scene, which translates to considerable digital transformations. Even when a single additional hue light source was added physically, our model reports that all color transformations – hue, brightness, contrast and saturation – are necessary to match the image of the original scene to the image with the added hue light. Our neural network achieves an average mean squared error loss of 0.5327, suggesting that color transformations alone do not fully capture the changes introduced by an additional hue light source.

SECTION: Appendix BFurther Details of Experimental Setup

To quantify the stability and general behavior of the generated patches, a basic setup was created. The scene to be attacked consisted of a few simple objects:

a bottle,

a cup,

a small potted plant,

a vase where the potted plant sits in,

a tennis racket,

a spoon,

and a picture of a person.

A baseline without a patch in the scene and all detected objects using YOLOv3 and YOLOv5 can be seen in Figure12. Occasionally, a dining table is recognized with low confidence by the object detectors. However, this is not included in the ground truth because this object is not actually a dining table, and its recognition depends heavily on the exact position of the camera, which can vary slightly between the experiments. In the case of YOLOv5 detections (Figure12(right)) it is noticeable that the confidence for the vase is very low or it is not detected at all, which is why this object was removed from further observations.

SECTION: Appendix CPerformance comparison of local and global adversarial patches

This work investigates two different types of attacks: local (using YOLOv5) and global (using YOLOv3). All physical experiments described in Section4.3, except for the distance dependence, were repeated for the local patch. Here, we present the results of those experiments and compare the performance of two types of attacks. Important to notice is that evaluation metrics used to measure the efficiency of the attacks in two cases are different. The evaluation metric used for measuring local patch performance is the detection confidence of the attacked object. We interpret this value as follows: the lower the confidence, the better the patch performs. The first two columns in Table1show the detection confidence values for the standard case, with normal lighting and no patch.

All objects were attacked locally with a patch approximately 7 cm x 7 cm in size, except for the tennis racket, which required a larger size patch, approximately 11cm x 11cm, to significantly decrease its confidence. The second two columns in Table1show the baseline confidence for all objects attacked under standard brightness and hue with the patch parallel to the image plane. Each object was attacked individually, with the patch placed overlapping the object. An example is shown in Figure13.

Due to the nature of these experiments, it was not always possible to conduct them with equal quality for all objects. For instance, applying a local patch with different rotation angles to the potted plant proved to be very difficult. Therefore, only the results for the objects where the patch application could be done most consistently are included here.

SECTION: C.1Rotation dependence

The results of the rotation experiment with the local patch are quite similar to those with the global patch. The attack performs relatively well up to a rotation angle of 30° around all axes. However, a slight difference is noted: rotation around the z-axis does not affect performance as much as it does for the global patch, indicating that the local patch is a bit more stable in this regard. The recorded confidence values for this experiment are shown in Tables2,3, and4.

SECTION: C.2Size dependence

Varying the size of the patch leads to the straightforward conclusion that a larger patch significantly improves the performance, as shown in Table5. These results align with the experiments performed with the global patch. However, there is one thing different in local attacks setup we should address to. Due to the nature of a local patch, it has to overlap the attacked object. This leads to targeted object becomes less and less visible with an increase in patch size. All recorded confidences (that are not“N/A”) have been verified to be caused by the patch (and not the inability to see the targeted object) by applying a control patch. This control patch, generated from random noise, has no adversarial properties. If the confidence with the control patch is higher than with the local patch by at least 0.3, it is considered a valid data point. Otherwise, too much of the object is overlapped to be seen and recognized, even without the adversarial properties of the local patch.

SECTION: C.3Brightness dependence

The variable brightness experiments show the most significant difference in performance between local and global patches. While the effectiveness of global patch decreases with increased brightness, the local patch performs better under brighter light for most objects, as can be seen in Table6. This improved performance of the local patch at high brightness levels could be due to the lack of light spots, resulting in less clipping from high exposure. However, the results for tennis racket suggest an inverted behavior than for the other objects, similar to the global patch experiment. This set of experiments would require further testing to investigate different behaviours.

SECTION: C.4Hue dependence

The results of the hue experiment with the local patch are shown in Table7and Figure14. The findings are very similar to the global patch experiment, with patch performance decreasing at similar hue values. The Figure14is less clear that the appropriate one for the global patch, because detection confidence is a less sophisticated metric for comparing patch performance than mean average precision. The plot still shows a clear trend: patch performance worsens at very low hue values (10∘to 30∘) and high hue values above 300∘, while it performs quite well between 40∘and 200∘/250∘, depending on the object.

SECTION: Appendix DDiscovering vulnerabilities of
adversarial patches - Brightness dependence

Figure15complements the experiments presented in Section7. The plot shows mean average precision over brightness of the scene for different patch positions (position1 and position2) in digital experiments. These results further confirm the discussion in Section4.3, that the patch performance is highly dependent on the patch position in the scene. Our experiments indicate that the digital and straightforward imitation of physical patches yield similar performance when placed in identical positions, contrary to our real-world observations. This finding reinforces our assertion that accurately replicating real-world conditions in a digital environment is challenging.

SECTION: Appendix EGlobal adversarial patch color analysis

All digital experiments with the global patch are performed with the originally generated version of a patch shown in Figure16(left). The physical experiments use physical patches printed on standard paper. The capture of the physical patch taken with our camera is shown in Figure16(right). As can be seen, the "quality" of the physical patch is highly dependant on environmental conditions and the camera being used. Also, the picture of the patch on Figure16(right) is taken under normal daylight and without any filters or additional obstructions, one can noticed that the colors are less intense and that the edges are less sharp.

We performed patch color analysis in HSV (stands for Hue, Saturation and Value – brightness) color space, and in RGB (stands for Red, Green and Blue) color space. Figure17shows the distribution of different values of hue, saturation, and brightness for both the original patch and photo of the patch (left), and the distribution of different values of red, green, and blue colors for both the original patch and a photo of the patch (right). Our results confirm the intuitive conclusion stated above, that colors in a photo of a patch are less saturated, and support our claim that the transformation from the physical to the digital world is not easy.