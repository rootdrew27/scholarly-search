SECTION: TAVRNN: Temporal Attention-enhanced Variational Graph RNN Captures Neural Dynamics and Behavior

We introduce Temporal Attention-enhanced Variational Graph Recurrent Neural Network (TAVRNN), a novel framework for analyzing the evolving dynamics of neuronal connectivity networks in response to external stimuli and behavioral feedback. TAVRNN captures temporal changes in network structure by modeling sequential snapshots of neuronal activity, enabling the identification of key connectivity patterns. Leveraging temporal attention mechanisms and variational graph techniques, TAVRNN uncovers how connectivity shifts align with behavior over time. We validate TAVRNN on two datasets:in vivocalcium imaging data from freely behaving rats and novelin vitroelectrophysiological data from theDishBrainsystem, where biological neurons control a simulated environment during the game ofpong. We show that TAVRNN outperforms previous baseline models in classification, clustering tasks and computational efficiency while accurately linking connectivity changes to performance variations. Crucially, TAVRNN reveals that high game performance in theDishBrainsystem correlates with the alignment of sensory and motor subregion channels, a relationship not evident in earlier models.
This framework represents the first application of dynamic graph representation of electrophysiological (neuronal) data fromDishBrainsystem, providing insights into the reorganization of neuronal networks during learning. TAVRNN’s ability to differentiate between neuronal states associated with successful and unsuccessful learning outcomes, offers significant implications for real-time monitoring and manipulation of biological neuronal systems.

KeywordsRepresentation Learning, Attention, Graph Recurrent Neural Network, Neuronal Dynamics, Electrophysiology, Calcium Imaging, Behaviour

SECTION: 1Introduction

The field of artificial intelligence has from the outset used natural systems, refined over evolutionary timescales, as templates for its models[1]. Neuroscience has been a significant source of inspiration, from the McCulloch-Pitts neuron and the parallel distributed architectures of connectionism and deep learning, to the contemporary call for Neuro-AI as a paradigm for research in AI[2]. Progress leveraging the neurocomputational capacity of biological neurons requires more advanced machine learning methods to enable better prediction and interpretation of behavior from neuronal activity. The understanding gained from these efforts may offer the potential for more refined machine learning algorithms that require less data and energy.Past attempts to examine higher-order neuronal dynamics typically isolates the temporal evolution of neuronal signals[3,4,5]. However, the specific network dynamics integral to the neural learning process, particularly the unit-population relationship, have yet to be fully explored. Analysis at either level can be informative but fail to explain behavioral outcomes sufficiently[6,7]. To address this gap we analyzed the spiking activity at the single unit level ofin vivocalcium imaging data from the hippocampus of freely behaving rats[8]andin vitroelectrophysiological data from theDishBrainsystem[6]. Within theDishBrainframework,in vitroneuronal networks are intricately combined within silicocomputing via high-density multi-electrode arrays (HD-MEAs). Through real-time closed-loop structured stimulation and recording, these biological neural networks (BNNs) are then embedded in a simplified Pong-game and showcase self-organized adaptive electrophysiological dynamics.
We propose a novel approach: investigating the temporal trajectories of a single neuron data in synchronization with the online evolution of behavior. Exploring the evolving structure and functional connectivity of BNN in this integrated manner, we aim to provide a more comprehensive understanding of the neuronal mechanisms driving adaptive learning in real-time environments.By analyzing the simultaneous temporal evolution of neuronal and behavioral data, this method provides crucial insights into the links between population-level neural activity and behavior. Moreover, it extends beyond this scope by examining interactions between individual neurons and uncovering the patterns that underlie learning and neural information processing in a system such as theDishBrainsystem. The dynamic interplay between neurons within the network not only facilitates information processing and response generation but also reveals how learning modulates synaptic interactions, affecting signal transmission across the network. This approach enhances our understanding of both cellular and network-level processes critical to learning, with significant implications for neuroscience and artificial intelligence. It also holds promise for informing the development of advanced learning algorithms and innovative treatments for neurological disorders.

SECTION: 2Background

SECTION: 2.1Large-scale neuronal recordings and learnable latent embeddings to link brain and behavior

Simultaneous recordings from large populations of neurons provide a wealth of electrophysiological data and are central to understanding brain function. A key challenge in neuroscience is linking these high-dimensional neuronal recordings to neurocomputational processes and ensuing behavior, a task that spans a wide range of recording schemes and datasets. In this work, we utilize two exemplar datasets: a high-density microelectrode arrays (HD-MEA) recordings of in-vitro neurons and hippocampal data from behaving rats as examples of such large-scale recordings, allowing us to explore the connection between neuronal dynamics and behavior across different scales[9]. Progress in Synthetic Biological Intelligence (SBI) environments necessitates innovative methods for analyzing and interpreting neuronal data to establish connections between brain function and behavior. Network models enable the study of simultaneous recordings from biological neural networks (BNNs), highlighting the significance of neuronal cell assemblies in memory[10]and stimulus processing[11]. Although neuronal latent embeddings offer insights into behavior-related neuronal correlates, there is a paucity of nonlinear techniques that can adeptly and flexibly utilize combined behavioral and observed neuronal data to elucidate the underlying neuronal dynamics. Conversely, existing nonlinear methods for associating neuronal and behavioral data, in a single model, usually investigate the temporal trajectory of the entire neuronal population as a whole, neglecting the interaction-based network of single neurons. These methods also struggle to track individual neuron activity and uncover the evolving connectivity that facilitates adaptive learning[3]. Population-wide analysis of neuronal recordings demands a novel theoretical framework for advancing the algorithmic understanding of intelligence.

SECTION: 2.2Node embedding techniques

Node embedding techniques translate network nodes into vectors within a low-dimensional latent space, enabling traditional vector-based machine learning methods[12]. Current approaches typically treat networks as static, assuming fixed node and edge sets throughout the learning process[13,14,15,16,17,18]. These methods often apply static embeddings to network snapshots, which simplifies the inherently time-varying nature of neuronal dynamics and the resulting temporal network dependencies, potentially overlooking the evolving characteristics of neuronal networks[19]. Several techniques have been developed to account for the temporal evolution of networks[20,21,22,23], but they often represent each node with a deterministic vector in a low-dimensional space[24], failing to capture the uncertainty in node embeddings that arises from integrating node attributes and network structure. This limitation underscores the need for probabilistic embedding techniques that reflect the uncertain, dynamic nature of node characteristics and interactions over time.To address these shortcomings, the Graph Recurrent Neural Network (GRNN) was proposed to extend traditional graph convolutional networks to dynamic networks[25]. However, GRNN struggled to fully capture the complex interaction between network topology and node attributes due to its reliance on unimodal distributions. To improve the modeling of sparse dynamic networks, the Variational Graph Recurrent Neural Network (VGRNN)[26]was introduced, but it still faced challenges in emphasizing relevant historical information and distinguishing the varying importance of past time steps. Our model enhances GRNN by incorporating high-level latent random variables, providing richer and more interpretable latent representations. We propose an improvement to the VGRNN framework by introducing a temporal attention mechanism that evaluates the topological similarity of the network across time steps, accounting for varying time lags to better capture complex network dynamics. This approach provides a deeper understanding of how network structures evolve over time and, in systems likeDishBrain, offers insights into the neuronal mechanisms driving adaptive learning inin vitroneuronal assemblies.

SECTION: 3Datasets

We used the dataset from[8], consisting of multicellular recordings from 120 putative pyramidal neurons in the CA1 hippocampal subfield of male Long–Evans rats using silicon probes. Rats ran on a 1.6-meter linear track, receiving water rewards at both ends (Fig.1a), with spiking data recorded at 40 Hz for  254 seconds. The rat’s position on the track was simultaneously recorded (Fig.1b) and served as ground truth to validate TAVRNN in a downstream classification task to link population neural activity to the rat’s position on the track, which, based on previous evidence, is thought to be encoded by place cells in the hippocampus[27].

TheDishBrainsystem, integrated in real-time with the MaxOne MEA software (Maxwell Biosystems, AG, Switzerland), facilitates closed-loop stimulation and recording of cultured cortical networks during engagement in a simplified version of Pong[6].
Neuronal activity from 24 cultures across 437 sessions (262 ’Gameplay’, 175 ’Rest’) was recorded at 20 kHz using an HD-MEA with 900 channels. During Gameplay, sensory stimulation was delivered via 8 electrodes using rate coding (4Hz–40Hz) for the ball’s-axis and place coding for the-axis. Paddle movement was controlled by the level of electrophysiological activity in counterbalanced "motor areas" (Fig.1c). In the "motor regions," activity in half of each subregion moved the paddle "up" (,) and the other half moved it "down" (,). Cultures received feedback via the same sensory regions, such that unpredictable 150 mV stimulations at 5 Hz were introduced when they missed the ball as random external inputs into the system. This was applied to arbitrary locations among the 8 sensory electrodes, at varied intervals lasting up to 4 seconds. A configurable 4-second rest period ensued before the next rally commenced. During Rest sessions, activity was recorded to move the paddle without stimulation or feedback, while outcomes were still recorded. Gameplay and Rest sessions lasted 20 and 10 minutes, respectively, with spiking events from all channels extracted in each session.
Further details on this system are provided in AppendixA.1,A.2,A.3.
Behavioral data was collected by measuring the cultures’ ability to intercept the ball, quantified by the number of ‘hits’. Each rally ended with a ‘miss’, resetting the ball to a random position for a new episode.
The hit/miss ratio was defined as the ratio of accurate hits to the number of missed balls (i.e. number of rallies played). This dataset was used in a downstream clustering task with regions applied as labels to observe how channels clustered at different performance levels.

For the rat hippocampal recording, we used binary spiking data from 120 neurons across 10,178 time points at 40 Hz. We selected time windows of spiking activity when the rat was within the first and last 0.2 meters of the track, yielding 85 crossings (Fig.1b). These varying length time windows were subsequently labeled as 1 for the beginning and -1 for the end of the track for the downstream classification task. To ensure that the covariance matrix is not ill-conditioned in these time windows according to the Marchenko-Pastur distribution[28,29,30], we performed a comparison to a shuffled control, where neuron identity was maintained but time points were independently shuffled for each neuron, repeating this process 1000 times to estimate confidence intervals and only considering correlations beyond the 95% confidence bounds in the analysis. For further details, see AppendixA.6.For each of the 24 neuronal cultures in theDishBrainsystem, spiking activity from all Gameplay and Rest trials was down-sampled from a sampling frequency of 20KHz by applying a binary OR operation within 50 ms time bins. A value of 1 was assigned if a spike occurred in any trial within the bin, and 0 otherwise. This process produced 24 binary spiking time series (one per culture), each with 900 channels, and 24,000 time points during Gameplay and 12,000 during Rest.
To investigate the single-unit interactions and dynamics of the underlying neuronal networks and their variations in game performance, we then segmented each Gameplay or Rest session into sliding windows of 2 minutes, each overlapping by half a window (i.e., 1 minute). This method generated 19 snapshots during Gameplay and 9 during Rest sessions. The selected window size ensured that the covariance matrices were not ill-conditioned based on Marchenko-Pastur distribution from random matrix theory[28]. We computed the hit/miss ratio for each time window by averaging results across all trials for each culture. The three time windows with the highest and lowest hit/miss ratios were classified respectively as the best () and worst () performing windows.were chosen for the main comparative analyses in the following sections (see Fig.1d for average performance levels in these six time windows and AppendixA.4for additional comparisons).

SECTION: 4Methodology

SECTION: 4.1Temporal Network Construction

Within each window of either dataset, we constructed a network adjacency matrix representing functional connectivity using zero-lag Pearson correlations as edges and 120 neurons or 900 channels as nodes. We employed graph kernels for selecting the connectivity inference method (Pearson correlation) and determining the cutoff threshold for theDishBraindataset (see AppendixA.5).The functional connectivity between nodes from both datasets was represented as edges in a matrix. For each time window, the corresponding temporal network is represented by a graph, whererepresents a specific channel, anddenotes the connectivity edge between nodesand. The structure of these dynamic network graphsis captured in time-resolved adjacency matrices, with elements in, whereis the number of nodes. These matrices are generated by applying a threshold (as obtained from the graph kernels - see AppendixA.5) to the functional connectivity matrices, retaining only the connections above that threshold based on absolute correlation values and setting the remainder to zero. Note that given this input structure, TAVRNN is capable of handling temporal graphs from time windows of varying lengths as in the rat hippocampal dataset in this study.
Additionally, each dynamic graphincludes node featuresin, wherecorresponds to the feature vector of each node, calculated from the connection weights of each node andis the number of features.

SECTION: 4.2Temporal Attention-enhanced Variational Graph RNN (TAVRNN)

In this section, a probabilistic TAVRNN framework is developed to extract representative latent embeddings of the dynamic connectivity networks in a purely unsupervised manner. Fig.2summarises the pipeline of the introduced framework in this section. The Python implementation of our proposed framework is available at the followingGithub Repository.

We present a spatiotemporal variational Bayes objective function designed to maximize the lower bound on the log model-evidence known as the evidence lower bound (ELBO) written asor equivalently minimize its negative value known as the variational free energy (VFE). This objective is applied to a series of adjacency matricesfrom dynamic networks, based on the sequence of node features, whereis the length of the sequence. Introducing a latent embeddings sequence, the VFEcan be written via importance decomposition as:

Here, the subscriptsandrepresent the parameters of the GNN that model the generative distributionand the posterior distribution, respectively.
Using the following general ancestral factorizations:

Eq. (1) is expanded to yield the sequential VFE (sVFE) as follows:

Here,andrefer to the partial sequences up to theandtime samples, respectively.represents the (positive-valued) Kullback-Leibler divergence (KLD).Since we wantto represent all the information of, we replacein Eq. (4) by.
Noting that Eq. (4) holds for any arbitrary density function, we restrict our options to the density functions that satisfy the following equation:

This allows us to use a simple recurrent neural network for modeling. Also, to computeusing a recurrent neural network, we simplify it by using a surrogate term.
Applying the above substitutions into Eq. (4) gives:

The conditional probabilities in Eq. (6) capture the inherent causal structure and temporal coherence of the temporal spiking activity networks. This sVFE underpins the TAVRNN framework.

Here, we describe a model parameterization using a graph RNN for the sVFE Eq.6. Initially, the conditional latent prior and approximate posterior in Eq.6are assumed to follow Gaussian distributions:

with isotropic covariances, anddenoting the diagonal function.
To enable gradient descent optimization of the sVFE (Eq.6), the pairs of mean and standard deviation in Eq.7are modeled as:

In this configuration, the prior model, the measurement feature model, and the state feature modelare designed as fully connected neural networks. Meanwhile, the encoder modelis implemented as a GNN. The memory-embedding recurrent statesin Eq.8are derived as follows:

where the recurrent modelis implemented as a spatial-aware Gated Recurrent Unit (GRU). According to Eq.9,functions as the memory embeddings for the historical path.Subsequently, the likelihood of the adjacency matrix in Eq.2is modeled as a Bernoulli distribution:

whereis the reconstructed adjacency matrix, derived using a matrix product followed by sigmoid activation:

In summary, the end-to-end integration of the prior (Eq.8a), encoder (Eq.8b), recurrent module (Eq.9), and inner-product decoder (Eq.11) forms a probabilistic recurrent graph autoencoder. This model first constructs sequential stochastic hierarchical latent embedding spaces onand then utilizes these embeddings to perform stochastic estimation of the adjacency matrices. By optimizing the sVFE (Eq.6) with respect to the model parameters, these embedding spaces adapt to capture a wide array of stochastic spatiotemporal variations across dynamic networks in an entirely unsupervised manner. Further details of the method are provided in AppendixA.7andA.9.

To more accurately reflect spatiotemporal dependencies, we reparameterized the recurrent model (Eq.9) to include a spatially-aware GRU. This modification facilitates dynamic updates of the recurrent states over time.
The update gate, reset gate, and candidate activationare calculated as:

Finally, the output of the GRU will be computed as:

These equations describe the forward pass of our spatially-aware GRU, improving its capacity to process and incorporate spatial information through time, where. Althoughcould serve as the final value for, given the temporal nature of our graph data, we consider a global state for the entire graph at each time step. While the GRU adds memory to the states, in our GNN structure, each node’s state updates based on local information from its neighbors. For this reason, we add a hypothetical node to the graph which is connected to all other nodes. The state of this node is supposed to represent the global state of the graph. According to the dynamic nature of the graph’s state, we let the model compute the final value ofthrough an attention mechanism on,,,and(see Fig.2). Mathematical details of this temporal attention module are presented in AppendixA.8. Using the above equations,serves as memory embeddings that capture graph-structured temporal information from previous latent state sequences. This model replaces the conventional GRU’s FCNNs with single-layer GNNsthat incorporate a message passing scheme. This adaptation enables the GRU to efficiently leverage both the spatial topologies and temporal dependencies in dynamic graph data.

SECTION: 4.3Baselines

We used the following unsupervised node-level embedding methods as baselines since our datasets and study focus on unlabeled node sets (see AppendixA.10):
1)VGAE[31]: Unsupervised framework using a variational auto-encoder with a graph convolutional network encoder and an inner product decoder.
2)DynGEM[20]: Deep auto-encoder model to generate node embeddings at each time snapshot, initialized from the embedding at.
3)DynAE[32]: Autoencoder model using multiple fully connected layers for both encoder and decoder to capture highly non-linear interactions between nodes at each time step and across multiple time steps.
4)DynRNN[32]: RNN-based model using LSTM networks as both encoder and decoder to capture long-term dependencies in dynamic graphs.
5)DynAERNN[32]: Employs a fully connected encoder to acquire low-dimensional hidden representations, passed through an LSTM network and a fully connected decoder.
6)GraphERT[33]: Leverages graph embedding representation using transformers with a masked language model on sequences of graph random walks.

SECTION: 5Results

We first evaluate all methods on a classification task using the rat hippocampal dataset, where the ground truth labels are available and correspond to the rat’s position on the track. After demonstrating TAVRNN’s competitiveness with state-of-the-art temporal graph embedding methods, we proceed to theDishBraindataset for a clustering task. In this setting, characterized by higher dimensionality and intricate single-unit dynamics across varying game performance levels, TAVRNN proves its strength, significantly outperforming all baseline methods.

SECTION: 5.1Rat hippocampus dataset

Table1presents a comparison of the TAVRNN model and baseline methods in the classification task using the rat hippocampal dataset across multiple evaluation metrics. Among the methods, only GraphERT achieved a higher accuracy than TAVRNN, although TAVRNN closely approached its performance and surpassed GraphERT in terms of recall.

Next, we performed an ablation test, by using four additional variations of our proposed model to test if adding each structure helps the downstream task. The results in Table2outline that removing Temporal Attention, replacing the Spatial-aware GRU with a conventional GRU, or replacing the Variational Graph Autoencoder with a simpler Graph Autoencoder all lead to significant performance drops across all evaluation metrics for TAVRNN.

SECTION: 5.2Time complexity analysis

We also analyzed the time complexity of all baseline methods and compared them to TAVRNN. Table3provides the order of time complexity for one forward pass on all thecells for one time window in all methods. In this table,stands for the maximum dimensionality of the hidden layers in different algorithms. See AppendixA.10for more details on how the time complexities are computed and meaning of various symbols in the Table. As demonstrated in Table3, all the methods except GraphERT have similar orders of time complexities, but different constant coefficients.  Fig.3shows the log-log plot of these time complexities against the number of nodes using all the coefficients and hyper parameters as reported in the original paper  for each algorithm. It shows that TAVRNN and VGAE exhibit the lowest time complexity, making them the most computationally efficient methods. In contrast, GraphERT shows the highest complexity, leading to a significant increase in run time as the number of nodes in the input graph grows. This large time complexity is consistent with many constant coefficients we see for GraphERT in Table3.

SECTION: 5.3DishBrain dataset

Next, we move to test TAVRNN performance on theDishBraindataset. Fig.4a-b shows the connectivity networks for the top and bottom three time windows across all trials for a sample culture, ranked by hit/miss ratio during both Gameplay and Rest. The heatmaps display pairwise Pearson correlations between channels for each window. The nodes in these heatmaps are sorted by channel type on the HD-MEA, belonging to,,,, orregions. Across all recorded cultures, Gameplay sessions showed higher average weight, lower modularity, and lower clustering coefficients compared to Rest. Fig.4c compares these metrics for the best and worst time windows in both Gameplay and Rest, revealing significant differences between the two states but no significant difference betweenandduring Gameplay. Fig.4d shows the evolution of these metrics with increasing hit/miss ratio during Gameplay sessions across all recordings.

Fig.5a-b visualizes the embeddings for the same sample networks from Fig.4using all methods. Nodes are color-coded by their subregions on the HD-MEA. TAVRNN reveals that during high game performance, nodes from different subregions (e.g.,or motor subregions forandmovements) form distinct clusters. The clusters become increasingly distinct as game performance reaches its highest level (). Notably, thecluster overlaps with motor clusters even at peak performance, suggesting co-activation of a subgroup ofcluster with each motor region. This clustering was not detected in the functional connectivity networks of the spiking activity (see for example Fig.4) but does accord with previous electrophysiological analysis[6].
TAVRNN outperforms the other baselines in separating the clusters based on the corresponding channel’s subregion label. The superior performance of TAVRNN compared can be linked to its capability to incorporate the temporal history of network activity. Additionally, the attention layer in the TAVRNN framework enhances its effectiveness. This layer assesses the relevance of historical network activities by comparing their functional connectivity with the current snapshot, thereby significantly influencing the representation in the embedding space and leading to improved performance over the rest.
This demonstrates that successful adaptive learning requires synchronous activity between subregions, even as the modularity index of functional connectivity networks decreases during better performance. Our findings uncover the latent topology of the temporal networks revealing that clustering of subregions during successful behavior, as seen in the embedding space, highlights functional modules co-activated during optimal performance, which are not necessarily spatially proximate (see Fig.1c).
Additionally, Fig.6represents t-SNE visualization of the learned representations of the three best and three worst windows based on hit/miss ratios (and) during Gameplay and Rest, as modeled by TAVRNN for all aggregated trials of the same sample culture. These visualizations reveal an absence of distinguishable clusters during the Rest state or during low-performing periods of Gameplay. However, as we progress to time windows associated with higher performance levels in the game, distinct clustering patterns emerge.
Absence of such clustering during poor performance or Rest (as in Fig.6) implies a disruption in the coordinated activity of these modules suggesting that adaptive learning involves dynamic reorganization of neuronal circuits to optimize behavior.

Table4represents the comparison results during the best performing Gameplay session () across all cultures in terms of the Silhouette, Adjusted Rand Index (ARI), Homogeneity, and Completeness scores on the clustering task where channels are labeled based on their role (,, or). We found that TAVRNN outperforms all baseline methods on all metrics.
The Silhouette score, which assesses the degree of separation among clusters, indicated some overlap insessions. This suggests that a complete separation of clusters may not be optimal for the transmission of information between sensory and motor subregions, reflecting a functional co-activation required among channels within these clusters for goal-directed tasks.
The ARI evaluated the alignment between true and predicted labels where even TAVRNN showed deviations from perfect alignment, highlighting the challenges of predefined neuron classifications in theDishBrainplatform. This discrepancy stems from the absence of a definitive ground truth for defining motor subregions, complicating accurate neuron segregation. Notably, theDishBrainplatform was originally designed considering various motor subregion configurations forandpaddle movements, with the final predefined regions selected based on optimal performance in experimental cultures[6].
Our results indicate that neurons assigned specific roles based on their subregions did not always align with their expected activity patterns, emphasizing the complexity of predicting neuronal behavior in biological systems.Note that the GraphERT method leverages a representation of the entire graph through the CLS token[33], yielding high accuracy in tasks that rely on global network data, such as the classification in rat hippocampus dataset. However, importantly, while TAVRNN demonstrates comparable performance in that task, it significantly outperforms GraphERT in a task where the dynamics of individual nodes are crucial such as the clustering inDishBraindataset. Where single-unit activity is the focus of representation learning rather than population-level behavior, TAVRNN excels by efficiently capturing the temporal latent dynamics of individual nodes in the graph. Additionally, our method exhibits robust performance across datasets with significantly different sampling frequencies, ranging from 40 Hz to 20 kHz for the rat andDishBraindatasets.Overall, our framework provides a valuable tool to facilitate the optimization of neuronal clusters for specific tasks in simulated environments, enhancing the design and efficacy of future experiments.
Homogeneity and completeness metrics revealed that clusters contained neurons from multiple classes and did not group all neurons of a class together, even during optimal performance. This indicates a more distributed and nuanced representation of sensory and motor functions within the neuronal network, blurring the predefined boundaries between regions.
Our findings highlight the complex interplay of neuronal activity in clustered environments and emphasize the potential of our framework to enhance the understanding and design of future experiments in neuronal clustering and task-specific roles in both biological and simulated systems.

SECTION: 6Conclusions

By employing a sophisticated representation learning framework, our approach applies a nonlinear dimensionality reduction technique that preserves critical information from individual neurons over time as a groundbreaking method to explore adpative learning in biological neurons. This is different from previous dimensionality reduction methods that examined the temporal trajectory of the entire population as a whole[3]. Our methodology enable dissection of the intricate dynamics between single units that underpin successful and unsuccessful behavioral outcomes of neuronal populations. Notably, our TAVRNN framework successfully identified interpretable attributes that correlate with good and poor performance of live biological neurons in a simulated environment of pong such as in theDishBrainsystem. Our findings suggest that in such a system, adaptive learning is facilitated by the dynamic reorganization of neuronal circuits and co-activation of distinct neuronal clusters, optimizing behavioral responses. Moreover, assessing the understanding of the spatial layout of individual channels on the HD-MEA showed that these co-activations are not confined to spatially adjacent subpopulations. Instead, a more complex pattern of self-organization emerges among neuronal subregions that are spatially distant from each other. This indicates a complex pattern of self-organization among distanced neuronal subpopulations, driven endogenously rather than by exogenous influences. These insights open new avenues for targeting specific neuronal mechanisms in skill acquisition and could inform future interventions aimed at enhancing learning and memory, both in health and clinical settings. This finding not only advances our understanding of neuronal behavior in learning tasks but also challenges existing paradigms about the spatial requirements for neuronal co-activation and learning efficacy. A current limitation of our framework is its reliance on undirected networks of functional connectivity. Future iterations could benefit from incorporating directed networks, which would allow for the differentiation between inhibitory and excitatory relationships among channels by using signed correlation values. Additionally, exploring tasks such as link prediction using our framework also represents a promising direction.

Furthermore, individual neurons within a population undergo specialization through dynamic interactions and synaptic plasticity[34]. The emergence of specialized neurons often occurs through complex interactions influenced by various factors such as synaptic connectivity, neuronal excitability, and network dynamics[35]. Over time, certain neurons strengthen connections relevant to specific task-related information, while others diminish in importance[36]. This process of synaptic pruning and strengthening enables neurons to become finely tuned to particular roles within the behavioral task during development[37]. As the task is repeated, neuronal circuits refine their activity patterns, leading to the emergence of specialized neurons that efficiently contribute to task performance.Despite this intricate process by which individual neurons specialize in specific roles within a population, there is no predefined algorithm or pathway to precisely identify which individual neurons within a subpopulation will assume these roles in a live biological neuronal network. In this context, methodologies like the introduced TAVRNN framework can offer valuable assistance in future iterations of theDishBrainsystem. By leveraging the results from the unsupervised clustering task applied to the embeddings learned by TAVRNN, configurations of predefined subregions on the chip can be optimized. Thereby, this framework can help approximate an optimal setup for enhancing performance within different game environments or behavioral tasks, eliminating the need for exhaustive experimental testing of all conceivable configurations. Subsequently, the performance of the system utilizing the configuration suggested by the clustering results from the TAVRNN can be empirically evaluated against other configurations.

SECTION: References

SECTION: Appendix AAppendix / supplemental material

SECTION: A.1Cell Culture

Approximatelycells were plated on each Multielectrode Array. Neuronal cells were cultured either from the cortices of E15.5 mouse embryos or differentiated from human induced pluripotent stem cells via a dual SMAD inhibition (DSI) protocol or through a lentivirus-based NGN2 direct differentiation protocols as previously described[6]. Cells were cultured until plating. For primary mouse neurons, this occurred at day-in-vitro (DIV) 0, for DSI cultures this occurred at between DIV 30 - 33 depending on culture development, for NGN2 cultures this occurred at DIV 3.

SECTION: A.2MEA Setup and Plating

MaxOne Multielectrode Arrays (MEA; Maxwell Biosystems, AG, Switzerland) was used and is a high-resolution electrophysiology platform featuring 26,000 platinum electrodes arranged over an 8 mm2. The MaxOne system is based on complementary meta-oxide-semiconductor (CMOS) technology and allows recording from up to 1024 channels. MEAs were coated with either polyethylenimine (PEI) in borate buffer for primary culture cells or Poly-D-Lysine for cells from an iPSC background before being coated with either 10 µg/ml mouse laminin or 10 µg/ml human 521 Laminin (Stemcell Technologies Australia, Melbourne, Australia) respectively to facilitate cell adhesion. Approximatelycells were plated on MEA after preparation as per[6]. Cells were allowed approximately one hour to adhere to MEA surface before the well was flooded. The day after plating, cell culture media was changed for all culture types to BrainPhys™ Neuronal Medium (Stemcell Technologies Australia, Melbourne, Australia) supplemented with 1% penicillin-streptomycin. Cultures were maintained in a low O2 incubator kept at 5% CO2, 5% O2, 36°C and 80% relative humidity. Every two days, half the media from each well was removed and replaced with free media. Media changes always occurred after all recording sessions.

SECTION: A.3DishBrain platform and electrode configuration

The current DishBrain platform is configured as a low-latency, real-time MEA control system with on-line spike detection and recording software. The DishBrain platform provides on-line spike detection and recording configured as a low-latency, real-time MEA control. The DishBrain software runs at 20 kHz and allows recording at an incredibly fine timescale. This setup captured neuronal electrical activity and provided long-term, safe external electrical stimulation through biphasic pulses that elicited action potentials in neurons, as detailed in previous studies[38].
There is the option of recording spikes in binary files, and regardless of recording, they are counted throughout 10 milliseconds (200 samples), at which point the game environment is provided with how many spikes are detected in each electrode in each predefined motor region as described below. Based on which motor region the spikes occurred in, they are interpreted as motor activity, moving the ‘paddle’ up or down in the virtual space. As the ball moves around the play area at a fixed speed and bounces off the edge of the play area and the paddle, the pong game is also updated at every 10ms interval. Once the ball hits the edge of the play area behind the paddle, one rally of pong has come to an end. The game environment will instead determine which type of feedback to apply at the end of the rally: random, silent, or none. Feedback is also provided when the ball contacts the paddle under the standard stimulus condition. A ‘stimulation sequencer’ module tracks the location of the ball relative to the paddle during each rally and encodes it as stimulation to one of eight stimulation sites. Each time a sample is received from the MEA, the stimulation sequencer is updated 20,000 times a second, and after the previous lot of MEA commands has completed, it constructs a new sequence of MEA commands based on the information it has been configured to transmit based on both place codes and rate codes. The stimulations take the form of a short square bi-phasic pulse that is a positive voltage, then a negative voltage. This pulse sequence is read and applied to the electrode by a Digital to Analog Converter (or DAC) on the MEA. A real-time interactive version of the game visualiser is available athttps://spikestream.corticallabs.com/. Alternatively, cells could be recorded at ‘Rest’ in a Gameplay environment where activity was recorded to move the paddle but no stimulation was delivered, with corresponding outcomes still recorded. Using this spontaneous activity alone as a baseline, the Gameplay characteristics of a culture were determined. Low level code for interacting with Maxwell API was written in C to minimize processing latencies-so packet processing latency was typically50s. High-level code was written in Python, including configuration setups and general instructions for game settings. A 5 ms spike-to-stim latency was achieved, which was substantially due to MaxOne’s inflexible hardware buffering. Fig.S1illustrates a schematic view of Software components and data flow in the DishBrain closed loop system.

SECTION: A.4Additional Results

In this section, we present the learned representations of the three best
performing windows in terms of the culture’s hit/miss ratios during Gameplay for two additional cultures in Figs.S2andS3. The figures repeatedly demonstrate TAVRNN’s outperformance over the other baseline methods in identifying clusters of channels that belong to the same region on the HD-MEA.

SECTION: A.5Connectivity Inference Mechanisms

Methods for inferring connectivity are broadly categorized into two types:model-freeandmodel-basedapproaches. Model-free methods rely on descriptive statistics and do not presuppose any specific underlying data generation mechanism, making them versatile for initial analyses. In contrast, model-based methods involve hypothesizing a mathematical model to elucidate the underlying biological processes by estimating its parameters and structure. Typically, these methods analyze time-series data, such as spike trains from individual neurons. However, recent advances have enabled studies to integrate spike inference with connectivity analysis directly from time-series data[39]. In this work, we focus on utilizing the model-free methods.

Model-free methods do not presuppose any specific mechanisms underlying the observed data, offering a simpler alternative to model-based approaches. However, these methods do not facilitate the generation of activity data crucial for model validation or predictive analysis. Model-free techniques are primarily divided into two categories: those employing descriptive statistics such as Pearson correlation coefficient (PC) and cross-correlation (CC) and those utilizing information-theoretic measures such as Mutual information (MI), and Transfer entropy (TE)[39,40,41,42,43,44,45].

In light of the diversity of connectivity inference methods discussed previously, each method can generate distinct graph representations from identical datasets. To extract meaningful insights from these varied representations, it is essential to employ a comparison methodology. However, graph comparison is computationally challenging. Ideally, one would verify if two graphs are exactly identical, a problem known as graph isomorphism, which is NP-complete[46]. This complexity renders the task computationally prohibitive for large graphs.

To circumvent these difficulties, kernel methods offer a viable alternative. Kernels are functions designed to measure the similarity between pairs, enabling the transformation of objects into a high-dimensional space conducive to linear analysis methods. Graph kernels, specifically, facilitate the comparison of graphs by evaluating their structure, topology, and other attributes, thus proving instrumental in machine learning applications for graph data, such as clustering and classification[47,48,49].

Graph kernels vary in their approach to measuring similarity. Some rely on neighborhood aggregation, which consolidates information from adjacent nodes to form local feature vectors[50,51,52], while others utilize assignment and matching techniques to establish correspondences between nodes in different graphs[53]. Additionally, some kernels identify and compare subgraph patterns[54], and others analyze walks and paths to capture structural nuances[55].

Here we concentrate on neighborhood aggregation methods, particularly pertinent for analyzing connectivity graphs derived from neuronal recordings, typically involving fewer than 1000 nodes without definitive node labels. These methods are also foundational for the graph neural network models. We exemplify this approach with the 1-dimensionalWeisfeiler-Lehman(1-WL) algorithm[50], illustrating its application and effectiveness.

Weisfeiler-LehmanAlgorithmTheWeisfeiler-Lehman(WL) graph kernel is a sophisticated approach for computing graph similarities, which leverages an iterative relabeling scheme based on theWeisfeiler-Lehmanisomorphism test. This method extends the basic graph kernel framework by incorporating local neighborhood information into the graph representation, making it particularly effective for graph classification tasks.

Consider a graph, whereis the set of vertices,is the set of edges, andis a labeling function that maps each vertex to a label from a finite alphabet. Initially, each vertex is assigned a label based on its original label or degree.

Define. At each iteration, a new labelingis computed as follows:

wheredenotes the set of neighbors of vertexanddenotes a multiset, ensuring that the labels of neighboring vertices are considered without regard to their order. The function HASH maps the concatenated labels to a new, unique label. The algorithm continues iteratively, relabeling vertices until the labels converge or no new labels are produced (Fig.S4).

After each iteration, compute a feature vectoras the histogram of the labels across all vertices:

whereis the set of all possible labels at iteration.

The WL kernel between two graphsandis defined as the sum of base kernel evaluations on the corresponding histograms at each iteration:

whereis typically chosen to be the linear kernel, andis a predefined number of iterations, determining the depth of neighborhood aggregation.

In this study, we analyzed 437 recording sessions, comprising 262 Gameplay and 175 Rest sessions, to construct functional connectivity graphs. These graphs were derived using four distinct network inference algorithms: Zero-lag Pearson Correlations (PC), Cross-Correlation (CC), Mutual Information (MI), and Transfer Entropy (TE). For the PC analysis, connectivity matrices were thresholded at varying levels, retaining only the strongest connections as determined by their absolute correlation values. For both CC and TE, we explored delay values. Each method produced 437 distinct networks.

Subsequently, a Weisfeiler-Lehman (WL) graph kernel with depthwas utilized to compute the kernel matrix, which was then employed in a Support Vector Machine (SVM) classifier to distinguish between Gameplay and Rest sessions. Classification effectiveness was evaluated through a 5-fold cross-validation on theDishBraindataset, achieving the results summarized in TableS1. Notably, classification performance for CC and TE improved with increasing delay values, reflecting enhanced discriminative power of the graph kernels with longer embedding lengths. However, this increase in delay also introduced greater computational complexity, presenting challenges in scalability and traceability.

SECTION: A.6Marchenko-Pastur Distribution and Shuffling Procedure

In random matrix theory, the Marchenko-Pastur (MP) distribution describes the asymptotic behavior of the eigenvalues of large-dimensional sample covariance matrices. Consider a random matrix, whererepresents the number of variables (e.g., neurons or channels) andrepresents the number of observations (e.g., time points). The sample covariance matrix is defined as:

As bothandgrow large, while the ratioremains constant, the empirical distribution of the eigenvalues ofconverges to the Marchenko-Pastur distribution[28]:

for, whereis the variance of the entries of matrixand:

In the case where, which holds for our data (is large relative to), the MP distribution suggests that most of the eigenvalues will be close to zero. As a result, the sample covariance matrix is likely to be ill-conditioned, and hence unreliable for further analysis.

To account for potential spurious correlations due to ill-conditioning of the sample covariance matrix, we perform a shuffling control procedure:

Shuffle Time Points:The time points of each channel are independently shuffled while maintaining the channel identity. This process destroys any temporal correlation, ensuring that the correlation between channels is not influenced by the original time structure.

Multiple Iterations:The shuffling procedure is repeated multiple times (e.g., we chose 1000 iterations) to build a null distribution of correlations for each pair of channels.

Confidence Intervals:Based on the null distribution obtained from the shuffled data, we compute confidence intervals for each pair of channels. Correlation values from the original data that lie outside of theconfidence interval are considered statistically significant.

This approach provides a robust method for identifying significant correlations in the presence of potential ill-conditioning of the sample covariance matrix.

SECTION: A.7Unsupervised sequential VFE (sVFE) loss

In a Variational Graph Auto Encoder (VGAE), an encoder network is responsible for learning the latent embeddings, which capture the representation of nodes in a reduced-dimensional space. The probablity of an edge between nodesandin the reconstructed graph is determined by the inner product of their respective latent embeddings,and. This process is usually accompanied by a sigmoid activation function to constrain the output values between 0 and 1:

In this context,represents the sigmoid function,refers to theth row of the matrix, andcorresponds to theth element of the matrix, indicating the predicted probability of an edge between nodesandat time.

Considering thatindicates the probability of an edge, the likelihood of the observed adjacency matrixbased on the embeddings can be independently modeled for each edge using a Bernoulli distribution:

In this case,represents the actual entry in the adjacency matrix, signifying the presence, absence, or weight (for weighted graphs) of an edge between nodesand.

The log-likelihood of the adjacency matrix,, can be expressed as the negative binary cross entropy (BCE):

We approximate the first expectation term in the sequential VFE (sVFE) using Monte Carlo integration as follows:

Here,represents the particle index, andrefers to the number of particles, which may be set to 1 when the mini-batch size is sufficiently large[56].

Latent particlesare sampled fromas described by Eq. (7b), utilizing the reparameterization trick, whereis drawn fromandrepresents the Hadamard (element-wise) product. Recurrent state particlesare derived using Eq. (9), based onand the previous time-step’s state.

Additionally, an analytical solution for the Kullback-Leibler divergencein the sequential VFE Eq. (4) can be derived in closed form as:

This KLD loss is deterministic, thereby eliminating the need for Monte Carlo approximation. It quantifies the statistical distance between the conditional prior as specified in Eq. (7a) and the approximate posterior in Eq. (7b). Optimizing this measure strengthens the causality within the latent space, as the prior Eq. (8a) focuses on the influence of preceding graphs and embeddings.

By integrating Eq. (S4) and Eq. (S5) into Eq. (4), we formulate an unsupervised sVFE loss that forms the foundation of the proposed TAVRNN framework:

SECTION: A.8Temporal attention mechanism

The goal of this section is to present the mathematical details of the temporal attention mechanism for computingforand,,.
Let thedimensional row vectorpresent the global state of the graph at time step.111For,is equal to that row ofwhich corresponds to the hypothetical node that is connected to all other nodes. Also,is equal to the corresponding row of.Also letbe amatrix that its-th row is equal to.
We compute the query vectorand the key matrixas follows:

Here, thematricesand, and also thedimensional row vectorsandare learnable parameters of our model. Then, the attention vector, which is adimensional row vector, will be defined as:

Let us define the value matrices as follows:

and

where thematrixand thedimensional row vectorare the other learnable parameters of our model.

Finally, the state matrixwill be computed as follows:

SECTION: A.9TAVRNN model training hyperparameters

All the experiments were run on a 2.3 GHz Quad-Core Intel Core i5. PyTorch 1.8.1 was used to build neural network blocks.

We configured our TAVRNN model by employing graph-structured GRU-Attention with a single recurrent hidden layer consisting of 32 units. The window sizein the attention mechanism is set to the maximum possible for every time step, allowing the model to attend to all previous time steps, including the very first one. The functionsandin Eqs. (8b) and (9) are implemented using a 32-dimensional fully-connected layer. For the functionin Eq. (8a), we use two 32 and 8 dimensional fully-connected layers. To modelandwe employ a 2-layer GCN with 32 and 8 layers, respectively. Our model is initialized using Glorot initialization[57]. The learning rate for training is set to 0.01. Training is performed over 1000 epochs using the Adam SGD optimizer[58].

The implementation of our proposed model is available at the followingGithub Repository.

SECTION: A.10Time Complexity Analysis

In this section, we will compute the time complexity for each method. This analysis provides insights into the computational cost and efficiency of different methods for representation learning of temporal graph data. More specifically, we compute the time complexity of a forward pass on the entire set of the graph nodes in one snapshot for each method.

GraphERT is a Transformer-based model for temporal graphs. It uses multiple random walks with different transition parametersandto capture the neighborhood structure around each node at specific time steps. These random walks are fed into a Transformer, which learns node-to-node interactions and their temporal relevance using multi-head attention.

Random Walks Generation:

For each graph snapshot, the algorithm generatesrandom walks, where:

is the number of random walks starting from each node for each pair of values assigned toand.

is the number of nodes in the graph.

andare the number of different values for the hyperparametersand.

The time complexity for generating the random walks is:

whereis the length of each random walk.

Transformer Processing:

Each random walk is processed by the Transformer. The time complexity of the Transformer is dominated by the self-attention mechanism, which scales quadratically with the sequence length and linearly with the number of attention heads.

For each random walk, the time complexity is:

where:

is the random walk length.

is the maximum dimensionality of the representation vectors used in different transformer layers.

is the number of attention heads.

is the number of layers in the Transformer.

Total Time Complexity:

The total number of random walks is. Combining the time complexity for random walk generation and Transformer processing, the total time complexity for processing a single graph snapshot is:

We can assume that,,,andare constant values, because they can be fixed values, independent of the graph size () and the intended dimensionality of the final representations (). Therefore, we can simplify the total complexity as follows:

However, it is worth noting that the constant value of this running time is large enough to make practical issues in real experiments. That is why GraphERT shows the most time complexity in Figure3. Look at TableS2for more details about the used values for the hyperparameters of this method.

Hyperparameters for GraphERT, DynAE, DynRNN, DynAERNN, and DynGEM

To compute the time complexity of a Variational Graph Autoencoder (VGAE) withnodes,edges,Graph Convolutional Network (GCN) layers, and hidden dimensions, where the final latent representation dimension is, we need to analyze the time complexity at each layer of the GCN. This will account for both node-wise and edge-wise operations.

Step 1: GCN Layer Operations

A GCN layer applies a linear transformation followed by neighborhood aggregation. The complexity of a single GCN layer is typically determined by:

Node-wise operations: These involve multiplying the node features by a weight matrix. This has a time complexity of, whereis the input dimension of the layer andis the output dimension.

Edge-wise operations: These involve aggregating the features of neighboring nodes through a message-passing operation over edges. This has a time complexity of.

Step 2: Time Complexity of Each GCN Layer

For the-th GCN layer:

Let the input feature dimension beand the output feature dimension be.

Node-wise multiplication has complexity.

Edge-wise aggregation has complexity.

Thus, the total time complexity of the-th layer is:

Step 3: Summing Over All GCN Layers

We haveGCN layers with dimensions, whereis the input feature dimension andis the output dimension. Therefore, the total time complexity for all layers is:

Step 4: VGAE Encoder and Decoder

Encoder: The encoder, which maps node features to a latent representation space (mean and variance for the latent variables), has the same complexity as the GCN layers, so its complexity is.

Decoder: In VGAE, the decoder typically involves reconstructing the adjacency matrix from the latent space. The reconstruction (e.g., using a dot product between latent vectors) has a time complexity of, as it involves calculating pairwise similarities between all node pairs.

Step 5: Total Time Complexity of VGAE

Summing up the time complexity of the GCN-based encoder and the decoder, we get the overall time complexity:

This expands to:

Conclusion

Let us denoteby. We know that. So,and the time complexity of the VGAE is:

This reflects the complexities of both the encoder (GCN layers) and the decoder (adjacency matrix reconstruction). The most significant term depends on the number of nodes,  and the dimensions of the latent space. Hyperparameters of the VGAE model and the values assigned to them in the original paper are listed in TableS2.

DynGEM uses a Multi-Layer Perceptron (MLP) autoencoder to generate low-dimensional embeddings for dynamic graphs at each snapshot. At time step, the model is trained on the first snapshot of the graph using a randomly initialized deep autoencoder. For subsequent time steps, embeddings and network parameters are initialized from the previous time step.

Givennodes,hidden layers with sizes, and the latent representation dimension, the time complexity of processing the input graph for each snapshot is:

Conclusion

Let us denoteby. We know that. So,and the time complexity of the DynGEM is:

Hyperparameters of this method and the assigned values to them can be found in TableS4.

DynAE extends a static MLP autoencoder to handle temporal graphs. It useslook-back adjacency matrices from past snapshots and feeds them into a deep autoencoder to reconstruct the current graph based on previous graphs.

Given an input size of(whereis the number of nodes andis the number of leook-back snapshots), andlayers in the autoencoder, with the latent representation dimension, the time complexity for the encoder is:

Conclusion

Let us denoteby. We know that. So,. In addition,can be considered as a constant number, and the time complexity of the DynAE is:

Hyperparameters of this method and the assigned values to them can be found in TableS5.

DynRNN is similar to DynAE, but it uses Recurrent Neural Networks (RNNs), specifically Long Short-Term Memory (LSTM) networks, to capture temporal dependencies across snapshots. Each node’s neighborhood at each snapshot is passed into the LSTM.

The time complexity for LSTM stepon one node is:

Givennodes,LSTM layers with sizesandsnapshots,
the total time complexity for one snapshot is:

Conclusion

Let us denoteby. We know that. So,. Is addition,can be considered as a constant number, the time complexity of the DynRNN is:

Hyperparameters of this method and the assigned values to them can be found in TableS6.

DynAERNN combines the autoencoder from DynAE with the LSTM-based RNN from DynRNN. The encoder compresses the neighborhood vectors ofsnapshots into a low-dimensional space, which the LSTM processes across time to capture temporal dependencies.

The total time complexity for DynAERNN is the sum of the autoencoder and LSTM complexities:

Conclusion

Let us denoteby. We know that. So,. In addition,can be considered as a constant number time complexity of the DynRNN is:

Hyperparameters of this method and the assigned values to them can be found in TableS7.

The time complexity of the TAVRNN framework is driven by several components, including GNN layers, GRU operations, and an attention mechanism. Below, we break down the total complexity into the time complexity of each component.

1. GNN and GRU Layers:

At each time step, the model processes the graph using a combination of GNN layers and a GRU-based RNN. The time complexity for these operations can be broken down as follows:

Low-dimensional Embedding: first of all, each-dimensional neighborhood vector is mapped to a-dimensional embedding using a one layer feed forward network. The time complexity of this part will be:

Graph Convolution (GNN): Similar to the VGAE mentioned above , the time complexity of the GNN layer is:

GRU Operation: Since the inner functions of our GPU cell is implemented by GCN layers, the dominant term in the time complexity of the GPU cell in each time step is equal to:

2. Temporal Attention Mechanism:

The attention mechanism aggregates past hidden states over a window of size. The attention of the model into the lastsnapshots is computed in:

whereis the attention window size andis the hidden dimension. The time complexity of computing the weighted average vectors for all thenode according to these computed attentions is:

3. Reconstruction:
Similar to VGAE, the reconstruction process in TAVRNN is through computing the inner product of the final representation of each pair of the nodes, and its time complexity is:

4. Overall Time Complexity for Each Time Step:

The overall time complexity at each time step is a combination of the initial projection to a low-dimensional space using a feedforward layer, GNN and GRU computations, attention mechanism, and reconstruction:

Conclusion

Let us denoteby. We know that. So,. We can infer that the time complexity of  TAVRNN is:

The summary of the time complexities for different methods is shown in TableS8.