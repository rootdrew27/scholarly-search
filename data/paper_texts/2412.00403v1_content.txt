SECTION: Fine-Tuning Pre-trained Large Time Series Models for Prediction of Wind Turbine SCADA Data

The remarkable achievements of large models in the fields of natural language processing (NLP) and computer vision (CV) have sparked interest in their application to time series forecasting within industrial contexts. This paper explores the application of a pre-trained large time series model, Timer, which was initially trained on a wide range of time series data from multiple domains, in the prediction of Supervisory Control and Data Acquisition (SCADA) data collected from wind turbines. The model was fine-tuned on SCADA datasets sourced from two wind farms, which exhibited differing characteristics, and its accuracy was subsequently evaluated. Additionally, the impact of data volume was studied to evaluate the few-shot ability of the Timer. Finally, an application study on one-turbine fine-tuning for whole-plant prediction was implemented where both few-shot and cross-turbine generalization capacity is required. The results reveal that the pre-trained large model does not consistently outperform other baseline models in terms of prediction accuracy whenever the data is abundant or not, but demonstrates superior performance in the application study. This result underscores the distinctive advantages of the pre-trained large time series model in facilitating swift deployment.

KeywordsLarge Time Series ModelTime Series PredictionWind TurbineFew-shot

SECTION: 1Introduction

The time series prediction of data collected by Supervisory Control and Data Acquisition (SCADA) system of wind turbines is a pivotal challenge as it serves as a foundational method of artificial intelligence (AI) in various aspects of wind turbine operations and maintenance (O&M), including data preprocessing[1,2], fault diagnosis[3,4,5], and wind power forecasting[6,7]. Within the sphere of data preprocessing, time series prediction is employed to fill in missing values by leveraging historical monitoring data. For fault diagnosis, the distribution of discrepancies between actual monitored values and those generated by time series predictions is examined to identify anomalies. As for the domain of wind power forecasting, the outcomes of time series predictions are directly applied. Therefore, as the cornerstone of these applications, the enhancement of time series prediction accuracy is crucial for improving their effectiveness and reliability, which in turn contributes to the efficiency and profitability of renewable energy generation.

The existing time series prediction methods are primarily based on deep learning, including recurrent neural network (RNN)[8], graph neural networks (GNN)[9], and the transformer[10]. Deep learning methods have made advancements in precision compared to classical forecast methods, but they have not yet demonstrated the advantages brought by the increase in parameter scale of large models, which has been conducted in the fields of NLP and CV[11,12,13,14]. The powerful problem-solving capabilities and the “one for many” generalization performance demonstrated by large models are impressive, and these abilities can play a significant role in the O&M of wind turbines. The wind turbine O&M is constantly challenged by the need for enhanced precision. Additionally, it necessitates a versatile approach capable of generalizing across various turbine and facilities to accommodate the diversity in data patterns, thereby streamlining the effort involved in developing and sustaining models.

There are two methods for applying large models to time series prediction: adjusting the large language models to fit the data patterns of time series, and training foundation models from scratch on time series data. The approaches to adapt large language models to time series include two types: text-visible LLM adaption and embedding-visible LLM adaption[15]. The former[16]converts numerical time series data into strings and integrates them into prompts along with other contextual information. The prompts are then processed by LLM which generates outputs based on the inference capabilities. The latter[17]embeds numerical time series data into vector sequences and fine-tunes the embedding layer on downstream time series datasets to align the vector representations of time series with those of text. These two methods require fewer computational resources compared to training a large model from scratch and are more easily integrated with text for multimodal analysis. However, the lack of evidence that time series data exhibit patterns similar to language raises doubts about the appropriateness of using large language models for time series forecasting, and existing literature has highlighted the limitations of these approaches, necessitating the development of large time series models specifically trained on time series data[18].

Training a foundation model for time series from scratch usually involves preprocessing time series data and designing model architecture. In the data preprocessing stage, data quality management is necessary, and due to the limited amount of time series data in a single domain, alignment of the data formats across multiple domains is required. After data preparation, large-scale pre-training is typically conducted based on the transformer architecture. As the training data encompasses time series from diverse domains, the model acquires a broad-spectrum capability for analyzing time series data across a variety of domains.

To ascertain the applicability of the large time series foundation model within specialized domains and to delineate its comparative strengths and weaknesses against conventional models, this study employs a pre-trained large time series model named Timer[19]for the prediction of wind turbine SCADA data. Timer encompasses 67 million parameters and has been initialized with pre-training time series datasets spanning various sectors. The experiments organized and preprocessed the SCADA data from two real-world wind farms, which were subsequently used for fine-tuning and evaluation of the Timer. The variety in data volume and plant type (onshore or offshore) enables a comprehensive evaluation of the large time series model’s performance across varying conditions. For the wind farm with adequate data, the fraction of data employed in the fine-tuning was modified to further scrutinize the influence of data volume on the model’s predictive accuracy. This work also designed an application scenario of one-turbine fine-tuning for whole-plant prediction, which necessitates both the few-shot and generalization capabilities of the model. Experimental results across different wind farms and data volumes indicate that large time series model does not exhibit a dominant accuracy advantage in data-sufficient conditions. In scenarios with limited data, pre-trained large time series models demonstrate few-shot learning advantages, although this capability does not significantly surpass that of LSTM in short-term predictions. In the context of fine-tuning on a single turbine, the large model not only exhibits few-shot learning ability but also generalization across turbines, yielding comprehensive accuracy advantages over other methods in this scenario. This demonstrates the strengths of pre-trained large time series models for rapid deployment in wind farms.

The contributions of this paper include: (1) This paper applies the large time series foundation model to the time series prediction of real-world SCADA data; (2) A comparative study was conducted to evaluate the strengths and weaknesses of large time series model against conventional methods across varying data volumes and prediction horizons; (3) The few-shot learning and generalization benefits of the large time series model was illustrated within the context of single-turbine fine-tuning for whole-plant prediction, offering valuable insight for future application of large time series models in wind turbine SCADA data.

The remaining sections are outlined as follows. Section2presents the methodology, including the data preprocessing and the architecture of the model; Section3describes the implementation of experiments based on three real-world SCADA dataset, along with the presentation of results. Finally, the conclusions are given in Section4.

SECTION: 2Methodology

SECTION: 2.1Timer

The Timer was proposed in reference[19], which is a 67-million-parameter transformer model that has undergone large-scale pre-training on time series datasets across multiple fields. It is pre-trained by performing autoregressive next-token predictions on the time series, demonstrating promising performance in various downstream tasks across multiple domains.

The Timer model was pre-trained on the Unified Time Series Dataset (UTSD), a high-quality collection of time series data spanning various domains. The dataset integrates 29 distinct datasets, classified into ten different fields according to their origin, such as energy, environment, health, and others. This dataset incorporates time series with diverse sampling rates, extending from yearly to minute-by-minute intervals. UTSD implements a series of strategies to guarantee the quality of the data. Initially, missing values in the data are addressed through linear interpolation; subsequently, comprehensive statistical analyses are performed to evaluate stationarity and forecastability. These metrics facilitate the identification of four superior subsets within UTSD, each escalating in complexity and variety of patterns in relation to their size. The most extensive subset, UTSD-12g, encompasses one billion data points. The vast scale of UTSD ensures comprehensive model training and the acquisition of generalized time series patterns across a multitude of domains.

The Timer employs the single-series sequence (S3) format to standardize heterogeneous data from disparate sources, accommodating the formatting discrepancies that arise due to variations in the number of variables, sampling frequencies, and other attributes. S3 is an iteration of the channel-independent (CI) strategy. CI splits multivariate time series into univariate series, with each variable analyzed independently, thereby disregarding the inter-variable correlations. In contrast, conventional time series modeling often utilizes a channel-dependent (CD) strategy, which entails simultaneous modeling of multiple variables, taking into account their inter-dependencies. The difference between these two strategies is delineated in Figure1. Although the CI approach neglects the important correlations between variables, it offers a convenient means of harmonizing such diverse data. Additionally, researches[20,21]have shown that the CI, compared to CD strategy, offers better adaptability, lower training data requirements, and reduced risk of overfitting, leading to higher precision in time series modeling.

S3 extends the CI approach by not requiring temporal alignment within the same batch of time series samples, nor do the samples need to originate from the same dataset. Additionally, S3 implements instance normalization, ensuring that the training time points for each univariate sequence adhere to a normal distribution. This process helps to neutralize disparities in amplitude across various datasets.

The Timer adopts a strategy of segmenting univariate time series into patches for the purpose of tokenization. Conventionally, each time point within a series is treated as an individual token. However, due to the quadratic relationship between the computational complexity of attention mechanisms and sequence length, tokenizing by individual points results in a very high computational complexity for long sequences. Furthermore, the information of a single time point often pales in comparison to the importance of local trend characteristics. As a result, the practice of dividing time series into patches of a defined size as tokens has emerged as a prevalent technique. The Timer utilizes non-overlapping windows for segmentation and the tokenization formula is presented as follows:

whereis the original time series, andis the token sequence.

The Timer leverages a decoder-only transformer architecture for time series modeling. The distinction between encoder and decoder modules has been a fundamental aspect of transformer design since its inception, with the encoder facilitating global bidirectional attention for the extraction of features from time series data, and the decoder utilizing an attention mask to enforce unidirectional attention, thereby precluding tokens from attending to subsequent positions in the sequence. Inspired by generative pre-training (GPT), the decoder-only transformer configuration has increasingly become the norm, as researches[22,23]suggest that models based on this architecture demonstrate enhanced generalization capabilities. In alignment with this trend, the Timer model adopts the decoder-only transformer block for its time series modeling. The model architecture of the Timer is depicted in Figure2, and the equation of the model is presented as follows:

whererepresents weights,stands for the optional time stamp embedding, andis the latent representation of the embedding and transformer blocks.

Similar to GPT, the Timer model also utilizes autoregression as its pre-training task, a self-supervised learning method that equips the model with the capability to predict next token in a time series. This approach facilitates the model’s ability to learn from extensive, unlabeled time series datasets. The objective function for its pre-training task is presented as follows:

SECTION: 2.2Fine-tune on SCADA dataset

Prior to fine-tuning the pre-trained large time series model, it is essential to preprocess the SCADA data obtained from real-world wind farms to guarantee data quality. To exclude the influence of wind curtailment, sensor noise, transient errors, and equipment failures, this work implements a data cleaning strategy designed to eliminate outliers by leveraging key variables within the wind turbine SCADA dataset.

Initially, an examination of the distribution of each monitoring parameter within the SCADA data was conducted, removing outliers likely resulting from sensor damage or data transmission issues. Subsequently, with consideration to the operational principles of wind turbines, additional data cleansing was performed by referencing the turbine’s working states across different wind speed ranges. Below the cut-in wind speed, the turbine is disconnected from the grid, and the power output is nil. In the range between the cut-in wind speed and the rated wind speed, which is the maximum power point tracking (MPPT) segment, the turbine maintains a blade pitch angle of zero degrees, thus achieving the highest wind energy utilization coefficient, where the relationship between power and wind speed is approximately cubic. From the rated wind speed to the cut-off wind speed, the turbine incrementally increases the blade pitch angle in response to rising wind speeds and ensure a constant rated power output. Consequently, leveraging these principles, outliers primarily due to power limiting were identified and removed through the interrelation of wind speed, power, and blade pitch angle: within the MPPT segment, an upper limit for the blade pitch angle was established, with values exceeding this limit being flagged as outliers; in the range between the rated and cut-off wind speed, a lower limit for power was set, and data points falling below this threshold were excluded. The principle of this cleaning step is shown in Figure3. Subsequently, density-based spatial clustering of applications with noise (DBSCAN) and local outlier factor (LOF) were applied for the final refinement of the SCADA data, with the objective of excluding measurement errors attributable to sensor malfunctions.

After data cleaning, the distribution of normal data points on the time axis becomes discontinuous. In response to this situation, this paper replaces individual existing outliers with linear interpolation and, according to the required sequence length of the time series, applies a sliding window to continuous normal time points to create time series samples, ensuring that the patterns of the time series are not disrupted.

The fine-tuning of the pre-trained Timer model on SCADA datasets for downstream tasks encompasses several key steps. Initially, the processed time series samples are transformed into the S3 format. Subsequently, given the simplicity of the autoregressive pre-training task for time series prediction, the finetuning also involves the prediction of the next token, utilizing the loss function detailed in Equation (3). Throughout the fine-tuning process, the Timer backbone parameters remain unfrozen, and no additional regression head is appended to the Timer model. Instead, a small learning rate is applied uniformly across the Timer model, with the Adam optimizer employed for optimization. Following fine-tuning, in a manner consistent with models that typically utilize autoregression, inference is carried out by iteratively forecasting the next token. The number of iterations is determined by the required prediction horizon, and the requisite prediction length is subsequently extracted.

SECTION: 3Experiment

SECTION: 3.1Dataset and Preprocessing

In the experiment, real-world SCADA datasets obtained from two wind farms located differently in China are utilized. Plant 1, an onshore plant equipped with 64 turbines each rated at 1.5 MW, provided data spanning three years. The initial two years of data were allocated for constructing the training sets, while the final year was divided equally between validation and testing, each encompassing six months of data. Plant 2, an offshore wind farm with 121 turbines each rated at 4.0 MW, also provided a one-year dataset, where the training set comprised six months, and the validation and test sets each comprised three months. The SCADA data from all two wind farms were sampled at 10-minute intervals. The raw data underwent the cleaning process to eliminate outliers, and the efficacy of this method across the three wind farms is illustrated in Figure4.

Four key variables were selected from the SCADA attributes to construct multivariate time series: wind speed, power, generator speed, and ambient temperature. A sliding window was employed to generate the time series dataset from the continuous normal data points, with a window size of 768. For the training and validation sets, the window slid in increments of 100, whereas for the test set, the increment was 1. The numbers of samples used for training, validation, and testing are detailed in Table1. Plant 1 offers a relatively large sample size, facilitating the assessment of the performance of large time series models in data-rich environments. Conversely, plant 2 present smaller sample sizes, which are suitable for evaluating whether large time series models demonstrate distinct properties compared to traditional models in few-shot scenarios. The differences among these two wind farms in terms of wind farm type, turbine model, and data volume allow the experiment to cover a broad range of wind farm application scenarios.

SECTION: 3.2Experiment Settings

This study encompasses three experiments. In the first experiment, the Timer was fine-tuned on the datasets obtained from the two wind farms and its time series prediction accuracy was assessed on the corresponding test sets. To accommodate various time series prediction scenarios, multiple prediction lengths were employed for the testing phase. Furthermore, the experiment includes a comparison between the Timer without pre-training or fine-tuning, and three additional time series prediction models: long short-term memory networks (LSTM), two transformer models with varying numbers of parameter. This comparative analysis across different scenarios serves to validate the applicability and benefits of the large time series model for predictions. The second experiment, carried out on plant 1, changed the quantity of samples used for training to delve deeper into the performance of the Timer under varying data volumes, particularly in few-shot learning scenarios, and to ascertain its comparative advantages over traditional models. The third experiment constitutes an application study, with the objective of utilizing the few-shot learning capabilities of large models and assessing their generalization ability. Data from a single wind turbine at Plant 1 was utilized for model fine-tuning or training, following which the model was applied to all turbines within the wind farm. The experiment is supposed to demonstrate the potential for rapid deployment inherent in large models, thereby circumventing the requirement for extensive data collection procedures. The Mean Squared Error (MSE) was used to evaluate the accuracy of models.

The declaration of the hyperparameters for several models involved in the experiments is as follows. The Timer architecture comprised 8 transformer decoder blocks, each with a model dimension of 1024, a feed-forward network (FFN) comprising 2048 hidden units, an 8-head multi-head self-attention mechanism, and a dropout rate of 0.1. Including both the input embedding layer and the output regression head, the Timer model encompassed a total of 67.40 M parameters. In the process of tokenization, a sequence of 768 time points was segmented into 8 patches, each consisting of 96 time points. The initial 7 tokens were employed as the historical context for predicting the 8th token, thereby deriving the temporal trend over a span of 96 time points. Actually, in the experimental setup, all parameters remained fixed, with the exception of the dropout rate and the number of tokens for the input, to ensure consistency with the Timer architecture as pre-trained in the literature[19]. In the experimental setup, the Timer was examined across three distinct training paradigms: training from scratch, utilizing pre-trained weights without further fine-tuning, and fine-tuning the pre-trained model. These configurations are designated as Timer-scratch, Timer-pretrained, and Timer-finetuned, respectively. Of particular interest is the performance of the Timer-finetuned model, whereas the other two configurations are primarily used to elucidate the effects of pre-training and fine-tuning on model efficacy through comparative analysis.

The Transformer model adopted a channel-dependent and decoder-only architecture, utilizing a patch length of 96. For the model with a larger scale of parameters, the configuration of the transformer blocks aligned with that of the Timer, yielding a total parameter count that closely mirrors the Timer, at approximately 68.00 million. For the Transformer with fewer parameters, the architecture was streamlined by reducing the number of transformer blocks to 4, each with a model dimension of 256 and a FFN comprising 512 hidden units. This model is referred to as transformer-mini, and it contains a total of 2.31 million parameters. The LSTM model, on the other hand, was structured as a unidirectional network, featuring 128 hidden units, a depth of three layers, and a dropout rate of 0.1, processing the time series data sequentially step by step without patching.

All models were trained utilizing the Adam optimizer. For models trained from scratch, an initial learning rate ofwith a cosine decay scheduler was employed across a total of 2000 epochs. Fine-tuning was performed with a reduced learning rate offor 100 epochs. The number of epochs was chosen to ensure convergence across varying data volumes, and early stopping was implemented for both training and fine-tuning phases, based on the accuracy achieved on the validation set.

SECTION: 3.3Results

The MSE of different methods across various prediction length on the initial wind farm dataset is detailed in Table2, with the optimal outcomes for each prediction length highlighted in bold. The results reveal that the LSTM model attains the highest precision for short prediction length, whereas the Timer-finetuned outperforms others as the prediction length extends. Moreover, when the prediction length equals 96, the Transformer-mini model demonstrates the greatest accuracy. The variation in accuracy with prediction length is depicted in Figure 5.

The results imply that the three models are suitable for distinct predictive scenarios, and that the pre-trained and fine-tuned large models do not universally outperform across all prediction tasks. The LSTM model, with its step-wise modeling approach, provides superior accuracy for single-step predictions but is less effective for long-term forecasting due to error compounding. In contrast, models that segment data into patches for tokenization exhibit a comparative advantage in long-term predictions. Additionally, an analysis of the three Timer models illustrates the influence of pre-training and fine-tuning on model performance. As anticipated, the Timer that has undergone both pre-training and fine-tuning achieves the highest level of accuracy. The model that is pre-trained but not fine-tuned demonstrates a degree of accuracy in the downstream task of time series prediction of SCADA data. The results across varying prediction lengths indicate that pre-training notably enhances short-term prediction accuracy, while fine-tuning is more instrumental in improving long-term prediction performance. The comparison between the Transformer and Transformer-mini models indicates that an increase in parameters contributes to improved accuracy for short-term predictions, whereas it results in inferior performance for long-term predictions.

On Plant 2, the MSE for different methods is presented in Table3and Figure6. The results indicate that, on this dataset with insufficient data, the Timer that has undergone pre-training and fine-tuning demonstrates a more pronounced comparative advantage over other methods featuring a large parameter scale. The enlarged accuracy gap between the pre-trained and scratch models indicates that pre-training confers enhanced few-shot capabilities to the model, allowing for better prediction performance with less data. However, this advantage is more effective in the short term. For the transformer and transformer-mini models, which have a large scale of parameters, the impact of data quantity on accuracy is significant, resulting in a loss of predictive capability for both short-term and long-term prediction. Comparison between the two models reveals that an increase in the scale of parameters may lead to a decrease in accuracy, potentially due to overfitting when faced with limited data. This finding also underscores the importance of pre-training for the application of large models. For LSTM, which has fewer parameters than the transformer-based models, the influence of data volume on predictive accuracy is relatively diminished. Short-term accuracy is comparable to that of the Timer-finetuned but continues to demonstrate suboptimal performance in long-term forecasting.

To examine the influence of data volume on model accuracy, the proportion of data allocated for training was adjusted to train or fine-tune models. The test results are depicted in Figure7, where the accuracy of the pre-trained Timer in the zero-shot context is delineated by a purple horizontal line as a baseline. Pre-trained large time series models necessitate less data for short prediction horizons as compared to other transformer-based architectures, where accuracy remains largely stable with diminishing data volumes. Nevertheless, the benefit of pre-training wanes as the prediction horizon extends. Notably, the Timer-scratch, which has the same scale of parameters as the Transformer but lacks pre-training, does not exhibit a significant decline in accuracy. This is possibly due to its channel-independent strategy that provides stronger generalization capabilities. The LSTM still exhibits a reduced dependency on data volume, with advanced accuracy lying in short-term forecasting. However, it tend to exhibit unstable performance when tasked with long-term prediction.

SECTION: 3.4One-turbine Fine-tuning for Whole-Plant Prediction

Data from a single wind turbine at Plant 1 were employed to fine-tune the pre-trained large model and to train benchmarks, which were then evaluated using data from all turbines in the wind farm. This application not only investigates the influence of data volume but also evaluates the models’ generalization capabilities across various individual turbines. To mitigate the effects of randomness, the test was conducted three times, each time utilizing data from a distinct turbine. The average MSE across these three trials is detailed in Table4. The fine-tuned pre-trained large model demonstrated superior performance across all prediction lengths. While in the previous experiment, some models may outperform the Timer-finetuned for specific prediction lengths when the data is limited, the pre-trained large model’s generalization advantage led to its overall dominance over other models in this experiment, carrying substantial relevance for practical applications. In real-world scenarios, by collecting data from just one turbine to train a large model, its strengths in few-shot and generalization can be exploited to apply the model across other turbines throughout the plant, thereby substantially reducing the effort required for data collection and expediting the deployment of the model.

SECTION: 4Conclusion

This paper explores the application of large foundation models for time series in the prediction of wind turbine SCADA data. Two wind farms, encompassing both onshore and offshore facilities, and turbines with capacities of 1.5 MW and 4 MW, were employed to assess the predictive efficacy of the large model, Timer, and to benchmark it against alternative methodologies. The experimental results across various wind farms and data volumes suggest that the large time series model does not consistently yield a superior accuracy in data-abundant cases. In scenarios of limited data, it manifest few-shot learning advantage, although this does not notably outperform LSTM in short-term forecasting. When fine-tuned on data from an individual turbine, the large model not only demonstrates its few-shot learning capacity but also its ability to generalize across different turbines, resulting in a comprehensive accuracy enhancement compared to other models within this specific context. These findings underscore the utility of pre-trained large time series models for expedited deployment in wind farms.

In the experiments, the influences of various components within the pre-trained large model on its overall performance were examined. It is evident that the impact of pre-training on model accuracy is predominantly observed in short-term predictions. Additionally, a comparative analysis of Transformers with varying parameter counts suggests that an increase in parameters predominantly enhances short-term prediction accuracy. These observations may stem from the inherent volatility and randomness of wind resources, which introduce higher unpredictability into wind turbine monitoring data compared to other domains encountered during pre-training, with only short-term temporal patterns being effectively captured. However, in short-term prediction scenarios, such as one-step-ahead forecasting, the LSTM, which processes sequences step-by-step and has a small scale of parameters, surpasses large models that treat patches as tokens, regardless of whether data is abundant or limited, which diminishes the prominence of the advantages of pre-trained large time series model. Consequently, for time series prediction of SCADA data, further refinement of current large time series models is necessary, particularly in terms of model architecture and pre-training data selection, to broaden the applicability and enhance the performance.

SECTION: References