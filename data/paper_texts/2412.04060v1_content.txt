SECTION: Expanding Deep Learning-based Sensing Systems with Multi-Source Knowledge Transfer

Expanding the existing sensing systems to provide high-quality deep learning models for more domains, such as new users or environments, is challenged by the limited labeled data and the data and device heterogeneities. While knowledge distillation methods could overcome label scarcity and device heterogeneity, they assume the teachers are fully reliable and overlook the data heterogeneity, which prevents the direct adoption of existing models. To address this problem, this paper proposes an efficient knowledge transfer framework, HaKT, to expand sensing systems. It first selects multiple high-quality models from the system at a low cost and then fuses their knowledge by assigning sample-wise weights to their predictions. Later, the fused knowledge is selectively injected into the customized models for new domains based on the knowledge quality. Extensive experiments on different tasks, modalities, and settings show that HaKT outperforms stat-of-the-art baselines by at most 16.5% accuracy and saves up to 39% communication traffic.

SECTION: 1.Introduction

The integration of deep learning with sensing systems has gained significant attention in recent years due to its effectiveness in processing diverse sensory data across a wide range of applications(Xu et al.,2023; Ouyang et al.,2022,2023; Ji et al.,2023). As deep learning techniques continue to mature and computing resources advance, there is an increasing demand for the large-scale deployment of these models in sensing systems(Doe,2023). However, despite this growing need, the challenge of expanding these deep learning-based systems remains largely unaddressed. In this context, expansion refers to the ability to develop effective models that can seamlessly accommodate new users, devices, environments, or datasets.

We identify the problem of expansion in sensory applications as particularly challenging. First, labeling sensor data is both time-consuming and costly, resulting in limited labeled data for new targets, which undermines the effectiveness of direct supervised training methods(Xu et al.,2021). Second, data collected from various sources, such as different users, devices, or environments, often exhibit varying distributions. In more extreme cases, data from different sources may represent different categories, leading to performance degradation or rendering existing models inapplicable when transferred to new targets(Xu et al.,2023). Third, devices across domains may differ in computational power and memory resources, imposing constraints on model architecture and making current models less suitable for new devices(Wen et al.,2023). Moreover, developing models for new targets must also account for overall training and communication costs. Given these challenges, this work addresses a critical question:How can we effectively and efficiently expand existing sensing systems?

Figure1illustrates a realistic scenario for the sensing systems expansion. Existing domains, such as different users, devices, datasets, or organizations, maintain heterogeneous models for processing local data, referred to as thesource domains. Due to privacy concerns, the data from one source domain cannot be accessed by others. The new targets, i.e.,target domains, have limited labeled data but many unlabeled data due to the large labeling overhead. The data within these domains are non-independent and identically distributed (non-IID). The objective is to provide high-quality customized models for the target domains at a minimal cost.

Existing approaches struggle to work in the practical scenario. Directly training models on target domain data is less effective due to label scarcity(Xu et al.,2021; Song et al.,2022). Federated learning frameworks train models using distributed data from multiple clients(Ouyang et al.,2021; Zheng et al.,2023; Cai et al.,2023). However, many of them provide one unified model for all clients and may incur frequent model transmissions and heavy retraining overhead once new targets join. Transfer learning aims to apply existing models to new domains with data or task heterogeneity(Pan and Yang,2009; Tan et al.,2018; Tong et al.,2021; He et al.,2023). To handle data heterogeneity, domain adaptation techniques are widely used to enhance model robustness by aligning feature distributions across domains(Zhu et al.,2020; Wilson et al.,2021; He et al.,2023). Nevertheless, transfer learning works overlook device heterogeneity, making it difficult to adopt existing models across diverse hardware environments. Knowledge distillation addresses device-side constraints by transferring knowledge from teacher models to student models(Gou et al.,2021; You et al.,2017; Hinton et al.,2015; Borup et al.,2023). Yet existing methods assume that the teacher models are fully reliable and do not account for the impact of data heterogeneity. The non-IID data across domains makes source models less accurate on target domains. Therefore, there is a significant gap in addressing the system expansion problem.

To address this gap, we notice that while source models are trained on non-IID data, they may still retain valuable ”knowledge”, such as the ability to interpret sensor characteristics and distinguish between different classes. Our key idea is to leverage the knowledge from source models to assist target domains, which can help mitigate label scarcity. However, due to data heterogeneity, the knowledge from certain source models may be ineffective in target domains or result in conflicting predictions for the same sample—an issue we refer to asknowledge conflictsin this paper. Therefore, the central challenge is: How can we transfer knowledge from source models to train customized target models? This involves addressing three specific subchallenges.

First, it is difficult to identify models with high-quality knowledge, as their performance in the source domains does not necessarily reflect their effectiveness in target domains. Besides, evaluating these models on target domain data is problematic due to label scarcity. Second, effectively utilizing conflicting knowledge from different sources to train target models is challenging. Resolving knowledge conflicts requires prioritizing certain models, but the reliability of knowledge from each model can vary dynamically across different samples and domains. Third, minimizing system overhead during the expansion process is essential. Evaluating every source model on target domains can incur significant communication and execution costs, especially when there are many large models. Moreover, training target models with multiple source models can be expensive and time-consuming, necessitating optimization to reduce overhead.

To address these challenges, a practicalHeterogeneity-awareKnowledgeTransfer framework (HaKT) is proposed: 1) To identify high-quality source models, HaKT first utilizes simple statistical features, such as mean values, to filter out source domains with low similarity to the target domain. The models from the remaining domains are then further selected based on their performance on both labeled and unlabeled data in the target domain. 2) To address knowledge conflicts, an attention-based mixer is trained to assign sample-wise weights to each model’s predictions by measuring the similarity between the representations extracted by the selected models and the target model. A knowledge dictionary is constructed to selectively store the fused predictions, considering their fluctuating quality during training. This stored knowledge is later injected into the target model along with the ground-truth labels, with the transfer speed dynamically adjusted according to the quality of the knowledge. 3) To minimize system overhead, the model selection process is encapsulated in a communication protocol that only transmits models with high potential (judged based on statistical features) for further evaluation in the target domains. A low-cost joint training scheme is implemented to simultaneously update the mixer, the target model, and the partially frozen source models. To reduce encoding overhead, the mixer fuses predictions for all the data to update the knowledge dictionary only when its performance improves.

Extensive experiments have been conducted across various modalities and tasks, including Human Activity Recognition, Gesture Recognition, and Image Classification. Compared with five state-of-the-art baselines, HaKT achieves up to a 16.5% improvement in accuracy and reduces communication traffic by up to 39% during sensing systems expansion. The key contributions are summarized as follows:

We address a practical sensing system expansion problem characterized by label scarcity and both data and device heterogeneities.

We propose a general knowledge transfer framework, HaKT, which efficiently selects, fuses, and injects knowledge to deliver high-quality customized models for targets while maintaining practical system overhead.

We comprehensively evaluate the proposed framework across various tasks, modalities, architectures, and settings, demonstrating superior performance compared with state-of-the-art baselines at a reduced cost.

The paper is organized as follows: Section 2 presents the motivation. Section 3 provides the framework overview. Section 4 describes the technical details. Sections 5 show the experiment results. Section 6 presents discussions. Section 7 describes the related works. Section 8 concludes the paper.

SECTION: 2.Motivation Study

SECTION: 2.1.Problem Formulation

There aresource domainswithin an sensing system, each possessing heterogeneous models for data analytics, represented by, whereandare the encoder and classifier for the-th domain, respectively. The objective is to expand the sensing system totarget domains,, by providing high-quality customized models for each target. However, onlyof the data in the target domains are labeled, while the remainder remains unlabeled due to the high cost of labeling. Besides, the raw data in the source domains are inaccessible due to privacy constraints.

SECTION: 2.2.Potential of Knowledge Transfer

To demonstrate the potential of knowledge transfer for providing high-quality models, we compare two naive approaches: direct training and model transfer. Direct training only train with the limited labeled data (10%) in the target domain, whereas the model transfer applies the source models to the target domain. Both methods are evaluated on the HARBox dataset (see Section5.1). In Figure2(a), the performance of the source modelsbefore transfer(after transfer) is measured on the source (target) domain test sets.

Figure2(a)demonstrates that direct training yields only around 50% accuracy under conditions of label scarcity. When models from the source domains are applied to the target domain data, they suffer varying degrees of performance degradation due to data heterogeneity. However, the model from domain 5 maintains an accuracy of over 60%, which might be due to a more similar data distribution. These results suggest that transferring high-quality models with appropriate selection strategies to new targets could outperform direct training. However, device heterogeneity and the customized requirements of target domains may restrict the direct adoption of these models. Additionally, when source and target domains exhibit substantial differences in data distribution or contain different categories, even the best-performing model may still fall short of the desired accuracy.

SECTION: 2.3.Limitations of Existing Methods

We further investigate the limitations of existing knowledge transfer methods on the HARBox dataset, including one domain adaptation method (LEAD(Qu et al.,2024)), one model merging method (MEHLSoup(Li et al.,2024)), and one knowledge distillation method (DistillWeighted(Borup et al.,2023)). See Section5.1for detailed descriptions. Additionally, we introduce a variant of DistillWeighted, namedRandom, where source models are randomly selected during the knowledge transfer process. The target models are configured as TPN-M (see Section5.1), and we report the average accuracy across ten target domains.

In Figure2(b), both LEAD and MEHLSoup demonstrate suboptimal performance, as they are restricted to leveraging knowledge only from source models that match the target model architecture —a limitation that also applies to other domain adaptation and model merging methods. In contrast, knowledge distillation methods like DistillWeighted are not bound by source model architecture, leading to better performance. Moreover, while domain adaptation typically relies on a single source model, utilizing multiple source models, as demonstrated by DistillWeighted, results in better target models. This improvement arises because the knowledge from multiple teacher models is more comprehensive and can compensate for each other(You et al.,2017). However, existing multi-source distillation methods cannot effectively handle the knowledge conflicts among different source models, which negatively impact the quality of the transferred knowledge.

Knowledge conflicts arise when heterogeneous source models produce different predictions for the same input. Figure2(c)illustrates the per-sample predictions of two models selected by DistillWeighted, which differ significantly. DistillWeighted simply assign fixed weights to each model, which fails to resolve these conflicts. When some selected models are inaccurate on the target due to data heterogeneity, the accuracy of the fused predictions can be even lower than that of the best single model.

SECTION: 3.Framework Overview

We further analyze the challenges in expanding sensing systems and introduce the proposed framework, HaKT.

SECTION: 3.1.Challenges in Scaling Sensing Systems

To efficiently expand sensing systems to new target domains, three key challenges must be addressed:

First, it is difficult to identify high-quality source models within the sensing system. The performances of a model in its source domain does not necessarily reflect its performance after the transfer due to the varying discrepancies between different source and target domain pairs. Estimating performance degradation based on discrepancy measurements, such as Maximum Mean Discrepancy(Shlens,2014; Chang et al.,2020), is impractical because these metrics require access to both source and target domain data, which violates data privacy constraints. Additionally, evaluating model performance solely on the limited labeled data in the target domains may not accurately reflect the model’s in-the-wild performance, as those data can hardly capture the diversity of the target data [C1].

Second, transferring knowledge from multiple source models to customized target models is challenging. Due to data heterogeneity, the knowledge in source models may not be directly applicable to the target domain data. Additionally, knowledge conflicts occur when source models make conflicting predictions for the same input, leading to contradictory update directions and less effective model training. Resolving these knowledge conflicts is particularly difficult because the quality and relevance of the knowledge from each model can vary dynamically across different samples. For example, a model’s prediction may be accurate for some subsets of target data but unreliable for others. This context-dependent variability makes it challenging to determine which model’s knowledge should be prioritized [C2].

Third, minimizing system overhead is crucial during expansion. Evaluating source models on the target domains would incur significant communication and execution costs, especially given the large number of source and target domains in sensing systems. However, if all models are not tested on the target domains, some high-quality models might be discarded, leading to suboptimal performance for new targets. Furthermore, leveraging the knowledge from multiple models to train the target model can also introduce large training overhead, which needs to be minimized particularly for resource constraint devices [C3].

SECTION: 3.2.System Architecture

To facilitate efficient sensing system expansion, HaKT is proposed to address the limitations of existing methods and overcome the three aforementioned challenges. The overview of HaKT is presented in Figure3. HaKT first determines a suitable model skeleton either directly provided by the target or from a model library with device profiling. The model library includes open-source models from the Internet and the architectures from the source domains. Then the Efficient Model Selection Protocol is evoked to select high-quality source models at a low cost. Later, the Sample-wise Knowledge Fusion is performed to aggregate the conflicting knowledge. Subsequently, the target model is trained with the Adaptive Knowledge Injection based on a low-cost training scheme. In HaKT, three core technical components are designed:

Efficient Model Selection Protocolinvolves a two-stage process to identify high-quality models at a low cost. To avoid full model transmission and execution, a coarse-grained selection first filters out less effective models based on lightweight features [C1, C3]. The remaining model candidates are then transmitted to the targets for a fine-grained selection, which evaluates them using both labeled and unlabeled data [C1].

Sample-wise Knowledge Fusionis proposed to resolve the knowledge conflicts. An attention-based mixer is trained to assign sample-specific weights to the predictions of the selected models based on the representation proximity extracted by the selected source and target models [C2]. Additionally, the selected models are partially frozen and fine-tuned to enhance the quality of the fused knowledge [C2, C3].

Adaptive Knowledge Injectionfacilitates the injection of fused knowledge to the target models. It utilizes a Knowledge Dictionary to selectively store the fused knowledge and an adaptive learner to dynamically adjust the importance of the knowledge based on its quality during training [C2]. To minimize training overhead, the system only fuses predictions for all the data to update the Knowledge Dictionary after the performance of the mixer shows improvement [C3].

HaKT is a highly flexible and decentralized framework for sensing system expansion. Without constraints in training methods, architectures, or data quality, any domains could be included as source domains to contribute knowledge for new targets. Moreover, the constructed target models can be further included as source models for other new targets. Besides, the model customization process for the new targets in HaKT is cheap in terms of communication and training overhead. Section4further introduces the details of HaKT on providing a customized model for one target, the processes of which are scalable and repeatable for any number of targets.

SECTION: 4.Design of HaKT

SECTION: 4.1.Efficient Model Selection Protocol

The process of the Efficient Model Selection Protocol is detailed in Figure4. In the Feature-based Coarse Selection stage (Steps FbCS.1-3), domains with potentially high-performing models are identified by comparing lightweight features between the source and target domains. Only source domains with high feature similarity transmit their models to the target, reducing communication traffic and model execution costs. During the Centroids-Accuracy Joint Selection stage (Steps CAJS.1-3), the transmitted models extract centroids and estimate their accuracy on the target domain data, which are leveraged to select the final models.

Lightweight features, including the mean value, standard deviation, skewness, and kurtosis, are extracted from both the source domains and target domain data. These features provide a coarse-grained description of domain characteristics without relying on any learning models. The target domain transmits its extracted features to the source domains, where each source domaincomputes a feature similarity score:whereis the total number of features. The similarity functionis set to cosine similarity. The target domain then selects the topof source domains with the highest similarity scores. Only the selected domains that receive a model inquiry from the target domain transmit their models back. This approach significantly reduces communication traffic, as only a small percentage of models are transmitted and high-level features are much smaller in size compared with those models.

After the models are received in the target domain, they are further selected based on their accuracy and the similarity of their class centroids. The accuracyof the-th source model is computed on the target domain labeled data, which, however, can be unreliable due to the limited amount of labeled data. To address this, we further use class centroids, which represent the class-wise feature distributions captured by the models. These centroids are computed by averaging the encoder outputs for samples within each class:

whererepresents the features extracted by the encoderof the-th domain from the-th data sample. The classifier output,, is processed using the functionto obtain a pseudo label. However, due to data heterogeneity, the pseudo labels produced byandon the target domain may be inaccurate. To enhance the quality of the centroids, entropy, a measure of the prediction confidence, is used to filter out features with low certainty. The entropyof the logits outputis calculated, and theof features with the lowest entropy (i.e., the highest confidence) are selected for centroid extraction.

The centroids of the source and target domains are compared to estimate the data distribution similarity:

whereis the number of overlapping classes between the source and target domains. A higher value ofindicates a greater similarity in data distribution between the-th source and target domains, suggesting that the source model is likely to experience a smaller performance drop when applied to the target data. Compared to selection methods(Li et al.,2019; Borup et al.,2023)that rely solely on labeled data, using centroids extracted from both labeled and unlabeled data provides a more accurate reflection of domain similarity and model effectiveness. The centroid similarity scoreis then multiplied by the model accuracyto rank the source domains and determine the final set ofselected models.

SECTION: 4.2.Sample-wise Knowledge Fusion

To resolve knowledge conflicts, an attention-based mixer is trained to assign sample-wise weights to the selected models based on their relative importance. Simultaneously, a cost-effective adaptation is applied to the source models to enhance their knowledge quality.

The attention-based mixer aggregates conflicting predictions from the selected models by leveraging the sample-wise feature adjacency between the source and target models. The featureextracted by the target encoder is projected through a linear layerto obtain the query vector. Similarly, the features, extracted by the selected source models, are projected through the respective linear layersto obtain the key vectors:

Different from the traditional attention mechanism(Vaswani,2017), which uses a single linear layer to compute the keys, the mixer utilizes multiple linear layersto accommodate the heterogeneous source model architectures. Since the models from different source domains extract features with varying dimensions, the input size of eachmust be tailored accordingly. The output size ofis standardized to a common dimension for subsequent computations. The similarities between the query and the keys are then calculated and normalized using SoftMax to obtain the attention scorefor the-th model on the data sample:

The attention scoremeasures the feature similarity between the target and the selected models, which is used to aggregate the predictions from the selected classifiers:

If the features extracted by the target model and the-th model are highly similar, a higher weightis assigned to the prediction of the-th model. This is because the-th classifier is likely to be more accurate on data from a distribution that closely resembles the data it is trained with. However, training the attention-based mixer is challenging, as it depends on input from the target model, which itself requires training. To address this, a low-cost joint training scheme is proposed to train the mixer and the target model simultaneously, which is detailed in Section4.3.

To further improve the accuracy of the fused predictions, a cost-effective adaptation is applied to the selected models, enhancing the prediction accuracy of each. Since adapting allselected source models would be computationally expensive, only their classifiers are trained jointly with the mixer, while their encoders remain frozen. This approach reduces the computational burden, as classifiers are typically lightweight(He et al.,2016). Early-stage experiments indicate that adapting the classifiers alone is sufficient to provide high-quality predictions for the attention-based mixer. Additionally, freezing the encoders accelerates the knowledge aggregation process. By precomputing features for all target domain data using the frozen encoders and storing them in memory, they are ready to be fetched when the mixer requires the prediction results for a sample. This process eliminates the need to repeatedly execute the forward pass of the selected encoders, thereby reducing the overall computation time.

SECTION: 4.3.Adaptive Knowledge Injection

The fused knowledge is further distilled into the target model:

whererepresents the cross-entropy loss on the labeled data, anddenotes the distillation loss based on the pseudo labels. A knowledge dictionaryand an adaptive learner are further designed to enhance the training efficacy.

Directly learning from the fused predictioncan hinder the convergence of the target model. This is because the aggregation results from the mixer change dynamically during its training (e.g., the pseudo-label of a sample may shift from class A to class C), potentially leading to conflicting gradient update directions. Additionally, the quality of the fused predictions may fluctuate from epoch to epoch. To address this issue, a knowledge dictionary is introduced to provide more stable learning objectives. After each model update, the fused predictions from the attention-based mixer are stored in the knowledge dictionary only if the accuracy of the mixer improves. These predictions are stored in a soft-label format rather than as one-hot vectors, allowing the target model to capture the confidence levels of the mixer in its fused predictions. In subsequent epochs, the target model learns from these soft pseudo labels stored in the knowledge dictionary, rather than directly from the potentially unstable predictions generated by the mixer.

Given the varying quality of the fused predictions in the knowledge dictionary, an adaptive learner is employed to adjust the weightof the distillation loss:, whererepresents the accuracy of the attention-based mixer on the training data. Theandare predetermined hyperparameters. Thecontrols the scaling factor of the weight, whileserves as a threshold to prevent the target model from learning from fused predictions of low quality. The weightincreases when the fused prediction accuracy is high, allowing the model to learn more effectively from reliable predictions.

The training of the attention-based mixer, the unfrozen source classifiers, and the target domain model is complex, as they depend on inputs from each other. To enable a cost-effective training process, a joint training scheme is developed as shown in Algorithm1.

The labeled and unlabeled data,, are encoded by the frozen source encodersto high-level features, which are later used to train both the attention-based mixer and the target model. In each epoch, the target encoderprocesses the labeled and unlabeled data, generating feature representationsand. To manage the computational overhead of encoding a large volume of unlabeled dataand assigning pseudo labels, only a subset ofis sampled in each epoch, with the sample size kept proportional to the size of the labeled data. This strategy ensures that the entire set of unlabeled data is progressively utilized over multiple iterations, thereby reducing training time and memory usage of each epoch without compromising model performance. The knowledge dictionary is updated only when the mixer’s quality improves, minimizing the cost of generating pseudo-labels for all unlabeled data.

The cross-entropy loss is computed usingand labelsand minimized by one optimizer to train the mixer and the unfrozen classifiers (illustrated in gray in Figure5). Equation (7) is minimized by a separate optimizer to train the target model (illustrated in green in Figure5). After the model training, onlyandare stored for the inference.

SECTION: 5.Evaluations

SECTION: 5.1.Experiment Setting

HaKT is evaluated on four datasets that span various modalities, tasks, and scales. Table1provides a summary of these datasets, with further details as follows:

HARBox(Ouyang et al.,2021).This dataset consists of 9-axis Inertial Measurement Unit (IMU) data collected via crowdsourcing from 120 users. It includes data for five activities, such as walking and hopping.

ImageNet-R(Hendrycks et al.,2021).This dataset contains over 30k images from 200 classes in 16 different styles. Each style can be considered a small dataset. We filtered out styles with limited data or unclear labels, resulting in 8 styles for experiments.

NinaPro(Pizzolato et al.,2017).This dataset contains the electromyogram (EMG) data collected from 10 subjects. Two commercial EMG sensors, the Myo Armbands, are deployed around the elbows of the subjects for 6-class gesture recognition.

Alzheimer’s Disease (AD)(Ouyang et al.,2023).This dataset consists of Alzheimer’s Disease-related activity data collected from 16 home environments using multiple sensing modalities. It includes 11 activity classes, such as writing and sleeping.

While HaKT is evaluated on these three diverse applications, it has the potential to extend to other sensing systems, such as traffic management or smart agriculture(Jiang et al.,2023; Zhu et al.,2018), which we plan to explore in future work.

Table1summarizes the model libraries, which include six different models for each dataset. For IMU data, the TPN-(S, M, L)(Saeed et al.,2019)and CPC-(S, M, L)(Haresamudram et al.,2021)models are used, with feature channels of 12, 16, 32 for TPN and 8, 12, 16 for CPC, respectively. For image processing, the model library consists of GoogleNet(Szegedy et al.,2015), MobileNet-v3 (S, L)(Howard et al.,2019), and ResNet-(18, 34, 50)(He et al.,2016). For EMG data, the ConvNet-(S, M, L)(Côté-Allard et al.,2019)models and a RNN-(S, M, L) are utilized, with feature channels of 4, 8, 12 for ConvNet and 32, 48, 56 for RNN, respectively. To handle the multi-modal data in AD, we adapt the model in(Ouyang et al.,2023)by varying the number of layers and feature dimensions, creating 5-layer ADNet-(S, M, L) and 3-layer TinyADNet-(S, M, L) models with 64, 128, 256 for ADNet and 32, 64, 96 feature channels for TinyADNet.

The five most relevant baselines are selected and slightly adapted for comparison:

DistillWeighted(Borup et al.,2023).DistillWeighted uses existing vision models to build models for new tasks. Based on the PARC metric(Bolya et al.,2021), it assigns fixed weights to combine the predictions of all source models for knowledge distillation. As executing all source models is too expensive, we pre-selectmodels using the PARC metric and then apply DistillWeighted.

DistillNearest(Borup et al.,2023).DistillNearest selects a single model from the most similar source domain based on the PARC metric. The target model then learns from the pseudo labels generated by the selected model and the labeled data.

AccDistill(Li et al.,2019).Source domain models with top-k accuracy are selected and ensembled in(Li et al.,2019). To support model customization, we modify it by transferring the knowledge from the ensembled model to the target models.

LEAD(Qu et al.,2024).LEAD is a domain adaptation method that adapts the source model to builds instance-level decision boundary for target data using decomposed source features.

MEHLSoup(Li et al.,2024).MEHLSoup merges multiple source domain models with a learned mixing coefficient, which is optimized by a block coordinate gradient descent algorithm on the target domain data.

Other knowledge distillation, domain adaptation, or model merging methods are not included, as they have already been outperformed by the considered baselines(Borup et al.,2023; Qu et al.,2024; Li et al.,2024). Since LEAD and MEHLSoup, as well as other adaptation and merging methods, are unable to handle model heterogeneity, they are not directly comparable to HaKT. To make both methods executable, we select source domains with architectures that match the target models as candidates. Federated learning methods are not included for comparison due to the difference in the considered scenario (See Section2.1).

The system is deployed on a server equipped with a 12th Gen Intel(R) Core i9-12900KF processor and an edge device, Nvidia Jetson Xavier. To simulate different source domains, the source domain data and models are stored in separate folders on the server due to the limited number of available devices. The target domain data is deployed on the edge device. The model training overhead, including time and memory usage, is measured on the edge devices, which are closely correlated with energy consumption, particularly on edge devices. The communication overhead is monitored by tracking the network traffic between the server and the edge device. The real-life deployment on other devices, such as smartphones or personal computers, is further discussed in Section6.

For different datasets, the learning rates of the target model and the mixer are searched among. The training epochs of both are set to 200 and 100. The scaling ratioand the biasin the adaptive learner are determined using a grid search within the rangesand, with step sizes of 0.5 and 0.1, respectively. Theis set to three.

SECTION: 5.2.Result Comparisons in One-Time Sensing Systems Expansion

We first compare the results of HaKT against the baselines in a one-time expansion setting, where one domain is randomly selected as the target domain, and the remaining domains serve as source domains. The source domain architectures are randomly selected from TPN-(S, M, L), ResNet-(18, 34, 50), ConvNet-(S, M, L), and ADNet-(S, M, L). The source domain models are trained using supervised learning on the labeled data of each domain. For the target domains, 60% of the data is randomly selected as the training set, 20% as the validation set, and the remaining 20% as the test set. Onlyof the training set data is labeled, while the rest remains unlabeled. For ImageNet-R, each of the eight styles is tested separately. For the other three datasets, ten different splits are randomly generated, and the average accuracy and communication overhead are reported.

The results on different target architectures in the model library are presented in Figure6. Notably, LEAD and MEHLSoup can only leverage source domains that share the same architecture as the target domains, making them inapplicable when the required architecture (e.g., CPC-S for HARBox) is not available among the source models. HaKT consistently achieves comparable or superior accuracy across four datasets for most architectures. Specifically, HaKT surpasses the best baseline by 7.0%, 16.5%, 15.9%, 6.4%, 5.0%, and 4.0% for CPC-(S, M, L) and TPN-(S, M, L), respectively. On ImageNet-R, when the target models are MobileNet-(S, L), HaKT achieves gains of 4.1% and 3.4% over the best baselines, respectively. Although HaKT performs slightly worse than MEHLSoup on NinaPro, it significantly outperforms MEHLSoup on the other datasets, likely due to the lower data heterogeneity in NinaPro, which aligns better with MEHLSoup’s approach. Unlike domain adaptation and model merging methods that are limited to source models matching the target architecture, HaKT can effectively utilize knowledge from source models with diverse architectures, leading to improved performance. These results demonstrate HaKT’s versatility in delivering high-quality customized models across diverse tasks and modalities.

The portion of labeled data is varied to evaluate the robustness of HaKT. As shown in Figure7, HaKT outperforms or achieves comparable performance to the baselines in 13 out of 16 cases. Specifically, on the HARBox dataset, whenis 0.10, 0.15, and 0.20, HaKT achieves accuracy improvements of 5.04%, 3.77%, and 4.56%, respectively. This is achieved by leveraging both labeled and unlabeled data to select high-quality models and generate accurate pseudo-labels for unlabeled data through sample-wise knowledge fusion. In few cases, the best baseline slightly outperforms HaKT (e.g., whenon HARBox). This may be due to the use of a fixed thresholdin the adaptive learners, which may not yield an optimal weightacross different values of. To address this, we plan to explore dynamic thresholding to further enhance HaKT’s robustness. Besides, we observe that the performance of the baselines is generally lower than reported in their original papers. This discrepancy is likely due to the more challenging experiment settings, which involve limited labels and large heterogeneities that HaKT is specifically designed to address.

During the one-time expansion, HaKT reduces the average communication traffic by 39%, 36%, 8.3%, and 37.5% compared with baselines that use all source domain models on the HARBox, ImageNet-R, NinaPro, and AD datasets, respectively. Additionally, the source model execution cost in HaKT is reduced by approximately 40% when, demonstrating the efficiency of HaKT in the expansion process. Besides, when the number of selected modelsvaries from one to three on the HARBox dataset, the performance achieved by HaKT increases from 75.43% to 80.57%, which is 4.9% and 5.0% higher than the best baselines, respectively. This improvement highlights the effectiveness of HaKT in aggregating knowledge from multiple models.

SECTION: 5.3.Result Comparison on Multi-Round Sensing Systems Expansion

We further present the effectiveness of HaKT in scaling sensing systems in a multi-round expansion setting.

The domains in each dataset are randomly divided into five groups, denoted as. Detailed information about the groups is provided in Table4. In round, the domains inserve as the source domains, while the domains inare the target domains, with their model skeleton randomly selected from the model libraries. Once the models inare ready for use, they are incorporated as source domains in the subsequent round, sharing their knowledge with new targets for further expansion. For instance, during round 2 expansion on the HARBox dataset, the source domains include 60 users fromand, whose knowledge is used to build models for 20 users in. After round 2 expansion, the system scales from 60 to 80 users, and the models inare subsequently leveraged to construct models foralong withand. The parameteris set to 10%. All other settings are kept consistent with Section5.2.

Table2presents the performance in different rounds of expansion. The average accuracy achieved by HaKT is 3.9%, 1.6%, 0.2%, and 5.8% higher compared with the best baselines on the four datasets. Due to the space limit, we present the detailed results of the four rounds on the HARBox dataset in Table3, and similar results have been observed for other datasets. In Table3, HaKT outperforms the best baselines by 4.2%, 3.2%, 3.1%, and 4.3% in accuracy. In round, HaKT provides better customized models for groupsince it selects better source models, fuses knowledge in finer granularity, and injects knowledge dynamically according to their quality. In contrast, DistillWeighted assigns fixed weights to models, which may not fully capture the varying quality of each source on different samples. Moreover, as models trained in earlier rounds can be used later, models trained with HaKT consistently transfer higher-quality knowledge to the target models in subsequent rounds, leading to better performance on the new targets.

In Table2and Table3, as the system scales, the increase in the number of source domains results in larger traffic. HaKT effectively reduces this communication burden across all datasets. For instance, on the HARBox dataset, HaKT reduces the communication traffic by 1.5 GB compared with DistillWeighted. Note that the communication traffic of LEAP and MEHLSoup is not directly comparable to HaKT, as these methods are constrained to using a limited subset of source domains with architectures that align with the target domains. This limitation stems from their inability to handle model heterogeneity, which also contributes to their inferior performance. Overall, the results demonstrate HaKT’s superior effectiveness and efficiency in scaling sensing systems.

SECTION: 5.4.Ablation Study

Table5shows that the Feature-based Coarse Selection (FbCS) and Centroids-Accuracy Joint Selection can enhance performance by up to 6.7% and 4.4% in accuracy, respectively. The reason is that the statistical features and high-level representations based on labeled and unlabeled data could accurately reflect the domain similarity and the source model effectiveness. Besides, we observe that a larger improvement from the Coarse Selection typically leads to a smaller incremental gain from the Fine-grained Selection. This may occur because the lightweight features of specific modalities are sufficient for selecting high-quality models. However, the combination of both selection methods demonstrates stronger generalizability across different tasks and modalities. The Sample-wise Knowledge Fusion achieves an 11.5% accuracy improvement on HARBox, which is attributed to the sample-wise weights learned by the attention-based mixer could more effectively combine predictions from the source models. Additionally, the Adaptive Knowledge Injection improves accuracy by at least 2.1%, highlighting the benefit of selectively storing fused predictions and adjusting the weight of the distillation loss based on their quality. The performance gains of HaKT over theDirect Trainingapproach demonstrate the advantages of leveraging source domain models for training target models.

Optimizing the Model Selection Overhead.The impact of the FbCS on communication overhead is illustrated in Figure8(a) by varying its selection ratio,. Figure8(a) shows that asdecreases from 1.0 (without FbCS) to 0.03 (without Centroids-Accuracy Joint Selection), the communication traffic consistently decreases because fewer models are selected for transmission. The model execution cost also decreases as fewer source models are chosen for encoding data in the target domain. Additionally, Figure8(a) shows that the accuracy achieved by the target model increases and then slightly decreases asdecreases. This pattern occurs because, whenis large, the FbCS filters out less useful models. However, whenbecomes too small, the coarse selection inadvertently discard some high-quality models.

The accuracy of the pseudo labels.

Optimizing the Training Overhead.Figure8(b) presents the training overhead on the ImageNet-R dataset. The high memory usage is due to the large size of vision models. The Cost-effective Adaptation, which partially tune the selected models during training, lead to a 2.0reduction in memory usage and a 2.3reduction in training time due to fewer parameters being optimized. Similarly, incorporating Low-cost Joint Training reduces the per-epoch training time from 64.1s to 37.8s. Overall, HaKT achieves significant reductions in both training time (4.6) and memory usage (2.7), indicating a more energy-efficient training process.

Several alternative model selection methods are compared with the selection approach of HaKT in Table6. The knowledge transfer process in HaKT is applied to all selection methods. Accuracy and the PARC criteria achieve better performance compared with random selection. However, both methods rely on the labeled data, making them less effective when presented with label scarcity. In contrast, the Efficient Model Selection Protocol in HaKT leverages both labeled and unlabeled data for selection and avoids full model transmission, resulting in a 1.1% accuracy improvement while using only 61.3% traffic of the communication expense.

The Sample-wise Knowledge Fusion method is compared with other knowledge fusion methods in Table7.Nearestrepresents no fusion, where one single model is selected and used.Weightedindicates the use of the fusion method from DistillWeighted.Equalrefers to assigning equal weights to all selected models. The accuracy of the pseudo labels generated by HaKT is 11.6% higher than the best alternative method. Consequently, by learning from the higher-quality fused knowledge, the target models achieve a 16.5% improvement in accuracy.

SECTION: 6.Discussions

Applicability to Resource-Constrained Devices.The diversity of device types in various sensing systems presents challenges for customized model training. To minimize system overhead during expansion, HaKT optimizes communication traffic through an efficient model selection protocol and reduces training memory and time with a low-cost joint training scheme, making the expansion process more feasible for edge servers. However, the complete model training process may still exceed the capabilities of battery-powered IoT devices and wearables. In such cases, offloading model training to nearby trusted edge servers or leveraging edge-cloud collaboration can serve as effective solutions(Samikwa et al.,2023; Wang et al.,2024).

Privacy Concerns during System Expansion.Most domain adaptation methods require simultaneous access to both source and target domain data, which limits their applicability in privacy-sensitive scenarios(He et al.,2023; Qu et al.,2024). In contrast, HaKT better preserves data privacy by exchanging only high-level features and models between domains. While sharing features may still carry some risk of sensitive information leakage, it is generally necessary to identify relevant domains(Bolya et al.,2021). In future work, we aim to enhance privacy further by selectively sharing non-sensitive features through methods that identify and exclude sensitive content(Qu et al.,2024).

SECTION: 7.Related Works

Transfer Learning.Transfer learning explores methods to apply existing models to new targets, overcoming data or task heterogeneities(Pan and Yang,2009; Tan et al.,2018). To address data heterogeneity, domain adaptation techniques have been widely studied to align the feature distributions between source and target domain(Zhu et al.,2020; Wilson et al.,2021; He et al.,2023). However, most methods require access to both source and target domain data during training, which is not feasible in the scenario considered. Additionally, some multi-source transfer learning approaches focus on selecting source models with better generalizability(Tong et al.,2021; Agostinelli et al.,2022; Lee et al.,2019). For example,(Agostinelli et al.,2022)proposes constructing empirical predictors for model selection, which estimate the performance models could achieve after transfer. However, these methods often overlook device heterogeneity, which might prevent the direct adoption of source models in target domains.

Knowledge Distillation.In knowledge distillation, an efficient student model is trained using the knowledge of one or more teacher models, such as their predicted pseudo labels or intermediate features(Liu et al.,2020; Romero et al.,2014; Hinton et al.,2015; Vemulapalli et al.,2024). Specifically, multi-teacher distillation approaches(Borup et al.,2023; Liu et al.,2020; Zhang et al.,2022)aggregate the knowledge of multiple teachers by assigning weights, aiming to provide the student model with more accurate and comprehensive knowledge. Most knowledge distillation studies focus on a closed-set problem, where teachers with high-quality knowledge are predetermined and available to use(Hinton et al.,2015; Liu et al.,2020; Zhang et al.,2022; Borup et al.,2023). However, in the sensing system expansion problem, the knowledge from source domain models may not be directly applicable to the target domain due to data heterogeneity, leading to suboptimal performance.

Model Customization.Model customization has been extensively studied to meet specific computational and performance requirements(Wen et al.,2023; Cai et al.,2020; Ren et al.,2021). Directly training customized models on target data is less effective due to label scarcity(Ouyang et al.,2023; Xu et al.,2023). To address this, self-supervised learning methods that leverage unlabeled data have been proposed to enhance performance(Xu et al.,2021; Ouyang et al.,2022). These methods are not included as baselines for performance comparison as they are orthogonal to HaKT. Some works explore pre-deployment or post-deployment model generation techniques based on the specific requirements and conditions of target environments(Cai et al.,2020; Wen et al.,2023; Liu et al.,2018). While these methods focus on optimal architecture search in terms of latency and accuracy, HaKT emphasizes the knowledge transfer process from the selected source models to any target models that satisfy the customized needs of target domains.

SECTION: 8.Conclusion

To efficiently expand sensing systems, a general knowledge transfer framework, HaKT, is designed to address label scarcity and data and device heterogeneities. HaKT employs an Efficient Model Selection Protocol to identify high-quality source domain models at a low cost. The knowledge from the selected models is aggregated using Sample-wise Knowledge Fusion, which assigns different weights to each sample. The fused knowledge is then distilled into customized target models through Adaptive Knowledge Injection. Extensive experiments across various tasks, modalities, and settings demonstrate the effectiveness and efficiency of HaKT compared with state-of-the-art baselines.

SECTION: References