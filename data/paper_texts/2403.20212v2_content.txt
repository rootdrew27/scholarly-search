SECTION: On Size and Hardness Generalization in Unsupervised Learning for the Travelling Salesman Problem

We study the generalization capability of Unsupervised Learning in solving the Travelling Salesman Problem (TSP). We use a Graph Neural Network (GNN) trained with a surrogate loss function to generate an embedding for each node. We use these embeddings to construct a heat map that indicates the likelihood of each edge being part of the optimal route. We then apply local search to generate our final predictions. Our investigation explores how different training instance sizes, embedding dimensions, and distributions influence the outcomes of Unsupervised Learning methods. Our results show that training with larger instance sizes and increasing embedding dimensions can build a more effective representation, enhancing the model’s ability to solve TSP. Furthermore, in evaluating generalization across different distributions, we first determine the hardness of various distributions and explore how different hardnesses affect the final results. Our findings suggest that models trained on harder instances exhibit better generalization capabilities, highlighting the importance of selecting appropriate training instances in solving TSP using Unsupervised Learning.

SECTION: 1Introduction

The goal of machine learning for Combinatorial Optimization (CO) is to enhance or surpass handcrafted heuristics.
Recently, there has been an increasing trend in applying Machine Learning (ML) to tackle CO problems(Bengio et al.,2021). Different from manually crafted heuristics, machine learning approaches harness the power of data to uncover patterns in CO problems.

The Euclidean Travelling Salesman Problem (TSP) is one of the most famous and intensively studied CO problems. TSP asks the following question:Given a list of cities and the distances between each pair of cities, what is the shortest possible route that visits each city exactly once and returns to the origin city?A variety of methods have been developed to solve TSP, including the Lin-Kernighan-Helsgaun (LKH) heuristics, which is known for their effectiveness in approximating solutions(Helsgaun,2000), and the Concorde solver, which guarantees optimality of the solutions. The application of ML for TSP has primarily focused on Supervised Learning (SL) and Reinforcement Learning (RL). However, SL methods encounter the challenge of expensive annotations, while RL methods struggle with sparse reward problems.

Recently,(Min et al.,2024)proposes a new approach named UTSP that employs Unsupervised Learning (UL) to build a data-driven heuristics for the TSP. This unsupervised method does not depend on any labelled dataset and generates a heatmap in a non-autoregressive manner, offering a distinct alternative to traditional SL and RL models.

While the UL heuristics offer a promising approach, the challenge of generalizing across varying sizes and distributions remains significant. In particular, the model presented in(Min et al.,2024)requires retraining to adapt to new sizes, indicating that a model trained on one size cannot effectively generalize to different sizes.

This paper explores the generalization capabilities of unsupervised heuristics for the TSP. Our findings indicate that the UL model is able to generalize across different problem sizes. Regarding the generalization behavior of different distributions, based on the hardness results by(Gent & Walsh,1996), we relate different distributions to distinct levels of hardnesses. This allows us to investigate the impact of the training data’s hardness on the model’s performance.

Our primary contributions are outlined as follows: We propose a novel approach for enabling a TSP model, once trained, to generalize effectively across different problemsizes. We show that training with larger problem sizes can enhance model performance. Furthermore, we investigate the impact of variousembedding dimensionson TSP performance, finding that larger embedding dimensions can build more effective representations to guide the search process. Additionally, we explore how the model performs when trained on datasets of varyingdistributions. Our findings indicate that models trained on harder instances exhibit better performance, which underscores the importance of training instances’ distribution within the framework of UL for solving CO problems like the TSP.

While recent research papers explored using data-driven techniques for CO problems, most have focused on SL or RL. Very few have examined the generalization behaviours, particularly how training data (different distributions of TSP instances) influences final model performance(Bi et al.,2022). Our work addresses this gap, offering insights into the significance of training data selection and its direct impact on the effectiveness of ML models for CO tasks. This exploration contributes to understanding ML models in CO and provides practical guidelines for improving model generalization and performance in solving TSP.

SECTION: 2Related works

SECTION: 2.1RL for TSP

The goal of using RL for CO is to train an agent capable of either maximizing or minimizing the expected sum of future rewards, known as the return. For a given policy, the expected return from a current state is defined as the value function. In the context of TSP, RL typically focuses on minimizing the length of the predicted route(Ye et al.,2024; Zhou et al.,2023; Chen et al.,2024; Ma et al.,2024). For example,(Kool et al.,2019)proposes a model based on attention layers and trains
the model using RL using a deterministic
greedy rollout.(Bello et al.,2016)trains a recurrent neural network to predict permutations of city coordinates and optimizes the parameters with a policy gradient method using the negative tour length as a reward signal.

However, as the size of the TSP increases, the rewards become increasingly sparse, necessitating long exploration steps before the agent achieves a positive return. So the RL setting is challenging as it only learns once the agent, randomly or through more sophisticated strategies, finds a better solution. Additionally, within RL, the learning process is hard to converge, and the process may become trapped in local minima, as discussed in(Bengio et al.,2021).

SECTION: 2.2SL For TSP

In SL, the model is trained with a dataset including input coordinates alongside their corresponding optimal TSP solutions. The objective is to identify a function that predicts outputs for any given input coordinates, aiming for these predictions to approximate the optimal solutions(Li et al.,2024; Sun & Yang,2024; Fu et al.,2021).
For example,(Xin et al.,2021)trains a Sparse Graph Network using SL to evaluate edge scores, which are then integrated with the Lin-Kernighan-Helsgaun (LKH) algorithm to guide its search process.(Fu et al.,2021)uses a
GNN to learn from solved optimal solutions. The model is trained on a small-scale instances, which could be used to build larger heat maps.

However, In SL, the generation of optimal solutions for training is time-consuming. Finding optimal or near-optimal solutions for large TSP instances requires significant computational resources and sophisticated algorithms.

In other words, an ideal model should circumvent these issues, avoiding the sparse reward problem in RL and not relying on labelled optimal solutuons in SL. Addressing this, a recent approach by(Min et al.,2024)uses unsupervised learning (UL) and trains a GNN using a surrogate loss. The model generates heat maps through a non-autoregressive process, without relying on labelled optimal solutions or requiring the agents to explore better solutions, thereby circumventing the need for expensive annotation and mitigating the sparse reward problem.

This paper is structured as follows: Section3introduces the background of UL for TSP. Section4presents a method for generalizing across various problem sizes. Section5investigates the generalization behavior w.r.t. different embedding dimensions and training sizes. Finally, Section6explores the generalization across different distributions through the lens of instance hardness.

SECTION: 3UL for TSP

Let’s revisit the definition of the TSP. Essentially, the TSP can be reinterpreted as identifying the shortest Hamiltonian Cycle that encompasses all the cities.
In UL for TSP, the authors first reformulate the TSP into two constraints: the shortest path constraint and the Hamiltonian Cycle constraint. Subsequently, they construct a proxy for each of these constraints(Min et al.,2024).

In UTSP, givencities and their coordinates, UTSP first uses GNN to generate a soft indicator matrixand useto build the heat map. Rowofrepresents the probability distribution of directed edges originating from city, while columncorresponds to the probability distribution of directed edges terminating in city. This heat map is subsequently used to direct a local search algorithm.
As mentioned, the goal of UTSP is to construct a proxy for two constraints. For the shortest constraint, the authors optimize the distance term:, whereis the Frobenius inner product,is the distance matrix andis the distance between cityand city. To address the Hamiltonian Cycle constraint, the authors introduce thetransformation, which is designed to implicitly encode this constraint.

SECTION: 3.1Understandingtransformation

transformation is defined as:

where

is the shift matrix, where. We can interpretas representing a Hamiltonian cycle that follows the path, whileserves as an approximation of a general permutation matrix. Given that our initial heat maprepresents a Hamiltonian cycle, and considering that both the Hamiltonian cycle constraint holds and the node ordering is equivariant under permutation operations, the Hamiltonian cycle constraint is implicitly encoded in this framework. For more details, we refer the reader to(Min & Gomes,2023).

We can also writetransformation as:

whereis thecolumn of,.
Equation2provides another way of understanding thetransformation. The elements inare defined using two nearest columns in. As shown in Figure1,and. Since the non-zero element inis located at the first position and the non-zero element inis at the third position, it indicates a directed edge from node 1 to node 3 in the heat map. This is depicted as the purple edge in Figure1. Similarly, the presence of a non-zero element at the second position inimplies that there is a directed edge from node 3 to node 2 in the heat map, represented by the yellow edge.

SECTION: 3.2Training UTSP

In UTSP, the author train the model using the following lossis:

Here, theRow-wise constraintencouragesto behave like a doubly stochastic matrix, thus serving as a soft relaxation of a permutation matrix(Min & Gomes,2023). TheNo self-loopsterm discourages self loops in, whereis the distance ofself-loop, theMinimize the Distanceterm acts as a proxy for minimizing the distance of a Hamiltonian Cycle.

Although UTSP offers a promising unsupervised way to learn the heat maps, a notable limitation of the model is its lack of generalization. Specifically, a model trained on TSP instances withcities cannot be applied to other instances, such as instances withorcities. This limitation arises due tohaving a fixed dimension of. Consequently, the model’s architecture is inherently tied to the size of the training instances, restricting its adaptability to TSP instances of varying city counts.

SECTION: 4Size Generalization

Recall the understanding oftransformation in Equation2. We can interpret that the GNN generates a-dimensional embedding for each city. In our generalized model, given TSP instances with different sizes, for each node in these instances, the GNN outputs an embedding of dimension. Following this, a Softmax activation function is applied to each column of the embedding matrix, resulting in the generation of.

We then buildusing111It is important to observe that when,is not doubly stochastic. We also tried either replacingwithor substitutingwith, both of which yield similar outcomes.:

whereis thecolumn of. Equation4can be reformulated analogously to Equation1with.

In practice, we train our model under the loss:

By letting the GNN to output an-dimensional embedding for each city, the model achieves generalization across different instances. This means that, through Equation2, the heat mapwill consistently match the size of the input cities ().

SECTION: 5Experiment

Here, we explore the impact of the generalized model on different problem sizes. Specifically, we study TSP with 200, 500, and 1000 cities, each size is evaluated using 128 test instances.

Different from previously UTSP setting, our new methodology involves training models on larger datasets and testing them on smaller ones. Specifically, we train a model on a TSP-2000 dataset withand test it on a TSP-1000 dataset; another model is trained on TSP-1000 withand tested on TSP-500; and finally, a model trained on TSP-400 withis tested on TSP-200. The TSP-2000, 1000, and 400 training datasets are created by randomly distributing points on a 2D plane, subject to a uniform distribution. For TSP-200 and TSP-400, we train the model for 300 epochs, while for TSP-1000, we train the model for 600 epochs. Each of these datasets consists of 5,000 training instances.

We train our model on one NVIDIA A100 Graphics Processing Unit, using the same Graph Neural Network (GNN) architecture as described in(Min et al.,2024). The model is trained on TSP instances of sizes 400, 1000, and 2000, using a configuration of two hidden layers, with each layer comprising 128 hidden units. The hyperparameter, as specified in Equation4, is set to 100. Our test instances are taken from(Fu et al.,2021). Here, the performance gap is calculated using the, whererepresents the TSP length generated by our model anddenotes the optimal length. We run the search algorithm on Intel Xeon Gold 6326.

In our approach, consistent with the existing UTSP framework, we employ the same search methodology. The process begins with the generation of the heat map, from which we extract the toplargest values in each row. This extraction leads to the formation of a new heat map, denoted as. We computeto symmetrize this updated heat map.is then used to guide the search process.
We further calculate the overlap between non-zero edges inand the optimal solutions, where a higher overlap ratio indicates thatmore effectively covers the optimal solution. For more detailed information, we refer to(Min et al.,2024).

Our results are shown in Table1,
in the case of TSP-200, our model achieves a gap of0.0558%, when tackling TSP-500, the model continues to demonstrate its robustness, with a gap of0.8229%. The performance in both TSP-200 and TSP-500 suggests that our model’s approach to guiding the local search is effective across various scales of the TSP.

When the model is applied to the largest tested instance size, TSP-1000, it achieves a gap of1.1616%. which is the minimum one among all the methods. More importantly, it underscores the model’s generalization to scale and maintain a level of efficiency in large-scale TSP instances. Our results across all three instance sizes illustrate that the model trained using Equation5is able to generalize across instances of different sizes and effectively enhances the search process.

SECTION: 5.1Impact of Varyingon Training Performance

As mentioned in Equation4,represents the embedding dimension of each node. In this study, we investigate the effect of the embedding dimensionon the model’s performance. Specifically, we train models on TSP-2000 instances with varying embedding dimensions:and. We then evaluate these models on TSP-1000 instances to assess their performance.

The training curves for different embedding dimensions are shown in Figure2.
We calculate the overlap ratios and search performance using models with different embedding dimensions, the results are shown in Table2,3. Our findings indicate that an increase in the embedding dimension contributes to higher overlap ratios and enhanced search performance. For instance, the overlap ratio improves from 82.70% to 94.93% when the embedding dimensionis increased from 500 to 1500, based on the heat maps with top 5 elements from each row. Correspondingly, the search performance also improves, with the gap decreasing from 2.0746% to 1.4145%. This highlights the significance of embedding dimension in increasing model efficacy.
A larger embedding dimension can better identify optimal or near-optimal solutions and narrow the gap.

Specifically, it is noteworthy that when selecting the top 20 elements from each row, bothandachieve a 100.00% overlap ratio, whereasdoes not cover all the optimal solutions, resulting in a larger gap. Furthermore, we observe thatexhibits marginally better performance compared to. This suggests that beyond a certain threshold, increasing the embedding dimension yields diminishing returns in terms of covering optimal solutions. It also implies that there might be an optimal range for the embedding dimension, indicating a need for careful consideration in the choice ofto optimize model performance.

SECTION: 5.2Impact of Varyingon Training Performance

Our model can generalize across different sizes, meaning that training on one size can effectively translate to performance on another, previously unseen size. Here we investigate how varying the training size impacts the model’s performance. We train the model using TSP-400, TSP-1000, and TSP-2000 instances, all with the same embedding dimension. The training results are illustrated in Figure3.

We then test how different training instances’ sizes can affect the overlap ratio and the performance. The results are shown in Table4,5. We note that training with larger instances enhances search performance under both top 5 and top 20 conditions. Specifically, when selecting the top 5 elements from each row, the performance gap improves from 3.0762% to 1.4145%. Similarly, when choosing the top 20 elements from each row, the gap shows a marked improvement, decreasing from 1.1885% to 1.1616%.

Our results highlight the importance of selecting larger training instance sizes to enhance model performance and efficiency.

SECTION: 6Hardness Generalization

Previous studies suggest that UL can generalize across different sizes, guide the search and reduce the search space,
Here, we delve into how UL’s capability to reduce the search space is influenced by different distributions. Specifically, we explore the relationship between different distributions and the efficiency of using UL for solving the TSP.

However, building a connection between various distributions and the efficacy of UL in reducing the search space presents significant challenges. To address this, we first focus on correlating different distributions with their hardness levels.

A phase transition refers to a change in the solvability of NP-hard problems. When some parameters of the problem is varied, for example, the density of constraints in a Boolean
satisfiability problem (SAT) problem(Mitchell et al.,1992), the problem undergoes a transition from being almost solvable to unsolvable. To be specific, The phase transition in SAT refers to a sharp change in the solvability of these problems, depending on the ratio of the number of clauses to the number of variables in the formula. When the ratio is low (few clauses relative to variables), most instances of the problem are easy to solve. This is because there are fewer constraints, making it more likely to find a satisfying assignment. Conversely, when this ratio is high (many clauses relative to variables), the problem becomes over-constrained, and most instances are also easy to solve because they are almost certainly unsatisfiable. The most interesting part occurs at a certain critical ratio, typically around 4.3 for 3-SAT problems. At this ratio, the problems undergo a phase transition and become extremely hard to solve. In other words, the problems are most difficult around the phase transition point(Monasson et al.,1999).

Phase transitions provides a powerful framework to study the properties of NP-hard problems.
However, the exact nature and location of these transitions can be difficult to determine and may depend intricately on the structure of the different problems. For TSP,(Gent & Walsh,1996)suggest using the parameter, wheredenotes the area covered by the TSP instance,represents the length of the optimal solution, andis the number of cities. This approach is based on the observation that there is a rapid transition in solvability around a fixed value of the parameter, specifically at approximately.

Here we study four different distributions and see how it can effect the search space reduction, an illustration of these four distribution is shown in Figure77.
As mentioned earlier, around the phase transition point, the problems often exhibits the greatest computational complexity (Hard). Figure8illustrates the scheme of phase transition in the TSP. The-axis is thevalue, while the-axis corresponds to the level of hardness. The point at whichequals the critical thresholdmarks the peak of difficulty, exhibiting the highest hardness, we refer more details to(Gent & Walsh,1996).

Furthermore, we present thevalues for four different distributions, where eachis computed as an average from 100 instances, each with a size of 200, 500 and 1000, detailed in Table6and Figure8.

As shown in Figure8, the Uniform distribution is closest to the phase transition point. This indicates a highest level of hardness. Consequently, in terms of transitioning from hard to easy, the order is observed as follows: UniformImplosionExplosionExpansion. Following upon this concept, we examine how these distributions influence the capacity of UL to efficiently reduce the search space and guide the search.

We first train the models using 4 different distributions with the same parameters in Section4. We calculate the overlap ratio of these models for TSP-200, 500, and 1000. The training results are shown in Figure9,10and11. We observe that models trained with harder instances consistently exhibit a lower loss. Specifically, the loss curves for models trained using the Uniform distribution consistently show the lowest loss, while those trained with Expansion and Explosion distributions demonstrate higher losses.
This suggests that the hardness level of training instances plays a significant role in the effectiveness of the model training, directly impacting the loss metrics. It is important to note that throughout our training process, all other hyperparameter settings remained constant. Therefore, the observed variations in loss can be attributed solely to the differences in training distributions.

We then evaluate how different distributions can affect the search results. We pick the top 5 element each row and build the heat maps. The overlap ratio and the search results are shown in Table7,8and9. When training on easier distributions such as Explosion and Expansion, we observe low overlap ratios and larger performance gaps. This indicates that models trained on simpler distributions may struggle to generalize effectively to more challenging instances of the problem. The lower overlap ratios suggest that the solutions generated by these models are less aligned with the optimal solutions, and the larger performance gaps highlight a significant disparity in effectiveness when these models are applied to the test TSP instances. Training on harder distributions, such as Uniform, yields higher overlap ratios and improved search performance. This indicates that models trained on harder distributions can build a better representation of the search space, which enables the search to perform more effectively. It is also observed that theplateausduring training are more pronounced when training on harder instances, suggesting that the optimization landscape becomes more complex when the hardness level increases.

We evaluate the model’s performance on TSP-1000 instances by utilizing the top 20 elements from each row for each distribution, as detailed in Table10. We observe that by selecting the top 20 elements,is able to cover 100.00% of the optimal solutions. Overall, the performance gaps across the distributions are similar, with training on uniform distributions continuing to exhibit the lowest performance gap.

SECTION: 7Conclusion

This work introduces a new methodology that allows a trained, unsupervised TSP model to generalize across different problem sizes. Our results demonstrate that training on larger problem instances can improve performance compared to training with smaller instances. Additionally, we delve into the influence of embedding dimensions on TSP results, showing that larger embedding dimensions are important in constructing more effective representations that guide the search process more efficiently. Moreover, we investigate the model’s performance using training datasets with different levels of hardnesses. We show that training on harder instances can improve model performance, emphasizing the importance of selecting training instances with appropriate difficulty levels. We train our models on different TSP distributions to understand their impact on the effectiveness of UL models.
Our study indicates a clear relationship between the inherent hardness of distribution and the model’s capacity to generalize and effectively solve TSP instances. To our knowledge, this is the first study to systematically investigate and demonstrate this connection.

Our results highlight the relationship between the characteristics of training instances (size and hardness), embedding dimensions, and model performance in UL, particularly when addressing CO problems such as the TSP. We anticipate that these findings — emphasizing the benefits of training on larger, harder instances with increased embedding dimensions — can inspire further research in the application of Unsupervised Learning to Combinatorial Optimization tasks.

SECTION: 8Acknowledgement

This project is partially supported by the Eric and Wendy Schmidt AI
in Science Postdoctoral Fellowship, a Schmidt Futures program; the National Science Foundation
(NSF) and the National Institute of Food and Agriculture (NIFA); the Air
Force Office of Scientific Research (AFOSR); the Department of Energy; and the Toyota Research Institute (TRI).

SECTION: References