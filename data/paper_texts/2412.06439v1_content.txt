SECTION: Local Attention Transformers for High-Detail Optical Flow Upsampling
Most recent works on optical flow use convex upsampling as the last step to obtain high-resolution flow. In this work, we show and discuss several issues and limitations of this currently widely adopted convex upsampling approach. We propose a series of changes,
in an attempt to resolve current issues. First, we propose to decouple the weights for the final convex upsampler, making it easier to find the correct convex combination. For the same reason, we also provide extra contextual features to the convex upsampler. Then, we increase the convex mask size by using an attention-based alternative convex upsampler; Transformers for Convex Upsampling. This upsampler is based on the observation that convex upsampling can be reformulated as attention, and we propose to use local attention masks as a drop-in replacement for convex masks to increase the mask size. We provide empirical evidence that a larger mask size increases the likelihood of the existence of the convex combination. Lastly, we propose an alternative training scheme to remove bilinear interpolation artifacts from the model output.
Our proposed ideas could theoretically be applied to almost every current state-of-the-art optical flow architecture. On the FlyingChairs + FlyingThings3D training setting we reduce the Sintel Clean training end-point-error of RAFT fromto, GMA fromto, and that of FlowFormer fromto, by solely adapting the convex upsampler.

SECTION: Introduction
Current state-of-the-art deep optical flow modelsis heavily inspired by RAFT. RAFT applies an iterative, recurrent, optimization and makes this possible by reducing memory and compute by predicting flow atth of the input resolution. This low-resolution flow map is then upsampled to full resolution. Upsampling methods for optical flow have different requirements than traditional image upsampling methods like bilinear interpolation.i.e., if two objects at an edge move in different directions, interpolating them in the middle will give values around the mean of the two directions. This is never correct in terms of optical flow; a pixel either follows one object, or the other. Alternatively, upsampling methods that do not use interpolation like nearest neighbor upsampling makes flow edges jagged and not aligned with object edges.

To solve these issues for optical flow, RAFTproposes convex upsampling. There, the main idea is to upsample by a convex combination of the low-resolution neighbors: each low-resolution pixel is weighted, where all weights must be positive and sum to, which is easily obtained by applying the softmax function, see. Following the success of RAFT, this convex upsampling is currently adopted practically unchanged in all current SOTA flow models.

In this paper, we make the observation that convex upsampling for optical flow has received relatively little attention in the literature: the design of convex upsampling has not changed much since RAFT.

Here, we rephrase the traditional convex upsampling in a more flexible model using Neighborhood Attention (NA). Neighborhood Attention is a natural model for convex upsampling, as it is also local, and by the softmax operator inherently provides a convex combination. One of the benefits is that NA allows to decouple the number of learnable parameters from the mask size, allowing larger input sizes.

We have the following contributions. We rephrase convex upsampling as Neighborhood Attention (NA). NA allows us to evaluate larger mask sizes, making more solutions possible. It also allows us to replace the 1-step 8x upsampling with three hierarchical steps of 2x upsampling, which helps retain spatial information. The hierarchical upsampling allows us to also include the input image features at matching resolutions, to better align flow with object edges. We also investigate decoupling the final upsampling model from the intermediate upsamplings used in the recurrent optimization. As a final investigation we explore the role of optical flow sampling in data-augmentation.

Our proposed ideas could theoretically be applied to almost every current state-of-the-art optical flow architecture. On the FlyingChairs + FlyingThings3D training setting we reduce the Sintel Clean training end-point-error of RAFT fromto, GMA fromto, and that of FlowFormer fromto, by solely adapting the convex upsampler. We will make all code available.

SECTION: Related Work
is typically estimated between two consecutive frames by matching image-1 to image-2, and the seminal RAFTapproach inspired much follow up work. RAFT uses a gated recurrent unit in a step-wise, recurrent, optimization process. Because of its computational complexity, the recurrent optimization is done onth of the input image resolution, after which the low resolution output flow is upsampled to full resolution. The follow up work done by GMAadds global attention on the input features to add global, contextual information. Similarly, SeparableFlowimproves the correlation volume construction by first ensuring global contextual features. This idea is extended by FlowFormer(++), CRAFTand GMFlowNetwho add strong Transformer blocks. Essentially, RAFT is extended by improving and replacing different components other than the step-wise optimization, as this optimization approach remains the global design. So, the current optical flow state of the artis based on RAFT and inherits its main properties: low resolution iterative optimization followed by upsampling. Here, we focus on these properties and on the low resolution upsampling in particular.

MS-RAFT(+)also explores different resolutions in a setting based on RAFT. Important for us is that the convex upsampling is different, as they upsampletimes by a factor of, rather than once by a factor of.Inspired by this, we investigate the impact of this-step approach when used on the other state-of-the-art networks that currently use a single upsampling operation by factor.

is fundamental in computer vision tasks. Non learning-based approaches such as Nearest Neighbor, bilinear, or bicubic interpolation, and learning-based approaches such as Transposed convolutions, PixelShuffle as used in super resolution, or convex upsampling. Learned-based upsampling can be trained end-to-endor progressive as done in GANs. For optical flow, bilinear- or Nearest Neighbor interpolation can be used for decent performanceas long as the upsampling factor is small. All the current SOTA optical flow modelsrequire upsampling with factor. This makes traditional upsampling unsuitable, and hence convex upsampling is widely adopted by these models. Here, we extend this reasoning and formulate convex upsampling as local self-attention.

Self-attentionused for image recogitionresearch is bringing back the hierarchical structure of convolutional neural networks. As such, SwinFormerwas proposed. In a similar way, Neighborhood Attention (NA)was proposed. While the general idea of NA is similar to SwinFormer, the main design difference is how the local attention maps relate to the queries. NA ensures that as long as a query is not near the image border, the query is always at the center of the local attention map. This property makes these local attention maps effectively similar to convex upsampling masks. An advantage of local attention maps is that their size is decoupled from the number of parameters, so we investigate the use of attention maps when taken directly as a drop-in replacement for convex upsampling masks.

SECTION: Method
We show a visual comparison of the baseline convex upsampling of RAFTversus our proposed method inand will explain its modules in the following.

SECTION: RAFT’s convex upsampler
Most SOTA models for optical flow use a context encoder that takes image-1 as input, generally based on a three-scale ResNetarchitecture where each scale has a neural networkwiththat down-scales the resolution by factor, as follows:

The flow predictor takesand uses a linear projection to obtain the initial gated recurrent unit (GRU) internal state, as well as the shared input to each GRU step. The GRU module is defined as, and the optical flow map as. We define for image input sizethatand.

The correlation volumein RAFTis defined to provide the correlation information for a given pixel at spatial position. Forrefinement iterations the optimization approach is then defined as following, whereis the final low-resolution output flow.

Now taketo be a low-resolution flow map with hidden statewhere. For RAFT’supsampler which is used to upsample thefrom sizeto, a convex combination of the low-resolution nearby pixels fromis used. That is, for every low-resolution pixel, find sub-pixel valuesby first predicting ascalarfor every sub-pixel. Thishasscalars values;for mask size. For a mask centered on low resolution pixel, all the values within the mask including the pixel itself, form the neighbors of; called. Then, the value of the sub-pixelis calculated using the dot-product as following, for upsampling factorand mask size. Furthermore,refers to the use of the ReLUactivation function.

SECTION: Neighborhood Attention Transformers for Convex Upsampling
For our attention-based convex upsampler, we start with the same input, but also concatenateand, to build the embedding vectorsfor all pixelsas following.

Then we apply local Neighborhood Attention Transformers (NAT)for local contextual feature enhancement, usingTransformer blocks which sequentially form. For these Transformer blocks we use dimensionalityfor scale,for scale, andfor scale. We set the head dimensionality to. Note that the tokens from the embedding vectorscorrespond to the low-resolution pixels.

Then, for upsampling factor, multi-head attention is used to formattention maps for eachfrom. We use head dimensionality ofsuch that we halve the size of the embedding dimensionality for each upsampling operation. Forheads, this requires a query, key, and value dimensionality of, which can then be reshaped to obtainquery, key, and value maps with dimensionality.

Then, we construct the local attention maps using neighborhood attention (NA)with window size. Note that to obtain these local attention maps (LAM) they are normalized using the softmaxfunction, so similarly to convex upsampling masks; the values are positive and sum to.

We then aggregate these local attention maps with the low-resolution, as well as the value features. Again, we use neighborhood attentionfor this.

Note that this aggregation operation on a per-pixel level is implemented as following, whenwhererefers to the attention maps from LAM before softmax normalization.

So, aggregation as used in local attention is effectively similar to convex upsampling, as Equationand Equationare equivalent. For both, the dot product is taken within a sliding window between the convex maps, or attention maps, and the low-resolution flow, or the values. For simplicity, we ignore the different padding implementation, as this is not necessarily relevant here.

From Equation, we obtain, which is the by factorconvex upsampled flow. We also obtain the by factorupsampled featuresbased on Equation.

In the convex upsampling implementation of RAFT as described in Section, upsampling is done once by factor. The most important reason for this is that convex upsampling expects a feature map and a low-resolution flow map as inputs. However, it only provides a single output, namely the upsampling masks; see Equation. Therefore, the operation cannot easily be repeated. For our TCU, this is different. As we can see from Equationsand; we have the same inputs as outputs, but at a different scale. We can effectively repeat this operation as often as needed, and are able to upsampletimes by factor, rather than once by factor. This has several advantages, one is a spatial inductive bias; the network only has to learn the alignment ofsub-pixels at the time, rather thanat once.

Another advantage of the hierarchical approach as discussed in the previous paragraph is that it allows for concatenating feature maps from different scales. Note that from Equationstillwe have image features atscales, yet only use thescale from Equationas only these are used as inputs in equationsand. If we adopt our hierarchical method, we are able to concatenate each of the scales from Equations(),() and(), to the upsampling step of our convex upsampling with corresponding scale, as could be done in Equation.

For the traditional convex upsampler, it is difficult to increase the mask sizedue to the use of a single vector of sizefor the mask values, with mask sizeand upsampling factor. This is because Equationuses a fully-connected layer for this purpose, and hence increasingcomes with a strong increase in the number of parameters, and is difficult to optimize. Fortunately, our Transformer based Convex Upsampler (TCU) does not have this problem. As the convex masks are simply local attention maps, and the size of local attention maps is not dependent on the number of parameters, we can freely increase the mask size, as long as it fits in memory.

We use an increased mask size to explore finding new solutions. A strong limitation of convex upsampling is that a high-resolution pixel can only be predicted correctly if there exists a convex combination of the low-resolution neighbor pixelssuch that the dot-product forms the desired output value. Therefore, if the low-resolution flow mapis not correct or not locally informative enough and no such convex combination exist, the desired output value can never be obtained. We propose to increase the size ofand include more low-resolution pixels, rather than just look at the direct neighbors using amask. For our sequential upsampling steps we use mask sizes, in that order from low- to high-resolution.

Many flow prediction architecturestake a recurrent step-wise refinement approach to solve optical flow, as we describe in Equationtill. During training, a loss value is calculated for each intermediate flow map, where each flow map requires to be upsampled to high resolution in order to compare it to the ground truth. Many SOTA workschoose to share the same convex upsampler and its weights over all steps. However, we consider the first flow predictions to be extremely noisy variants of the final flow. When the convex upsampler and its weights are shared over all steps, this is effectively equivalent to just adding strong noise to a part of the input data. In general, the loss is down-weighed for the first steps, but this could be insufficient. We want the convex upsampler of the final output refinement iteration to fully focus on its own objective, and not have its parameters shared with noisy estimates from earlier refinement iterations. To achieve this, we propose to decouple the convex upsampler of the last refinement iteration and give it its own weights.

This also brings the advantage that a different upsampling method can be used for the last refinement iteration. Our Transformed-based convex upsampling approach, TCU, uses more memory than the original convex upsampling approach. So, we exploit the idea of a decoupled upsampler for the last refinement iteration to make our TCU model feasible in practise. Namely, the original shared convex upsampler is used for the firstrefinement iterations, and TCU is only used for the last refinement iteration which provides the final model output. Note that at test-time, only the upsampler of the last refinement iteration is used.

SECTION: Effect of sampling in data-augmentation
In addition to the architecture change, we also investigate the training scheme.
Noticeably, almost all recent works on optical flow are based on the same original PyTorch implementation of RAFT, and all use bilinear sampling for augmentation of their training data. The original reason of RAFT for convex upsampling was to avoid bilinear upsampling on flow maps. However, in the current setting convex upsampling is used, but with the learning objective to predict bilinearly interpolated flow. Interestingly, to the best of our knowledge, all public top submissions to the Sintelleaderboard show bilinear interpolation artifacts in the form of white and non-crisp edges, even though these artifacts are not in the non-augmented training data. We explore an additional training scheme to remove bilinear interpolation artifacts. Disabling this interpolation in the augmentation is likely not a good idea, as it is used to avoid overfitting. Instead, we propose an additional training scheme; (-AUG). There, a trained model is trained for an additional 40K iterations with all interpolation-based augmentations disabled.

SECTION: Experiments
The only difference from the original training setting is the convex upsampler from the last refinement iteration. Training all model components from random initialization in this highly similar setting would be unnecessarily costly. Instead, all the training sessions are started with pre-trained weights for the flow predictor and the convex upsampler of the firstiterations. Only the weights of the convex upsampler for the last refinement iteration are randomly initialized. For all experiments, we fine-tune foriterations with a batch size of, on the dataset that the model was last trained on. A learning rate ofis used for the pre-trained weights, and a learning rate ofis used for the untrained upsampler of the last refinement iteration. We will make all code available.

SECTION: Performance on High-Detail Areas
An important reason for our upsampler is the performance on high-detail areas. To investigate this, we look at the performance on non-overlappingpatches of the test data. We take the ground truth optical flow and assume the number of edge pixels in the ground truth flow map to strongly correlate with the amount of details, and hence with the difficulty for the convex upsampler. We extract spatial gradients using the Kornia library, and consider thenorm on the-dimensional vector that comes from extracting theandgradients for eachchannel as an edge detector. To obtain a binary edge map, a binary threshold ofis used. To get the level of detail for a patch, the average value is taken of the binary edge map of that patch. Next, we plot the average end-point-error (EPE) for each level of detail, for which a bin width ofis used. Samples with level of detail that is larger than the specified domain are placed in the last bucket.

The results in Figureshow a strong degrade in accuracy for increasing amounts of detail, which confirms that our hypothetical problem exists. We provide the statistics on the amount of samples per bucket from Figurein Table. From this table, note for example that the bucketsonly contain 2% of the patches, yet contribute for 13% to the end-point-error. This strongly highlights the importance of our method, as even though the amount of high-detail patches is low, its impact on the end-point-error can be significant.

SECTION: Transformers for Convex Upsampler
Next, we investigate the impact of the proposed individual components.refers to decoupling the last refinement’s convex upsampler, and giving it its own weights.refers to concatenating the features from the context branch to the input of the convex upsampler. When TCU is used features are added at all scales, otherwise only the low resolution features are appended to the input.refers to the use of our Transformers for Convex Upsampling (TCU) with mask sizefor the first upsampling step,for the second step, andfor the last step. Lastly,refers to the additional fine-tuning steps with disabled interpolation-based augmentations.

We first investigate the performance for several of our proposed models on the FlyingThings3Dtest data, after being trained on C+T. The results hereof are shown in Figure. From this figure we observe that all our proposed changes result in improvements over the previous model that did not have the change. This is as expected, as we do not expect strong relations between each of our proposed changes, as each of our proposed changes aims at providing improvements in a different way. While these results are good, it is also important to consider situations where this might not be the case. This result is calculated for the test data of the dataset that the model was trained on, so there is no measure of cross-dataset generalization here. For cross-dataset generalization performance, we consider the performance on Sintel Clean, which is done next.

We create the same graph as before, but now for the Sintel Cleandataset. The results hereof are shown in Figure. In general, similar patterns as for FlyingThings3Dare observed. However, the gap between with and without (-AUG) is no longer as clear as before. Possibly, interpolation artifacts on edges is a good thing for cross-dataset generalization. Reason for this could be that interpolation on edges results in the ‘safe choice‘ for a model as it provides values around the mean, which then on average provides similar performance as sharp edges that are sometimes wrong, when evaluated on the end-point-error.

An interesting result from this is that increasing the mask size for TCU from (3/3/3) to (9/7/5) again provides clear improvements. This, together with the same result for FlyingThings3D, provides empirical evidence for our hypothesis that a larger mask size can makes more convex solutions possible, which in turn improves performance.

For Sintel Finalthere exist some important differences. Mainly, Sintel Final contains many strong blurring-based effects in an attempt to mimic real-world camera effects such as motion blur. This introduces a very important aspect; aligning flow with image edges is not a good thing. For Sintel Final, we would instead like to have a model that learns where the actual object edges are based on an image that contains motion blur. To inspect the performance, the same graph as before is generated, but now for Sintel Final. The results hereof can be found in Figure. As expected, every step we take towards better aligning flow with objects edges, degrades the models performance for this dataset. Interestingly, removing the bilinear interpolation artifacts from the model output (-AUG) causes a steep decrease in model performance. Clearly, bilinear interpolation artifacts provide an advantage here. This again confirms our earlier idea that possibly bilinear interpolation artifacts on edges are a ‘safe choice‘ when evaluated with the end-point-error, as the values are around the mean. If this is indeed the case, it makes sense that these artifacts help for strong cross-dataset generalization where edges do not align with flow.

Overall, our GMA+DC+FT+TCU(9/7/5) model sets a strong new baseline on all datasets, except Sintel Final. This is shown in Table. While cross-dataset generalization is an important aspect of optical flow models, we do not believe it to be realistic to build a model that generalizes to such impactful motion-blur artifacts that are not at all in the training data. It is important to note that generalization to KITTI-15is good, even though it consists of actual real-world images, taken by a camera.

results are reported in Tablefor various settings (e.g.C+T, C+T+S+K+H). While the C+T setting can be seen as a good measure of cross-dataset generalization, training with the training data of specific datasets is also considered interesting. Therefore, we integrate our approach on GMAfor the C+T+S+K+H setting. As we observe here, our method can provide an improvement on Sintel Final as well when the training data also contains these blurring artifacts, as is the case for this setting.

SECTION: Discussion
We observe that our -AUG training scheme decreases the presence of these artifacts in the model output, as can be seen in our submission to the Sintel public scoreboard. Possibly, completely removing these artifacts would require longer training without augmentations. However, this will likely cause an overfit to the training data, so we leave a better solution to this for future work.

Overall, we find good results by reconsidering the design of the convex upsampler and the bilinear interpolation on the flow during training. In general, all our methods; +TCU, +DC, +FT, and -AUG achieve a better fit on the the training data. This was our initial goal, and therefore we can confirm that our changes have the desired effect. However, generalization is an important aspect of optical flow models. As such, we ask for careful consideration for adopting our methods when a large generalization gap exists, as in such case our method may not result in improvements. When there is no large generalization gap present as is the case for Sintel Clean, we show in the (C+T) setting that all our proposed changes can provide improvements on a wide variety of models such as RAFT, GMA, and FlowFormer. We expect similar improvements for other models that currently use the original convex upsampling by factor.

Lastly, it is important to consider the accuracy of the edges in the training data. For example, KITTI-15has its flow maps constructed from sensory data, so its exact accuracy on minor details can possibly be off. Sintel Clean is considered a strong benchmark as the flow map is constructed with 100% certainty, and the images form a good representation of the high-detail edges. Possibly, Springwould be a good evaluation metric, but unfortunately at the time of this work, this dataset has not yet been released.

SECTION: References