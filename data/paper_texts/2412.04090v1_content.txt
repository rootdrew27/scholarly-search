SECTION: LossAgent: Towards Any Optimization Objectives for Image Processing with LLM Agents

We present the first loss agent, dubbed LossAgent, for low-level image processing tasks,e.g., image super-resolution and restoration, intending to achieve any customized optimization objectives of low-level image processing in different practical applications. Notably, not all optimization objectives, such as complex hand-crafted perceptual metrics, text description, and intricate human feedback, can be instantiated with existing low-level losses,e.g., MSE loss. which presents a crucial challenge in optimizing image processing networks in an end-to-end manner. To eliminate this, our LossAgent introduces the powerful large language model (LLM) as the loss agent, where the rich textual understanding of prior knowledge empowers the loss agent with the potential to understand complex optimization objectives, trajectory, and state feedback from external environments in the optimization process of the low-level image processing networks. In particular, we establish the loss repository by incorporating existing loss functions that support the end-to-end optimization for low-level image processing. Then, we design the optimization-oriented prompt engineering for the loss agent to actively and intelligently decide the compositional weights for each loss in the repository at each optimization interaction, thereby achieving the required optimization trajectory for any customized optimization objectives. Extensive experiments on three typical low-level image processing tasks and multiple optimization objectives have shown the effectiveness and applicability of our proposed LossAgent. Code and pre-trained models will be available athttps://github.com/lbc12345/LossAgent.

SECTION: 1Introduction

With the revolutionary advancements in deep learning technology, low-level image processing tasks,e.g., image super-resolution and restoration, have garnered increasing interest from researchers.
Typically, low-level image processing tasks are optimized with the commonly-used loss function, such as MSE and L1 Losses, in an end-to-end manner, to improve the objective quality[61,10,23,22,8,54]or perceptual quality[59,60,6,7,63,50].
However, optimizing models using a single optimization objective falls short of meeting real-world needs. For example, in image super-resolution, we desire the super-resolved images to not only restore the ground truth at the pixel level but also to appear natural without artificial textures or visually distracting artifacts[14]. To address this, some researchers have introduced the combination of multiple loss functions[14,49,48,50,63](e.g., GANs) to train networks, enabling the optimized models to satisfy multiple optimization objectives. Nevertheless, this approach requires the loss functions corresponding to optimization objectives to be differentiable and suitable for training. Consequently, some advanced image quality assessment (IQA) metrics, which align more closely with human visual perception, are not differentiable and thus cannot be directly utilized for end-to-end network optimization.

Recently, large language models (LLMs) such as GPT series[4,34]and LLaMA series[30,45,37], have shown promising reasoning and understanding capabilities. This has also catalyzed the trend of utilizing LLMs as intelligent agents[40,25,11,41], especially in the field of embodied AI[56,33,39,12]. By providing the agent with the environment information, predefined settings, rules, external feedback, and a set of optional actions, it can leverage its powerful reasoning capabilities to generate outputs that meet customized requirements, such as tool selection[38,40], action decisions[58], programming[43,12], etc.

Inspired by this series of works, we propose the first loss agent, dubbed LossAgent, for low-level image processing, enabling any customized optimization objectives of the image processing network for multiple practical applications. To achieve this, we introduce the pre-trained large language model (LLM),i.e., LLaMA-3[30]as the loss agent to control the optimization trajectory for different objectives. In the optimization process, an intuitive strategy is to exploit the expected optimization objective as the loss function to guide the optimization of image processing networks. However, not all optimization objectives can assist this, such as the complex hand-crafted optimization objective, textual description, and human feedback, since they cannot be differentiable for end-to-end optimization. To solve the problem, we propose the compositional loss repository, which collects existing popular loss functions supported for low-level image processing, and utilize our proposed LossAgent to adaptively and actively assign the weights for each loss at each iteration period based on external environments to achieve customized optimization trajectory toward required optimization objective. In this process, we carefully design the optimization-oriented prompt engineering, which constructs the prompt templates to guide the LLM to understand the current optimization states, trajectory, and objectives, thereby achieving accurate loss weights planning.

To fully utilize the reasoning capabilities of LLM, the agent receives input of all weights of the model from the beginning of the training phase to the current stage. This enables the LossAgent to smoothly and automatically optimize the image processing model towards predefined optimization objectives through the analysis of historical weights, inference from external feedback, and following customized instructions.

Overall, the LossAgent possesses the following core features:

LossAgent is capable of obtaining feedback from non-differentiable optimization objectives and leveraging the model’s powerful reasoning capabilities to convert this feedback into a composition of loss weights for training, thereby enabling the model to be optimized in an end-to-end manner towards any optimization objectives.

LossAgent enjoys a high degree of flexibility. Leveraging its powerful reasoning capabilities, the agent can update loss weights fully automatically. Additionally, due to its ability to follow instructions, it can also receive feedbacks from external environments during the training process to pursue customized needs.

LossAgent exhibits high scalability. As depicted in Figure1, our AgentLoss can be extended to various low-level image processing tasks and multiple different optimization objectives, even if they are not differentiable, which has been proven in the experimental parts.

SECTION: 2Related Works

SECTION: 2.1Image Processing

Image processing consists a broad spectrum of tasks, including image restoration[35,23,10], image enhancement[59,47,51], and image super-resolution[60,6,7,50,63,21]. In low-level image processing tasks, pioneering works[9,24,65]focus primarily on optimizing fidelity-wise metrics such as PSNR and SSIM through L1 or L2 loss functions. However, models optimized by these metrics tend to generate over-smooth results[14]. To mitigate this problem, works[14,49,63,50,17]leveraging generative adversarial networks (GANs) to enable the SR network to learn the distribution of real-world high-quality images. By introducing a weighted combination of VGG perceptual loss[14,42]and GAN loss, GAN-based works[49,50,63]are well-optimized for human perception objectives. More recently, transformer-based[23,6,7]and diffusion-based works[10,54,26,36]further improve the performance on aforementioned optimization objectives.

However, despite the revolution of network structures and loss function designs, optimization trajectories of image processing models have become relatively fixed. While there is a strong demand for advanced image quality assessment (IQA) metrics[63], many recently developed IQA metrics[20,52,53,18]cannot be utilized as optimization objectives due to their non-differentiable nature. In this paper, we tackle this challenge by introducing an LLM-based loss agent. This agent is capable of bridging any customized optimization objectives with the combination of loss function weights, allowing for the optimization of image processing models in an end-to-end manner.

SECTION: 2.2LLM Agents

With the development of data science and computing resources, numerous of large language models (LLMs)[19,45,4]have emerged with remarkable language understanding and reasoning abilities. Despite of the above advantages, LLMs may struggle with tasks in certain specialized domains, leading to inaccurate outputs[11,31]. Consequently, researchers leverage these powerful LLMs as tools planner[38]and intelligent agents[41], adaptively coordinating domain-specific expert models based on external demands. For example, MM-REACT[58]tackles various multimodal reasoning and action tasks via prompting ChatGPT[4]to invoke domain experts. ToolFormer[38]embeds external API tags within text sequences to enhance LLMs’ interaction with external resources. HuggingGPT[40]effectively harnesses various expert models from HuggingFace while utilizing LLMs as a controller to adeptly address tasks across multiple specialized domains. More recently, with appropriate instruction tuning, researchers have enabled LLMs to adapt to a broader range of tasks, allowing for more specialized task planning[40,43,12]. Besides, in the field of embodied AI, LLM has been seamlessly integrated with vision experts as an agent[56,33]. The agent is capable of receiving environmental feedback and generating optimal actions accordingly.

Different from these great efforts, we propose the first LLM-based agent to handle any customized optimization objectives for image processing models, named LossAgent. By leveraging the powerful understanding and reasoning capabilities of LLMs, we transform feedback from external models or metrics into appropriate adjustments of loss weights in image processing models, allowing image processing models to be optimized towards any objectives. We hope that our LossAgent will facilitate the development of image processing to a more open-ended and intelligent society.

SECTION: 3Methods

Notably, there are multiple optimization objectives for image processing tasks such as traditional metrics like MSE loss to advanced IQA metrics that align with human perception. However, not all optimization objectives can be exploited to guide the end-to-end optimization of image processing networks since they are not all differentiable. This raises a significant and interesting question “how to optimize an image processing model when optimization objectives are non-differentiable?” In this paper, we address this question by proposing the first LLM-based loss agent, which transfers feedback from these optimization objectives through a pre-trained LLM into the adjustment of loss weights. This approach enables the image processing model to be optimized in an end-to-end manner. In this section, we first review the optimization objectives for low-level image processing models and then explain three parts of LossAgent illustrated in Figure1in details.

SECTION: 3.1Optimization Objectives of Image Processing Models

Although the network structures of image processing models have evolved significantly in recent years, the optimization objectives of these models have remained largely unchanged. Taking image super-resolution (ISR) as an example, early works[24,9,65]pursued higher PSNR values, while some recent works[63,50,59,54,10,60]have started optimizing networks to better align with human perception considering metrics such as LPIPS[64]and NIQE[32]. Despite advances in these ISR models, image quality assessment (IQA) models have concurrently experienced significant developments. An IQA model evaluates the visual quality of images by analyzing their attributes and detecting any distortions or imperfections, making it particularly suitable as an optimization objective for image processing models[46,57]. However, due to the specific operations in IQA models (e.g., incorporating other models and applying sampling[52,53]), some advanced IQA metrics are non-differentiable, preventing them from being utilized as the optimization objectives during the training of image processing models. Moreover, when leveraging textual feedback from humans or MLLM-based IQA models such as Co-Instruct[53]for optimization objectives, the metrics derived from these objectives are inherently non-differentiable.

In this paper, we address the above challenges by introducing an LLM-based agent, termed LossAgent. Instead of directly applying these optimization objectives as loss functions for training image processing models, LossAgent efficiently transfers various forms of feedback from customized optimization objectives into an actionable weighted composition of a set of differentiable loss functions.

SECTION: 3.2Weighted Compositional Loss Repository

To achieve any optimization trajectory in the training stage of image processing models, we establish the compositional loss repository with multiple typical differential loss functions, such as, LPIPS, where the dynamically weighted composition of them with coefficientsis achieved to modulate the optimization direction timely:

Here,is the total number of loss functions.
Based on the above weighted compositional loss repository, we can adjust the optimization direction directly by generating the weighting coefficients through our proposed loss agent. To enable the loss agent to adjust weight composition in time based on feedback from any optimization objective, we divide the training stage of the image processing model into N stages, where the current state of the image processing model and their corresponding compositional loss is as:

wherestands for the initial states of the image processing model andindicates thetraining stage. The external feedback of the optimization objective will be evaluated by the image processing model at the end of each training stage with a set of randomly selected testing images as:

whereis the number of images. We have provided the details in theDatasetspart of Section4.1.

SECTION: 3.3External Feedback from Optimization Objectives

To alleviate the cognitive burden on the loss agent for the image processing task, we introduce the external evaluation expertto produce the optimization feedback to the loss agent. Concretely, once we obtained the restored imagesat the stage, we can utilize external evaluation expertto evaluate the quality of restored imagesas:

whereis the external feedback from optimization objectives, which can be a quality score or textual description. Notably, the external evaluation expert is the tool to represent the optimization objective. For instance, if the optimization objective is to achieve a higher CLIPIQA[46]score, we select CLIPIQA as the external evaluation expert. Conversely, when the optimization objective is more general (e.g., to achieve higher quality), multiple evaluation experts can be utilized collaboratively to generate feedback. See more details in Section4.2.2.

SECTION: 3.4Loss Agent

It is noteworthy that the original LLM model cannot be directly applied to image processing tasks due to the knowledge discrepancy. To equip the LLM model with the capability to understand the image processing task and adjust the optimization direction of image processing, we exploit prompt engineering to adapt the pre-trained LLM model to our desired loss agent. Concretely, our proposed prompt engineering strategy can be divided into three parts: i)system prompt, ii)historical promptand iii)customized needs prompt.

After feedbackis generated from external expert models, the loss agent will collect and utilize this feedback to generate a new set of loss weights. LLM demonstrates exceptional capabilities in following instructions and making decisions[40,34,45]. Consequently, enabling the loss agent to accomplish our task is feasible by providing accurate and sufficient prompt guidance. Initially, we employ prompt engineering throughsystem promptapproach following previous works[40,56,33,43]to convey to the loss agent the role it needs to undertake, the inputs it will receive, the required outputs, and the objectives to be achieved. An example of our prompt engineering under the ISR scenario is given in Figure2. The most important instruction for the agent is the objectives clarification: “Your ultimate goal is to help the SR model achieve higher score feedback.”. This is because LLM may not encompass the knowledge of how these IQA metrics should be evaluated. Therefore, it is crucial to clarify whether lower or higher scores indicate better image quality. Without this context, LLM might intuitively assume that higher scores indicate better quality, resulting in incorrect reasoning.

Subsequently, to mitigate the hallucination phenomenon in LLM and prevent undesirable responses in situations of information scarcity, we gather the optimization trajectory of the loss agent ashistorical promptand provide this information as context to the LLM.

Following this, we impose certainrule-based constraintson LLM throughcustomized needs prompt. Furthermore, we incorporate format regularization into these rules to alleviate the challenge of parsing LLM outputs, which we found to be highly effective in standardizing the outputs. It is noteworthy that the design of suchcustomized needs promptnot only provides flexibility for current usage but also accommodates a variety of future needs.

Ultimately, the loss agent consolidates all received information, leveraging its robust understanding and reasoning capabilities to generate a new set of loss weights as:

This new combination of loss functions will be employed to optimize the image processing model at stage. Based on the system prompt, the historical prompt, and the customized needs prompt, our LossAgent is capable ofupdating reasonable new loss weightsfor training image processing model. Please refer to Section4.3for more details.

SECTION: 4Experiments

SECTION: 4.1Settings

To demonstrate the effectiveness of our LossAgent, we perform the evaluation on three representative low-level image processing tasks: classical image super-resolution, real-world image super-resolution and all-in-one image restoration. We adopt two typical image processing models: SwinIR[23]for super-resolution tasks and PromptIR[35]for all-in-one restoration task. To demonstrate the effectiveness of LossAgent towards various optimization objectives, we assess the performance of our method across three testing settings: single optimization objective, double optimization objectives and textual optimization objectives. For all score-based IQA optimization objectives, we adopt theirpyiqapython implementation[5]. We select open-sourcedMeta-Llama-3-8B-Instruct***https://huggingface.co/meta-llama/Meta-Llama-3-8B-Instructas the LLM of our loss agent due to its impressive reasoning capabilities. We provide training details in Section6.

For image SR tasks, we follow previous works[23,50]and adopt DF2K[1,44]as the training dataset. For all-in-one image restoration task, we follow[16,35]to use a combination of BSD400[2], WED[27], Rain100L[55]and SOTS[15]to optimize the model. We utilize five SR benchmarks with ground-truth to evaluate the performance of LossAgent on classical image SR: Set5[3], Set14[62], BSD100[28], Urban100[13]and Manga109[29]. Two real-world benchmarks without ground-truth are adopted to evaluate real-world image SR: OST300[48]and RealSRSet[63]. We follow PromptIR[35]to use SOTS(test)[15], Rain100L(test)[55]and BSD68[28]to evaluate the all-in-one image restoration performance. For testing imagesmentioned in Equation4, we randomly sample 10 images from Set14[62]for classical image SR; randomly sample 10 images from RealSRSet[63]for real-world image SR; randomly sample 10 images from evaluation sets of PromptIR for all-in-one IR.

SECTION: 4.2Evaluation on Optimization Objectives

In this section, we validate the effectiveness of LossAgent towards the single optimization objective. We select four IQA metrics as the optimization objective: NIQE[32], MANIQA[57], CLIPIQA[46]and Q-Align[52]. For each metric, we start from the pre-trained model weights and initial loss weights listed in Table2, and optimize the image processing model using LossAgent with external feedback from this metric. As demonstrated in Table1,3and4, our LossAgent outperforms baseline method (i.e., fixed loss weights) across almost all the benchmarks under all the optimization objectives, which not only reveals the effectiveness of LossAgent but also indicates that our method enjoys plausible generalization abilities across different image processing models. Notably, LossAgent performs well on real-world image SR task, suggesting the efficacy of our proposed method in complex application scenarios. However, in the all-in-one IR task, LossAgent does not perform as robustly as in the other two tasks. We attribute this to the minimal differences between images generated in consecutive stages, which limit the instructional information available to the agent and hinder its ability to perform thorough analysis and inference to adjust loss weights. We provide qualitative comparisons between the baseline method and our LossAgent on real-world image super-resolution task in Figure3. As observed, the image processing model restores images that are more aligned with human perception with the help of LossAgent. Specifically, the images in the second row encompass vivid textures, resulting in better quality assessments.

To fully explore the potential of LossAgent, we conduct an experiment on classical image SR task. In this experiment, we utilize two optimization objectives (i.e., Q-Align[52]and PSNR) simultaneously to adjust loss weights. As observed from Table5, including PSNR as an optimization objective yields PSNR gains across all benchmarks while maintaining comparable Q-Align performance. We attribute this to the powerful reasoning capabilities of LLM. Such results showcase the flexibility of LossAgent towards various optimization objectives.

While score metrics are common in image processing tasks, it is rare for tasks to utilize textual metrics as optimization objectives. Recently, Co-Instruct[53]employs MLLMs to evaluate image quality and generate corresponding textual descriptions. To explore the flexibility and scalability of LossAgent, we choose Co-Instruct as the optimization objective. Table6shows the results of all-in-one IR task. Notice that, there aren’t any methods available to evaluate a model optimized by textual guidance. Since Co-Instruct and Q-Align utilize similar network structures and training datasets, we find it reasonable to evaluate the performance of the Co-Instruct-optimized model by Q-Align score. As observed, the Co-Instruct-optimized model achieves comparable results with the baseline and Q-Align-optimized model, suggesting that LossAgent successfully transfers the non-differentiable optimization objective into appropriate adjustments of loss weights.

We have validated the flexibility and scalability of LossAgent in this part through three evaluation settings: single optimization objective, double optimization objectives, and textual optimization objectives. As observed, our LossAgent is efficient towards multiple image processing tasks and various optimization objectives, which also bridges advanced IQA metrics with image processing models. We provide more ablation studies of the loss agent in Section7.

SECTION: 4.3Evaluation on Effectiveness of Prompt Design

As described in Section3.4, we carefully devise prompts for the LLM to prevent hallucination and generate reasonable loss weights. Our prompt design mainly focuses on three parts: i)System promptclarifies the roles and goals of LLM. Most importantly, it provides a brief introduction to these IQA metrics about whether lower or higher scores indicate better image quality. ii)Historical promptaccommodates previous optimization trajectories, furnishing rich context for the LLM to infer reasonable loss weights. iii)Customized needs promptgives rule-based constraints on LLM’s reasoning process. Unless stated otherwise, the experiments in this section are conducted on classical image super-resolution tasks.

In Table7, we remove the prompt that describes the relationship between scores and the qualities of images. Take NIQE[32]as an example, where a lower score indicates a better quality, LossAgent fails to improve the performance of the ISR model on the NIQE metric. We attribute this to the LLM potentially interpreting a higher score as an indicator of better quality. Consequently, our system prompt design helps mitigate hallucination in the decision-making process of LossAgent.

Although LLM possesses strong reasoning and decision-making capabilities, it is unable to generate rational loss weights effectively without sufficient context. Therefore, we provide such context by collecting all historical optimization trajectories. As demonstrated in Table8, providing full historical information through prompt achieves the best performance, while providing only two trajectories (i.e., loss weights and feedback at stageand) leading to performance drops.

As LLM generates textual outputs, it is necessary to standardize its outputs by rule-based constraints, making the weights identifiable by programs. We empirically find that given an example of the format effectively reduces hallucination in LLM’s outputs. We validate this through the correct rate of output format, as shown in Table9. Removing this example leads to a significant drop in the successful rate of generating standardized output. In contrast, our LossAgent successfully generates standardized output, with only one failure case out of 800 samples. This demonstrates the effectiveness of our customized needs prompt design.

SECTION: 5Conclusion

In this paper, we propose the first loss agent to address any customized optimization objectives for low-level image processing tasks. By introducing powerful LLM as the loss agent, our LossAgent is capable of understanding various optimization objectives, trajectories, and stage feedback from external expert models. To take full advantage of the reasoning abilities of LLM, we carefully design the optimization-oriented prompt engineering for the loss agent by providing detailed instructions along with customized needs prompts. Moreover, we include historical information in our prompt to prevent hallucinations and incorrect reasoning caused by the LLM. Extensive experiments on three representative low-level image processing tasks with various customized optimization objectives have demonstrated the flexibility and scalability of our LossAgent.

SECTION: References

Supplementary Material

SECTION: 6Training Details

As demonstrated in Section3.2, we divide the entire training process of image processing models into several stages to enable the dynamic adjustment of the loss weights through LossAgent. We list the details of training iterations for each stage, the total number of training iterations, and the initial weights of loss functions in Table2. For two image super-resolution tasks, we utilize the PSNR-oriented pre-trained checkpoints of SwinIR[23]as initial checkpoints for both tasks, and then apply popular GAN-based training strategies for image SR tasks using our LossAgent. For all-in-one image restoration task, we adopt the pre-trained checkpoint of PromptIR[35]as the initial checkpoint. However, since GAN-based training is uncommon for this task, we use a combination of L1 loss, perceptual loss, and LPIPS loss as loss functions to evaluate the performance of our LossAgent. The rationale behind utilizing pre-trained checkpoints as initial checkpoints is to mitigate unstable fluctuations in the early stages of training of image processing models. Such fluctuations may otherwise misguide the LossAgent, leading to inaccurate updates of loss weights. It is noteworthy that, to avoid the affection from the learning rate of the optimizer to our experiments, we uniformly set the learning rate to 1e-4 for all three tasks and keep it constant throughout the training process. Following previous implementations, we utilize an Adam optimizer for each task. We use 8 NVIDIA TESLA V100 GPUs for our experiments, with a total batchsize of 32 for image SR tasks and a total batchsize of 16 for all-in-one restoration task.

SECTION: 7More Ablation Studies

In this section, we provide more ablation studies for LossAgent.

SECTION: 7.1Iterations for Each Stage

In this part, we conduct ablation studies about training iterations for each stage. As demonstrated in Table10, a moderate choice of 5000 training iterations for each stage achieves the best results. As if iterations are small (i.e., 2500), when reaching the end of training, the list of historical loss weights tends to become very long, thus making it difficult to perform reasoning. As if iterations are large (i.e., 10000), the total update steps tend to be insufficient for a reasonable adjustment of loss weights during training, thereby causing suboptimal results. Therefore, we select the optimal iteration steps for the classical image SR task to be 5000. We apply the same principle to the other two tasks, as listed in Table2.

SECTION: 7.2Testing Image Set

As a crucial part of generating feedback from external expert models, the choice of the testing image setis important. We observe that using the sampled Set14[62]as the testing image set achieves a better CLIPIQA score compared to using the sampled DIV2K[1]. We attribute this phenomenon to the relatively high resolution of the DIV2K images. Since some advanced IQA metrics leverage a pre-trained vision encoder to resize input images, this results in originally similar high-resolution images becoming even harder to distinguish after resizing. Consequently, the IQA model may assign similar or even identical scores to these images, failing to provide useful information to our LossAgent. This can cause the LLM to hallucinate and make unreasonable inferences, leading to incorrect adjustment of loss weights. As a result, we choose Set14 as the testing image set for the classical image SR task. We apply the same principle to the other two tasks.

SECTION: 7.3The Illustration of Loss Weight Curves

To provide a more intuitive understanding of how LossAgent updates the loss weights, we provide a visualization of the loss weight curves on classical image super-resolution task in Figure4.

SECTION: 8Case Study

In this section, we provide a case study on classical image super-resolution in Figure5to help readers better understand the process of LossAgent. As demonstrated, LossAgent is capable of analyzing the relationships between loss weights and score feedback from historical prompts (we mark such analysis in green). Moreover, LossAgent updates new loss weights considering not only these relationships but also the functionality of each loss function (we mark such thoughts in red). To get the updated loss weights, we use a Python program to parse the pattern “L1:Perceptual:GAN=0.7:0.3:0.05” into the numeric array “[0.7, 0.3, 0.05]”. Therefore, the correctness of this pattern is important. As analyzed in Section4.3, we use rule-based formatting constraints, which is helpful for the LLaMA3 model.