SECTION: Exploring Aleatoric Uncertainty in Object Detection via Vision Foundation Models

Datasets collected from the open world unavoidably suffer from various forms of randomness or noiseness, leading to the ubiquity of aleatoric (data) uncertainty. Quantifying such uncertainty is particularly pivotal for object detection, where images contain multi-scale objects with occlusion, obscureness, and even noisy annotations, in contrast to images with centric and similar-scale objects in classification. This paper suggests modeling and exploiting the uncertainty inherent in object detection data with vision foundation models and develops a data-centric reliable training paradigm. Technically, we propose to estimate the data uncertainty of each object instance based on the feature space of vision foundation models, which are trained on ultra-large-scale datasets and able to exhibit universal data representation. In particular, we assume a mixture-of-Gaussian structure of the object features and devise Mahalanobis distance-based measures to quantify the data uncertainty. Furthermore, we suggest two curial and practical usages of the estimated uncertainty: 1) for defining uncertainty-aware sample filter to abandon noisy and redundant instances to avoid over-fitting, and 2) for defining sample adaptive regularizer to balance easy/hard samples for adaptive training. The estimated aleatoric uncertainty serves as an extra level of annotations of the dataset, so it can be utilized in a plug-and-play manner with any model. Extensive empirical studies verify the effectiveness of the proposed aleatoric uncertainty measure on various advanced detection models and challenging benchmarks.††Preprint. Under review.

SECTION: 1Introduction

Deep learning has witnessed remarkable success in a wide range of scenarios and applications for predictive performance, such as image classification[32,9,44,13], semantic segmentation[47,42], and object detection[2,50,56,40,14]. Datasets collected from the open world unavoidably suffer from various randomness or noiseness[18,4], resulting in ubiquitous uncertainty inherent in the data (i.e.,aleatoricuncertainty or data uncertainty[7,17]). Quantifying such uncertainty is pivotal for comprehending the inherent fluctuations within the training data, which enables the construction of more resilient models that can accommodate and flexibly respond to conditions characterized by inherent uncertainty.

Compared to images with centric and similar-scale objects in classification benchmarks, images in object detection datasets are typically scene-centric and contain multiple objects in varying scales. Especially, some objects are accompanied by occlusion, obscureness, and even noisy annotations due to limited resources and time in the data collection process[31](as observed in Fig.1).
Naturally, the aleatoric uncertainty arises in object detection tasks. However, the majority of aleatoric uncertainty quantification methods target classification or regression problems[18,3,6,51], with few focusing on the fundamental and challenging object detection. To bridge the gap, we aimt to investigate aleatoric uncertainty at thedetection level, i.e., in the context of object detection.

It is almost impossible for human annotators to compare samples within the dataset and quantify each sample’s aleatoric uncertainty due to unaffordable time and resource costs.
When discriminative features from object instances are salient and obvious, we consider the aleatoric uncertainty to be low, as such instances can be easily detected and assigned to their semantic classes. However, when some of these features are occluded or missing, aleatoric uncertainty increases, making it more challenging to localize and classify such instances. Vision foundation models have learned rich and well-structured features from large-scale training data, enabling them to compare samples from diverse perspectives. In this paper, we opt for SAM[20]as the foundation model and bridge the gap in utilizing SAM to characterize aleatoric uncertainty at the detection level. SAM was trained on the expansive SA-1B dataset[20]that contains more than 1 billion masks spread over 11 million carefully curated images and has established superior performance in addressing open-world vision tasks. Unlike vision foundation models CLIP[37]and DINOv2[35], SAM received direct supervision in solving dense prediction tasks. Its vision encoder outputs high-resolution feature maps, which is beneficial for processing object detection datasets where objects can vary significantly in size.

In light of this, we proceed to capture the feature of each object instance in the feature space of SAM for measuring aleatoric uncertainty. Building on top of the existing ground-truth bounding boxes and class labels, we perform bounding box-based feature pooling to get a feature vector per object. While SAM was trained in a class-agnostic manner, semantically similar instances are found to be closely crowded together in its feature space. In recent work[46], one can directly assign semantics and generate captions based on SAM’s output embeddings via some text feature mixture and decoder. Based on these observations, we employ a class-conditional Gaussian distribution to model the feature distribution and derive a Mahalanobis distance-based uncertainty score as a measure of aleatoric uncertainty. As shown in Fig.1, the proposed uncertainty score effectively captures pertinent data characteristics such as object difficulty and noise level, aligning well with human cognitive level.

Furthermore, we devise two practical and crucial usages related to aleatoric uncertainty: uncertainty-aware sample filtering and loss regularization. We can utilize them as proxy tasks to examine the quality of aleatoric uncertainty and enhance detection performance.
Firstly, we introduce a quantile function based on aleatoric uncertainty scores to abandon noisy samples that may mislead model training, as well as redundant samples within sub-populations grouped by uncertainty scores to improve training efficiency. Secondly, we propose a sample adaptive training objective that incorporates uncertainty-aware entropy to regularize the binary cross-entropy loss, which can balance easy and hard samples more knowledgeably compared to typical focal loss[27]and entropy regularization[36].

Aleatoric uncertainty measure can serve as additional annotations of training data thus it can be employed for any model in a plug-and-play way. We conduct extensive empirical studies on challenging benchmarks: MS-COCO[26]and BDD100K[48], corresponding to natural and self-driving scenarios, respectively. These studies were performed using various advanced detectors, e.g., CNN-based YOLOX[12]and FCOS[43], and transformer-based Deformable DETR[56]and DINO[50], to evidence the effectiveness of aleatoric uncertainty measure. We first show that the sample adaptive regularizer incorporated data uncertainty can improve predictive performance regarding averaged precision (AP) and recall (AR). Furthermore, significant performance gains are observed when aleatoric uncertainty is exploited to abandon noisy samples, and our uncertainty-aware filter strategy outperforms the uniform sampling for redundant instances filtering. Finally, we conduct informative ablation studies to show the robustness of hyper-parameters and further explore the potential of aleatoric uncertainty.

SECTION: 2Related Works

Wide applications of SAM.SAM[20]is a vision foundation model designed to address dense prediction tasks by outputting instance masks and parts within regions of interest specified via visual prompts such as points and bounding boxes. Its strong generalization capabilities across domains have enabled a wide spectrum of downstream use cases. While SAM itself only provides class-agnostic masks, it can be utilized after semantic-aware object detection to generate masks for each bounding box. For instance, Grounded-SAM[41]that connects SAM with Grounding DINO[30]is a strong open-world object detection and segmentation model with text prompts. Exploiting caption models[21,22]or image tagging models[15,52,16]to get semantic descriptions of images and further use them as text prompts, Grounded-SAM serves as an effective auto-labeling tool. Additionally, SAM has been employed in segmentation tasks within industrial defect segmentation[1,23]and medical image segmentation[53].

In recent work[46], SAM was found to know semantics implicitly. Instead of starting from a semantic-aware object detection model, SAM can do captioning and assign semantic classes to the generated masks through a combination of text feature mixture and a text decoder following its vision encoder. We target a novel use case of SAM: annotating the aleatoric uncertainty of each training sample, which is distinct from the annotations of usual bounding boxes and masks. We benefit from the implicit semantic knowledge in the feature space of SAM’s vision encoder. Nevertheless, our use case does not rely on an extra text decoder or feature mixture.

Understanding data distribution provides insights into data structure, the generation of additional samples following the same distribution, and out-of-distribution (OOD) detection. Leveraging feature extractors trained to provide compact and informative data representations, feature space density modeling has been proven more effective for tasks like OOD detection, e.g.,[19,39,25]. Based on the familiarity hypothesis in[8], relying on rich features is particularly beneficial. Due to their large-scale training sets, the vision encoders of foundation models like SAM effectively fulfill this purpose.
While various density modeling techniques have been developed and OOD detection is one of the main use cases, we introduce a new use case: aleatoric uncertainty estimation, which is distinct from OOD detection. Although we employ a standard density modeling method, the achieved gains highlight the potential in this novel application.

In deep learning, uncertainty can be classified into two categories:aleatoricor data uncertainty andepistemicor model uncertainty[7,18,17].[6]propose a decomposition method of uncertainty to capture aleatoric uncertainty from the predictive distribution of Bayesian neural networks with latent input variables. Similarly,[18]developed a technique using MC-dropout[11]to independently characterize both uncertainty components.[51]propose a prediction-model-agnostic denoising approach to estimate aleatoric uncertainty for regression by augmenting a variance approximation module under the assumption of the zero mean distribution of data noise.[3]introduces a data uncertainty-aware method for face recognition by learning feature (mean) and uncertainty (variance) simultaneously in the feature embedding. Prior works mainly estimate aleatoric uncertainty for classification or regression tasks by predictive uncertainty decomposition on task-specific data distribution and training model. This explores the ability of vision foundation models trained on diverse data to be used to quantify data uncertainty from a data distribution perspective.

SECTION: 3Aleatoric Uncertainty Quantification in Object Detection

As data collection and annotation processes inevitably suffer from varying degrees of corruption, aleatoric uncertainty (i.e., data uncertainty) is ubiquitous in real-world datasets. Accurately characterizing data uncertainty can help us better understand training data to utilize it more efficiently and reliably, especially for modern large-scale datasets. To quantify data uncertainty, we leverage SAM to extract the feature of each object instance and model the training data distribution by fitting a multivariate Gaussian distribution in the feature space. Prior work[5]has shown the effectiveness of Gaussian distribution modeling on classification tasks. We anticipate that easy samples with low uncertainty will be closely crowded together, while hard/noisy ones with high uncertainty will be far away from the population and more dispersed. A similar intuition is utilized to quantify uncertainty in the classification literature in previous works[45,34]. From the perspective of density estimation within feature distribution, we derive a Mahalanobis distance-based uncertainty score to represent aleatoric uncertainty. We detail the whole process in Algorithm1.

The training dataset consists of the image-label pairs:withand, andrepresents the set of ground-truths for each image whereandis the bounding box and binary mask for each object instance, andis the corresponding class. Letdenote the feature map layer of the vision encoder in SAM, and we can employ it to obtain each image’s feature embedding. Building onand corresponding ground-truths:or, we further acquire each object’s feature vector:. The conditional Gaussian distribution with the classcan be defined as:

whereis the mean vector for class, andis an averaged covariance matrix shared by all classes for all training samples. Specifically, we can empirically estimate them by

whereis the number of training samples (i.e., object instances) with the label.

Leveraging the class-conditional Gaussian distributions fitted above, we measure the Mahalanobis distance between training objectand the corresponding class-conditional Gaussian distribution to represent the aleatoric uncertainty of each object in the training set., i.e.,

The Mahalanobis distancemeasures the distance between an object and the centroid of the category. A smallindicates that the object has typical features of the sub-population belonging to this class and boils down to low data uncertainty. Oppositely, the object with the hightends to contain ambiguous information (i.e., insufficient identifying characteristic) or noisy annotation (i.e., ambiguous bounding box or even wrong class label).

In order to more conveniently exploit data uncertainty, we employ a scaling procedure to transform the Mahalanobis distance to a range of, which is achieved through a combination of log transformation and min-max normalization techniques:

where the Mahalanobis distance belonging to each class is individually normalized to. Fig.2illustrates the distribution offor the training data of MS-COCO[26], and we also show the distribution by categories in Appendix. It is evident that a small percentage (approximately 5%-10%) of samples exhibit high uncertainty scores, implying the presence of noisy objects within the dataset. Additionally, a significant proportion of objects in the MS-COCO dataset are characterized as difficult/hard, as evidenced by the high density of uncertainty scores within the range of.

Furthermore, we give some sorting examples and their uncertainty scores belonging to classes “bus” and “zebra” in Fig1, see Appendix for more visual examples. We can observe a high level of agreement between human visual perception and MD-based data uncertainty scores. In conclusion, our empirical investigation suggests that:

The low data uncertainty represents an easy sample that can be readily recognized by humans or models due to abundant and unbroken features.

The objects with medium uncertainty scores are often located in distant positions or partially obscured within an image, posing challenges for accurate classification and detection.

The objects with high uncertainty often indicate low-quality samples, which may stem from unrecognizable instances or misleading annotated bounding boxes and categories. These instances are prone to being regarded as data noise due to their ambiguity or inconsistency.

SECTION: 4A Recipe for Aleatoric Uncertainty in Object Detection

This section explores the practical usage of aleatoric uncertainty in object detection. Based on estimated aleatoric uncertainty, we propose various data filtering strategies, which aim to remove underlying noisy and redundant objects from the training dataset, leading to more efficient and reliable model training. To further enhance the predictive performance, we develop an uncertainty-aware regularizer and incorporate it into the loss function. Moreover, these two usages can also serve as a proxy for examining the quality of estimated aleatoric uncertainty. It is worth noting that we can calculate the per-object uncertainty score beforehand and treat it as an offline proxy, so the proposed uncertainty-aware usages do not take any additional computational overhead during the model training. In particular, uncertainty scores can serve as an extra level of annotations of the training set and be utilized for any model in a plug-and-play way.

SECTION: 4.1Aleatoric uncertainty-aware data filtering

As shown in Fig.1and2, some objects have incomplete discriminative features or incorrect annotations, which can damage model training and lead to poor predictive performance. Given this, we propose discarding possible noisy samples that are harmful to model learning. Specifically, we employ a quantile function to discard objects with high uncertainty scores during model training. Letdenote the cumulative distribution function (CDF) of uncertainty scores over all classes, and then we can use the inverse function of CDFto represent its quantile function:

After that, we retain objectsthat are smaller than the specific quantile(e.g,) used for model training, i.e.,

Considering the class-imbalanced issues[26]in the MS-COCO dataset, we also try discarding noisy objects according to per class, i.e., first calculating the inverse function of CDF of each class, referred to as, and then retaining the objectsthat meet:

whereis the number of object instances with the label.

Object detection datasets, such as MS-COCO, typically contain numerous similar objects. Thus, an additional useful application of the uncertainty score is eliminating potentially redundant objects from the training set. Objects with closely clustered uncertainty scores within each class often exhibit similar or common patterns. Consequently, the model may only need to learn from a subset of these instances to achieve satisfactory performance. In this spirit, we can select a certain proportion of objects, known as valuable samples, from each sub-population with close uncertainty scores to enhance training efficiency while preserving model performance.

Concretely, we group the uncertainty score of each object intointerval bins for each class (each of size) and randomly throw awayobjects in each bin. Letbe the set of indices of samples with classwhose uncertainty score falls into the interval, and the object set that we retain:can be denoted as:

SECTION: 4.2Aleatoric uncertainty-aware Regularization

The uncertainty score serves as a valuable tool for characterizing each object’s difficulty and noise level, as demonstrated in Fig.1. Therefore, it is worth exploring how to leverage this knowledge to enhance model performance. The object detection models usually optimize multiple losses, e.g.,, and the standard training loss formulation is data uncertainty agnostic. The previous work, such as focal loss[27], primarily focuses on fitting hard samples and mitigating overfitting to easy samples. It is defined as, whereis the model’s predictive probability of the ground-truth class andis a predefined coefficient designed to alleviate the model overfitting to the already confident (i.e.,close to 1) majority class. Yet, the focal loss is sensitive to coefficientand may lead to inappropriate or even harmful regularization for some samples based on the predicted probability.

To address this issue, we incorporate data uncertainty scoreinto classification lossand propose an uncertainty-aware entropy to regularize the binary cross-entropy loss. Besides, prior work[33]has demonstrated that cross-entropy loss equipped with a maximum-entropy regularizer can be interpreted as the lower bound of focal loss, resulting in the ability of the proposed uncertainty-aware entropy regularizer to ensure the optimal performance of the model. As a result, we arrive at the sample adaptive classification loss:

whereandrefer to the predictive binary probability distribution and corresponding entropy for the object.is a predefined coefficient to control the strength of entropy regularization, which generally ranges from. Since we can estimate the per-object uncertainty score once before training, the proposed training objective scarcely introduces additional computing overhead.

SECTION: 5Experiments

To verify the effectiveness of the proposed aleatoric uncertainty measure in conveying valuable information about the dataset, we report the predictive performance when employing it for both data filtering and sample adaptive regularization. We mainly present primary experimental results on the challenging benchmark MS-COCO[26]for the bounding box detection task and use Deformable DETR[57]and anchor-free YOLOX[12]as the object detection models. In the Appendix, we provide more results for other detection models, such as FCOS[43]and DINO[50]. We also validate our method on the challenging self-driving dataset: BDD100K[48]. Moreover, we ablate the robustness of the proposed uncertainty-aware entropic regularizer to hyper-parameters.

Datasets.The 118k train set (train2017) and the 5k validation set (val2017) of COCO 2017 are utilized for training and evaluating the model on the bounding box (bbox) detection task. COCO 2017 comprises 80 classes and encompasses a diverse range of scenes, including indoor and outdoor environments, urban and rural settings, as well as various lighting and weather conditions. The training set contains, on average, 7 instances per image, with a maximum of 63 instances observed in a single image. These instances span a wide range of sizes, from small to large.

Metrics.To evaluate the prediction quality, we report standard COCO metrics, including averaged precision (AP) and recall (AR) over IoU thresholds,,, and,,for large, medium and small objects.

Implementation Details.In our study, we mainly employ two typical detection models as detectors: the transformer-based Deformable DETR (trained up to Epoch 50, with a 4-scale setup) and the CNN-based anchor-free YOLOX (specifically, YOLOX-S and YOLOX-M versions), and model details are summarized in Tab.2. We also report the performance of more detectors in the Appendix.
Deformable DETR surpasses previous DETR[2]in both performance and efficiency, achieving better performance than DETR (especially on small objects) with 10×less training epochs by combining the best of the sparse spatial sampling of deformable convolution.
YOLOX transforms the traditional YOLO detector, such as YOLOv3[38], into an anchor-free method and enhances it with a decoupled head and the proposed label assignment strategy SimOTA, thereby achieving state-of-the-art performance. As for implementation details, e.g., data preprocessing, experimental settings, etc., we completely follow the original paper. Moreover, it is important to note that we do not use strong data augmentation techniques such as Mixup[49]for all experiments. For the hyper-parameters in the proposed training loss (9), we setas 0.2 and 0.3 for YOLOX and Deformable DETR, respectively.

SECTION: 5.1Performance on uncertainty-aware regularizer

Table1demonstrates the performance comparison between binary cross-entropy with a constant weighting (Entropy) and uncertainty-aware entropy (UA-entropy) for YOLOX-S, YOLOX-M, and Deformable DETR. The proposed uncertainty-aware entropic regularizer is obviously the top-performing one and leads to a consistent improvement across all detection models. Notably, the performance gain is also prominent for the small-scale models, i.e., YOLOX-S and YOLOX-M, indicating that the proposed data uncertainty measure can convey valuable information about the dataset to model learning. More importantly, the superior performance gain of the proposed sample adaptive regularizer on small-scale models holds significant implications for real-world model deployment. Conversely, regularizing each sample with equal entropy shows only slight improvement or even deteriorates model performance, especially for the small-scale detector YOLOX-S (-0.88% AP). Moreover, the proposed method also achieves significant performance gain on more advanced Deformable DETR with focal loss, implying that the proposed training objective effectively combines data uncertainty to more reasonably balance the learning of difficult and easy samples. We also report the performance of other detectors (i.e., FCOS and DINO) in the Appendix, showing the consistent performance gain of the proposed UA-entropy.

SECTION: 5.2Performance on uncertainty-aware data filter

We verify the effectiveness of measured data uncertainty in filtering out noisy samples from the training set. Table3reports the results of discarding samples corresponding to the highest 5% and 10% uncertainty scores (i.e., filtering out possible noisy samples) for different models. We can observe that the predictive performance of each model is improved when samples with high uncertainty scores are abandoned both for 95% data and 90% data settings, which indicates that the reliability of detecting noisy samples in the training data and these samples do not contribute valuable supervision to model training. Therefore, our data uncertainty scores can serve as effective indicators for identifying noisy samples and mitigating the model learning from misleading supervisory information, thereby enhancing predictive performance.

Afterwards, we examine the effectiveness of the redundant samples filtering by comparing uncertainty-aware and random discarding (i.e., uniformly dropping a certain percentage of samples) strategies, with the experimental results summarized in Table4. As shown, the proposed uncertainty-aware filtering strategy consistently outperforms uniform sampling for all metrics under different data percentages, suggesting that leveraging data uncertainty scores to cluster samples (i.e., grouping overall training data into multiple subsets with similar patterns) is reliable. Furthermore, uniforming data selection can dramatically degrade predictive performance on relatively small-capacity models like YOLOX-S. Oppositely, our uncertainty-aware data sampling still maintains superior performance, with only a marginal reduction of 0.8% in AP while discarding 30% of the data. Interestingly, uncertainty-aware data sampling with 95% data surpasses predictive performance with 100% data, which further verifies the existence of noisy samples in training data. In the future, the proposed uncertainty-aware data filtering has the potential to emerge as a new paradigm for data pruning.

SECTION: 5.3Ablation studies

This section further examines the effectiveness of our aleatoric uncertainty measure on the self-driving dataset. We also conduct ablation studies on hyper-parametersin Eqn. (9) and the combination of aleatoric uncertainty-aware filter and regularizer.

We further examine the performance of the proposed data uncertainty measure for object detection in the self-driving scenario using the BDD100K dataset[48]. This large-scale and long-tailed driving video dataset includes a diverse set of 100k annotated images (70k/10k/20k images for train/val/test set) with 10 classes for object detection. Table5presents the performance of data uncertainty scores used for entropy regularization and noisy sample filtering, showing significant gains in terms of average precision (AP) on YOLOX. We can especially observe a more prominent gain on small-scale YOLOX-S. All of this further confirms the superior scalability of our method across different real-world tasks.

We analyze the effect of hyper-parameteron predictive performance in the loss function (9). Table6reports the comparison results under variousfor constant weighting and uncertainty-aware entropy regularization on YOLOX-S. As shown, the entropy penalty with a constant weighting is particularly sensitive to hyper-parameter, with large values (e.g., 0.4) resulting in significantly poor performance. In contrast, the proposed data uncertainty-aware regularizer is robust toowing to sample-uncertainty adaptive weighting, which highlights that data uncertainty provides a more reliable way to balance difficult and easy samples.

Table1and4have shown the effectiveness of data uncertainty for redundant sample filtering and entropy regularization. It is worth exploring whether the performance of uncertainty-aware data filtering can be further enhanced by incorporating sample-adaptive regularization. To this end, we compare the predictive performance of using uncertainty-aware data filtering alone versus its combination with sample-adaptive regularization under different proportions of training data. As shown in Fig.A4in Appendix, the proposed sample-adaptive regularization (UA-entropy) consistently improves the performance of redundant sample filtering on YOLOX-S and YOLOX-M by incorporating data uncertainty of each object to adaptively balance the impact of easy and hard samples within the remaining data.

SECTION: 6Conclusions and Future Works

This work investigates an important yet under-explored problem – how to accurately characterize aleatoric uncertainty in object detection. Profiting from the powerful feature representation capabilities of vision foundation models, we propose to estimate the aleatoric uncertainty of each object based on the representation space of foundation models. Furthermore, we explore two practical uncertainty-related tasks: aleatoric uncertainty-aware sample filtering and loss regularization. These tasks serve a dual purpose: examining the quality of aleatoric uncertainty and being used to develop a data-centric learning paradigm aimed at enhancing model performance and training efficiency. Extensive empirical studies validate the effectiveness of the proposed aleatoric uncertainty measure, demonstrating consistent performance gains across various advanced detection models.

In the future, we can explore leveraging various vision foundation models, e.g., DINOv2[35]and GroundingDINO[30], to quantify data uncertainty at the detection level. Additionally, it is critical to develop more techniques, such as knowledge distillation, to extract valuable knowledge from foundation models for uncertainty quantification. Large Vision Language Models (LVLMs)[29,55]bridge the gap between visual and linguistic understanding and exhibit the potential towards achieving general artificial intelligence. However, they also easily produce hallucinations or generate inconsistent responses with input images[28,54,24]. Typically, LVLMs are fine-tuned on language-image instruction-following data generated from COCO, so the proposed noisy sample filtering strategy could be beneficial in enhancing robustness and mitigating hallucinations.

SECTION: References

Supplementary Material