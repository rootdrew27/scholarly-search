SECTION: Emulating Clinical Quality Muscle B-mode Ultrasound Images from Plane Wave Images Using a Two-Stage Machine Learning Model
Research ultrasound scanners such as the Verasonics Vantage™ often lack the advanced image processing algorithms used by clinical systems. Image quality is even lower in plane wave imaging – often used for shear wave elasticity imaging (SWEI) – which sacrifices spatial resolution for temporal resolution. As a result, delay-and-summed images acquired from SWEI have limited interpretability. In this project, a two-stage machine learning model was trained to enhance single plane wave images of muscle acquired with a Verasonics Vantage™ system. The first stage of the model consists of a U-Net trained to emulate plane wave compounding, histogram matching, and unsharp masking using paired images. The second stage consists of a CycleGAN trained to emulate clinical muscle B-modes using unpaired images. This two-stage model was implemented on the Verasonics Vantage™ research ultrasound scanner, and its ability to provide high-speed image formation at a frame rate of 28.5 ± 0.6 FPS from a single plane wave transmit was demonstrated. A reader study with two physicians demonstrated that these processed images had significantly greater structural fidelity and less speckle than the original plane wave images.

SECTION: 
Ultrasound is a widely used medical imaging modality due to it being low-cost, portable, and non-ionizing. However, ultrasound images are degraded by speckle, electronic noise, differences in tissue sound speed, and other sources of error. Because of this, commercial clinical ultrasound scanners use proprietary post-processing algorithms to enhance images. Unfortunately, research scanners, such as the Verasonics Vantage™, lack these post-processing algorithms, often resulting in images that appear to be of lower quality. Because reader studies have demonstrated that clinicians prefer the post-processed images that clinical systems offer, it is difficult to accurately compare images from research scanners to images from clinical ultrasound systems.

Previous studies have attempted to address this disparity between images from research scanners and clinical scanners using machine-learning approaches. Huang et. al. introduced MimickNet, a CycleGAN that converts conventional delay-and-summed images into approximate Siemens Dynamic Tissue Contrast Enhanced (DTCE™) post-processed images. The utility of MimickNet was successfully demonstrated on fetal, phantom, and liver targets. Additionally, histogram matching has also been proposed as a normalization method to fairly compare images across ultrasound image formation methods. In other studies, researchers used CycleGANs to approximate images acquired with cart-based ultrasound systems from images acquired with point-of-care ultrasound devices for diverse tissues including cardiac, thyroid, carotid, breast, and forearm and calf muscle. In, authors applied a GAN to translate ultrasound images acquired with diverse imaging systems and parameters into images that were seemingly taken from the same system.

Another disadvantage of focused delay-and-sum ultrasound (fDAS-US) is the time required to acquire each frame. For a B-mode image to be produced, multiple focused transmit beams are used, limiting the frame rate. This makes fDAS-US less unsuitable for applications such as shear wave imaging or elastography where high frame rates are required. For these applications, plane wave imaging and plane wave compounding are often used instead. Plane wave imaging uses a single unfocused plane wave transmit to insonify the tissue in the field of view. Because the frame rate is only limited by the duration of a single round-trip pulse-echo, kilohertz frame rates can be achieved using plane wave imaging. However, because the transmit beam is unfocused in plane wave imaging, the main lobe of the ultrasound system’s point spread function is larger, reducing image resolution. Additionally, the total acoustic output is lower with fewer transmits, resulting in decreased SNR.

To compensate for the limitations of plane wave imaging, plane wave compounding is often utilized. In plane wave compounding, multiple plane waves transmitted at different angles are coherently compounded to acquire improved images. Although spatial resolution and contrast improve as the number of plane waves transmitted increases, frame rate decreases. Because of this decrease in frame rate, past work has demonstrated that it is possible to emulate plane wave compounded (PWC) images from a single plane wave using machine learning approaches. There has also been research in applying CNNs, GANs, and CycleGANs for the enhancement and super-resolution of single plane wave images of phantoms, carotid, and thyroid.

One important application for ultrasound is muscle imaging. Muscle ultrasound is often used for diagnosing myopathies and muscle injuries. There has also been a large interest in musculoskeletal SWEI as studies have indicated a link between shear wave speeds and myopathies, dystrophies, and muscle spasticities. However, muscle is a complex tissue due to the presence of transversely isotropic muscle fibers and fascicles. In transverse images where the transducer is perpendicular to the direction of the muscle fibers, muscle has an appearance dubbed the “starry night appearance”. In longitudinal images where the transducer is parallel to the direction of the muscle fibers, the muscle fascicles appear as relatively uniform parallel lines. This dependence on transducer orientation poses a challenge for post-processing algorithms designed for muscle.

Our group has observed that SWEI DAS images, due to their low resolution, have limited utility for identifying tissue structures or further analyses such as tissue segmentation. Currently, there is a lack of post-processing algorithms that can enhance plane wave images of muscle which are often acquired for muscle SWEI in real-time. As seen in Figure, applying MimickNet to muscle images yielded poor-quality images as the model was not trained on muscle data nor plane wave data, rather B-mode images of fetal, phantom, and liver targets. To address this gap, we present a two-stage machine-learning approach to approximate clinical quality images of muscle from single plane waves. These machine learning models are implemented on the Verasonics Vantage™ system to provide real-time enhancement of single plane wave muscle images.

SECTION: 
To train each stage of the two-stage machine learning model independently, two datasets were used: a paired dataset for the first stage, and an unpaired dataset for the second stage.

SECTION: 
The paired dataset consists of 15,948 images of the vastus lateralis muscle (4 cm lateral by 4 cm axial) acquired from 10 healthy volunteers under a Duke IRB-approved protocol. These images were collected on the Verasonics Vantage™ using an L7-4 probe during SWEI acquisitions. The setup for collecting these images is described by Paley et. al., and consists of placing the transducer 2/3 the distance from the lateral condyle to the greater trochanter of the femur of each volunteer’s self-described dominant leg. Because muscle is transversely isotropic due to the presence of muscle fibers, it was necessary to train the machine learning model on both transverse (across the fiber) and longitudinal (along the fiber) images of muscle. The transducer was rotated by a Newport rotation stage across 36 different angles spanning 180 degrees, with the transducer repositioned as needed to maintain contact during the rotation. Thus, the dataset includes both transverse and isotropic views of the vastus lateralis. In this paper, we consider any images taken at the 18 angles most parallel to the muscle fibers to be longitudinal images, and images taken at the remaining 18 angles are considered transverse.

The beamformed data from a single non-steered (0°) plane wave was envelope-detected and log-compressed to generate the input training images. Paired ground truth images were generated using 12 plane waves acquired at 3 different angles: -3°, 0°, and 3°. These 12-steered plane wave images were coherently compounded, envelope-detected, and log-compressed. These images were then filtered with a traditional image processing pipeline consisting of histogram matching and unsharp maskingto produce the final ground truth images. The SWEI B-modes had an image size of 97x191 pixels before being upsampled to 512x512 pixels using bicubic interpolation.

SECTION: 
The second stage of the model is a CycleGAN trained to perform style transfer between muscle images acquired with the Verasonics Vantage™ research scanner and clinical ultrasound scanners. The input image domain consists of the compounded and filtered images as described in the Paired Dataset section. The dataset used for the clinical image domain consists of images sourced from multiple online repositories listed in Table.

Images containing artifacts from dead elements, poor contact, and motion were excluded. Images that had very low resolution, were blurry, or contained substantial annotations were also removed. Images that contained annotations located in the periphery of the image or were screenshots were cropped to isolate the ultrasound image. The total number of images in the clinical domain dataset decreased from 6,483 to 3,500 after removing these poor-quality images.

Figuredisplays example images from the clinical image repositories (Table). As seen from the example images, these online datasets exhibit different contrasts, resolutions, and dynamic ranges. Additionally, the dataset is largely comprised of transverse views of muscle with 2,354 transverse muscle images as compared to 1,146 longitudinal images.

Both the paired and unpaired datasets were split 80%, 10%, and 10% into training, validation, and testing sets respectively. During training, images from both datasets were augmented by random flipping and cropping.

SECTION: 
A two-stage machine learning model was trained on the paired and unpaired datasets. For the first stage, a U-Net was trained on the paired dataset to approximate not only plane wave compounding, but also a traditional image-processing pipeline consisting of histogram matching and unsharp filtering. The U-Net’s architecture is the same as the second stage CycleGAN’s generator presented in Figure. This U-Net was trained over 100 epochs using a batch size of 1, the ADAM optimizer with a learning rate of 2e-4, and L1 loss. The training weights after the epoch with the lowest validation loss were saved.

The second stage uses a CycleGAN to translate the output of the first stage into images that resemble clinical muscle images. The CycleGAN consists of 2 generators and 2 discriminators responsible for performing style transfer between research scanner images and clinical scanner images. During training, the CycleGAN uses the unpaired dataset described above. During inference, the output of the first stage is used as the input for the forward generator of the CycleGAN. The CycleGAN is based upon MimickNetand is presented in Figure. The output of the discriminator is a 16x16x1 matrix following the PatchGAN approach, and mean squared error was used for all loss functions following the LSGAN approach. The loss of the forward generator G (), which translates from research scanner images to clinical scanner images, is described as follows:

Whererepresents the adversarial loss,represents the cycle-consistency loss, andrepresents the identity loss. The loss of the reverse generator F (), which translates from clinical scanner images to research scanner images, is similar:

Here,andare tunable hyperparameters.

To stabilize the training of the CycleGAN, parameter sweeps were performed over batch size,,, learning rate and learning rate schedule (using the ADAM optimizer), number of layers and filters (for both generators and both discriminators), and normalization techniques including batch, instance, and spectral normalization. The final parameters were a batch size of 1; aof 1 and aof 0.1; a piecewise learning rate of 1e-4, 5e-5, and 1e-5 after 0, 10,000, and 30,000 steps respectively; layers and filters as displayed in Figure; and spectral normalization applied only to the discriminator of the research scanner image domain.

SECTION: 
As our Verasonics system was limited to MATLAB R2019a, it was necessary to import the stage 1 and stage 2 models, which were trained with Python 3.7 and TensorFlow 2.9.1, into MATLAB R2019a. To do so, the TensorFlow models were first converted into the Open Neural Network Exchange (ONNX opset-9) format and imported into MATLAB. Whereas TensorFlow’s implementation of the transposed convolution layer pads the input image, MATLAB’s implementation crops the output image. Due to this difference, these layers were replaced using MATLAB’s implementation while preserving the original kernel weights. Finally, the layers were assembled into MATLAB DAGNetworks.

To incorporate the model into the Verasonics acquisition sequences, a Verasonics External Process object was created which resizes, envelope-detects, and log-compresses the plane wave data before post-processing the beamformed image with the DAGNetworks. The output is displayed on a persistent MATLAB figure which serves as a custom display window. The custom display window displays the plane wave image produced by the Verasonics and the sequential outputs of the first and second stages in real-time. Using single plane wave transmits and dynamic receive focusing with an F-number of 0.81, this system was used to image the vastus lateralis of a healthy volunteer as seen in Figure.

For real-world frame rate comparisons, the External Process object was modified to either use histogram matching (to serve as a baseline reference), the first ML stage, or the combined ML stages, and the average frame rate was evaluated with each method.

SECTION: 
Due to the difficulty of obtaining accurate quantitative measurements of image quality, especially for unpaired images as in the case of the CycleGAN, a reader study was performed by two neurologists from the Duke University Medical Center (LHW and YH). Each reader evaluated 24 sets of muscle ultrasound images. This sample size was determined using a power analysis with an estimated Cohen’s effect size of 0.35. Each set was composed of 4 images: the plane wave input image, the plane wave compounded and filtered image, the output of the first ML stage, and the output of the second ML stage. Readers were asked to score each image based on 2 criteria on a Likert-type scale describing subjective levels of image quality from 0 to 3. The criteria are described as follows:

Amount of speckle (or noise) present in the image. A score of 0 corresponds to low amounts of speckle in the image, and a score of 3 corresponds to large amounts of speckle.

Structural fidelity (how clear and distinct the muscle fibers and fascicles are). A score of 0 corresponds to low structural fidelity, and a score of 3 corresponds to high structural fidelity.

Readers were encouraged to use the full range of the scoring scale (from 0 to 3). To help familiarize readers with the image presentation format and the range of image qualities in the dataset, the first 4 sets of images were used as examples and were excluded during data analysis.

In addition to the reader study, ROIs were applied to the same 24 sets of muscle ultrasound images and evaluated with imaging metrics. To evaluate speckle, standard deviation was calculated on a rectangular ROI placed over a hypoechoic region of the image. Contrast-to-noise ratio (CNR) was calculated using rectangular ROIs placed over hyperechoic and hypoechoic regions of the image. The following equation was used for CNR:

To evaluate fiber cohesiveness, standard deviation was calculated over a line segment placed on a muscle fiber or fascicle. An example set of images with ROIs applied is shown in Figure.

SECTION: 
SECTION: 
As seen in Figure, the first stage U-Net was able to produce images that closely resemble the ground truth produced by PWC and filtering using a traditional image processing pipeline (histogram matching and unsharp filtering). To compare the U-Net with the traditional image-processing pipeline, normalized RMSE, structural similarity index measure (SSIM), and processing time per image are tabulated in Table. The normalized RMSE and SSIM for the plane wave input and the U-Net were calculated against the ground truth. The RMSE was normalized using the L2 norm of the ground truth image, and a sliding window size of 11x11 pixels was used for the SSIM. As expected, the U-Net had a lower average normalized RMSE of 0.274 and a higher average SSIM of 0.622 when compared to the plane wave input.

One of the advantages of machine learning models is their facile implementation on GPUs which greatly accelerate training and inference times. Traditional image processing libraries often lack GPU support resulting in slower computation times. The U-Net had an average inference time of 18 ± 2 milliseconds when running on a Tesla V100. In contrast, the traditional image processing pipeline had an average runtime of 202 ± 18 milliseconds per image while running on an Intel Xeon Gold 6252 CPU (2.10 GHz).

SECTION: 
Using the output of the first stage U-Net as the input to the second stage CycleGAN, Figureshows outputs of the CycleGAN during inference. The model increased mean CNR from 3.67 in the input images to 5.11 as seen in Table. The model also decreased the amount of speckle present in the images which is desirable in clinical images, reducing the standard deviation of the speckle from an average of 0.208 in the input images to 0.068 (Table). The model also improved the cohesiveness of the muscle fibers and fascicles by connecting the fibers and fascicles that were interrupted by the speckle pattern. Mean fiber/fascicle standard deviation decreased from 0.162 to 0.115 (Table). This sharpening can be clearly seen in Figure, image 5C, where the hyperechoic line clearly bisects the fatty tissue.

SECTION: 
The speckle and structural fidelity scores for each image were averaged between the two readers. Figureprovides 2 examples of the paired images that the readers evaluated and their corresponding scores. The average scores and standard deviations of the entire reader study are presented in Figure. A Friedman’s ANOVA was conducted for each quality metric between four groups: the input image, the PWC and filtered image, the output of the stage 1 U-Net, and the output of the stage 2 CycleGAN. Following the Friedman’s ANOVA, which resulted in significant p-values0.01 for both the speckle and structural fidelity metrics, a post-hoc Nemenyi’s test was performed. For the speckle quality metric, scores for the plane wave input, PWC and filtered, and stage 1 images did not differ significantly. However, the speckle score for the stage 2 CycleGAN was significantly lower than the other three groups. For the structural fidelity metric, the scores for the PWC and filtered images and the stage 1 images were both 1.5. However, structural fidelity scores for all other pairs of groups differed significantly. Tableshows the p-values of the post-hoc Nemenyi’s test.

These results show that the two-stage machine learning model successfully decreased the amount of speckle present in the plane wave images while improving their structural fidelity. However, the PWC and filtering process (as well as the first stage) increased the amount of speckle present in the images as rated by the readers. There were no significant differences between scores for the stage 1 images and PWC and filtered images, providing further support that the first stage machine learning model successfully emulated the traditional PWC and filtering image-processing pipeline.

SECTION: 
Screenshots of the custom display window during real-time imaging with the Verasonics are shown in Figure, where each row of images is a separate screenshot. Tabledemonstrates that histogram matching had the highest frame rate of 81.8 ± 1.2 FPS and processing with the combined stages had the slowest frame rate of 28.5 ± 0.6 FPS.

SECTION: 
The first stage ML model was trained to emulate plane wave compounding and a traditional image processing pipeline. As seen in Figureand Table, not only did it successfully emulate the traditional image-processing pipeline by halving the normalized RMSE and nearly doubling the SSIM as compared to the input plane wave image, the first stage ML model was able to do so in less time. However, the SSIM of 0.622 for the U-Net is still a relatively poor score for the SSIM metric. Additionally, readers rated the traditional image processing pipeline and first stage as having increased amounts of speckle (Figure), likely due to the unsharp filter amplifying the speckle.

The second stage CycleGAN generates images that closely resemble those produced by clinical scanners as seen in Figure. Combining the two stages together, the combined ML model was able to process plane wave images of skeletal muscle and generate clinical style images in real-time at a frame rate of 28.5 ± 0.6 FPS (Table). This frame rate can easily be considered “real-time,” demonstrating the utility of using machine learning models for real-time ultrasound enhancement. As seen in Table, the model reduced speckle while improving CNR and fiber cohesiveness. This improvement in image quality is especially noticeable in Figurewhere the input image is heavily corrupted by speckle and noise, but the combined model was able to connect muscle fibers and fascicles while suppressing speckle.

One limitation of the model may be attributed to the unpaired dataset. As seen in Table, there are nearly twice the number of transverse images of muscle as there are longitudinal. This imbalance may bias the CycleGAN to produce images that resemble transverse images of muscle even when the input image is a longitudinal image of muscle. Additionally, CycleGANs are used to perform style transfer from one style to another, and the heterogeneous contrasts, resolutions, and dynamic ranges between the four online repositories of clinical images may pose challenges for the CycleGAN when emulating a clinical style.

The use of generative machine learning models in medical imaging is also limited due to their black box natureand ability to hallucinate and introduce false information into the data. The stage 2 CycleGAN, which sharpens and connects muscle fibers and fascia, can also generate structures that were not originally present. The two-stage design of the model helps alleviate these limitations by enabling the reader to select between a highly processed clinical-style image that may contain hallucinated structures, or a less-processed image that is more likely to preserve the original information in the image.

Enhancing plane wave images of muscle to improve muscle and fiber definition is useful because during SWEI acquisitions, large numbers of plane wave images are acquired. While the ML-based image enhancements developed herein are not applicable to SWEI tracking data, enhanced fiber and fascia definition can be helpful for later analyses such as muscle segmentation and determining muscle fiber orientation in B-mode images. Additionally, one significant advantage of this approach is that it can help streamline SWEI acquisitions on the Verasonics. During SWEI acquisitions, it is helpful to periodically obtain B-mode images to verify that the probe is accurately positioned and is imaging the correct target. However, adding B-mode sequences to SWEI acquisition sequences adds complexity and interrupts the SWEI acquisition. Instead, plane wave images acquired during SWEI can be continuously processed and displayed using this model without interruption, providing real-time feedback during acquisitions and thus improving data quality.

SECTION: 
To improve CycleGAN performance, especially for longitudinal muscle images, it would be prudent to obtain a high-quality clinical dataset with a balanced number of longitudinal and transverse images. A clinical dataset with uniform contrast, dynamic range, and resolution may also facilitate training of the CycleGAN and improve model performance.

This two-stage model is very application-specific. While the unpaired clinical dataset consists of a variety of clinical repositories, the paired research dataset consists only of plane wave images of the vastus lateralis acquired on a single probe (L7-4) and acquisition sequence. Training the CycleGAN using data acquired with multiple different transducers, acquisition sequences, and muscle targets may lead to a more generalizable model. The current acquisition sequence reconstructs 97x191 pixel images, and the architecture of the U-Net model restricts the input and output image size to a relatively small resolution of 512x512. In future work, the acquisition sequence and U-Net model can be modified and expanded to generate higher-resolution images. With the success of diffusion models in image generation, cycle-consistent diffusion models can also be implemented for unpaired ultrasound image translation. However, the iterative nature of diffusion models results in long sampling times that limit their ability to perform real-time inference. While methods such as strided sampling and progressive distillation have been developed to speed up inference of diffusion models, these methods are generally still slower than the single-step inference of GANs.

SECTION: 
This project demonstrates the utility of using a two-stage machine learning model to enhance ultrasound images of skeletal muscle in real-time at a frame rate of 28.5 ± 0.6 FPS, specifically muscle images acquired using single plane waves on research scanners. The project also describes a method for implementing TensorFlow models in the Verasonics for real-time image processing. The 2-stage model decreased speckle, as quantified by standard deviation, from 0.208 ± 0.018 in the input images to 0.068 ± 0.014. The model also increased CNR from 3.67 ± 1.09 to 5.11 ± 1.58. Fiber cohesiveness, as quantified by standard deviation across a line fiber or segment, also decreased from 0.162 ± 0.042 to 0.115 ± 0.043. Finally, readers from the Duke University Medical Center rated the images generated by the model as having significantly lower speckle content and higher structural fidelity. Future work may explore expanding the training dataset for improved model performance and generalizability.

SECTION: Code Availability
Code for this paper, including TensorFlow models, training, and detailed Verasonics implementation, is available at

SECTION: Acknowledgments
This work was supported by the Duke University Pratt Research Fellows Program.

SECTION: References