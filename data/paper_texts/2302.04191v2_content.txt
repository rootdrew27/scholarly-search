SECTION: Probing Electroweak Phase Transition in Extended Singlet Scalar Model with Resonantproduction inChannel using Parameterized Machine Learning
In this paper, a collider signature of a heavy Higgs boson atTeV HL-LHC is studied, where the heavy Higgs boson decays into a pair of standard model Higgs boson, which further decays tostate and subsequently tofinal state. To study this, we consider singlet scalar extension of the standard model and select the parameter space and mass of the heavy Higgs boson such that it prefers a strong first-order electroweak phase transition. The study is done following theanalysis of CMS Collaboration and further using parameterized machine learning for final discrimination which simplifies the training process along with an improved discrimination between signal and background over the range of benchmark points. Despite the lower branching fraction, this channel can be a potential probe of the electroweak phase transition with the data sets collected by the CMS and ATLAS experiments at theTeV HL-LHC withof integrated luminosity and a production of resonant di-Higgs signal can be potentially discovered up to 490 GeV of resonance mass.

SECTION: Introduction
Discovery of the Higgs boson at Large Hadron Colliderin 2012 completes the discovery of all the fundamental particles predicted in the standard model (SM). However, there are many questions which remain unanswered, for example, origin of matter-anti matter asymmetry, mechanism of neutrino mass generation, nature of dark matteretc.
The mechanism by which matter anti-matter asymmetry is generated, is called baryogenesis. Depending on the characteristics of electroweak phase transition (EWPT), one can account how much baryon asymmetry is created by standard model and beyond standard model (BSM) processes. To have successful electroweak baryogenesis, three Sakharov conditionsshould be satisfied which includes the deviation from thermal equilibrium or CPT symmetry needs to be broken as imposed by the third Sakharov condition. Considering only the standard model Higgs doublet, electroweak phase transition is not a strong first-order phase transition. Rather it is a crossover transitionand it can not generate sufficient baryon asymmetry of the universe. However, some variations of the standard model for example, singlet scalar extension of the standard model, denoted by the xSM, actually can make electroweak phase transition a strong first-order electroweak phase transition (SFOEWPT). In this paper, we mostly analyze the collider signature of the xSM considering the parameter space which satisfy the SFOEWPT.

Currently, CMS and ATLAS have performed resonant di-Higgs searchesin different decay final states :,and,,,and. So far, there has been no significant excess over SM backgrounds. On the other hand, there are a number of phenomenological studies on the parameter regions suitable for SFOEWPT.
A discovery up to 500 GeV of heavy singlet-like Higgs mass is possible in the,final statesandfinal state with a luminosity of 3at the 14 TeV high-luminosity LHC (HL-LHC). In thefinal state, a discovery is achievable in the range of [350, 600] GeV at the 13 TeV LHC with a luminosity of 3. There are also existing studies of di-Higgs discovery reach for HL-LHC using other models like generic two-Higgs-doublet models (2HDM) in different final states.

In this study, using the xSM, we analyze the prospects of exclusion or discovery in thechannel at the 14 TeV HL-LHC with a luminosity of 3. We considerdecay of, as this has not been covered yet by other studies and there is
an existing study by CMSwhich is used to validate the analysis methodology. Few points are considered to use this final state instead ofor. For thechannel, there is no existing 13 TeV results from CMS or ATLAS for resonant di-Higgs production, so that we can validate our results.
Betweenand, the first one has larger branching ratio, where the second one does not suffer from multijet backgrounds.
Also, we already have an existing study on the same final state of bbWW, which acts as a relevant comparison with that of bbZZ.
In principle,orchannels can also be studied in details, but this is beyond the scope of this paper.
We assume a final combination of both CMS and ATLAS experiments. We choose the benchmark points with mass of BSM Higgs having a range between 300 GeV and 850 GeV producing the maximum signal rate of resonant di-Higgs production and satisfying all the recent experimental constraints coming from electroweak precision data and the Higgs signal rate as well as the theoretical constraints from perturbativity, vacuum stability and a SFOEWPT.

There are several phenomenological studies of resonant di-Higgs production using multivariate analysis and machine learning. In our analysis, once the basic event selection is done, for final signal-to-background discrimination we use parameterized machine learningmethod to apply a single deep neural network (DNN) algorithm for all the benchmark points taking the mass of the resonant particle as a parameter to the network. This parameterized DNN replaces the individual classifiers trained at individual mass points of the resonant particle with a single classifier and simplifies the training process with improved performance. Finally, the signal significance is obtained by the parameterized DNN score distributions of signal and background events. From our study and results shown in Fig., we can conclude as follows :

Despite the lower branching ratio ofchannel, for singlet-like Higgs masses below 490 GeV, the combination of CMS and ATLAS experiments gives significance higher thanin thefinal state along with theandchannels and a discovery can be achieved at the 14 TeV HL-LHC with a luminosity of 3for the regions of parameter space where SFOEWPT is satisfied.

Only CMS search does not achieve discovery significance in this channel, but we can exclude up to 550 GeV of singlet-like Higgs masses.

As per the previous studies done in Ref., our analysis can also be used for a complementary study of gravitational waves along with the di-Higgs production in collider search.

Our work is detailed in following ways : In Sec., we describe the overview of the xSM model along with the theoretical and phenomenological constraints, the requirements for a SFOEWPT and the benchmark points by scanning the parameter space. In Sec., the validation of backgrounds is discussed by comparing with 13 TeV CMS analysis
results. In Sec., we present the analysis of the signal and backgrounds at 14 TeV HL-LHC. Sec.offers a summary and conclusion. In the Appendix, the distributions of the kinematic variables are discussed which are used as input variables of the parameterized DNN for 14 TeV HL-LHC.

SECTION: The xSM Model & EWPT
SECTION: The Model
Most generalised potential of the scalar sector of the xSM takes the form,

whereis the real singlet scalar extension of the standard model. The coefficient,are the couplings through which the SM Higgs doubletmixes with. Ifandare absent, the potential issymmetric under the transformation. However, we keep all the terms here, as these terms have significant role in electroweak phase transition as well as di-Higgs collider phenomenology.

When the electroweak symmetry breaks, the Higgs doubletgets its vacuum expectation value (vev) and let assume the singlet scalaralso gets a positive vev (). For the stability of the Higgs potential, the quartic Higgs coupling should be positive along all the directions, which gives,and. Once these conditions are satisfied, the Higgs potential definitely acquires one or multiple minima. The minimization conditions give the following sets of equations,

Also the condition for stable minimum gives,

In addition to that, the requirements for global minimum and perturbativity boundare imposed numerically, which are as follows,

After EWSB, the fieldsandmix with each other and the mass squared matrix elements are given by,

By diagonalizing the mass matrix one can get the mass eigenvalues as,

The corresponding mass eigenstates are,

whereis the mixing angle betweenand, which is defined as,

Due to the mixing between theand,
standard model Higgs boson and BSM Higgs coupling with pairs of fermions or vector bosons (represented by)
are re-scaled byandrespectively,

To study the resonant di-Higgs production the most important interaction is, whereis the tri-linear coupling given by,

In this work, we only consider the mass hierarchy, so that an on-shellcan decay into anpair. The decay width oftopair is given by,

and the total width ofis given by,

whereis the total width of the SM Higgs boson if its mass becomesand values ofare taken from Ref..
For, the signal rate normalized to the SM value is estimated by,

For, the production cross-section can be written as,

whereis the LHC production cross section of SM Higgs boson when the
SM Higgs mass is equal to.

SECTION: Existing Phenomenological Constraints
The Higgs signal strength measurements severely constrain the mixing angle of the Higgs boson with the BSM Higgs. A global fit is already performed using LHC rundata by marginalizing up toconfidence limit (C.L.) of the Higgs signal strength measurement values in Higgs production channels (,,and) and decays (,,,and), and obtained a upper limit on, which is. We also verify this limit.

There have been many LHC analyses which are focused on the searching of the heavy Higgs boson. We consider the bounds from the existing searches such asand also, wheredecays into,and.
All these constraints have been considered and exclusion region in the plane of () is shown in Ref.. The benchmark points which we are going to consider here are chosen considering all of the above constraints.

The parameters of the xSM model are also constrained by the measurement of the electroweak precision observables (EWPO). The mixing between the SM Higgs and the BSM scalar deviates the values of the oblique parameters (,and) from standard model predictions, which constrain thedepending on the mass of the heavy BSM scalar. Considering presently measured values of the oblique parameters and deviations withinC.L., the obtained upper limit onisforGeV toforGeV which also matches with the previous study.

SECTION: EWPT constraints
To account for the present baryon asymmetry of the universe, the SM Higgs mass should be belowGeV considering only one Higgs doublet in the theory. LHC already discovered Higgs boson with massGeV, which disfavours SFOEWPT. However, SFOEWPT can be achieved by extending the standard model and in this study we consider singlet scalar extension of the standard model. The finite temperature effective potential is considered wheretree level potential and gauge independent thermal mass correction to the potential are included so that electroweak symmetry at high temperature is restored. Here,andparameters create barrier between broken and unbroken phase which allows SFOEWPT. The term with co-efficientstrengthens the first-order transition. At high temperature Ref.are followed and thedependent and gauge independent vevs can be written in a cylindrical coordinate representation as,

whereand. To define the critical temperature we use the condition where the broken and unbroken phases are degenerate (). Using critical temperature we can calculate the quenching effect of the sphaleron process. For large quenching effect the first-order EWPT is strong, which requires,

We want to select the benchmark points which satisfy the SFOEWPT as well as all the bounds which are discussed in the previous section such as Higgs signal strength, LHC search for heavy Higgs, EWPO, etc. In order to do that, first the parameters,,,andare scanned in the following range,

The rest of the parameters are calculated using the values ofGeV andGeV. A naive perturbativity bound on the Higgs portal couplingis also applied. After scanning the above parameters and selecting the points which satisfy all the bounds of the previous section along with the perturbative bound, the qualified benchmark points are passed throughpackageto calculate the critical temperature, sphaleron energy, tunnelling rate from the unbroken phase to the broken phase etc., to check whether SFOEWPT conditions are satisfied.

SECTION: Identification of benchmark points
We choose the parameters which satisfy the requirements as discussed above. Depending on that, we select benchmark points having maximum signal rate
in 11 consecutivemass windows of equal width
with a total range ofGeV. Upper bound onat 850 GeV is decided by satisfying conditions of SFOEWPT. We do not consider benchmark points corresponding to minimum signal rate, as it is expected to have very low sensitivity, beyond the possible reach of 14 TeV HL-LHC for our final state. All the benchmark points are given in Table. The benchmark points B3 and B4 are kept to compare with the previous studiesin spite of thesearchin CMS experiment already excludes those benchmark points.

SECTION: Reproduction of existing results of 13 TeV LHC
To cross-check with the existing LHC results, the CMS analysis in Ref.is followed and the distributions of final pseudo transverse mass (defined later in this section) of the backgrounds in the signal region are reproduced to justify the proper generation of backgrounds. In this CMS analysis, they look for the resonant search of graviton and radion for various range of masses in di-Higgs decay mode where the final state is.
The top-pair () production as the dominant SM background and Drell-Yan with 2 jets (DY) as another sub-dominant background are simulated at leading order (LO) accuracy with MadGraph5_aMC@NLOv2.6.7. For simplicity, Monte Carlo generation of our signal and backgrounds is restricted to. When we further estimate the
sensitivity, the possible contributions from final states with a pair of electrons are taken into account, for which very similar efficiencies are expected.

PYTHIA8 is usedfor parton showering, fragmentation and hadronization. We use DELPHES3for simulating the detector effects where we use the default CMS DELPHES card .
The anti-clustering algorithm is used to reconstruct jets having a radius parameter R fixed at 0.4. The efficiency and misidentification probability of b-tagging are implemented by the CMVA algorithminside the CMS Delphes card. In the analysis, medium working point of the CMVA algorithm is used which is defined such as the efficiency is about 66%, while the mis-identification rate is about 1% .For the analysis, the selection criteria is used as follows :

Events are required to have at least two muons both of which will be within. The transverse momentum of the leading muon needs to be larger than 20 GeV, while for the subleading muon the minimum requirement is 15 GeV.

Two jets constituting thecandidate have to haveGeV and, and to be separated from leptons by a distance of.

One of thebosons is reconstructed from the two highestmuons.

Two b-jets are selected using CMVA algorithm. If the selection criteria is satisfied by more than two b-jets, we select the two b-jet candidates having a combined invariant mass closer toGeV.

The reconstruction of the di-Higgs candidates is done in the regions that are chosen in the kinematic space defined by the dilepton invariant massand the invariant massof the pair of b-jets. The signal region (SR) is defined by the requirementsGeV to select only events with
on-shell Z bosons decaying into charged leptons andGeV to select the Higgs boson decaying into the pair of b-jets.

Missing transverse energy,is imposed to be larger than 25 GeV
to suppress one of the major backgrounds, DY.

To differentiate signal and backgrounds in the SR, training of a Boosted Decision Tree (BDT)is done on simulated MC samples that include a mix of theand DY samples representing the dominant backgrounds and a resonant signal sample as described below in details. Details of the BDT architecture used is given in Appendix.

Pseudo transverse mass of the di-Higgs (HH) candidate is formed as,, where E andare denoted by the energy and the z-axis component of the Lorentz energy-momentum vector of the HH candidate, which is constructed as the
sum of the Lorentz vectors of the two leptons, two b-jets, and the four-vector (), whereis the magnitude of, representing neutrinos as the z-component of the neutrinosâ€™ momentum is unknown.
Distributions ofare used as the final discriminant to match with the CMS analysis as in Ref..

For BDT,
the input variables includebetween two b-jets,between two leptons and the, the invariant mass and the tranverse momentum of the on-shell Z boson and both Higgs boson candidates. The invariant mass of the Higgs boson that decays to two Z bosons () is
an approximation of its invariant mass obtained by summing up the four-vectors of the two charged leptons and the four-vector of the missing transverse momentum.
To compare with the CMS results, we train a BDT including the signal resonant di-Higgs samples with the mass of the resonance from 260 to 450 GeV and the combined background samples. The selection is applied according to BDT output distributions of signal sample for mass 300 GeV and combined background to achieve the maximum
signal significance.

Fig.shows the di-Higgs pseudo transverse mass distributions of the background in thechannel for the graviton resonance mass hypothesis for resonance mass of 300 GeV.
NLO K factor for DY is taken to be 1.135while for, NNLO + NNLL K-factor is taken to be 2.15. We observe comparable agreement between the background estimate obtained by our analysis and CMS data points from Ref., which validates the production of background samples. We observe a discrepancy in the higher pseudo transverse mass region. The CMS analysis considers Drell-Yan sample in association with up to four jets, while we consider Drell-Yan sample in association with up to two jets in our analysis. After the final SR selection, there are very low statistics left for the DY sample. To train the BDT, one needs to produce a large number of events at the initial stage for this background sample, which was beyond our scope for the production of the sample in association with up to four jets. The smaller number of jets in our Drell-Yan sample compared to the CMS analysis is the most likely cause for the discrepancy in the higher mass region of pseudo transverse mass given the fact that, due to the detector mismeasurements, the missing transverse momentum is positively correlated with the jet transverse momentum and multiplicity and the fact that the agreement is better in the CMS analysis.
Also, as there is negligible presence of signal statistics in this higher mass region of pseudo transverse mass, it justifies that this discrepancy will rarely affect our final estimate of significance for the 14 TeV HL-LHC prediction.

SECTION: Projections for 14 TeV HL-LHC
SECTION: Analysis strategy
Once the validation of our backgrounds against the CMS results at the 13 TeV LHC is done, the projections are estimated at the 14 TeV HL-LHC with a revised analysis strategy.
The primary selections of events are kept similar to 13 TeV due to the similarity of distributions of kinematic variables.

Events are selected having at least two muons of opposite electric charge, both of which will be within. The transverse momentum of leading muon requires to be larger than 20 GeV, while the subleading muon has the minimum requirement of 10 GeV.

Two jets constituting thecandidate have to haveGeV and, and to be separated from leptons by a distance of.

One of thebosons is reconstructed from the two highestmuons.

Two b-jets are selected using CMVA algorithm. If all selection criteria are satisfied by more than two b-jets, we select the two b-jet candidates having the highest.

The di-Higgs candidates are reconstructed in signal regions defined by the dilepton invariant massand the invariant massof the two b-jets. The signal region (SR) is defined by the requirementsGeV andGeV.

For final discrimination between signal and background in the SR, a parameterized neural networkis trained on simulated MC samples that include a mix of theand DY samples representing the backgrounds and the resonant signal sample as described below in details.

SECTION: Parameterized neural network for final discrimination
Machine learning algorithms like boosted decision tree, neural networkare used frequently in signal-background classification in high energy physics experiments to achieve a higher sensitivity. Usually, a set of separate and independent classifiers is trained for each value of the input parameters (i.e. mass of the resonant particle in our case) corresponding to specific signal hypothesis. To separate the signal and background at each mass point, these individual classifiers perform much better compared to the classifier which is trained combining all of the masses together and evaluated on individual signal masses. But, one of the limitations of this approach is that a proper framework of training, testing and tuning including different hyperparameters needs to be maintained for each individual classifier, which makes the idea of having individual classifier at each individual signal mass point unfeasible.
Parameterized neural network mitigates these issues by taking the true invariant mass of the resonant particle as a parameter to the network and adding this parameter as an additional input along with the other input features. The main advantage of the parameterized machine learning is the usage of a single network to evaluate the performance in different values of the parameter. Fig.shows the performance comparison among the parameterized DNN, individual DNN and individual BDT network. Parameterized DNN is trained combining all the signal mass points having the values of the true resonant masses corresponding to the mass points as input parameters and tested at 511 GeV signal mass corresponding to BM5. Detailed architecture of the parameterized DNN used is described in Appendix. The individual DNN and BDT are trained and tested only at the 511 GeV mass point corresponding to BM5. It shows that with a single network, the parameterized DNN is able to perform as good as a network with a dedicated training for one individual signal mass point. The ROC curve for parameterized DNN gets comparatively higher value of area under the curve (auc) metric, as it is trained on higher number of events combining all the signal mass points, compared to individual DNN or BDT which used signal events of only one mass point for training. However, all the ROC curves have comparable performance, showing the effectiveness of applying parameterized DNN network.

Parameterized DNN provides discrimination between signal and background across the range of invariant masses of resonant particle by a single network, which saves a lot of time as well as gives comparable performance compared to BDT or DNN trained on individual mass points. It also gives improved discrimination at intermediate mass points, as the network even learns the smooth interpolation in the signal masses between two signal mass points where the training of the network is not done. Detailed description of the set of variables used as input is given in Table.
The final parameterized DNN score distributions normalized toare shown in Fig.for BM5.

The distributions of final output score of parameterized neural network are used for final discriminant of signal vs background to calculate the significance as a function of resonance mass following the profile likelihood ratio basedtechnique.

SECTION: Final results and projection study
The uncertainties for these backgrounds are considered here from the theoretical uncertainties coming from the factorization and renormalization scale variations and uncertainties in the parton distribution functions as well as the uncertainty on the integrated luminosity. For, the factorization scale uncertainty and PDF uncertainties are taken directly from Ref.. For DY, the uncertainties from the theoretical cross-sections at 13 TeVis assumed to be reduced by a factor of 1/2 for 14 TeV HL-LHC. Besides, 1% uncertainty on the total integrated luminosity is considered which affects both the yields of signal processes as well as background processes.

To evaluate the sensitivity, thevalue is estimated
from the distributions of final parametrized DNN score with the profile likelihood method considering the asymptotic formula explained in Refs..Gaussian significance is calculated by convertingvalues. The uncertainty band influenced by the systematic uncertainties considered is made by altering the event yields for the uncertainties of, computing theand converting it to significance as mentioned above, for instance, for BM4 of massGeV, the uncertainty on significance is.

is shown as a function of resonance mass in Fig..
The significance corresponds to a combination ofandchannel, taking the efficiencies of signal and background selection ofchannel to be equal to those of thechannel estimated in the analysis above.
If we search with only data from CMS experiment withof integrated luminosity at the 14 TeV HL-LHC, discovery significance can not be observed over the range of resonant masses, though if a signal is not observed in the future HL-LHC experiments, the maximum signal rate BM points up toGeV atC.L. can be excluded. If we presume to combine the data from CMS and ATLAS experiments eventually, by doubling the number of events obtained in this analysis, it is possible to discover the BM points having maximum signal rate up toGeV with5. Also, if we do not observe a signal in the future HL-LHC experiments, the maximum signal rate BM points up toGeV can be excluded atC.L.

We compare the significance with those of,andchannels for the 14 TeV HL-LHC and in case ofchannel for the 13 TeV LHC and it is shown in Fig.. The benchmark points are only compared from BM3 to BM11 because there is difference in BM1 and BM2 points with respect to the Ref.. In case of heavy Higgs mass,

less than 490 GeV, for a search of resonant di-Higgs production, the maximum sensitivity is found in thefinal state, if we ignore the 13 TeV CMS-ATLAS combination of bbWW channel. Forabove 490 GeV, the combination of CMS and ATLAS experiments gives the estimates of the significance for thefinal state quite comparable with, even better at some BM points. In addition, thechannel with a combination of CMS and ATLAS data can be a potential probe with theandchannel, which can be used as a complementary check if we observe a signal in theandchannels. Also, it has a higher sensitivity than that ofchannel. Theanalysis does not consider the Drell-Yan in association with jets background where significant contribution is expected from.

SECTION: Discussion & Summary
In this paper, we observed the prospect of HL-LHC in discovering a resonant production of the heavy singlet-like scalar by gluon fusion process in the xSM which eventually decays into SM-like Higgs pair infinal state, where oneboson decays into two electrons or muons and another decays to two neutrinos. This final state is important, where it balances between its large branching ratio in thechannel having a huge amount of QCD background and the clean leptonic decay ofalong with significant branching ratio ofin decaying to neutrinos. To validate the analysis, our simulation was compared against the CMS 13 TeV analysis. For a heavy singlet-like scalar mass from 300 to 850 GeV, we selected 11 benchmark points that satisfy a SFOEWPT along with the theoretical and phenomenological constraints and calculated the significance at the 14 TeV HL-LHC for an integrated luminosity of. For that purpose, a parameterized DNN was used for final discrimination, which is an efficient method that helps for the classification of the signal and background processes by utilizing only a single network for all the benchmark points. For a phenomenological analysis, we used parameterised DNN for the first time for final event discrimination and we encourage to use this simple and effective model for other phenomenological analyses involving a number of parameters corresponding to different signal hypotheses.
Our results are also compared with the previous analyses in,,andchannels and it was concluded that inclusion ofcould be a potential search channel for a combination of CMS and ATLAS experiments along with the other channels previously explored.
Also, we can exclude regions of parameter space if HL-LHC discovery is not achieved. However, in case of the benchmark points corresponding to minimum signal rate,
exclusion of a signal will never be possible.
Therefore, if the chance of SFOEWPT generation in the xSM needs to be fully excluded, it may require a 100 TeV pp collider in future.

SECTION: Acknowledgments
The authors would like to thank Anish Ghoshal, Manimala Mitra, Haolin Li, Debabrata Bhowmik, Gourab Saha and Arnab Roy for useful discussions and Subir Sarkar for computing infrastructure support. PP is supported by Senior Research Fellowship from University Grant Commission (UGC), India. SS is supported by FAPESP grant 2021/09547-9.

SECTION: Descriptions of kinematic variables
Descriptions of the kinematic variables which are given as input to the parameterized DNN classifier are given in Tablebelow. We plot the distributions of the input variables in Fig.for signal and combined background ofand DY used for 14 TeV prediction. The signal is taken corresponding to BM5 given in Table. All the plots are normalized to unit area.

SECTION: BDT and Neural network architectures
TMVAis used for BDTtraining.

Kerasis used for parameterized DNN training.

SECTION: References