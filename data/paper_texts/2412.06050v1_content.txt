SECTION: Concerning the Use of Turbulent Flow Data for Machine Learning
This article describes some common issues encountered in the use of Direct Numerical Simulation (DNS) turbulent flow data for machine learning. We focus on two specific issues; 1) the requirements for a fair validation set, and 2) the pitfalls in downsampling DNS data before training. We attempt to shed light on the impact these issues can have on machine learning and computer vision for turbulence. Further, we include statistical and spectral analysis for the homogenous isotropic turbulence from the John Hopkins Turbulence Database, a Kolmogorov flow, and a Rayleigh-Bénard Convection Cell using data generated by the authors, to concretely demonstrate these issues.

SECTION: Introduction
Throughout the last 10 years, the fluid dynamics research community has increased its focus on Machine Learning (ML). The broad application of Deep Learning (DL) and Convolutional Neural Network (CNN) based computer vision techniques to the study of turbulent flowshas brought with it a new set of challenges for the turbulence community.

Here, we focus on key issues which can arise in the application of common ML methodologies to Direct Numerical Simulation (DNS) outputs. We consider the impact these methodologies may have on accuracy, and generalisability, and how this can affect results from ML work. Importantly, we present circumstances where results may appear to demonstrate superior performance against state of the art results, but are biased.

SECTION: On Correlated-in-time Datasets
SECTION: In Prior Work
ML approaches for computer vision tasks such as classification, segmentation, and super-resolution typically assume that samples of data in a dataset are Independent and Identically Distributed (IID). CNNs, which form the backbone of of most modern computer vision tasks, share this assumption. However, in practice, this assumption is often violated, especially in real-world data. Despite this, ML models, particularly deep learning models, have demonstrated remarkable success, suggesting that the IID assumption is a soft constraint.

The widespread use of CNNs in tasks related to fluid dynamicsillustrates that the same condition is violable in applications to turbulence. Not only does turbulence not adhere to the independence assumption, but turbulent structures may be correlated to one another spatially (measured by a two-point correlation), and correlations in time may exist between individual snapshots of a given DNS instance for any turbulent flow. We define independence for two random variablesandto be when their joint probability distribution,, is the product of their marginal distributions, i.e.,for alland. The decorrelation is defined as the correlation coefficient being zero; this leads to the
expectation of the product of two independent random variables being equal to the product of individual expectations, i.e.,. We focus here on correlations in time, defined via the Autocorrelation Function (ACF) Eq., valid for statistically stationary flows. For statistically non-stationary flows, transformations exist which may be applied to the data to extract statistically stationary data (e.g. differencing). The ACF is defined here as:

whereis the autocorrelation function,is the velocity at a time,is the time-lag, andrepresents an averaging operator. Figureprovides an illustrative ACF for the homogeneous isotropic turbulence dataset from the John Hopkins Turbulence Database (JHTDB), whereis the timestep non-dimensionalised as, in whichis the RMS velocity, andis the domain length.

In prior work, flow-specific physical time scales are often used as a means of ensuring samples are temporally decorrelated. The separation period may be defined in terms of viscous time scales, wall time units (for wall-bounded flows), integral time scalesand large-eddy turnover time ().
In other cases, separation time is expressed in terms of simulation time-step, such as,,, and. A discussion of the separation time between snapshots is omitted altogether in other pieces of work.

In those cases where either the snapshot separation period is based on the numerical (DNS) timestep without an investigation into the separation required for decorrelation of turbulent fluctuations, or a discussion on the separation period is omitted entirely, two considerations emerge:

Selecting training and validation data as random subsets of the data, snapshots may be highly correlated with one another (i.e.between snapshots does not lead to the ACF decaying to zero). This is akin to validating on the training data – the validation data is not useful in gauging whether a model has overfit to the training data.

Where correlations between training and validation data are mitigated, correlations within the training set may reduce the ‘effective’ dataset size. Across training samples, the model is not presented with new information to learn from, and may overfit., demonstrate that small, decorrelated datasets are sufficient to train benchmark turbulence super-resolution models. We advocate the use of validation data derived from different initial conditions, e.g. where the simulation begins with perturbed initial conditions, for simulations where the initial conditions are a random field.

Physical time scales such asmay be large, presupposing that the largest eddies in a flow correspond to the characteristic length scale. In certain cases, such as Kolmogorov flows, prescribed forcing frequencies do not allow for the presence of eddies at those scales. We suggest a heuristic decorrelation metric: once could filter simulation data by computing the ACF and determining the period required for the ACF to decay to zero, obtaining decorrelated snapshots.

Intuitively, statistical correlation differs from dependence. Two snapshots of turbulence with a largebetween them may be completely decorrelated, but both both of them belong to the same time-evolution, and thus the later snapshot is necessarily dependent on the earlier state. We hypothesise that mitigating temporal correlation would improve model performance and training convergence.

SECTION: Results from a DDPM-based Super-Resolution of a Kolmogorov Flow
We illustrate the impact of training with correlated-in-time data on a case study: Super-resolving snapshots of a 2D Kolmogorov flow using a Denoising Diffusion Probabilistic Model (DDPM). As the efficacy of DDPM-based generative modelling for turbulence is an active area of research, we use this method to demonstrate this issue. A Kolmogorov flow is a theoretical forced isotropic flow, governed by the incompressible Navier-Stokes equations with an additional forcing term:

whereis the velocity,represents spatial coordinates, Re is the Reynolds number (set asin this simulation),is the pressure,is a sinusoidal forcing term in thedirection, and all fields are dimensionless. The governing equations are solved using a spectral code, with fully periodic boundaries over a square of length, discretised intogrid points.

Two datasets are generated: the first, with snapshots separated by the decorrelation period, and the second, with correlated-in-time snapshots, where everycorresponds to one decorrelation period. Each dataset is used to train a DDPM for ansuper-resolution task, and evaluated on decorrelated data generated using different initialisations to those used in training. Identical architectures and training hyperparameters are used for both cases. We denote low-resolution with LR, super-resolution outputs with SR, and DNS data with HR throughout.

We observe that the model trained on correlated-in-time data suffers when testing on unseen data. This is most evident in the instantaneous snapshots (Figure), where it can be noted that the fields generated using the model trained on correlated data contain significantly more noise than the same field generated using the model trained on decorrelated data.

Statistics of the generated snapshots can be used to quantify whether turbulent structures have been recovered well. The Probability Distribution Function (PDF) of the vorticity highlights the superior performance of the model trained on decorrelated data (Figure) in terms of capturing primary statistics of the underlying DNS data when compared to the model trained on correlated data (Figure). Additionally, the time-averaged Turbulent Kinetic Energy (TKE) spectra of the results from both models clearly illustrate that the model trained on correlated-in-time data performs significantly worse than the model trained on decorrelated data (Figures,) – there is an observable offset in the spectrum throughout and tails off at lower wavenumbers. This example serves to highlight the impact that training on highly correlated data can have on model generalisability.

SECTION: On the Downsampling of DNS
In this section we discuss the impact that downsampling of DNS data for tractability of training ML models can have on the perceived accuracy of those models. We illustrate this through the example of super-resolution on a Rayleigh-Bénard convection cell.

SECTION: Average-Pooling as an Effective Top-Hat Filter
Training ML models on DNS datasets can be computationally intractable, as neural network based approaches require the tracking of gradients as data is passed through networks. This can be prohibitive as DNS datasets are often very large; even a smaller dataset, such as the JHTDB isotropic turbulence dataset, is still approximately 20 Tb.

Modern training of ML methods is typically carried out at scale on CUDA-enabled GPUs, the latest of which can possess more than 80 GB. There are a number of methods widely employed in the machine learning community to facilitate computational tractability, but the one we focus on is average-pooling.

Average-pooling allows for reduced data dimensionality, while filtering out small length-scale information (proportionally to the kernel width). Unlike natural images, where perceptual quality is the primary metric, turbulence can exist on length-scales much smaller than what the human eye perceives. We particularly draw focus to the effect that average-pooling can have on dissipation-range structures which define DNS as being fully-resolved, as in Figure, a time-averaged spectrum of the JHTDB coarse isotropic dataset. Average-pooling can also violate the divergence-free condition for incompressible flows, though spectral cut-off filters can be designed to preserve the divergence-free condition.

SECTION: In prior work
Two key approaches exist to address the issue of spectral cut-off due to average-pooling. The first is to work on problems where the grid size required for full resolution of the governing equations is small.
A common focus is 2D turbulence, such as 2D Taylor-Green vortices, decaying 2D homogeneous isotropic turbulence, and 2D Kolmogorov flow. While this may be sufficient for the purposes of demonstrating methods, this approach effectively ignores issues of practicality in dealing with 3D DNS data for complex engineering flows.
In other cases, 2D slices are taken from 3D fields. In these instances, 2D CNNs are being used for 3D turbulence problems; we note that the impact on performance of passing 3D information through a 2D network remains to be explored.

Several pieces of recent work address the computational constraints of training ML models on DNS by training on patches or subcrops of DNS fields, particularly for super-resolution. The advantages of doing so are that high-wavenumber turbulent structures are preserved and the effective dataset size is augmented, provided the two-point correlations do not indicate that the subsampled fields are highly self-correlated. However, there is no guarantee that super-resolution models will produce samples which are coherent with one another, unless special measures are taken.

SECTION: Results from a DDPM-based Super-Resolution of a Rayleigh-Bénard Convection Cell
Here we showcase our findings on the impact of average-pooling through a concrete example, using a DDPM to super-resolve snapshots of a 2D Rayleigh-Bénard Convection case. The governing equations are the dimensionless incompressible Navier-Stokes equations in 2D, with the Boussinesq approximation for thermal-fluid coupling:

whereis the velocity field,is the spatial coordinate,is the pressure,is a scalar temperature field,is the Prandtl number,is the Rayleigh number,is a unit vector in the vertical direction, andis the Kronecker delta.
The Rayleigh number is defined as, whereis the height of the cavity,is the thermal expansion coefficient,is the temperature difference between the top and bottom boundaries,is the gravitational acceleration,is the kinematic viscosity, andis the thermal diffusivity. The Prandtl number is defined as.
The domain is taken as a rectangle of aspect ratio 2, with unit height,, discretized intospatial grid points, resolving to approximately, whereis the Kolmogorov length scale. Simulations are carried out using a spectral code, with Fourier bases in streamwise directions and Chebyshev bases in non-periodic directions. The Prandtl number is set to, and the Rayleigh number is set toto induce turbulent dynamics. We employ fixed temperatures at the top and bottom walls, and periodic boundaries in the streamwise direction. Generated data was decorrelated using the methods outlined in §.

Initially, training a DDPM on DNS downsampled fromgrid points topoints led to seemingly very accurate model outputs. On an extreme super-resolution factor of, the instantaneous snapshots of the reconstructed flow (Figure) appeared to agree very well with the ground truth. The Power Spectral Density (PSD) in Figureshows that from practically nothing, the PSD is recovered almost perfectly. Barring minor deviations from the true PSD, the high-wavenumber components of the flow are recovered well up to, which was contrary to our expectations given the limited conditioning information.

On spectral analysis of the original DNS against the downsampled DNS, it was observed that the dissipation range was being cut off by downsampling (Figure), trivialising the super-resolution problem. Further machine learning experiments, carried out at the original DNS resolution of, show a clearer picture. From Figure, it is easier to observe that although the flow has been reconstructed well, there are deviations from the DNS. The PSDs in Figureshow that while the DDPM reconstructed fields (SR) are accurate up to, the DNS extends to wavenumbers much past this point – and shows a clear dissipation range. We emphasise here that drawing conclusions from Figuremay lead to misleading claims of state-of-the-art performance, when the performance on full resolution DNS is more modest.

We note that there is a slight discrepancy in performance up to wavenumbers offrom theSR (Figure) to theSR (Figure). This is attributed to a fixed
model architecture used for both resolutions. Proportionally, theSR task will ideally have been carried out using a larger DDPM-parameterising network, but the points of comparison are still justified.

SECTION: Conclusions and Further Work
In this work, we have provided an overview of two points of concern in the use of DNS turbulent flow data for ML. The presence of correlations-in-time in turbulence, leading to persistent structures, can lead to highly similar snapshots of data being presented to networks during training as unique samples. While this adds redundancy to training datasets, correlations across training and validation can actively hinder the training process. This was demonstrated on a super resolution task for a Kolmogorov flow using a DDPM, where it was made clear that training on correlated-in-time data significantly decreased the performance of a model. However, developments in ML have allowed for the incorporation of temporal dependencies in some instances, and spatiotemporal models are actively being investigated for turbulence applications.

It was observed that average-pooling/downsampling of data – a common dimensionality reduction technique for computational tractability of ML training – can cause problems with DNS datasets. The average-pooling operator is effectively a spectral cut-off filter. It was shown that for certain DNS cases, downsampling led to the dissipation range of wavenumbers being filtered out, the presence of which is typically what defines DNS as being DNS (in that all scales of turbulence are resolved). The impact this may have on ML models was investigated using the example of DDPM-based super-resolution of a Rayleigh-Béndard Convection cell. It was found that downsampling the DNS made the model appear to perform very well, but this was merely an obfuscation of the true model performance. Re-training the model at the true DNS resolution led to more realistic results, which would be more meaningful for any intended application of the ML methods.

[Funding Statement]This work was supported by the Engineering and Physical Sciences Research Council [EP-T517823-1]. SD acknowledges a Dame Kathleen Ollerenshaw Fellowship.

SECTION: References