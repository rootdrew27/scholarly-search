SECTION: AdaNCA: Neural Cellular Automata as Adaptors for More Robust Vision Transformer

Vision Transformers (ViTs) demonstrate remarkable performance in image classificationthrough visual-token interaction learning, particularly when equipped with local information via region attention or convolutions. Although such architectures improve the feature aggregation from different granularities, they often fail to contribute to the robustness of the networks. Neural Cellular Automata (NCA) enables the modeling of globalvisual-tokenrepresentations through local interactions, as its training strategies and architecture design confer strong generalization ability and robustness against noisy input. In this paper, we proposeAdaptorNeuralCellularAutomata (AdaNCA) for Vision Transformers that uses NCA as plug-and-play adaptors between ViT layers, thus enhancing ViT’s performance and robustness against adversarial samples as well as out-of-distribution inputs. To overcome the large computational overhead of standard NCAs, we proposeDynamic Interactionfor more efficient interaction learning. Using our analysis of AdaNCA placement and robustness improvement, we also develop an algorithm for identifying the most effective insertion points for AdaNCA. With less than a 3% increase in parameters, AdaNCA contributes to more than 10% of absolute improvement in accuracy under adversarial attacks on the ImageNet1K benchmark. Moreover, we demonstrate with extensive evaluations across eight robustness benchmarks and four ViT architectures that AdaNCA, as a plug-and-play module, consistently improves the robustness of ViTs.

SECTION: 1Introduction

Vision Transformers (ViTs) exhibit impressive performance in image classification, through globally modeling token interactions via self-attention mechanisms[11,14,77]. Recent works show that integrating local information into ViTs,e.g.,using region attention[26,38,39,54,65,70,73]or convolution[8,10,16,22,23,37,42,52,68,71,75], further enhances the ViT’s capabilities in image classification. Although advanced local structures contribute to better captures of local information, the robustness of ViTs has not increased. They remain vulnerable to noisy input such as adversarial samples[5,9,13,41,42]and out-of-distribution (OOD) inputs[17,18,28,30,67].

Recently, Neural Cellular Automata (NCA) was proposed as a lightweight architecture for modeling local cell interactions[44], where cells are represented by 1D vectors. To perform downstream tasks, similarly to the idea of token interactions in ViTs, cells in NCA interact with each other by alternating between a convolution-basedInteractionstage and an MLP-basedUpdatestage[46,49]. The critical difference, however, is that cell interactions in NCA evolve over time by recurrent application of the two stages, whereas ViT computes the token interaction in a single step per layer. During this process, cells dynamically modulate their representations, based on the interactions with their neighbors, and they gradually enlarge their receptive fields. Unlike commonly used convolutional neural networks, NCA maintains resolution during neighborhood expansion. Therecurrent update scheme enables the cells to explore various states, thus preventing NCA from overfitting and enhancing its generalization ability[44,46]. NCA training involves various kinds of stochasticity[45], which enables the models to generalize to input variability and adapt to unpredictable perturbations. It is the modulation of local information and stochasticity during training that make NCA robust against noisy input[49,48,55,62].

However, the original NCA has substantial computational overhead when operating in high-dimensional space, which is a common scenario in ViTs. This poses a non-trivial challenge when integrating NCA into ViTs. To reduce the dimensionality of interaction results, hence to lower the computational cost, we proposeDynamic Interactionto replace the standardInteractionstage. In this stage, tokens dynamically modify the interaction strategy, based on the observation of their environment. This adaptation to the variability of the environment contributes to the model robustness. Our modifiedAdaptorNCA(AdaNCA), as a plug-and-play module, improves ViTs performances, as illustrated in Figure1. Adding AdaNCA to different ViT architectures consistently improves their robustness to both adversarial attacks and OOD input. AdaNCA also improves clean accuracy.

Motivated by empirical observations of the positive relationship between network redundancy and model robustness[28], we develop a dynamic programming algorithm for computing the most effective insert position for AdaNCA within a ViT, based on our proposed quantification of network redundancy. Our method results in consistent improvements across eight robustness benchmarks and four different baseline ViT architectures. Critically, we demonstrate that the improvements do not originate from the increase in parameters and FLOPS but are attributed to AdaNCA. Our contributions are as follows:

We propose AdaNCA: It integratesNeuralCellularAutomata into ViTs’ middle layers as lightweightAdaptors for the robustness enhancement of ViTs against adversarial attacks and OOD inputs in image classification. With less than 3% more parameters, AdaNCA-extended ViTs can, under certain adversarial attacks, achieve 10% higher accuracy.

We introduceDynamic Interactionto replace theInteractionstage in standard NCA, thus enhancing model robustness and efficiency in terms of parameters and computation.

We propose a method for determining the most effective insert positions of AdaNCA, for maximum robustness improvement.

SECTION: 2Related Works

SECTION: 2.1Local structure in Vision Transformers

Since the proposal of Vision Transformer (ViT)[14], a series of works have introduced local structures into ViTs to enhance their performance[8,10,16,22,23,37,42,52,62,68,70,71,73,75,76]. Here, we mention one of the earliest local structure modifications and those relevant to our work.
Stand-Alone Self-Attention (SASA), as introduced byRamachandran et al. [54], utilizes sliding window self-attention in ViTs. Following this,Liu et al. [38]develop a non-sliding window attention mechanism that partitions feature maps and computes self-attention, both within and between these partitions; it is termed Shifted Window (Swin) attention. Another method for modeling local information is convolution.D’Ascoli et al. [16]introduce a soft local-inductive bias by using gated positional self-attention, thus fusing self-attention and convolution.
Despite these advancements in better modeling of local information, few methods lead to a more robust ViT architecture[42]. This leaves the models to behave subpar when encountering slightly noisy inputs or distribution shifts.

SECTION: 2.2Robust architecture in Vision Transformers

Researchers have developed various architectural changes for building more robust ViTs against adversarial attacks, such as FGSM[61]or PGD[41], as well as out-of-distribution (OOD) inputs, such as image corruption[28].Zhou et al. [78]propose Full Attention Networks to boost the robustness of ViTs against OOD images.Mao et al. [42]first systematically analyze the relationship between different components in a ViT, drawing a positive relationship between convolutional components and the robustness of ViTs against adversarial samples and OOD data. By extending[42]and[78],Guo et al. [23]propose input-dependent average pooling in order to adaptively select different aggregation neighborhoods for different tokens, thus achieving the state-of-the-art robust ViTs in OOD generalization. Different interpretations of the self-attention operation can also lead to more robust architectures[24,58]. However, the methods that introduce additional architectures[23,24,58,78]are either implemented on ViTs with limited size or focus on non-adversarial robustness. On the contrary, our method introduces NCA as lightweight plug-and-play adaptors into base-level ViTs, thus enhancing their clean accuracy and robustness against both adversarial samples and OOD inputs.

SECTION: 2.3Neural Cellular Automata

Gilpin[20]demonstrates that CA can be represented by convolutional neural networks. By extending[20],Mordvintsev et al. [44]propose NCA in order to mimic the biological cell interactions and model morphogenesis. Following this idea, several works apply NCA in computer vision, including texture synthesis[43,46,49,48,50], image generation[33,47,51,62], and image segmentation[32,57].Randazzo et al. [55]propose applying NCA for modeling collective intelligence on image classification tasks, but the limitation to binary images restricts its practical application.Tesfaldet et al. [62]first establish the connection between ViT and NCA via recurrent local attention.It leads to a more robust model for handling image corruptions in image inpainting tasks.However, their application is limited to image impainting on small datasets such as MNIST[1]and CIFAR10[36].The NCA in[62]attempts to emulate a ViT whereas our approach distinguishes itself by not doing so.We first applies NCA in image classification on ImageNet1K with base-level ViT models. Moreover, we propose the newDynamic Interactionfor efficient cell interaction modeling, reducing the computational overhead, and for enhancing the model performance.

SECTION: 3Method

The overview of our method is shown in Figure2. In this section, we first review the NCA model and ViT architecture. In Section3.1, we establish the connection between NCA and ViT, in terms of token interaction modeling. We then present the design of our AdaNCA in Section3.2. We insert AdaNCA into the middle layers of ViT to improve its robustness. We introduce the relationship between the insert position of AdaNCA and the relative improvements of model robustness in Section3.3. This relationship leads to the algorithm for deciding the most effective placement for AdaNCA.

SECTION: 3.1Preliminaries

Vision Transformers (ViTs) operate on token maps, where the number of tokens isand each token is represented by a-dimensional vector. ViTs learn the interaction between these tokens via self-attention[64]and compute the interaction result, as described in Equation1.

stand for query, key, and value, respectively. They are deduced from different linear projections of the input, i.e.,, where.is the hidden dimensionality in self-attention.is Softmax. After self-attention, tokens are fed into a Multilayer Perceptron (MLP) to obtain the updated representations:

is the MLP andstands for its parameters. The self-attention and MLP form a single ViT block, and a ViT model can be built via stacking ViT blocks.

NCA aims at modeling cell interactions. In the 2D domain, cells live on a 2D grid with size. Each cell is represented by a vector with dimensionality. All cells collectively define the cell states. In a single step of NCA, to generate the interaction output, cells first interact with their neighborhoods for an information exchange in theInteractionstage[49]; the interaction is typically instantiated via depth-wise convolutions[44,46,48]:

is theth convolutional kernel, anddenotes the total number of kernels.‘’ denotes depth-wise convolution.The kernels can either be fixed[49,48]or learnable[44,46]. The results of all kernels are concatenated channel-wise in theoperation.is then passed to an MLP in theUpdatestage[49]:

is then used to update the cell states in a residual scheme.is the MLP, andstands for its parameters. Typically, NCA uses the simplest MLP, with two linear layers and one activation between them., sampled from, is a random binary mask to introduce stochasticity in NCA; it ensures asynchronicity during the cell updates[45].is point-wise multiplication. NCA learns an underlying dynamic that governs the cell behaviors[50], as depicted by the stochastic differential equation (SDE) in Equation5:

represents operations inInteractionas well asUpdatestages.is the set containing trainable parameters in the two stages. Discretizing the SDE withnaturally results in a recurrent residual update scheme:

Aftersteps, the cell statesis extracted to accomplish certain downstream tasks. The traditional NCA involves several other specific designs though, in our case, it is impractical to adapt them. We provide a discussion on this topic in AppendixE.

Both NCA and ViT learn interactions between a set of elements, i.e., tokens in ViT and cells in NCA. Hereafter, we refer to a cell in NCA as a token, aligning it with the concept in ViTs. The asynchronicity[45]introduced by the random maskcan be regarded as a cell-wise stochastic depth[31], a more fine-grained version of the sample-wise stochastic depth. In previous NCA works, stochasticity is maintained during testing[46].Such a scheme is problematic in our case because (1) test-time stochasticity produces obfuscated gradients[3], leading to the circumvention of adversarial attacks, and (2) the model can output different results given the same inputs.To this end, we adopt the strategy in dropout-like techniques[31,59], which compensates activation values during training. Given, the evolution of NCA in AdaNCA is defined as:

We discuss the necessity of such a scheme in SectionD.1in the Appendix.Furthermore, NCA typicallyoutputsthe cell states at a random time step, resulting in random update steps for all cells. Such randomness ensures the stability of NCA across various time steps[44].Finally, the recurrent steps of NCA during a single training epoch enable the exploration of a wide range of cell states. In the early stage of training, the model is not adequately trained hence serves as a source of noise to itself through the recurrence. With all these components,the trained model can effectively handle the variability and unpredictability of the input thus be robust against noisy input. Our ablation studies in Section4.3demonstrate the effectiveness of these strategies in enhancing the model performance.

SECTION: 3.2AdaNCA architecture

The architecture of AdaNCA is shown in Figure3. It shares a similar update scheme with the standard NCA, as described in Equation7; but, it is more computationally efficient due to the proposedDynamic Interactionstage. All convolutional kernels for token interaction are trainable. In the following paragraphs, we first present the design of theDynamic Interactionstage and then introduce a way for more efficient token interaction by using multi-scaleDynamic Interaction.

TheInteractionstage in the original NCA performs a channel-wise concatenation of theoutput tensorsfrom different depth-wise convolutions. Whereas, ourDynamic Interactioncomputes a weighted sum of those results.
Specifically, a weight computationnetworktakes the token mapas input and outputs per-token scalar weightsfor each of thekernels.We modify Equation3to Equation8:

where.‘’ denotes the convolution. Recall that ‘’ is the depth-wise convolution.We instantiate the weight computation moduleby using a two-layer convolutional network. The first layer transforms the dimensionality fromto, and the second layer computes the actual weights, thus producingscalars for each token. Both layers useconvolutions to factor in information from both the token and its neighbors. To stabilize training, we add a batch normalization between the two convolutions. Our design of the weight computation network coincides with the one in[23]. Although, our focus is on extracting various information from the same neighborhoods rather than on aggregating data from different neighborhoods.

Inspired by[48], which uses multi-scale tokenInteractionto facilitate long-range token communication, we propose multi-scaleDynamic Interaction. Concretely, all convolutions in Equation8now have one more degree of freedom in dilation. Dilationrepresents the current operating scale being, and. Hence, the originalDynamic Interactionis a special case where. To increase the feature expressivity, we perform a weighted sum on the outputs of all scales, where the per-token weightsare generated by a networkas described in Equation9.

where.Thein Equation8is shared across all scales.The weight computation networkmirrors that of.

SECTION: 3.3Insert positions of AdaNCA

Given a ViT and an AdaNCA, to maximize the robustness improvements, we need to determine where to insert AdaNCA. To this end, we first establish the correlation between the placement of AdaNCA and the robustness enhancement it brings. Motivated by the fact that the network redundancy contributes to the model robustness[28], we hypothesize that the effect of AdaNCA should correlate to the layer redundancy corresponding to the insert position. To quantify the redundancy, we propose theSet Cohesion Index. Given a trained model withlayers and two layer indiceswhere,is defined in Equation10.

stands for the indicator function.is the function for quantifying the output similarity between layerand. We choose Centered Kernel Alignment (CKA)[35], a common metric for measuring layer similarities inside or between neural networks[25]. A higherstands for a more cohesive layer set defined by layers fromto. Inserting AdaNCA after layerwould partition the network into two layer sets, and we can compute the sum ofof the layers before and after,i.e.,. This serves as a quantification of the network redundancy that corresponds to position. We assume that AdaNCA will not change the layer similarity structure because it is too small compared to a single layer in all ViTs.

In addition to the quantification of the network redundancy, the robustness improvement, brought by AdaNCA, is quantified using the relative increase in the attack failure rate of the AdaNCA-inserted models and the corresponding baseline. Specifically, if a model can achieveclean test accuracy as well asaccuracy under adversarial attacks, the attack failure rate is. The robustness improvementis then defined as. In our experiments, we find thatis significantly correlated with the network redundancy(Pearson correlation). We refer readers to AppendixAfor details of the experiments. The results validate our hypothesis and indicate that AdaNCA should be inserted into the position that can maximize network redundancy. We develop a dynamic programming algorithm to find these positions and refer readers to AppendixA.1for the details.

SECTION: 4Experiments

We use four ViT models as the baseline: Swin-base (Swin-B)[38], FAN-Base-Hybrid (FAN-B)[78], RVT-Base-Plus (RVT-B)[42], and ConViT-Base (ConViT-B)[16]. They include a hierarchical model (Swin), a convolution-attention hybrid model (FAN), and two regular models in which all layers share the same structure (RVT and ConViT). RVT is specifically built to be a robust model, whereas ConViT is not. All four models are equipped with different kinds of local structures. We use two SOTA models in terms of robustness against out-of-distribution (OOD) data, TAPADL-RVT and TAPADL-FAN[23]for comparison.Note that the SOTA method involves training with an additional loss (ADL) and that, for completeness, we keep the results from the TAPADL models trained with such a loss. However, as our focus is on the effect of architectural changes, we do not incorporate the ADL loss in training the AdaNCA-enhanced ViTs.We follow the training scheme for each model, respectively, to train the AdaNCA-equipped model from scratch on ImageNet1K. We conduct the analysis presented in Section3.3to decide the optimal position to insert multiple AdaNCA modules, in which the ImageNet1K pre-trained weights for analysis are obtained from the PyTorch Image Models library[69]. To balance between the computational cost and robustness improvement, we limit the number of AdaNCA to two or three, depending on the model architecture. The recurrent time step of all AdaNCA is chosen from, and we follow the design principle of ViT; it is to put more computation in the middle or high layers[38].We fix the random steps during testing to a single integer chosen from the rangeto achieve precise results and ensure non-stochasticity during adversarial attacks. All the activation functions used in the MLP in AdaNCA are GELU[29], and the input, hidden, and output dimensionalities of the MLP are all the same. We refer readers to AppendixC.6for the details of the training and insert scheme of AdaNCA. All of our experiments are performed on four Nvidia A100 GPUs.

SECTION: 4.1Results on Image Classification

We test all models on the ImageNet1K validation set for clean accuracy. For the adversarial robustness evaluation, we choose common adversarial attack methods PGD[41], CW[5], APGD-DLR[9], and APGD-CE[9]. Moreover, we also include the natural adversarial examples in ImageNet-A (IM-A)[13]. For the PGD attack, we align with the settings used in[42]: max magnitude, step size, steps. We refer readers to the AppendixC.7for details of the other attacks. For testing the OOD generalization, we use ImageNet-C (IM-C)[28], ImageNet-R (IM-R)[30], and ImageNet-Sketch (IM-SK)[67]. We report the mean corruption error (mCE) on ImageNet-C and accuracy on all other kinds of robustness benchmarks in Table1. Our results highlight that AdaNCA-enhanced ViTs consistently outperform corresponding baselines in various robustness tests as well as in terms of clean accuracy. Importantly, the enlarged baseline models (sign) do not bring comparable improvements to AdaNCA, suggesting that the enhancements do not merely stem from the increase in computational budgets. However, the existing method[23]that introduces local structure into ViTs can potentially undermine the adversarial robustness of the baselines.
In Table2, we conduct an in-depth study on the corruption errors of the different categories of common corruptions in ImageNet-C.
The results show that AdaNCA enhances robustness without the trade-off seen in methods that ignore texture information[17,53]. While these methods may improve mCE for non-Blur noise, they often worsen mCE for Blur noise[53]. In contrast, AdaNCA consistently improves robustness across most categories. We refer readers to AppendixCfor more results.

SECTION: 4.2Layer similarity structure

Our key assumption in Section3.3is that AdaNCA will not change the layer similarity structure due to its small size, and that is why we usepre-trainednetworks to conduct this analysis. Here, we examine the pair-wise layer similarities in Swin-B[38]and Swin-B-AdaNCA in Figure5.

is the mean offrom all layer sets. We refer readers to AppendixC.14for more results. AdaNCA not only preserves the original layer similarity structure but also contributes to a clearer stage partition, validating our assumption in Section3.3. The results might be attributed to the fact that AdaNCA transmits information between different layer sets and thus layers inside each set do not bother adapting to the layers outside the set.

SECTION: 4.3Ablation studies

We conduct ablation studies on ImageNet100, a 100-class subset of ImageNet1K. Previous studies[7,15,72,74]have shown that ImageNet100 serves as a representative subset of ImageNet1K. Hence, we can obtain representative results for the self-evaluation of the model while efficiently using the computational resources. All the ablation experiments are based on a Swin-tiny[38]model. We insert it after the fourth layer to obtain the best robustness improvement, according to our analysis in Section3.3and AppendixA. First, we ablate on two hyperparameters, the number of convolutional kernels used in theDynamic Interactionstage () and the maximum scale () used in the multi-scaleDynamic Interactionstage. TheClean AccuracyandAttack Failure Rateare shown in Figure5. The attack failure rate is quantified using the same method as in Section3.3and AppendixA. Multi-scale interaction can contribute to the performance while overly large scale can lose local informationand complicate the process of selecting the interaction neighbors. This issue is also observed in a previous work[62].Increasing the number of kernels benefits the performance while too many kernels undermine the robustness. According to the results, we choose,.
We then perform ablations on several design choices:

Recurrent update (Recur).Ablation on unrolling the recurrence with average time stepin AdaNCA intoindependent AdaNCA with time step being 1.

Stochastic update (StocU).Ablate the stochastic update during training, leading to globally synchronized update of all tokens[45].

Random step (RandS).Change the recurrence time step from a randomly chosen integer in rangeto. It cannot be turned on without recurrence.

Dynamic interaction (DynIn).Ablate theDynamic Interactionso that the interaction results are simply summed together. The number of kernels remains the same.

As shown in Table3, the highest robustness improvement is achieved with all components. Among them, turning off the recurrence leads to the largest drop in the robustness, as recurrence allows the model to explore more cell states than finishing the update in a single step. While it achieves the highest clean accuracy, it uses4x more parameters than our method, and the improvement of the clean performance is likely due to more parameters. Without any of the two sources of randomness, stochastic update and random steps, the model cannot adapt to the variability of the inputs and thus exhibits vulnerabilities against adversarial attacks. Finally, turning off our Dynamic Interaction will cause drops in both clean accuracy and robustness, as tokens cannot decide their unique interaction weights and thus cannot generalize to noisy inputs. We provide extended ablation studies in SectionD.2in the Appendix.

SECTION: 4.4Noise sensitivity examination

A drawback of adversarially robust models is their increased sensitivity to noise in specific frequency bands[60].
For instance, while adversarially trained models are robust against adversarial attacks, they can be sensitive to noise from a larger frequency-band range compared to standard models[60]. Here, we use the method and data from[60]to examine the noise sensitivity of AdaNCA-enhanced ViTs. Specifically, we evaluate the classification performance on a set of images that are mixed with noise of varying magnitudes and frequencies.The noise is sampled from Gaussian distribution with zero mean and the standard deviation indicates its magnitude. Then, it is filtered within
various spatial-frequency bands, resulting in different frequencies of noise.Higher classification accuracy on a specific noise type indicates that the model is less sensitive to that noise. Figure6presents the results, including human data sourced from[60]. Our findings demonstrate that AdaNCA enhances ViTs by reducing the sensitivity to noise with certain frequency components, equipping ViTs with more human-like noise-resilient abilities. Crucially, AdaNCA improves the model robustness differently than adversarial training since the AdaNCA-enhanced ViTs do not exhibit increased sensitivity to the noise. We quantitatively validate the conclusion and refer readers to AppendixC.16for the details.

SECTION: 5Limitation

AdaNCA has certain limitations. First, the AdaNCA-equipped ViTs cannot adapt to unseen recurrent steps of AdaNCA, which limits the generalization ability. For example, if the training step range of AdaNCA is [3,5], it cannot produce meaningful results with the test step being 6. AdaNCA introduces a non-negligible computation into the original architecture. Our experiments are conducted on ImageNet1K with the image size of 224224. Whether AdaNCA can lead to impressive improvements on larger-scale problems,e.g.,ImageNet22K, remains a question. The size of the images can also affect the efficiency of token interaction.

SECTION: 6Broader Impact

AdaNCA contributes to more robust ViTs, facilitating their usage in real-world scenarios. We bridge two powerful models, NCA and ViT, on large-scale image classification, potentially encouraging research dedicated to their synergistic combination in more practical settings. Our findings on AdaNCA improving network redundancy can stimulate more works on architectural robustness in deep learning that involves increasing the redundancy to enhance robustness.In the context of this paper, we believe that AdaNCA does not introduce any significant negative implications.

SECTION: 7Conclusion

We have proposed AdaNCA, an efficient Neural Cellular Automata (NCA) that, when inserted between their middle layers, improves ViT performances and robustness against adversarial attacks as well as out-of-distribution inputs. We design our model by connecting NCA and ViT, in terms of token interaction modeling, and we proposeDynamic Interactionto improve the computational efficiency of standard NCA. Exploiting the training strategies and design choices in NCA,i.e.,stochastic update, random steps, and multi-scale interaction, we further improve the AdaNCA-enhanced ViTs’ clean accuracy and robustness. To decide the placement of AdaNCA, we propose the Set Cohesion Index that quantifies the network redundancy via layer similarity and conclude that AdaNCA should be inserted between two layer sets that consist of redundant layers. Our results demonstrate that AdaNCA consistently improves ViTs performances and robustness. Evidence suggests that the mechanism by which we obtain improvement reduces the sensitivity of ViTs to certain types of noise and makes the noise-resilient ability of ViTs similar to that of humans.

SECTION: References

SECTION: Appendix: Table of Contents

[sections]\printcontents[sections]1

SECTION: Appendix AEstablish the correlation between AdaNCA placement and robustness improvement

Our motivation for investigating the relationship between AdaNCA and robustness stems from an empirical observation, namely that making neural networks more monolithic contributes to their robustness[28]. One of these monolithic ideas is redundancy in networks. It has been observed that several consecutive layers output similar results[4], hence building what we call “a layer set."
We hypothesize that AdaNCA, as adaptors inside ViTs, should connect the different sets inside a ViT and transmit information between them. In this way, layers inside a set will no longer bother adapting to other layers outside the set, improving the redundancy and thus robustness. To this end, we propose the layer redundancy quantificationand network redundancy quantification, as well as the robustness improvement measurementin Section3.3.

For the robustness improvement, we insert AdaNCA into all possible positions of 3 ViT models, Swin-tiny[38], FAN-small-hybrid[78], and RVT-small-plus[42], and train them along with the baseline models on the ImageNet100 dataset[15,72,74], a representative 100-class subset of ImageNet1K. The total amount of models is 34, including 3 baselines and 31 AdaNCA models. All AdaNCA-models have a 1%-2% parameter increase and 5% more FLOPS. The training hyperparameters are given in Table4. All models are trained for 300 epochs with the Cosine scheduler. Here, we only consider adversarial robustness for simplification, as it is shown that adversarial robustness is correlated with image corruption robustness within one backbone architecture[42]. We use a white-box version of AutoAttack[9]in the AdaNCA placement analysis in Section3.3, which comprises PGD[41], CW[5], APGD-DLR[9], and APGD-CE[9]. The hyperparameters of the four attacks are in Table5.

We show the qualitative results of our experiments on the Set Cohesion Index and robustness improvement in Figure7and the quantitative results in Figure8. Qualitatively,generally follows the trend ofexcept for the top 3 layers and the last layer. Specifically,for the top three layers consistently exhibits a pattern where it decreases in the second layer and increases in the third layer, regardless of the trend in, which always increases.
We hypothesize that the proximity of the top 3 layers to the input image causes AdaNCA to similarly impact the model’s robustness by adapting the input to the subsequent layers. Furthermore, the position immediately before the final layer likely serves as a transitional stage for output, adapting to different output strategies (e.g., FAN has an additional class attention head while Swin and RVT use average pooling on all tokens to generate features for classification). The distinct behavior of the last layer compared to other layers has also been noted in previous research[21].
Hence, we exclude the models (AdaNCA applied in the top three layers and before the final layer) from our analysis. The resulting number of models is 19. To conduct a cross-model quantitative comparison, we normalize allas well as allin a single type of model. Each of the 3 models thus has a set ofas well as. We plot all sets ofandfrom 3 models in Figure8. Note that the coordinate (1.0,1.0) has two overlapping points (Swin-tiny and FAN-small-hybrid), hence only 18 points are visible in the figure.is significantly correlated with(), as we report in Section3.3.

SECTION: A.1Dynamic programming for AdaNCA placement

GivenAdaNCAs, the ViT is expected to be partitioned intosets. The dynamic programming involves filling an array, whererepresent the maximum value ofachievable by partitioning the firstlayers intosets. Thecan be obtained via Equation11.

The boundary conditions are: 1), which is partitioning the firstlayers into 1 set; 2). By recording the partition position, we can findpartition points for inserting the AdaNCA. The pseudo-code is presented in Algorithm1.

Note that here the layer index starts from 0, and so does the input requirement of.

SECTION: Appendix BNotes on statistical significance

We do not report the error bar for training models with different seeds on ImageNet1K, as it would be very expensive (Table10). However, we follow the seed used in the released code for each model. We test the adversarial attack using 5 seeds and find the difference between different seeds negligible (standard deviation: PGD 0.08, CW 0.01, APGD-DLR 0.01, APGD-CE 0.02). As all our results on adversarial attacks have differences larger than, they are statistically significant.

For ImageNet100 experiments in the ablation study, we train the model 3 times and find the clean accuracy changes within a small range (standard deviation), and the robustness test results barely change (standard deviation). We also test the robustness improvement within one model using 5 seeds and the standard deviation is.

For the AdaNCA placement analysis, our correlation result is statistically significant ().

SECTION: Appendix CImageNet1K experiments

SECTION: C.1AdaNCA settings for each model

Based on Algorithm1, we insert AdaNCA into the four chosen baseline models. The specific settings for each AdaNCA are shown in Table6. Note that insert position 0 means before the network, since FAN-B model uses a complex patch embedding layer, we can treat it as a unique layer that encodes semantic information rather than the simple convolution patch embedding used in other models. In practice, we find inserting AdaNCA after it can contribute to the model performance. Moreover, we add the drop path operation after each AdaNCA, and the drop path rate follows the one of the layer that AdaNCA follows. Hence, the regularization is pretty strong even without the stochastic update. However, as shown in our ablation studies in Section4.3, the stochastic update indeed contributes to the model performance. Our FLOPS computation for AdaNCA models are based on Test steps.

Our choice of AdaNCA steps differs from all previous NCA models, which typically iterate for hundreds of steps. We make this compromise as the computational costs increase linearly as the step grows. We aim to minimize the increase in the number of parameters and FLOPS for scalability and we do not want the source of improvement to merely stem from the increase in the size and computation of the models. We show that more NCA steps will indeed contribute to the model’s performance in Table7, while it introduces extra FLOPS. The model is the same as in Section4.3which is trained using a range of steps being. We want to underscore that it is the architecture and evolution scheme that defines an NCA as introduced in Section3.1, instead of the number of its recurrent steps. Admittedly, fewer steps will lead to a coarser path to the target state, and can potentially undermine the model’s performance. Notably, with our scheme, AdaNCA has achieved generally strong robustness improvements compared to the baselines. It indicates that our choice of the recurrent steps of AdaNCA is a good balance between computational costs and performance.

SECTION: C.2Discussion on the model choices

In our experiments, we choose RVT[42], FAN[78], Swin[38], and ConViT[16]. Our choice not only includes different types of ViTs (Regular, Hybrid, Hierarchical) and robust as well as non-robust architectures (RVT, FAN and Swin, ConViT), but also covers other aspects of ViT characteristics. First, RVT and Swin use average pooling on the final token maps to obtain the 1D feature for classification, while FAN and ConViT adopt a separate class token. It has been proved that those two strategies of classification can have a significant influence on the model robustness[42]. Despite this, AdaNCA are effective in both ways for classification.
Moreover, all the architectures already contain certain kinds of local structures. RVT contains depth-wise convolution within MLP and a convolutional patch embedding layer. FAN has a ConvNeXt[40]head for patch embedding. Swin has shifted window attention. ConViT has convolution-attention coupled gated positional self-attention layers. Local structures have been proven effective in improving model robustness[42]. Therefore, we partially eliminate the possibility that AdaNCA is effective simply because of introducing local information in ViTs without any local inductive bias, such as the original ViT[14]or DeiT[63]. As shown in our ablation studies in Section4.3, AdaNCA not only contributes to more parameter-efficient models but also improves the model robustness compared to not using the training strategies or design from NCA.
Furthermore, in our choices, Swin does not conduct weight exponential moving average (EMA), while the other 3 models perform. It indicates that AdaNCA can be effective with or without model EMA.

SECTION: C.3Discussion on the hyperparameters of MLP inside AdaNCA

In AdaNCA, we set the hidden dimensionality of the MLP to the same one as the input dimension. It is different from the common design choice of MLP in ViT that uses a 4-time larger hidden layer than the input layer. Moreover, it also deviates from the design of the previous NCA that uses more than 8 times larger hidden layer size than the input one. Instead, we set the hidden dimensionality to be the same as the input one. The reason is that AdaNCA introduces additional parameters and computation in ViTs and we want the extra computational overhead to be as low as possible. The lowest dimensionality that will not cause inevitable information loss is the same one as the input dimension. Therefore, we design the MLP in AdaNCA as a non-compression-non-expand structure.

SECTION: C.4The effect of AdaNCA placement on robustness on ImageNet1K

Our algorithm for deciding the placement of AdaNCA is based on the correlation between the robustness improvement and the Set Cohesion Index in Section3.3. All the experiments are conducted on ImageNet100 to efficiently use the computational resources. Here, we compare two schemes for deciding the placement of AdaNCA on ImageNet1K on Swin-B[38]and FAN-B[78]to demonstrate our result validity. The first scheme isNo-Prior, which does not involve the knowledge of the layer similarity and performs the most reasonable placement choice. For Swin-B, the choice for placing 3 AdaNCA is to insert them between each stage pair defined by the transition between different embedding dimensionalities, namely after layer 2, layer 4, and layer 22. Coincidentally, this choice aligns with what we obtain from the dynamic programming algorithm, which is to place AdaNCA after layer 2, layer8, and layer 22. For FAN-B, although it is a hybrid ViT, we only consider inserting AdaNCA into its main network where all layers share the same structure. In this case, theNo-Priorchooses to uniformly insert AdaNCA between the 16 layers, that is after layers 5 and 10. Our algorithm decides the placement should instead be after layers 6 and 9. Table8shows the results of two Swin-B-AdaNCA models. Inserting AdaNCA with theNo-Priorscheme can still contribute to the model performance and robustness, but not as effective as using our proposed method.

SECTION: C.5Details of architecture change in Swin-Base⋆and ConViT-Base⋆

For Swin-Base⋆, we add two extra layers in stage 3 with embedding dimensionality being 512, since in the original design most of the computational budgets are dedicated to stage 3, and two layers form a complete Swin operation. For ConViT-Base⋆, we add an extra Gated Positional Self-Attention (GPSA) layer.

SECTION: C.6Training details

We use different training schemes for the four selected baseline models, closely following the parameter settings for each of them (link to reference configuration files:RVT-B,FAN-B,Swin-B,ConViT-B,). Most training settings are in line with DeiT[63]since all models used build the training upon the scheme of training a DeiT but with minor changes. Some specific training settings are listed in Table9.

All models are trained for 300 epochs. Our ablation studies on the size of the model (Swin-B-abl, ConViT-B-abl) also follow the same training settings. The detailed time consumption for training each model using 4 Nvidia-A100 80G GPUs is in Table10. The excessive time of RVT is because of the patch-wise augmentation[42].

SECTION: C.7Adversarial attacks

We test all AdaNCA-equipped ViTs using four adversarial attacks based on the code[34]. The detailed setting of each attack is given in Table11. We try setting the Expectation Over Transformation (EOT) to 3 and the results do not change significantly (For Swin-B, APGD-DLR, EOT=1: 25.124, EOT=3: 25.121). Hence, we fix the EOT to 1.

We choose PGD[41]since it is the most popular method for examining model adversarial robustness after architectural changes[58,42]. However, it is relatively easy to overcome the PGD attack using obfuscated gradients through methods such as random inference, noisy architecture, or non-differentiable components[3]. Our AdaNCA does not fulfill the requirement for producing obfuscated gradients since it is fully differentiable and we turn off all randomness during test. However, we still want to examine whether recurrence would result in corrupted gradient information due to the drawback of cross entropy loss[9]. Moreover, the step size in PGD can largely affect the result. Hence, we choose Auto-PGD family[9]to automatically decide the step size and incorporate the new Difference of Logits Ratio (DLR) loss, resulting in APGD-CE and APGD-DLR, respectively. We also want to include an optimization-based adversarial attack and thus select the CW[5]attack.

We also consider the black-box attack, specifically Square[2]. However, due to the extreme computational cost of performing Square on ImageNet1K, we instead conduct Square attack to three models, Swin-tiny (Swin-T)[38], FAN-small-hybrid (FAN-S)[78], and RVT-small-plus (RVT-S), on ImageNet100. The three models are used in our AdaNCA analysis in Section3.3. The maximum magnitudeand the number of queries is 1000. Results are shown in Table12. The AdaNCA placements are in line with the highest robustness improvement placements demonstrated in Figure7.

SECTION: C.8The effect of the range of the steps in random step training

Our random stap training strategy contributes to the model robustness as shown in Table3. In all of our experiments, we adopt a range of 2 in the random step setting. Here, we examine the effect of increasing the range. We use the same setting as described in Section4.3. Results are given in Table13. We can observe that more choices of the recurrent steps worsen the model performance. This might stem from too much noise introduced into the training process which leads to underfitting. Therefore, we only adopt a range of 2 in our experiments.

SECTION: C.9Reason for using ImageNet22K model for RVT

We use the ImageNet22K-pretrained model for RVT-Base-plus in our main results. This is because we do not find an official release of the ImageNet1K-trained weights. Moreover, our trainable parameter count on the model in the released code differs from the one reported in the original paper (ours: 88.5M, in-paper: 91.8M)[42,66]. Hence, self-training might deviate from the results in the official paper. We tried to contact the author for an ImageNet1K version of the model but did not succeed. We test the result of the released model (ImageNet22K version) on PGD attack and get an accuracy of 30.47. In the paper, the authors report this number to be 29.9 on the ImageNet1K model. Hence, we assume that the results of adversarial attacks can be used as a representative, though might be slightly optimistic. Importantly,this does not falsify our claim that TAPADL modification undermines the adversarial robustness of RVT, since TAPADL-RVT already falls short in PGD attack when compared to the ImageNet1K version of RVT-Base-plus. However, for the O.O.D test, ImageNet22K model can differ a lot from the ImageNet1K models, as most data would be counted as in-distribution w.r.t ImageNet22K. Therefore, we use the official values reported in the original paper[42]on those benchmarks. Moreover, for the comparison other than adversarial attacks, we use TAPADL-RVT[23]as a proxy of the RVT model.

SECTION: C.10Visualization of attention maps

We aim to qualitatively show that AdaNCA helps ViTs perform correct classification when facing noise. Here, we use GradCAM++[6]to visualize the attention map of Swin-Base[38]and Swin-B-AdaNCA on the clean images as well as images containing adversarial noise. We use APGD-DLR to generate the adversarial images. Results are shown in Figure9. We can observe that AdaNCA-enhanced Swin model focuses more on the objects, while the baseline model attends to areas unrelated to the object on the images when facing adversarial noise.

SECTION: C.11Integrating AdaNCA into pre-trained ViT models

In our experiments, we train all models from scratch. Implementing AdaNCA as a plug-and-play module for pre-trained ViT models would certainly improve the training speed. To explore this, we experiment by inserting AdaNCA into a pre-trained Swin-base model on ImageNet1K by 1) freezing all ViT layers; 2) training only the boundary layers, where boundary layers are the layers before and after the insert position of AdaNCA; 3) Finetuning all layers. Results are given in Table14. None of the schemes perform as well as training from scratch. The results indicate that the current NCA is able to adapt to such a scheme. However, it may struggle to effectively transmit information between two pre-trained ViT layers, as these layers have already established strong connections. In contrast, training the model from scratch allows NCA and ViT to synergistically adapt to feature variability, resulting in better overall performance. However, it is worth exploring in the future since the fine-tuning scheme can contribute to the performance.

SECTION: C.12Additional results on comparison with current methods

We have presented the comparison between our AdaNCA and the current SOTA method, TAPADL models[23], in Section4.1. Here, we provide an additional comparison with the ViTCA model[62]. In ViTCA, tokens interact with each other through local self-attention. We aim to compare our proposed Dynamic Interaction module with the interaction learning scheme in ViTCA. Results are given in Table15. Despite having more parameters, the ViTCA-like scheme performs worse in clean accuracy and is on-par with AdaNCA in robustness. This indicates that it is promising to explore the possibility of incorporating ViTCA into our framework.

SECTION: C.13Additional results on same model architecture but with more layers (models)

Due to the computational cost of RVT[42]and FAN[78](Table10), we do not train them with more layers and thus do not have aversion of these two models. Instead, we train the smaller version of models on ImageNet100. We choose RVT-small-plus (RVT-S) and FAN-small-hybrid (FAN-S) as two baselines, which is in line with our other experiments on ImageNet100. We add one extra layer to RVT-small-plus and one extra layer to the FAN network in FAN-small-hybrid, resulting in RVT-S⋆and FAN-S⋆. We compare it with our AdaNCA-equipped model where AdaNCA is after layer 9 in RVT-S and after layer 5 in the FAN-S, aligning with Table12. We use the same AutoAttack as described in SectionAto measure the robustness improvement and attack failure rate. Results are shown in Table16. We can observe that the increase in the number of parameters and FLOPS does not account for the improvement in robustness.

SECTION: C.14Additional results on layer similarity structure

Here, we show the layer similarity structure for FAN-B-Hybrid[78]and ConViT-B[16]with the ImageNet1K weights and the weights after training with AdaNCA. For RVT-Base-plus, we train it with the released code[66]but with a different number of parameters, as discussed in SectionC.9. This training is only for obtaining the layer similarity structure, and we find it stable after 30 epochs. The results are shown in Figure10. In practice, we ignore the stage partition found by the dynamic programming algorithm in SectionA.1that is after the first layer or before the last layer since we want a stage to contain more than 1 layer. The results further validate our assumption that AdaNCA is used as an adaptor between stages and transmits information between them, making them more and more different from each other. Interestingly, not all AdaNCA contributes to drastic clearer stage partitions. For example, the first AdaNCA in FAN-B is not effective in making the stage as clear as the second one. However, the overall Set Cohesion Index increases, and the layer similarity structures in all 4 networks do not change. We believe the deep learning architecture research can benefit from our results, in that developing more architectural changes which contribute to stage partition in the network and examine the effect on network robustness and generalization. More importantly, we use a single non-parametric metric for quantifying the layer similarities. Introducing advanced output similarity quantification methods might lead to new findings and other fascinating results.

SECTION: C.15Additional results on category-wise mCE on ImageNet-C

We provide additional results on category-wise mCE on ImageNet-C in Table17. Our test follows the data transformation used in[42].

SECTION: C.16Additional results on noise sensitivity examination

We use the data from[60]. In the experiment, human subjects are asked to classify the noise-contaminated images, and the classification accuracy is recorded. Then, the images are fed into the models trained on ImageNet1K, whose outputs are then transformed into a 16-way ImageNet label[56]and compared against the ground truth labels. Their classification accuracy is also recorded and used for comparison with human results.
We present the additional results on FAN-B-Hybrid[78]and the SOTA model TAPADL-RVT[23]compared to the AdaNCA-equipped model in Figure11.

Moreover, we adopt a quantitative metric on the test. In the original experiment[60], a Gaussian curve is fit based on the discretized accuracy map. However, such a method ignores the continuous change in the classification pattern. Hence, we propose a simple metric that examines the similarity between the accuracy map of humans and of models. Specifically, given the ground truth accuracy map (human performance), and model accuracy map, the similarityis defined as:

represent the magnitude and frequency of the noise, respectively. A higherindicates that the model can achieve more similar accuracy maps with humans averaged across all noisy images.is the total number of types of noise added. Since all models as well as humans perform similarly on low-magnitude noise, we ignore the first two noise levels (). Hence, in our experiments,. We reportin Table18. We also include the results of ResNet50[27]as well as the L2-adversarially-trained version[60](ResNet50-Adv, trained with L2-bounded adversarial noise where the maximum magnitude of noise is), and present the visualizations of the accuracy maps of those two models in Figure. Critically, our results indicate that the adversarially trained model cannot lead to improved accuracy similarities, resulting in a less human-like noise-resilient ability. This is in line with the conclusion of the original work[60], validating our proposed metric. Contrary to adversarial training, we obtain more human-like decision patterns than the compared models, validating our claim in Section4.4.

SECTION: C.17Datasets information and license

ImageNet1K[12]. This dataset contains 1.28M training images and 50000 images for validation. We report the top1 accuracy on the 50000 validation images. License:Custom (research, non-commercial).

ImageNet-C[28]. This dataset contains 15 types of 2D image corruption types that are generated by different algorithms. The metric on this dataset is mean corruption error, whose lower value represents a more robust model against those corrupted images. License: CC BY 4.0.

ImageNet-A[13]. This dataset contains naturally existing adversarial examples that can drastically decrease the accuracy of ImageNet1K-trained CNNs. It is a 200-class subset of the ImageNet1K dataset. License: MIT license.

ImageNet-R[30]. This dataset contains different artistic renditions of 200 classes from the original ImageNet object classes. The original ImageNet dataset discourages non-real-world images, and thus the artistic renditions render the images to be O.O.D. License: MIT license.

ImageNet-SK[67]. This dataset contains 50000 images with 1000 classes that match the validation set of the original ImageNet dataset. All the images are black-and-white sketches instead of real-world photographs of the object class. License: MIT license.

SECTION: C.18Model and code license

Swin-B[38]: MIT License.

FAN-B[78]: Nvidia Source Code License-NC.

ConViT-B[16]: Apache 2.0 License.

RVT[42]: Apache 2.0 License.

TAPADL[23]: MIT License.

Code for adversarial attacks[34]: MIT License.

PyTorch Image Model[69]: Apache 2.0 License.

Code for GradCAM++[19]: MIT License.

SECTION: Appendix DExtended ablation studies

In this section, we discuss the design of our AdaNCA and provide additional ablation studies on the designs of AdaNCA.

SECTION: D.1The dropout-like strategy

In Section3.1.1, we introduce our approach of using the dropout-like strategy to perform the stochastic update during training and testing. While previous NCA works claim that the stochasticity can be preserved[44,46]or can be simply switched off[62]during testing, the proposed dropout-like scheme is necessary in our case. First, We highlight that stochasticity during testing can hinder the evaluation of adversarial robustness by producing obfuscated gradients[3], leading to the circumvention of adversarial attacks. Table19illustrates this issue, where we test the classification accuracy under CW attack. Stochasticity also results in inconsistent outputs. This is problematic for practical image classification tasks where reliable output is critical, unlike applications focusing on visual effects[46,62]or collective behaviors[55]. The change in clean accuracy in Table19indicates that given the same image, the stochasticity can lead to different decisions, hindering the deployment of the trained models in real-world scenarios. To further demonstrate the necessity of our scheme, we remove the compensation of the output magnitude during training,i.e., we remove thein Equation7during training and directly test the model with a synchronized update. The results are given in Table20. The drop in clean accuracy and robustness suggests that downstream ViT layers struggle with varying NCA output magnitudes, indicating the usefulness of our proposed dropout-like method.

SECTION: D.2Dynamic Interaction

Our motivation for developing the Dynamic Interaction module is the high dimensionality of feature vectors in modern ViT models. We underscore that any operations involving linear transformations of the concatenated interaction results will lead to drastic increases in computational costs, as shown in Table21. Note that the concatenation scheme nearly doubles the FLOPS for RVT compared to the baseline, leading to difficulties in training. Such an increase renders scalability a challenge. Admittedly, more parameters can contribute to better performance, as shown in Table22. Note, however, that our Dynamic Interaction achieves  70% of the improvements of the original NCA concatenation scheme (10.06/14.62) in robustness improvement and  60% improvement in the clean accuracy (0.62/1.06), with merely  10% of the parameters and FLOPS (0.35/2.99 for # Params and 0.2/2.3 for FLOPS). Therefore, our Dynamic Interaction scheme provides a good trade-off between the performance and computational costs. It is capable of scaling up, allowing us to insert AdaNCA into even larger models, such as current vision-language models where the token dimensionality is even higher.
Moreover, we qualitatively showcase in Figure12, that Dynamic Interaction helps robustify AdaNCA when facing noisy inputs.

SECTION: D.3Multi-scale Dynamic Interaction

Our motivation for developing multi-scale interaction is to perform more efficient token interaction learning over local scales since ViT already contains global information. Enlarging the neighborhood size will: 1) Complicate the process of selecting the neighbors to interact with; 2) Introduce excessive noise, making it difficult for tokens to accurately acquire neighbor information. 3) Repeatedly acquire the global information provided by ViT. The recurrence further amplifies the noise. In our ablation study in Section4.3, we notice that increasing the number of scales to 3 will undermine the performance. Such an issue is also observed in previous work[62]where local self-attention is used for interaction learning. While in theory both Dynamic Interaction and self-attention can discount far-away information as the tokens can decide their own interaction neighborhood, overly large neighborhood size can lead to the problems mentioned above.
Note that our model gains performance when(neighborhood), indicating the usefulness of our multi-scale module.
We further explore whether the multi-scale issue can be solved by increasing the model capacity. Specifically, we develop two additional schemes. The first is to replace the dilation in Dynamic Interaction by simply using larger filters. The other one enlarges the receptive field of the weight computation networkin Equation9. Instead of using twoconvolution layers, we change the first layer to be aconvolution. As a result, the receptive field ofbecomes, matching the one when. We use the same training setting as in Section4.3. Results are given in Table23. Although increasing model capacity might alleviate the noise issues, AdaNCA struggles with overly large neighborhoods.

SECTION: Appendix EDifferences between traditional NCA and AdaNCA

While AdaNCA is inspired by NCA, it does not fully exploit the designs of traditional NCA. We discuss three key differences between AdaNCA and NCA below:

Different initial states. NCA in image generation starts from either constant or randomly initialized cell states, typically referred to as the seed states, while AdaNCA receives the outputs from previous ViT layers. Hence, AdaNCA handles structured inputs at the very beginning.

Different usage of cell states. Traditional NCA does not use all cell states for accomplishing the downstream tasks. After certain steps of evolution, a subset of the cell states is extracted to perform the given task. The unused cell states, termed hidden states, facilitate cell communications as they can be used to store additional information[44]. The dimensionality of the hidden states is typically several times that of the input. When the cell dimensionality is high, as is the case in ViT, adding too many hidden states will bring too much computational costs. Moreover, cells can store effective enough information when they have high dimensionality. Therefore, we do not adopt the hidden states design in AdaNCA.

No pooling strategy. A critical component of traditional NCA is the pooling strategy. Instead of starting from the seed states in every epoch, NCA fetches the starting states from a pool, where the output states from previous epochs are stored. Through this strategy, NCA can explore much longer time steps without suffering from gradients or memory issues. While it is tempting to incorporate the pooling trick into our method, two major concerns hinder its practical implementation: 1) The previous NCA models start from their own outputs in the pooling strategy. In other words, the cell states in the pool are generated by the model itself. However, AdaNCA starts from the outputs of a ViT layer. Such a difference renders the pool trick hard to implement. 2) Taking a step back, even if there is a well-designed pooling strategy for AdaNCA, it will bring too much computational costs during testing. A single step of AdaNCA introduces non-trivial FLOPS during testing, as shown in Table1. The ultimate goal of the pooling strategy is to ensure the stability of NCA in large time steps, while large time steps will slow down the inference.