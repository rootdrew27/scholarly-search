SECTION: Weighted Circle Fusion: Ensembling Circle Representation from Different Object Detection Results

Recently, the use of circle representation has emerged as a method to improve the identification of spherical objects (such as glomeruli, cells, and nuclei) in medical imaging studies. In traditional bounding box-based object detection, combining results from multiple models improves accuracy, especially when real-time processing isn’t crucial. Unfortunately, this widely adopted strategy is not readily available for combining circle representations. In this paper, we propose Weighted Circle Fusion (WCF), a simple approach for merging predictions from various circle detection models. Our method leverages confidence scores associated with each proposed bounding circle to generate averaged circles. We evaluate our method on a proprietary dataset for glomerular detection in whole slide imaging (WSI) and find a performance gain of 5% compared to existing ensemble methods. Additionally, we assess the efficiency of two annotation methods—fully manual annotation and a human-in-the-loop (HITL) approach—in labeling 200,000 glomeruli. The HITL approach, which integrates machine learning detection with human verification, demonstrated remarkable improvements in annotation efficiency. The Weighted Circle Fusion technique not only enhances object detection precision but also notably reduces false detections, presenting a promising direction for future research and application in pathological image analysis. The source code has been made publicly available at https://github.com/hrlblab/WeightedCircleFusion

SECTION: 1INTRODUCTION

Object detection plays an essential role in medical imaging[1], offering a wide range of applications that are enhanced by machine learning technologies. Traditional object detection models, such as Faster R-CNN[2], YOLO[3], and SSD[4], have been widely adopted across various domains for their efficiency and accuracy[5]. In medical object detection tasks, detecting glomeruli is essential for effective diagnosis and quantitative assessments in renal pathology. For these tasks, CircleNet[6]stands out in the medical field for its unique approach to detection tasks. Unlike conventional detection networks that rely on bounding boxes, CircleNet offers a rotation-consistent circle representation with fewer parameters for ball-shaped objects[7], such as glomeruli in kidney pathology (Fig.1). Despite CircleNet’s advantages, relying on a single CircleNet-trained model for detection tasks presents considerable challenges, including missed and false detections[8].

To enhance the robustness of object detection, ensemble learning algorithms, such as Non-Maximum Suppression (NMS)[9], Soft-NMS[10], and Weighted Box Fusion (WBF)[11], have been proposed to fuse the detection results from multiple models (Fig.1). NMS and Soft-NMS work by eliminating lower confidence detections based on an Intersection Over Union (IOU) threshold[12], with Soft-NMS adjusting detection scores rather than removing detections outright. WBF further refines this approach by merging overlapping detections, allowing those with higher confidence scores to improve the merged result. Unfortunately, such methods were optimized for traditional bounding box based representation for natural images.

In this paper, we propose a simple ensemble method, called Weighted Circle Fusion (WCF), designed specifically for circle representation in medical imaging detections. This method merges overlapping detections, with the fusion result’s position decided by the confidence of the contributing detections. Importantly, it calculates the number of overlapped circles merged for each object, while computing the average score for false positive elimination. In experiments, we assessed the detection results of glomeruli on whole slide images (WSIs) using five-fold cross-validation. Additionally, to validate the method’s consistency across rotations, we tested it on images rotated by 90 degrees. The results demonstrate the method’s decent rotation consistency. To summarize, the contribution of this paper is threefold:

The WCF method, combined with a dual thresholds strategy, enhances precision and reliability by fusing detection results from circle representation and eliminating false positives based on confidence scores and overlap across hard decisions.

Our method achieved a substantial performance gain (5% ) compared to the average results of individual models.

Utilizing a human-in-the-loop (HITL) approach to test the time required to annotate 10 WSIs, showed that it saves 68.59% of total annotation time compared to complete manual annotation.

SECTION: 2Methods

In this section, we introduce an innovative method for fusing predictions: Weighted Circle Fusion (Fig.2). This technique is designed to enhance the accuracy of object detection, particularly focusing on circular objects commonly encountered in medical imaging, such as cells, glomeruli, or other spherically shaped features. Our approach involves pairwise fusion of the detection results from five models, where the results from the first model are fused with the second, then the combined results are fused with the third model, and so on until the fifth model is included.

The WCF process begins with aggregating predictions from multiple models, resulting in several sets of detection outcomes. Initially, the detection results from the first model are stored in a list, referred to as. Subsequent detections from other models are compared against the entries in listbased on their cIOU[6].The definition of cIOU can be found in the corresponding reference. If the cIOU between any two detections exceeds a predetermined threshold, indicating an enhanced agreement between models on the presence and location of an object, these detections are considered for fusion.

Upon fusion of the two results, it is necessary to recalculate the coordinates and confidence score of the new, combined result. Given that our detection results are represented as circles, we utilize the circles’ center coordinates and radii for computation. Suppose the center coordinates and radius of a result from the first set are
(,) andwith a confidence score; and similarly, (,) andwith scorefor a result from the second set. The formulas for calculating the weighted average coordinates and radius are as follows:

For center coordinates:

For radius:

After calculating the fused coordinates, we compute the average of the scores of the merged results and keep track of how many detections have been merged to form this new result.

If a result from the second set cannot fuse with any result in list, it is directly added to. This process is repeated for each set of predictions until all m sets have been processed.

Upon completing the fusion of all model predictions, the confidence scorefor the fused result is calculated as follows:

whereis the confidence score of each individual model’s prediction.

Additionally, we apply a “count score”to quantify how many model predictions have been fused into a single detection. The max value ofdepends on how many models we use in our ensemble method.

To further refine the detection outcomes, we introduced two thresholds: “T count” for the count valueand “T score” for the average score of each result. Specifically, if both the count value and average score are below their respective thresholds, the detection result will be discarded. For the experiments in this paper, ”T count” is set to 2 and ”T score” is set to 0.9. This strategic approach enhances the precision of detection, making WCF particularly effective for instances where erroneous detections are common.

SECTION: 3Experiments

SECTION: 3.1Data

For our training dataset, we utilized an in-house dataset. This included 15,190 patches from whole slide images derived from renal biopsies. Additionally, we incorporated 9,260 patches from PAS-stained WSIs of murine kidneys. This dataset was divided into training, validation, and testing sets with a ratio of 7:1:2 for each of the five models.

For the training dataset for the plus version models, an additional 100,000 glomeruli were added to the basic training dataset used to train the base version of the model. These additional glomeruli were sourced from 170 WSI from our in-house dataset. The 100,000 glomeruli were divided into five groups of 40,000 glomeruli, with each group added to a different model. Each group of 40,000 glomeruli had a 20,000 overlap with the others. All patches in our training dataset were either cropped or resized to dimensions of 512 × 512 pixels. Each patch contained at least one glomerulus.

To evaluate the efficiency of different annotation methods for 200,000 glomeruli, we compared fully manual annotation with a human-in-the-loop (HITL) approach. The manual method involved human experts marking each glomerulus, whereas the HITL method integrated machine learning detection with human verification and correction. This comparison was conducted to assess the time efficiency and effectiveness of incorporating machine learning into the annotation process.

For the testing dataset, we included 15 PAS-stained WSIs, encompassing 2051 mouse glomeruli.

SECTION: 3.2Experiment Setting

The models were trained on the CircleNet architecture with a dla-34 backbone, using slightly varied datasets to enhance learning diversity and robustness. Training spanned 30 epochs for each model, and outputs were refined using the Non-Maximum Suppression algorithm.

We evaluated the efficiency of two annotation methods for 200,000 glomeruli in our KidneyPath dataset: fully manual annotation and a human-in-the-loop (HITL) approach. The manual method involved human experts marking each glomerulus, while the HITL method combined machine learning detection with human verification and correction. This comparison aimed to assess the time efficiency of integrating machine learning into the annotation process.

In this part of the experiment, we compared three ensemble methods: NMS, Soft-NMS, and WCF, as well as the results from five models and their plus version.
Each model was enhanced by the addition of 40,000 glomeruli training data, leading to improved performance. These 40,000 glomeruli were derived from an additional collection of 100,000 glomeruli, with a 20,000 overlap between each model.

Our WCF method was configured with specific parameters: a circle Intersection Over Union (cIOU) threshold of 0.5. For the experiments in this paper, ”T count” is set to 2 and ”T score” is set to 0.9. Initially, the WCF algorithm was applied to the outputs refined by the NMS algorithm to combine the strengths of individual detections into a single, more accurate result. The effectiveness of the WCF-fused results was meticulously evaluated and compared against the performance of individual models, traditional NMS, and Soft-NMS, with cIOU thresholds set at 0.5 and 0.3, respectively.

In this part, we delved into assessing the rotational consistency of their fusion method. This was achieved by extracting patches from Whole Slide Images and rotating them by 90 degrees prior to the detection process. The results from these rotated patches were then subjected to the same fusion process.

The models were evaluated based on the mean average precision (mAP) at IoU values of 0.5 and 0.75. Additionally, mAP was computed across a spectrum of IoU thresholds, thereby conducting a comprehensive assessment. This metric was calculated over a range of IoU thresholds, from 0.5 to 0.95 in steps of 0.05, at each step averaging the precision. Alongside precision, the average recall across these IoU thresholds was also measured, providing a rounded evaluation of model performance.

The IoU metric, a ratio reflecting the overlap between two objects versus their combined area, is traditionally calculated for bounding box representations. However, given that this study’s predictions utilize circle representations, we adopted the circle IoU (cIoU)[13]metric as our evaluation standard. The cIoU offers a more fitting measure for our circular detection outputs, aligning with the unique geometry of the objects being detected.

SECTION: 4Results

SECTION: 4.1Performance on glomerular detection

Fig.3and Table1showcase the performance of our fusion method, which integrates the outputs from five models and their enhanced version on murine glomerular WSIs. Averaged results are calculated from five original models and five enhanced models with 40000 additional global features, providing a comprehensive comparison across different fusion methods. The results demonstrate that our approach achieves remarkably higher mAP values and average recall rates. The enhanced models exhibit better average recall and average precision compared to the original models. Notably, the mAP obtained through our method surpasses that of any individual model included in the study. Although the average recall of our method is slightly lower compared to other fusion methods, it remains competitively high and exceeds the average recall of the five original models.

SECTION: 4.2Rotation consistency

The study meticulously explores the rotation consistency of our object detection method, offering detailed insights in Table2. The results underscored the WCF method’s notable consistency in rotation, highlighting its robustness against orientation changes. Our enhanced version of models also shows better rotation consistency compared to the original models.

SECTION: 4.3Manual Annotation vs. Human-in-the-loop Annotation

To evaluate the efficiency of manual annotation compared to a human-in-the-loop approach, we conducted a time analysis for annotating 10 WSIs. The results demonstrates that the HITL method considerably improves annotation efficiency, requiring an average of 2.9 minutes per image compared to 9.23 minutes per image for manual annotation.

SECTION: 5Conclusion

This work is the first to ensemble detection results for circle representation. We introduced a novel ensemble method, Weighted Circle Fusion (WCF), to refine predictions from multiple deep learning models. WCF demonstrated superior precision metrics, outperforming conventional benchmarks, especially in high-error contexts. Our findings highlight WCF’s potential in reducing errors in circle representation, making it a valuable strategy for medical image analysis using optimized deep learning approaches.

SECTION: References