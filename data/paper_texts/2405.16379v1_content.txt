SECTION: Selective inference for multiple pairs of clustersafter-means clustering

If the same data is used for both clustering and for testing a null hypothesis that is formulated in terms of the estimated clusters, then the traditional hypothesis testing framework often fails to control the Type I error.Gao et al. (2022)andChen and Witten (2023)provide selective inference frameworks for testing if a pair of estimated clusters indeed stem from underlying differences, for the case where hierarchical clustering and-means clustering, respectively, are used to define the clusters. In applications, however, it is often of interest to test for
multiple pairs of clusters. In our work, we extend the pairwise test ofChen and Witten (2023)to a test for multiple pairs of clusters, where the cluster assignments are produced by-means clustering. We further develop an analogous test for the setting where the variance is unknown, building on the work ofYun and Barber (2023)that extendsGao et al. (2022)’s pairwise test to the case of unknown variance. For both known and unknown variance settings, we present methods that address certain forms of data-dependence in the choice of pairs of clusters to test for. We show that our proposed tests control the Type I error, both theoretically and empirically, and provide a numerical study of their empirical powers under various settings.

SECTION: 1Introduction

Clustering is a widely used tool for studying unlabeled data that works by dividing a given data into groups based on certain similarity measures. The number of clusters to expect from a given data may not always be apparent, but several popular clustering algorithms require that it be specified, including-means clustering. In such cases,
researchers might try running the algorithm with a relatively large number of clusters and then examine if there exists any difference among several of the estimated clusters. It could then be of interest
to do a statistical test to investigate if there is indeed an underlying group structure among these clusters. In this work, we propose methods for testing the null hypothesis that states there is no difference in the means of the cluster centers of an arbitrary number of clusters, where the cluster assignments are produced by the-means algorithm run on the same data as the one used for inference; here, and in the rest of the paper, the cluster center of a cluster denotes the sample mean of the observations in the cluster.

Since our null hypothesis is formulated in terms of the clusters defined by-means clustering, it is inevitably data-dependent and breaches the assumption of the traditional hypothesis testing framework that all aspects of the inference procedure are determined independently of the data. As a result, traditional inference procedures may no longer be valid for such a setting—they could invalidate the p-value obtained, as well as undermine replicability, as discussed inBenjamini (2020). While sample splitting is a widely used method for addressing issues of data-dependence, it is not applicable to statistical inferences involving clusters, as discussed inGao et al. (2022)andNeufeld et al. (2024). An alternative approach that is relevant to such settings is a framework called selective inference, which, first proposed inFithian et al. (2014), allows for valid inference in the presence of data-dependence in the inference procedure. It works by accounting for the event that leads to this dependence—more specifically,Fithian et al. (2014)account for this event by considering the selective Type I error, the Type I error conditioned on the selection event.

To address the challenges of statistical inference for data-dependent clusters,
various selective inference procedures have been developed; examples includeGao et al. (2022)for hierarchical clustering algorithms,Chen and Witten (2023)for-means clustering,Bachoc et al. (2023)for convex clustering, andWatanabe and Suzuki (2021)for latent block models whose structure is determined by a clustering algorithm.

In particular,Gao et al. (2022)andChen and Witten (2023)provide selective inference frameworks for testing for
the difference in means between the cluster centers of a pair of clusters, which are chosen independently of the data from theestimated clusters. They consider the data generating distribution
whereobservationsforare generated independently as

with unknownand known. Letbe a partition of {1,…,n}, wheredenotes the set of indices of the observationss that are assigned to theth cluster.Gao et al. (2022)andChen and Witten (2023)consider the null hypothesis that states

whereanddenotes the mean of the cluster center of theth cluster.

Several works have extended these works to other related settings.Yun and Barber (2023)study the case where the parameterin (1) is unknown, andGonzález-Delgado et al. (2023)relax the assumption on the data generating process in (1) by allowing for dependence across the observations. Furthermore,Chen and Gao (2023)develop a method for testing the null hypothesis analogous to (2) for a single feature, which is also studied inHivert et al. (2022)but under different assumptions on the data.Hivert et al. (2022)additionally propose a method for testing for clusters that are in a specific arrangement with respect to each other. In this setting, they provide a method that combines the p-values produced by the test ofGao et al. (2022)for the pairs of clusters involved. While this work also considers a test for multiple clusters, it differs from our proposed tests in that the latter can be applied to any collection of clusters.

In this work, we extend the work of bothChen and Witten (2023)andYun and Barber (2023)by developing tests for multiple pairs of clusters for both known and unknown variances, where the clusters are produced by-means clustering.

SECTION: 1.1Global null hypothesis for multiple pairs of clusters

Letdenote the set of all possible index pairs out of integers 1 throughthe number of clusters outputted by-means clustering. We consider the null hypothesis that states

whereis defined as
the set of index pairs corresponding to the pairs of clusters to test for. Note that ifthen the null hypothesis states that the cluster centers of allclusters have equal means, i.e.,

The setcan be any subset ofand the way in which it is chosen determines the corresponding inference procedure.

Ifis chosen fromindependently of the data, then the data-dependence in the null hypothesis exists only through the clustering procedure. In this setting, note that ifcontains a single index pair, then the null hypothesis in (3) reduces to the null hypothesis in (2) that tests for the pair of clustersand

If the choice ofis data-dependent, then it introduces an additional selection event, which may lead to a lack of Type I error control if not accounted for. An example of such a data-dependent choice includes the selection of the pair of clusters
that are the closest to each other among all pairs.

Our contributions include the following:

when the noise levelin (1) is known, we provide a selective inference procedure for testing the null hypothesis in (3) for pre-specifiedalong with methods that address certain data-dependent choices of, and

we develop analogous procedures for the case whereis unknown.

For each of the tests that we propose, we provide a p-value that can be computed exactly.

An immediate test for the null hypothesis in (3) would be to combine the pairwise test ofChen and Witten (2023)with a correction for multiple comparisons. One such method for multiplicity adjustment is the Bonferroni correction, which is applicable to many settings due to the lack of distributional assumptions it makes, especially in this setting where the selective p-values may have complicated dependence structures; further discussion on the use of the Bonferroni correction in the context of testing for the null hypothesis in (3) can be found in Section3.1. Our method differs from this testing procedure in that it is based on a single test statistic that combines signals across all pairs of clusters of interest. With both being valid tests that control the Type I error, it would be interesting to compare how the two methods perform in terms of power—we provide a simulation study in Section6.1.1that explores their empirical powers in different settings.

The rest of the paper is organized as follows. In Section2,
we review the pairwise test ofChen and Witten (2023). In Sections3and4, we discuss the proposed tests for the null hypothesis in (3), for the cases where the setis pre-specified and chosen in a data-dependent way, respectively. In Section5, we propose analogous tests for the case of unknownSection6presents a simulation study on the Type I error control and empirical powers of the proposed tests, followed by an application to a real data in Section7. All of the proofs can be found in the Appendix, and the codes for reproducing the empirical results are available athttps://github.com/yjyun97/cluster_inf_multiple.

Throughout the paper, we letdenote the Frobenius norm of a matrix, and letdenote the-norm of a vector. Forwe letdenote the distribution of a random variablewherethe chi-squared distribution withdegrees of freedom. For a null hypothesisand an eventdenotes the probability of the event under.In the case where a null hypothesisdepends onfor some functionand random variabledenotes the conditional probability of an eventgivenunder—this notation appears in the statements of the theorems throughout this paper, which follow the style of those inYun and Barber (2023).For a setfor somewe letdenote a vector whoseth entry is 1 ifandotherwise; likewise,denotes a diagonal matrix whoseth diagonal entry is 1 ifand 0 otherwise. For anyanddenote an identity matrix inand a vector of 1s inrespectively, and fordenotes a matrix of 0s anda vector of 0s. For a setdenotes its cardinality, and for a matrixdenotes itsth row andits jth column. Finally, given a positive integer, we define.

SECTION: 2Pairwise test ofChen and Witten (2023)

We first review the method ofChen and Witten (2023)for testing the null hypothesis in (2), where-means clustering is used for generating the cluster assignments. Letdenote the matrix consisting of theobservations andthe cluster center of theth cluster. Further defineandwhich
denotes the projection matrix that projects onto the span ofChen and Witten (2023)propose the test statistic

which is the scaled distance between the cluster centers of theth andth clusters.

To account for the selection event, they condition on the clustering outcome—henceforth, letdenote the outcome of-means clustering run on the rows of a matrixwhere the outcome refers to the cluster assignments generated in every iteration of the algorithm. They further condition on components ofthat are independent ofin order to derive a p-value that can be computed. They thus provide the selective p-valuewhereis the conditional CDF (cumulative distribution function) ofgiven

whereThey show that the p-valueconditioned onis uniformly distributed under the null hypothesis in (2); specifically, they derive that the distribution functionequalswhich represents the CDF of thedistribution truncated to the set

where

In words,is the set of realizations of the test statistic for which the-means algorithm yields identical outcomes in every step of the algorithm to those of the algorithm run on

Chen and Witten (2023)derive an explicit characterization of the truncation setfor the clusters produced by the-means algorithm, specifically the standard Lloyd’s algorithm (Lloyd (1982)). Details of the algorithm can be found inChen and Witten (2023, Section 2.1).

To presentChen and Witten (2023)’s characterization ofwe first define relevant notations that have been modified from those ofChen and Witten (2023). Suppose that-means clustering is applied to the rows offoriterations. We letdenote theth cluster center determined at the initialization step of the-means algorithm, and for each, whererepresents the initialization step, we letdenote the cluster assignment of theth row ofatth step of the algorithm. Further define

forandwhererepresents the average of the rows ofin theth cluster, where the clusters are defined by the output of theth iteration of-means clustering run onFor eachanddefine the functionwhereanddenote the set of functions fromtoand the power set ofrespectively,

Here, and throughout the rest of the paper,for a matrixandis used interchangeably withfor the clarity of notations.Chen and Witten (2023)show that

The authors further show that
eachis the set of solutions to a quadratic inequality, and thusin (6) is the set of solutions to a system ofquadratic inequalities.

SECTION: 3Proposed test forwith pre-specified

Building on the work ofChen and Witten (2023), we develop a test for the null hypothesis in (3). Throughout this section, we consider the setting whereis known andis pre-specified.

SECTION: 3.1Baseline testing procedure for

Before presenting the proposed method, we first discuss a baseline test for the null hypothesis in (3) that combines the pairwise test ofChen and Witten (2023)reviewed in Section2with the Bonferroni correction. We consider the Bonferroni adjusted p-value given bywhich, conditioned onfollows the super-uniform distribution. As an illustration of the test’s Type I error control, Figure1presents a QQ plot of a sample ofgenerated under the null hypothesis in (3) withi.e.,forThe test, as expected, controls the Type I error, and we see that it becomes more conservative asincreases. More details on the simulation settings of Figure1can be found in Section6.1.1.

SECTION: 3.2Proposed method

We now present the proposed test for the null hypothesis in (3). Defineas the matrix of the orthogonal projection that projects onto the spaceWe propose the test statistic

which captures signals across all pairs of clusters of interest. Building on the work ofGao et al. (2022)andChen and Witten (2023), we consider the decomposition of

whereWith this decomposition in mind, we define the p-value aswhereis the conditional CDF ofgiven

Theorem1provides an explicit form of the distribution function

Under the null hypothesisin (3),

where, andrepresents the CDF of thedistribution truncated to the set

where

Furthermore,

It remains to characterize the selection eventin Theorem1. It follows from the characterization ofofChen and Witten (2023)discussed in Section2that

By the definitions of the functionsforandgiven above (6), eachis characterized by inequalities of the form

ifand those of the form

ifwhereandProposition2below, analogous toGao et al. (2022, Lemma 2)andChen and Witten (2023, Lemma 2), states that these inequalities can be written as quadratic inequalities in

LetandFor alland

with coefficients

whereand

It then follows from Theorem1and Proposition2thatcan be computed exactly.

The null hypothesisreduces to the null hypothesisifIn this setting,andreduce toandrespectively, and thus
the proposed test generalizes the pairwise test ofChen and Witten (2023).

Different choices ofcan lead to equivalent statements of the null hypothesisFor example, two different choicesandlead to the same statement ofif the spans ofandare equal. Under this condition, the proposed test remains the same sinceis invariant to different specifications ofthat correspond to the same setThe baseline testing procedure discussed in Section3.1, however, differs since different choices oflead to different tests. The reason is thatdepends on both the cardinality ofand the specific pairs of clusters chosen for the pairwise test ofChen and Witten (2023)—Section6.1.1presents a comparison of empirical power of the baseline testing procedure for different specifications ofassociated with the same set

SECTION: 4Proposed test forwith data-dependent choice of

In many applications, researchers may use the clustering outcomes to choose the pairs of clusters to test for. For instance, one may choose the index pairthat corresponds to the two clusters whose cluster centers are the farthest (or the closest) from each other (or to each other) and then test for the null hypothesis in (3) withto decide if the clustersandindeed stem from underlying differences. In such cases,is chosen in a data-dependent way, and the way in which it is chosen defines the additional selection event. Depending on howis chosen, not accounting for the selection event may lead to a lack of Type I error control. The left-hand plot of Figure2presents a QQ plot of a sample ofgenerated under the null hypothesis in (3) withthat corresponds to the pair of clusters that are the farthest apart among theclusters. It illustrates that the distribution ofdeviates from the uniform distribution, in such a way that the test based onfails to control the Type I error. However, not accounting for the data-dependence in the selection ofmay not always lead to a lack of Type I error control, as we see in the right-hand plot of Figure2, whose settings are analogous to those of the left-hand plot except that the pair of clusters that are the closest to each other is chosen. More discussion on this phenomenon can be found in Remark3, and additional details on the simulation settings of Figure2can be found in Section6.1.2.

In this section, we propose a test for the null hypothesis in (3) whereis chosen in a data-dependent way, for specific forms of data dependence. We adapt the test presented in Section3.2to additionally account for the data-dependence in the choice ofHenceforth, letfor a matrixdenote the outcome of the procedure that selects the setbased onWe consider the same test statisticand define the p-value as, whereis the conditional CDF ofgiven

whereis as defined in (8). Theorem3below, analogous to Theorem1, provides an explicit form of the distribution function

Under the null hypothesisin (3),

whereis as defined in Section3.2,
andrepresents the CDF of thedistribution truncated to the setwhere

Furthermore,

The characterization of the setdepends on the way in whichis chosen. We consider three settings where the choice ofdepends on the dataonly through thedistances between cluster centers, after the data has been divided intoclusters. We show thatin each of the settings can be written as a set of solutions to a system of inequalities.

Letdenote the-th largest among all between-cluster distancesforwhereis pre-specified. If we choose the pairs of clusters whose corresponding distances are among the-th largest, thenThe corresponding truncation set takes the form

whererepresents the relative complement ofwith respect to. Ifconsists of a single index pair corresponding to the pair of clusters whose cluster centers are the farthest apart among all pairs of clusters, which coincides with the setting of the left-hand plot of Figure2.

Letbe the-th smallest among all between-cluster distancesforwhereis pre-specified. If we choose the pairs of clusters whose corresponding distances are among the-th smallest, thenThe corresponding truncation set takes the form

If,consists of a single index pair corresponding to the pair of clusters whose cluster centers are the closest to each other among all pairs of clusters, which coincides with the setting of the right-hand plot of Figure2.

Supposeis a pre-specified threshold. If we choose the pairs of clusters where the distances between the cluster centers are no larger thanthenThe corresponding truncation set takes the form

Similarly, ifthentakes a similar form, but with the direction of the inequalities reversed.

Note that the setis defined by quantities of the formin each of the settings above. Proposition4shows thatfor any vectorcan be written as a quadratic expression in

LetandFor any vector,

with coefficients

whereand

Thus,in each of the three settings is a set of solutions to a system of quadratic inequalities, as is the case for. It follows thatcan be computed exactly by Theorem3and Proposition4.

We see in the right-hand plot of Figure2that the test based onwhich does not account for the data-dependence in the choice ofstill controls the Type I error under Setting2. Intuitively,is more likely to happen under the selection event of Setting2, so, in this setting, it may be natural to expect the test based onto be more conservative than the test based onIt could then be of interest to ask if the latter has any advantage over the former—in Section6.1.2, we compare the empirical powers of the two tests to address this question, and we observe that the test based onleads to a higher empirical power. Another example of such a phenomenon in a different context is discussed inSaha et al. (2024).

SECTION: 5Unknown variance

In practice, the noise levelin (1) is often unknown. In Section5.1,
we give a review of existing methods that test for a pair of clusters under this setting. Then, in Section5.2, we present our proposed test that considers multiple pairs of clusters.

SECTION: 5.1Existing methods

We start by discussing two existing approaches for testing for a pair of clustersandwhich are assumed to be chosen independently of the data.

Gao et al. (2022)andChen and Witten (2023)provide tests for the null hypothesis in (2) that are based on plug-in estimators forThey show that if the estimators satisfy certain properties, then the tests control the Type I error asymptotically in one of the two dimensions.Gao et al. (2022)provide the estimator

which, as they show, asymptotically over-estimatesunder certain conditions.Chen and Witten (2023)provide the median-based estimator

whererepresents the median of a distribution or the median of a set of values depending on the input, and show that a closely related estimator to that of (13)
is consistent in one of the two dimensions under certain conditions. In terms of the performance of the two estimators,Chen and Witten (2023)numerically illustrate that their proposed test achieves a higher empirical power when applied with

In Section6.2.1, we show empirically that the proposed test of Section3.2controls the Type I error when applied with each of the two estimators.

Alternatively,Yun and Barber (2023)propose a selective inference procedure that avoids the use of a plug-in estimator. They consider a stronger null hypothesis that states

whereare pre-specified. The null hypothesis
assumes that the means of all of the observations in the clustersandare equal, thereby allowing for the derivation of a test statistic whose distribution is known under the null hypothesis; more discussion on the motivation behind the stronger null hypothesis can be found inYun and Barber (2023, Section 3). They propose the test statistic

whereis as defined in Section3.2,and

They provide the selective p-valuewhereis the conditional CDF ofgiven

whereThey show that the p-valueconditioned onfollows the uniform distribution underSpecifically, they derive that the distribution functionequalswhich represents the CDF of thedistribution truncated to the set

where

whereYun and Barber (2023)derive an explicit characterization of the truncation setfor the case whereclusters are produced by a clustering algorithm that is invariant to the scale and location of the data, which includes-means clustering, and provide an importance sampling algorithm for the case where

SECTION: 5.2Proposed test for

As discussed in Section5.1, the pairwise tests ofGao et al. (2022)andChen and Witten (2023)for the null hypothesis in (2) that are based on plug-in estimators forcontrol the Type I error asymptotically. While the pairwise test ofYun and Barber (2023)controls the Type I error in finite samples, the computation of the associated p-value relies on a sampling algorithm in the presence ofclusters. In this section, we provide a test for multiple pairs of clusters that avoid the use of estimators and produce exact p-values, building on the works ofChen and Witten (2023)andYun and Barber (2023).

Following the approach ofYun and Barber (2023), we consider the null hypothesis that states

Note (16) is stronger than (3) in that the former assumes all of the observations in the clusters of interest have the same mean, and it reduces to the null hypothesis in (14) if

Letdenote the set of indices of all clusters of interest. Analogous to the test statistic in (15), we propose the test statistic

whereandare as defined in Section3.2,, and

which generalizesIntuitively,andreflect the overall between-cluster differences and within-cluster variations, respectively, for the clusters whose indices are inNote that the test statisticis undefined when each of the clusters with indices inconsists of a single observation, which aligns with the intuition that there is not enough information to estimate the level of within-cluster variations in such a case. Building on the work ofYun and Barber (2023), we consider the decomposition

whereandWith this decomposition in mind, we derive the selective p-value, separately for the cases where the setis pre-specified and chosen in a data-dependent way.

We first consider the case whereis pre-specified. In this setting, we define the selective p-value aswheredenotes the conditional CDF ofgiven

Theorem5gives an explicit form of the distribution function

Under the null hypothesisin (16),

whererepresents the CDF of thedistribution truncated to the set

where

Furthermore,

We next characterize the setAnalogous to (6) and (9),
we have

where, by the definitions of the functionsforandgiven above (6), eachis defined by inequalities of the form

ifand those of the form

ifwhereandTherefore, to characterize,
it suffices to find the sets of solutions to a system of inequalities of the forms above. Proposition6expresses these inequalities explicitly with respect to

Let,, andFor allandthe inequalities in (20) and (21) are equivalent to

respectively, where

with coefficients

where,,,,, and.

It follows by Theorem5and Proposition6thatcan be computed exactly.

Note that for anyandandare continuous functions, soandare also continuous. Thus, Proposition6shows that the set of solutions to each of (20) and (21) is equivalent to the sub-level set of a continuous function at 0, which can be found by solving for the roots of the function and checking the signs of its values on each interval partitioned by the roots; further details on the implementation can be found in AppendixA.2.2.

We next consider the setting whereis chosen in a data-dependent way and develop a test that is analogous to that of Section4. In this setting, we define the selective p-value as, whereis the conditional CDF ofgiven

whereis as defined in (18). Theorem7gives an explicit form of the distribution function

Under the null hypothesisin (16),

whererepresents the CDF of thedistribution truncated to the set

where

Furthermore,

The characterization of the setdepends on the specific way in whichis chosen. We again consider Settings1through3of Section4, withreplaced byThen, the setin Settings1and2is defined by inequalities of the form

whereandin Setting3is defined by inequalities of the form

whereandProposition8expresses these inequalities explicitly with respect to

Letandbe defined as in Proposition6. For any two vectorsand for anythe inequalities in (23) and (24) are equivalent to

respectively,
where

with coefficients

where,, and

The solution sets to the inequalities in (25) can be computed by a method analogous to that discussed in Remark4. It then follows by Theorem7and Proposition8thatcan be computed exactly.

SECTION: 6Simulations

We now present a simulation study of the proposed tests, exploring their Type I error control and empirical powers.
Sections6.1and6.2provide empirical results for the settings where the noise levelis known and unknown, respectively. Sections6.1.1and6.2.1consider the case whereis pre-specified, and Sections6.1.2and6.2.2address the case where the choice ofis data-dependent. Specifically, Sections6.1.1,6.2.1,6.1.2, and6.2.2demonstrate the numerical performance of the proposed tests based on the p-valuesandrespectively.
In relevant contexts, we make comparisons with the baseline testing procedure of Section3.1as well as the tests based on the plug-in estimatorsandFor the simplicity of writing, we henceforth denote the tests based onandasandrespectively, where

Before presenting the empirical results, we first discuss the simulation settings that are common to all experiments in this section. For each test,
we sample the associated p-value as follows. We draw each data from the distribution in (1) withandand run-means clustering to divide the observations intoclusters, where the values forandare specified in the respective sections.
We then compute the selective p-value. We discuss below the ways in which the Type I error control and the empirical power of a test are illustrated in each section.

For experiments under the null hypothesis, we setin (1) asTo explore the Type I error control of a test, we sample the associated p-value 1500 times. We then present a QQ plot that compares the empirical quantiles of the 1500 p-values against the theoretical quantiles of the uniform distribution supported on

For experiments under the alternative hypothesis, we consider the setting where there aredifferent values ofs, and we henceforth refer to the sets of indices of the observations partitioned by their means as true clusters. Additionally, we seti.e., the number of clusters produced by-means clustering is equal to the number of true clusters. We consider two different specifications ofin (1) for studying the empirical power of a test. For anyand eachdefine

(Horizontal)and

(-gon)

Note that ifforare arranged horizontally, andforform thevertices of a polygon, hence the labels. We set each of theclusters to contain an equal number of observations; specifically, there ares that are set tofor eachfor the Horizontal case, and similarly for the-gon case—we only consider values ofthat divideVisualizations of data generated from the two specifications ofalong with the clustering outcomes for the case whereandare shown in Figure3—in visualizations of clustering outcomes in this figure and in the rest of this paper, true clusters are differentiated by shape and (estimated) clusters by color.

For each signal strengthandset according to either of the two specifications above, we
sample 1500 p-values of the test of interest. Then, for each value ofwe compute the empirical power of the test as the proportion of null hypotheses that are rejected (at the significance level of 0.05) among those that are false, and present a plot of empirical powers against

SECTION: 6.1Testing forfor known

We start by presenting the Type I error control and empirical powers of the proposed tests for the null hypothesis in (3), whereis assumed to be known. The performance of the testsandare illustrated in Sections6.1.1and6.1.2, respectively. Unless specified otherwise, we setthroughout the experiments in this section.

For the setting whereis pre-specified, we test for the global null hypothesiswhere we consider three different choices of:

and

As the corresponding spacesforare identical, the proposed testremains invariant to the different choices of, while the baseline testing proceduredoes not; see Remark2for further discussion.

Figure4presents QQ plots of
samples ofgenerated under the null hypothesis. The plots show thatis uniformly distributed, which is consistent with Theorem1. Analogous plots forfor the setting whereandwas presented in Figure1.

Figure5presents the empirical powers ofandwhere the performance of the latter is compared for the three different choices ofThe figure illustrates that the relative performances of the tests vary depending on the signal strength: the proposed testachieves a higher empirical power thanin the presence of weak signals, while the opposite is true in the presence of strong signals.

We speculate that the intuition for the higher empirical power ofin the presence of weak signals lies in the construction of the test statistic that combines the signals across all pairs of clusters of interest by considering the span of all of the vectorss forinOn the other hand, the presence of at least one strong signal is conducive towhose test statistic is associated with only the strongest signal, potentially accounting for its superior performance for large values of

We next consider the setting whereis chosen in a data-dependent way.

The first and second columns of Figure6present QQ plots of empirical p-values obtained from the testsandrespectively, under the null hypothesis whenclusters are produced by-means clustering. Consistent with Theorem3, the figure shows thatis uniformly distributed under both Settings1and2. On the other hand,fails to control the Type I error under Setting1, where the test becomes more confident asthe number of pairs of clusters chosen, decreases. The test controls the Type I error under Setting2but becomes more conservative asdecreases. As discussed in Remark3, this observation aligns with the intuition that the null hypothesis is less likely to happen under Setting1and more likely to happen under Setting2. Note that the QQ plot of a sample offor the case wherewas also presented in Figure2.

Figure7presents analogous results for different values ofwhenpairs of clusters are chosen to be tested. The figure shows that asincreases,becomes more confident under Setting1and more conservative under Setting2. Both Figures6and7illustrate that the effects of not accounting for the data-dependence in the choice ofare not significant, especially whenis small oris large.

Figure8presents empirical powers ofandunder Settings1and2withandAs suggested by the Type I error control ofthe empirical power oftends to be lower than that ofunder Setting1, and the opposite is true under Setting2.

SECTION: 6.2Testing forfor unknown

We next consider the setting whereis unknown and test for the null hypothesis in (16). Unless specified otherwise, we setthroughout the experiments in this section. The choice ofthat is relatively large is due to a computational limitation ofwhich we discuss below.

Since the selective p-valueis the right-tail probability of a truncateddistribution, its computation involves taking ratios of probabilities associated with thedistribution, which may be very small in some cases. As a result, computing the probabilities using a built-in function inRand then taking ratios can lead to numerical inaccuracies. To address this computational issue, we take an alternative approach for computing the p-value. Specifically, following the approach ofYun and Barber (2023, Appendix A.3), we first use the procedure ofLi and Martin (2002)to approximate the truncation setwhich is associated with thedistribution (where) with a set associated with thedistribution, which we denote asso thatwhererepresents the CDF of thedistribution truncated to the setWe then compute the approximation ofusing the functionTChisqRatioApproxof the packageKmeansInferenceofChen and Witten (2023).

We speculate that the approximation of thedistribution with thedistribution is less accurate for values that are far in the right tail of thedistribution. We have observed that the realizations of the settend to decrease withand increase withand the signal strengthAccordingly, we have noticed that the accuracy of the approximation, as measured by the empirical Type I error control oftends to increase withand decrease withandwhere the realizations oftend to be underestimated for small values ofThus, to ensure that the results presented in this section are accurate both under the null hypothesis and the alternative hypothesis, we setunless specified otherwise.

We test for the global null hypothesisfor allwhere we set

Figure9presents QQ plots of samples of p-values obtained from the testunder the null hypothesis, which are consistent with Theorem5. Figure10presents analogous plots forforillustrating that each test controls the Type I error empirically.

Figure11presents empirical powers of the testsandforThe figure illustrates that the relative performances ofandfor either choice ofis analogous to that illustrated in Figure5, whereachieves a higher empirical power in the presence of weak signals. The figure shows that the empirical powers ofandfor either choice ofdo not differ much in the presence of weak signals. For strong signal strengths,tends to perform marginally better thanbut is outperformed byin most cases.

In this figure, as well as in Figures11and13, the empirical power ofmay not be trusted for large values offor the Horizontal case as we have observed that the realizations oftend to be large even when

Figure12presents the empirical powers ofandwhere the latter assumesis known, illustrating the loss of power due to not knowing

We next letbe chosen in a data-dependent way. We specifically consider the case where it is chosen as in Setting1withandThe leftmost plot of Figure13illustrates thatcontrols the Type I error, as implied by Theorem3. The middle and the rightmost plots compare the empirical powers ofandthe latter of which assumesis known, to illustrate the loss of power due to not knowing

SECTION: 7Real data application

We next apply the proposed methods to the penguins data ofHorst et al. (2020), which is also studied inGao et al. (2022),Chen and Witten (2023), andYun and Barber (2023). The data consists of measurements of different body parts of three species of penguins (Adelie, Gentoo, and Chinstrap) of the male and female sexes. For our purposes, we specifically consider the variables bill depth (mm) and bill length (mm) of female penguins. We test for the null hypothesis in (16): Sections7.1and7.2present the cases whereis pre-specified and chosen in a data-dependent way, respectively.

SECTION: 7.1Testing forwith pre-specified

For the case whereis pre-specified, we test for the equality of means of all observations, i.e., we consider the global null hypothesisfor allwhere we setWe apply the testsandforfor two different subsets of the penguins data, a subset consisting of observations from the Adelie species only and a subset consisting of observations from both the Adelie and Gentoo species, which we assume to be consistent with the null and the alternative hypotheses, respectively. We run-means clustering on the standardized data withand present an average of 100 realizations for each p-value to account for the randomness in the initialization step of the algorithm. Note that we omit the testdue to the relatively small number of features that could cause the associated p-value to be underestimated, as discussed in Section6.2.

Figure14presents visualizations of the outcomes of an instance of-means clustering run on the two subsets of the data, and Table1presents an average of 100 p-values associated with each of the tests considered. The table illustrates that the p-values of the proposed tests tend to be lower than those of the baseline testing procedure, both under the null and alternative hypotheses.

SECTION: 7.2Testing forwith data-dependent choice of

We next choosein a data-dependent way after running-means clustering on the subset of the data that consists of observations from the Adelie and Gentoo species, which coincides with the subset visualized in the right-hand plot of Figure14. We apply the testsandfor—again, we omit the testWe run-means clustering on the standardized data withand choosepairs of clusters according to each of Setting1and Setting2. The two pairs that are chosen according to Setting1areandand those chosen according to Setting2areand—note that such choices align with the visualizations of the clustering outcomes illustrated in Figure15. Table2presents the p-values of the tests and shows that the tests that do not account for the data-dependence in the choice ofresults in the same p-values as those that do. This observation is consistent with the simulation results of Section6.1.2, where we have observed that the effect of not accounting for this additional selection event is noticeable only for relatively large values of

SECTION: 8Discussion

In this work, we have developed tests for multiple pairs of clusters for both known and unknown variance settings, extending the work ofChen and Witten (2023)andYun and Barber (2023). We have shown that the proposed tests control the Type I error, and we have derived expressions for the associated p-values that can be computed exactly. We have also presented numerical illustrations of the empirical powers of the proposed tests, which we have compared with that of the baseline testing procedure that combinesChen and Witten (2023)’s test with the Bonferroni correction—empirical results illustrate that the proposed tests tend to have a higher empirical power in the presence of weak signals. We have also briefly discussed a computational limitation ofwhich we speculate lies in the computation of probabilities associated with a truncated distribution.

As a possible direction for future work, it would be of practical importance to develop tests for the null hypothesisfor data generated from a more flexible model that captures the complexity of real data. Another direction of computational importance would be to explore ways of computing more accurate selective p-values associated with a truncateddistribution, especially for truncation sets that lie far in the tail of the distribution with non-negligible probability. In this work, we have approximated thedistribution with thedistribution, which is then approximated using the normal distribution. It could be of interest to study ways of approximating thedistribution directly with the normal distribution. Improvements in the accuracy of such computations would not only address the computational limitation of the proposed test based onbut also provide a valuable tool in the literature of selective inference.

SECTION: 9Acknowledgements

Yinqiu He was partially supported by Wisconsin Alumni Research Foundation. We thank the Center for High Throughput Computing (Center for High Throughput Computing (2006)) for the computational resources that were used for producing the empirical results presented in Section6.

SECTION: References

SECTION: Appendix AAppendix

AppendixA.1contains proofs of the theorems and propositions
presented in this paper. AppendixA.2provides details on the implementations of the proposed tests, which align with the codes available athttps://github.com/yjyun97/cluster_inf_multiple.

SECTION: A.1Proofs

The proofs of Theorems1and3can be found in AppendixA.1.1, and those of Theorems5and7can be found in AppendixA.1.2. Additionally, the proofs of Propositions2,4,6, and8can be found in AppendicesA.1.3,A.1.4,A.1.5, andA.1.6, respectively.

We first introduce additional notations that are used throughout the proofs. We writeforandto denote thats follow the distributionindependently, and we writeto denote thatfollows the distributionunder the null hypothesisLikewise,anddenote that the equality and the proportionality, respectively, hold under the null hypothesis

Before presenting the proofs, we state and prove Lemmas9and10, which are used in the proofs of Theorems1,3,5, and7.

For any vectorunder

Sincefor someThen,sincefor allunder∎

Letbe a matrix whose rows are distributed independently as in (1). Letfor somewhereforare orthonormal. Supposein (1) satisfies the condition that for eachThen,

Defineand defineforto be matrices whereand the remaining entries are 0; here,fordenotes the entries of the matrixcorresponding to the rowsthroughand all columns. Next, letNote that

and

By the assumption thatfor alland the distributional assumptions onwe haveThus, it follows that

Then,

where the equality follows by linearity ofIt then follows from (27) that

Finally, by (26), we have

∎

We now present the proofs of Theorem1, Theorem3, Theorem5, and Theorem7.

The proofs closely followYun and Barber [2023, Appendix A.1]and parts ofGao et al. [2022, Appendix A.1].

We start by presenting the proof of Theorem3. We first note thatconditioned onandis uniformly distributed underby the property thatis uniformly distributed for a random variablewith CDFThen, for any

as desired.

We next characterize the distribution functionFor any realizationofdefine

for anyThen,is the conditional PDF (probability density function) ofgivenandWe aim to show

whereis the PDF of thedistribution. To show (28), we first state and prove Lemmas11and12.

Suppose the cluster assignments and the setare pre-specified, i.e.,forand the setare determined independently of the data. Then,

Letbe an orthonormal basis ofThen,so we have

where the second equality follows from the orthogonality of the vectorsforNote that for eachandby Lemma9, andBy the orthogonality acrossforand the distributional assumptions onwe haveFinally, independence acrossforgives∎

Suppose the cluster assignments and the setare pre-specified. Then,

under

Recallby Lemma11. We proveandare independent underby showing that

Note that for eachsoandare independent. By independence acrossforwe further have independence acrossforAs a result,andare independent, which allows (29) to be equivalently written as

since for random quantitiesandwe have thatimpliesWe next showLetbe an orthonormal basis ofand writewherefor allby Lemma9. Then, Lemma10gives the desired result. It follows that (30)
can be equivalently written aswhich holds by Lemma11.
∎

We now show (28). In the remainder of this section, we writeto make explicit the dependence ofonandFix any realizationofand definewhere

and

where

Letbe the PDF ofin the setting where the cluster assignments and the setare pre-specified; similarly defineas the joint PDF ofandandas the PDF ofNote that

Then,

where (32) follows from the definition of the function(33) follows from the observation in (31), and (34) holds by Lemma12. Thus, we have

where the equality follows from the observation that

By Lemma11,is the PDF of thedistribution,
and thus we have shown (28).

To prove Theorem1, recall thatis pre-specified in the setting of Theorem1. Then,and Theorem1immediately follows from Theorem3.

The proofs closely followYun and Barber [2023, Appendix A.1]and parts ofGao et al. [2022, Appendix A.1].

We first present the proof of Theorem7. We first note thatconditioned onandis uniformly distributed underby the property thatis uniformly distributed for a random variablewith CDFThen, for any

as desired.

We next characterize the distribution functionFor any realizationofdefine

for anyThen,is the conditional PDF ofgivenandWe aim to show

whereis the PDF of thedistribution. To show (36), we first state and prove Lemmas13and14, which are used in the proofs of Lemmas15and16.

Letandbe as defined in Section5.2. Then,andare orthogonal.

We show thatandare orthogonal, wherefor a matrixdenotes its column space. Note

and recall that for anyTherefore, we have

whereis as defined in Section5.2. Thus, to showit is enough to show

which immediately follows from the orthogonality between

∎

For eachunder

Fix anyUnderfor somefor allWe thus haveLikewise,givingTherefore,

∎

Suppose the cluster assignments and the setare pre-specified. Then,

We first showLetbe an orthonormal basis ofand writeThen,

Fix anyandWe haveandwhere the former follows by Lemma9sinceimpliesThen, independence acrossforand the distributional assumptions onimplyFinally, independence acrossforgives

We next show

where the first equality holds by the orthogonality acrossforand the fact thatfor eachFix anyandand note that

whereandis idempotent and has rankIt follows that

sinceby Lemma14.
Note thatforare independent by orthogonality acrossforand the distributional assumptions onIt follows that

Then, independence acrossforgives

Finally, we show thatandare independent. Note thatandare orthogonal by Lemma13, so for eachthe distributional assumptions onimply independence betweenandThen, independence acrossforimplies independence acrossforwhich then implies thatandare independent. Thus, by definition of thedistribution, we have

∎

Suppose the cluster assignments and the setare pre-specified. Then,

under

By Lemma15, we have

We proveandare independent underby showing that

To show (37), we repeatedly use the fact that for random quantitiesand

For eachthe distributional assumptions onand the orthogonality acrossandgive independence acrossandFurthermore, the independence acrossforimplies independence acrossforAs a result,andare independent, so (37) can be equivalently written as

where we use the fact in (38). Next, note that independence betweenandgives

Further note that there exist orthonormal basesandof the column spaces ofandrespectively, so we can writeandFor eachby Lemma9sinceimpliesFurthermore,for eachby Lemma14sincefor someThus, by Lemma10, we have

underThen, (40) and (41) imply

allowing (39) to be equivalently written as

Finally,undersincewhereandunderTherefore,
(42) is equivalent to

which holds by Lemma15.
∎

We now show (36). In the remainder of this section, we writeto make explicit the dependence ofonandFix any realizationofand definewhere

and

where

Letbe the PDF ofin the setting where the cluster assignments and the setare pre-specified; similarly defineas the joint PDF ofandandas the PDF ofNote that

Then,

where (45) follows from the definition of the function(46) follows from the observation in (44), and (47) holds by Lemma16. Thus, we have

where the equality follows from the observation that

By Lemma15, we have thatis the PDF of thedistribution, and thus (36) holds.

To prove Theorem5, recall thatis pre-specified in the setting of Theorem5. Then,and Theorem5immediately follows from Theorem7.

Recalland fix any

Fix anyand

Recalland fix any

For the simplicity of notations, letFix anyWe first show

Sincewe have

Substitutingwe have

Thus,

Similarly, we have

Then, sinceit follows that

Fix anyWe next show

Again, bywe have

Substitutingwe have

Thus,

Similarly, we have

Then, sinceit follows that

For the simplicity of notations, letFix anyWe first show

Sincewe have

Substitutingwe have

Thus,

Similarly, we have

Then, sinceit follows that

Fix anyandWe next show

By (A.1.6), we have

Then,

SECTION: A.2Notes on implementation

All of the implementation is done inR. Parts of the implementation of the proposed methods have been adapted from the source code of the packageKmeansInferenceofChen and Witten [2023]or call its functions—more details can be found in the codes. In the rest of this section, we elaborate on various aspects of the implementation of the proposed tests.

A challenge in computinggiven a set of vectorslies in finite precision. For instance, it may be the case that two linearly dependent vectors are numerically linearly independent due to finite precision. To address this phenomenon, we computedifferently depending on the value of

Ifthen we know thatsince the setforms a basis forby Lemma17below.

Ifwe resort to numerical methods for computingWe use the functionfast.svdfrom the packagecorpcorfor computing the condensed singular value decomposition (SVD) that gives the condensed SVDofwhereis the matrix whose columns consist of the vectors inIn the case wheredoes not have full rank, it is likely to be the case thatstill has full numerical rank due to finite precision. To account for finite precision, we set the rank ofi.e.,to be the number of diagonal entries ofwhich corresponds to the number of “nonzero” singular values ofwhere the default threshold value of the functionfast.svdis used for determining if a singular value is to be treated as zero.

To be consistent with the computation ofdiscussed above, we computedifferently depending on the value of

Ifwe compute the projection matrixby settingwhereis an orthogonal matrix whose columns are generated by the Gram-Schmidt orthogonalization procedure applied to the columns ofusing the functiongramSchmidtfrom the packagepracma.

Ifwe computeby settingwhereis as defined above.

Here, we state and prove Lemma17, which is referred to in the discussion above.

SupposeThen, the setforms a basis of

Note that ifthenFor anysuch thatnote that

Thus, we haveThe other direction trivially holds.

We next show thatforare linearly independent. SupposeNote

Defineand letdenoteth entry ofSinceforwe haveThen, sinceforwe haveThe same argument holds forFinally, sinceforwe haveThus,for alland it follows thatforare linearly independent.
∎

By Proposition6,is a set of solutions to a system of inequalities, where each inequality takes the form

In this section, we elaborate on the implementation for finding the set of solutions to (50). Sinceonis a bijective map, the set of values ofsatisfying the inequality is bijective with the set of values ofsatisfying the same inequality. Thus, we aim to find the sub-level set ofat 0, where

Defineto be the set of non-negative real roots ofSinceis continuous, intermediate value theorem implies that for anyonly if there existssuch thatwhereforis equal to 1 if-1 ifand 0 ifOnce we computewe find the set of solutions to the inequalityby checking the sign ofon each interval partitioned by its roots, i.e., the elements ofTo computewrite

and define

and

Note

which is a quartic equation inWe then solve forby checking the conditionfor each

We use theRbase functionpolyrootto solve for the roots of the quartic equality in (52). We now briefly discuss how we address finite precision in our implementation in the rest of the procedure. For determining whether a root is real, i.e., if its imaginary part is 0, and for checking if the conditionis satisfied, we use a relatively large tolerance level of 1—note that having additional values inleads to a finer partition of the interval, which does not alter the output of the procedure for computing the set of solutions to (51). To determine if there is multiplicity for a root, we use the functionalmost.uniquefrom the packagebazarwith a stringent threshold ofto avoid losing any root of

Note that the tests proposed throughout this paper, as well as those ofChen and Witten [2023], assume that the-means algorithm outputsclusters at each iteration of the algorithm, an assumption implicitly made in the characterization of the truncation setsin (6),in (9), andin (19). Thus, the tests cannot be applied with theoretical guarantees if-means clustering outputs a different number of clusters at any iteration of the algorithm.

However, there are instances in practice where the algorithm produces a different number of clusters at the final step than that at the initial step. We omit such cases in our simulations, having the corresponding functions returnNAfor the p-value, and only the outputs that are notNAare reflected in the QQ plots and the computation of the empirical powers. We have observed that the number of instances of this phenomenon is small compared to the number of p-values generated.