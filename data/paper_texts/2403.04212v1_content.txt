SECTION: Persona Extraction through Semantic Similarity forEmotional Support Conversation Generation

Providing emotional support through dialogue systems is becoming increasingly important in today’s world, as it can support both mental health and social interactions in many conversation scenarios. Previous works have shown that using persona is effective for generating empathetic and supportive responses. They have often relied on pre-provided persona rather than inferring them during conversations. However, it is not always possible to obtain a user persona before the conversation begins. To address this challenge, we proposePESS(PersonaExtraction throughSemanticSimilarity), a novel framework that can automatically infer informative and consistent persona from dialogues. We devise completeness loss and consistency loss based on semantic similarity scores. The completeness loss encourages the model to generate missing persona information, and the consistency loss guides the model to distinguish between consistent and inconsistent persona. Our experimental results demonstrate that high-quality persona information inferred by PESS is effective in generating emotionally supportive responses.

Index Terms—Persona, Consistency, Dialogue System, Emotional Support Conversation Generation

SECTION: 1INTRODUCTION

In today’s world, many people feel isolated and have mental health difficulties due to the recent pandemic[1,2]. They may not have enough friends to turn to for help, or they may be afraid to seek help publicly. This circumstance highlights the importance of dialogue systems and chatbots that can provide emotional support[3,4], providing a confidential space where people can express their feelings and seek help. Dialogue systems must get to know their users well to give appropriate emotional support. Getting to know users involves understanding their preferences, personality, and current state. This information is called the user’s persona. Numerous studies[5,6]have demonstrated the effectiveness of incorporating user persona into dialogue generation. A common approach in these studies has been to rely on pre-provided user persona, rather than inferring the persona during the conversation. However, in real-world settings, it is not always practical to ask users to provide their persona before the conversation begins.

To address this challenge, there is a need for models that can automatically infer persona information from dialogues. Several attempts have been made to extract persona information from dialogues. Xuet al.[7]trained classifiers to filter utterances that contain persona information from dialogue history. However, this approach is not always reliable, as user utterances can contain noise that makes it difficult to capture crucial persona information. Additionally, the user’s persona may be expressed across multiple utterances, requiring a certain level of reasoning.
Another approach[6]employed BART[8]which is fine-tuned on the Persona-Chat dataset[9]. Given the user’s entire utterances in dialogue history, their model is trained to infer the user’s persona which consists of multiple persona sentences. However, their model often missed some persona information or generated some persona that didn’t match with ground-truth persona. This is due to the lack of focus on ensuring sentence-level consistency between the inferred persona and the ground-truth persona.
Therefore, we need a more fine-grained approach that can take into account the sentence-level consistency of the persona.

We proposePESS(PersonaExtraction throughSemanticSimilarity) that can infer informative and consistent persona from dialogues by providing fine-grained signals to the model based on semantic similarity scores. We compare the ground-truth persona and generated persona at the sentence level to check if any persona sentences are missing and to determine whether each generated persona sentence is consistent or inconsistent with the ground-truth. The consistency of the generated persona with the ground-truth is determined by measuring semantic similarity scores between them. Based on this information, we design two losses Completeness Loss and Consistency Loss. The completeness loss encourages the model to identify and fill in missing persona information by penalizing the model for missing persona sentences. The consistency loss guides the model to distinguish between consistent and inconsistent persona by pulling the consistent persona sentences and the ground-truth persona closer, and by pushing the inconsistent persona sentences further away from the ground-truth persona.

In summary, our contributions are as follows: (1) We proposePESS, a persona extraction framework that can generate an informative and consistent persona. We achieve this by introducing Completeness Loss and Consistency Loss based on semantic similarity scores. The completeness loss is designed to encourage the generation of missing persona information, and the consistency loss guides the model to differentiate between consistent and inconsistent persona. (2) Our experiments demonstrate that the proposed persona extractor PESS generates a high-quality and consistent persona, and show that the persona inferred by PESS significantly contributes to generating emotionally supportive responses.

SECTION: 2METHOD

We start from comparing ground-truth persona and generated persona by measuring semantic similarity scores between them (2.2). Then we train persona extractor using two key components: Completeness Loss (2.3) and Consistency Loss (2.4) based on the information derived inSection2.2. Next, we infer the user’s persona from the dialogue history using the trained persona extractor and the inferred persona is leveraged to generate a response (2.6).

SECTION: 2.1Problem Definition

The conversation between two speakers A and B are represented as, whereandare the-th utterances of speakers A and B, respectively, andis the number of conversation turns. The ground-truth personas of speakers A and B are denoted asand. Here,andare-th ground-truth persona sentences of each speaker, and,are the number of speaker’s persona sentences, respectively. Assume that the set of speaker A’s utterances inis. Then the persona of speaker A, inferred fromby the persona extractor PESS is expressed as, whereis the number of the generated persona sentences. Here, the persona extractor is a transformer-based language model. We aim to encourage the persona extractor to generate an informative and consistent personafrom the speaker’s utterances history. Then, we use the inferred personaand dialogue historyto generate an appropriate response, which is speaker B’s response to speaker A’s-th utterance. For the sake of brevity, in the rest of this paper, we refer toasandas.

SECTION: 2.2Semantic Similarity for Consistency Measurement

Figure1illustrates the overall process of finding the consistent persona and the missing persona. First, we compare the ground-truth persona and the generated persona. The generated persona may contain both sentences that are consistent and inconsistent with the ground-truth. Therefore, fine-grained comparison is needed to determine which sentences are consistent and which are not. Huanget al.[10]segment the generated summaries into sentences to determine faithfulness of each sentence. Inspired by the work of[10], we split the generated persona and the ground-truth persona into sentences and measure semantic similarity between each sentence pair. This gives us a semantic similarity score matrix. The semantic similarity scoreof-th ground-truth persona sentenceand-th generated persona sentenceis:

whereis cosine similarity function, andrepresents sentence transformer[11]that calculates embedding of sentence.

Next, for each ground-truth persona sentence, we find the best matching generated persona sentence, which has maximum similarity score. We denote the mapping function from the-th ground-truth persona sentence to the best matching generated persona sentence as:

Here, iffor a given ground-truth persona sentence, it means thatis consistent with. Otherwise,is inconsistent with, and there is no matching generated sentence for. Here,is a hyperparameter that indicates similarity threshold.

We refer to the set of consistently generated persona sentences as, and the set of missing ground-truth persona sentences is denoted as. We utilize these two setsandto design the completeness loss and the consistency loss.

SECTION: 2.3Completeness Loss

To encourage the persona extractor to generate missing persona information, we construct a new target personain place of original target. An example is shown inFigure1.is formed by taking the union of the consistently generated personaand the missing persona:

The completeness loss is standard negative log-likelihood loss on new target personaas:

By introducing the completeness loss, we can provide additional fine-grained signals to the model. Specifically, we give a small penalty for consistent personasince the model already generates them with a high probability. In contrast, a larger penalty is applied to missing personadue to its lower likelihood of being generated. This encourages the model to focus more on generating the missing persona information.

SECTION: 2.4Consistency Loss

The objective of consistency loss is to train the persona extractor to distinguish between consistent and inconsistent persona sentences through contrastive learning[12]. The consistency loss guides the model to generate persona that are consistent with the ground-truth persona by pulling the consistent persona sentences and the ground-truth persona closer, and by pushing the inconsistent persona sentences further away from the ground-truth persona. Positive samples are persona sentences from consistently generated persona, and negative samples are persona sentences that are in generated personabut not in. The goal is to maximize the agreement of the positive samples and minimize the agreement of the negative samples in the embedding space. The consistency loss is expressed as follows:

whereandare the decoder’s last layer representations of generated persona,is the decoder’s last layer representations of the ground-truth persona.

SECTION: 2.5Training Objectives

The persona extractorPESSis trained with the combined total loss:

whereis standard negative log-likelihood loss on the ground-truth persona,

SECTION: 2.6Response Generation

After training our persona extractor PESS, we freeze PESS and combine it with response generation model. We refer to this combined model as PESS-GEN. We adopt the architecture proposed in PAL[6]for our response generation model.Figure2illustrates the structure of PESS-GEN. Given dialogue historywhich is a conversation between two speakers A and B, PESS infers speaker A’s personafrom the set of speaker A’s utterances.
Then,andare given to response generation model. The response generation model is trained to generate response, which is speaker B’s response to speaker A’s last utterance. The training objectiveof response generation model is represented as:

whereis length of. We denoteasinEquation6.