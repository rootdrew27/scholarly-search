SECTION: CViT: Continuous Vision Transformer for Operator Learning
Operator learning, which aims to approximate maps between infinite-dimensional function spaces, is an important area in scientific machine learning with applications across various physical domains. Here we introduce the Continuous Vision Transformer (CViT), a novel neural operator architecture that leverages advances in computer vision to address challenges in learning complex physical systems. CViT combines a vision transformer encoder, a novel grid-based coordinate embedding, and a query-wise cross-attention mechanism to effectively capture multi-scale dependencies. This design allows for flexible output representations and consistent evaluation at arbitrary resolutions.
We demonstrate CViT’s effectiveness across a diverse range of partial differential equation (PDE) systems, including fluid dynamics, climate modeling, and reaction-diffusion processes. Our comprehensive experiments show that CViT achieves state-of-the-art performance on multiple benchmarks, often surpassing larger foundation models, even without extensive pretraining and roll-out fine-tuning. Taken together, CViT exhibits robust handling of discontinuous solutions, multi-scale features, and intricate spatio-temporal dynamics. Our contributions can be viewed as a significant step towards adapting advanced computer vision architectures for building more flexible and accurate machine learning models in the physical sciences.

SECTION: Introduction
Neural operatorshave emerged as a powerful class of deep learning models for scientific machine learning applications, particularly in building efficient surrogates for expensive partial differential equation (PDE) solvers. These models aim to learn mappings between infinite-dimensional function spaces, enabling rapid acceleration of complex simulations in fields such as fluid dynamics and climate modeling. Popular architectures like Fourier Neural Operators (FNO)and DeepONethave shown promising results, supported by universal approximation guaranteesand interpretations as learning low-dimensional manifolds in function spaces.

However, the architectural design of current neural operators has largely been motivated by mathematical intuition about the structure of PDE solution spaces, rather than leveraging recent advances in deep learning architectures. This approach, while theoretically sound, may limit the performance and flexibility of these models when applied to complex, real-world physical systems.

In parallel, the field of computer vision has seen significant advancements in neural field models, which represent continuous functions parameterized by neural networks. A key innovation in this domain has been the development of conditioned neural fields, which allow for auxiliary inputs to modulate the field’s behavior. These models have demonstrated remarkable effectiveness in tasks such as representing high-resolution images and 3D scenes.

Motivated by the success of conditioned neural fields in computer vision, we introduce the Continuous Vision Transformer (CViT), a novel neural operator architecture that bridges the gap between advanced computer vision techniques and scientific machine learning. Our main contributions can be summarized as follows:

We introduce CViT, a neural operator that combines a vision transformer encoder with a novel, trainable grid-based coordinate embedding in its decoder. This design enables CViT to effectively capture multi-scale spatial dependencies and allows for continuous querying at arbitrary resolutions.

We present novel insights into the impact of coordinate embeddings on the Lipschitz constant of neural fields and neural operators. This analysis supports the choice of the proposed grid-based coordinate embedding and its efficacy in mitigating spectral bias, a common limitation in training neural operators .

Despite its architectural simplicity, CViT achieves state-of-the-art results on challenging benchmarks in climate modeling, fluid dynamics and reaction-diffusion processes. It often outperforms larger models while using fewer parameters and without requiring extensive pretraining.

Taken together, we explore the connection between operator learning architectures and conditioned neural fields, offering a unifying perspective for examining differences among popular operator learning models (see Appendicesand). This perspective not only enhances understanding of existing architectures but also provides a general framework for designing future neural operators. By bridging the gap between computer vision and scientific machine learning, CViT paves the way for improved surrogates of complex physical systems, with potential applications ranging from climate modeling to engineering design.

SECTION: Background and Related Work
The emergence of neural operators has sparked significant advancements in scientific machine learning, particularly in the realm of solving partial differential equations (PDEs) and modeling complex physical systems. Building upon the foundational architectures mentioned in the introduction, recent developments have focused on enhancing the expressiveness and efficiency of these models. For instance, extensions of the Fourier Neural Operator (FNO)have explored factorized representationsto reduce computational complexity while maintaining performance. Similarly, wavelet-based approacheshave been proposed to capture multi-scale features more effectively. Most existing neural operator architectures can be interpreted as conditioned neural fieldswith specific choices of base fields and conditioning mechanisms, see Appendicesandfor a detailed discussion.

Concurrently, the success of vision transformers in computer vision tasks has inspired their adaptation to scientific machine learning problems. The self-attention mechanism central to transformers offers a powerful tool for capturing long-range dependencies in spatial and temporal data, a crucial aspect in many PDE-governed systems. However, adapting vision transformers to the continuous nature of physical problems poses unique challenges, particularly in handling irregular domains and ensuring output consistency across different resolutions.

In the specific context of operator learning, several transformer-based approaches have emerged to address these challenges. OFormerintroduced a novel way to embed continuous input functions and output queries into a transformer architecture. This approach demonstrated the potential of transformers in handling the inherent continuity of physical problems. GNOTfurther extended this idea by incorporating graph structures, allowing for more flexible representation of input functions and improved handling of irregular domains. A significant advancement in this direction came with DPOT, which introduced a denoising pre-training strategy. This approach enables the model to learn from diverse PDE datasets, significantly enhancing its generalization capabilities.
However, these methods often require extensive computational resources for training and may struggle with maintaining consistency when evaluating at arbitrary resolutions.

Despite these advancements, several key challenges remain in the field of operator learning. These include efficiently handling high-dimensional data while capturing long-range dependencies, ensuring output consistency and accuracy across different resolutions, and balancing model expressiveness with computational efficiency.
Addressing even a subset of these challenges requires novel architectural designs that can leverage the strengths of both neural operators and vision transformers while overcoming their respective limitations. This sets the stage for our proposed Continuous Vision Transformer (CViT), which aims to tackle specific challenges related to resolution independence and efficient capturing of multi-scale features in regular grid-based problems, combining the continuous nature of neural operators with the powerful representation capabilities of vision transformers.

SECTION: Continuous Vision Transformer (CViT)
While neural operators have shown promising results in learning mappings between function spaces, their architectural design has not fully leveraged recent advancements in deep learning. Popular architectures like FNO, DeepONet, and NoMaD(see Appendix) primarily rely on simple building blocks such as Fourier layers or fully connected networks, which may not effectively capture complex spatial dependencies and multiscale features present in many physical systems.

Motivated by the success of vision transformers in computer vision tasks, we introduce the Continuous Vision Transformer (CViT), a novel neural operator architecture that combines the strengths of vision transformers and continuous function representations. CViT aims to learn more powerful and flexible representations of time-dependent physical systems by leveraging a vision transformer encoder to capture complex spatial dependencies in input functions, a trainable grid-based positional encoding for flexible representation of query coordinates, and a cross-attention mechanism to integrate input function information with query coordinates.

Taken together, the overall design of CViT’s architecture draws inspiration from the analysis of existing neural operators presented in Appendix, while leveraging the power of vision transformers to enhance expressiveness.

SECTION: Architecture Description
The CViT architecture consists of three main components: a vision transformer encoder, a grid-based positional encoding, and a cross-attention mechanism.

The vision transformer encoder takes as input a gridded representation of the input function, yielding a 2+1 dimensional spatio-temporal data tensorwithchannels. We patchify our inputs into 3D tokensby tokenizing each 2D spatial frame independently, following the process used in standard Vision Transformers. We then add trainable 1D temporal and 2D spatial positional embeddings to each token:

To reduce computational cost, we use a temporal aggregation layer based on the Perceiver architecture. Specifically, we learn a predefined number of latent input queriesby applying a cross-attention module that maps the flattened visual featuresto a latent tensoras

Here,is initialized by a unit Gaussian distribution andis obtained by tiling the latent querytimes. Besides compressing tokens over the time axis, this module also enables the model to handle inputs with a variable number of time steps.

We then process the aggregated tokensusing a sequence ofpre-norm Transformer blocks,

To enable continuous evaluation of outputs, we design a novel and efficient coordinate embedding to capture the fine-scale features of the target functions. Specifically, we create a uniform grid, forand, along with associated trainable latent grid features. For a query point, we compute a Nadaraya-Watson interpolant over grid latent features:

Hereis a hyperparameter that determines the locality of the interpolated features. It is important for determining the smoothness of the interpolation function. Specifically, larger values ofyield more localized weight distributions, resulting in a higher-frequency interpolant that captures finer-scale variations. Conversely, smallervalues produce a smoother interpolant by averaging over a broader neighborhood of points.

The interpolated grid featureis used as query input to a transformer decoder. This decoder uses the output of the vision transformer encoderas keys and values in a cross-attention mechanism:

Finally, a small MLP network projects the output to the desired output dimension.

The theoretical analysis of Lipschitz constants for different coordinate embeddings (as detailed in Appendix) provides crucial insights that inform the design choices in CViT and have broader implications for neural operator architectures. Our findings reveal that the choice of coordinate embedding significantly influences the decoder’s capacity to learn complex, high-frequency functions.

For conventional MLP decoders with linear coordinate embeddings, the Lipschitz constant is approximately 1 at initialization, which does not enhance the network’s ability to capture fine-scale features, thereby leading to prediction susceptible to spectral bias. In contrast, random Fourier features can increase the Lipschitz constant through two mechanisms: by increasing the standard deviation of the sampling distribution or by increasing the network width. This observation not only explains the effectiveness of Fourier features in addressing spectral bias, but also highlights a potential trade-off between network size and the frequency range that can be captured.

Our proposed grid-based coordinate embedding in CViT offers a more direct and controllable approach to increasing the network’s Lipschitz constant. By adjusting the interpolation parameter, we can tune the model’s ability to capture high-frequency components in the target functions. This provides a clear advantage as it allows for more precise control over the model’s spectral properties without necessarily increasing model complexity.

To further highlight the key innovations of CViT, we compare it with other popular transformer-based operator learning methods:

:
OFormer uses an encoder-decoder structure. Its encoder combines a point-wise MLP and stacked self-attention blocks to process input functions, while employing random Fourier Featuresfor query coordinate encoding. The model generates latent embeddings through cross-attention at sampled query locations.
In the decoder, OFormer uses recurrent MLPs for dynamic propagation instead of traditional masked attention. Unlike CViT, it doesn’t use ViT’s patch embedding to tokenize input functions, potentially limiting its ability to capture complex spatial dependencies.

: GNOT is a transformer-based framework for learning operators that addresses the challenges of multiple input functions and irregular meshes. It designs a heterogeneous normalized attention layer, providing an encoding interface for various input functions and additional prior information. Additionally, GNOT features a geometric gating mechanism, described as a soft domain decomposition approach to multi-scale problems. Unlike CViT, GNOT uses an plain MLP to process query coordinates, which may potentially suffer from spectral bias.

: DPOT is a transformer-based architecture designed for pretraining on multiple PDEs. It introduces a new auto-regressive denoising strategy and a novel model architecture based on Fourier attention. Unlike OFormer, GNOT, and CViT, DPOT does not explicitly take query coordinates as inputs, which implies that it cannot be evaluated at arbitrary locations.

: MPP is a large-scale PDE surrogate model that directly employs a Vision Transformer as its backbone. Similar to DPOT, it does not take query coordinates as inputs, thereby losing flexibility in diverse output representations.

SECTION: Experiments
We compare the CViT against popular neural operators on three challenging benchmarks in physical sciences. In addition to demonstrating CViT’s performance against strong baselines, we also conduct comprehensive ablation studies to probe the sensitivity on its own hyper-parameters.

We construct CViT models with different configurations, as summarized in Table. For all experiments, unless otherwise stated, we use a patch size offor tokenizing inputs. We also employ a decoder with a single cross-attention Transformer block for all configurations. While we tested decoders with multiple layers, they did not yield improvements. The grid resolution is set to the spatial resolution of each dataset. The latent dimension of grid features is set to 512, and if it does not match the transformer’s embedding dimension, we align it using a dense layer. Besides, we useto ensure sufficient locality of the interpolated features. These choices are validated by extensive ablation studies, as illustrated in Figure. Full details of the training and evaluation procedures are provided in Appendix.

We select the following methods as our baselines for comparisons.: One of the first neural operators with universal approximation guarantees.: A recently proposed architecture leveraging nonlinear decoders to achieve enhanced dimensionality reduction.: An efficient framework for operator learning in the frequency domain.: An improved version of FNO utilizing a separable Fourier representation, which reduces model complexity and facilitates deeper network structures.: A U-shaped neural operator with FNO layers.: A modern U-Net architecture using bias weights and group normalization, and wide ResNet-style 2D convolutional blocks, each of which is followed by a spatial attention block.: A U-Net variant where the lower blocks in both the downsampling and upsampling paths are replaced by Fourier blocks, each consisting of 2 FNO layers with residual connections.: A ResNet model that adapts filter sizes at different layers using dilated convolutions, providing an alternative method for aggregating global information.//: Various transformer-based architectures for operator learning, with different designs of their encoder/decoder and attention mechanisms./: Transformer-based networks with patch embedding as in ViT, and pre-trained on extensive PDE datasets using a rollout loss.

For all baselines, we report evaluation results from the original papers when applicable. When not applicable, we train and evaluate each model following the suggested settings in the respective paper. Details on the implementation of baseline models are provided in Appendix.

SECTION: Main Results
Here we provide our main results across three challenged benchmarks. The full details on the underlying equations, dataset generation and problem setup for each case are provided in the Appendix; see Section,and, respectively.

The first benchmark involves predicting the transport of discontinuous waveforms governed by a linear advection equation with periodic boundary conditions. We make use of the datasets and problem setup established by Hoop. This benchmark evaluates our model’s capability in handling discontinuous solutions and shocks in comparison to popular neural operator models.

Figureillustrates the test sample corresponding to the worst-case prediction of each model we compared. We observe that CViT is able to better capture the discontinuous targets and yield the most sharp predictions across all baselines. This is also reflected in both the relative L2 and Total Variation error metrics; see Appendix Tablefor a more complete summary, including details on model configurations, as well as average, median and worst case errors across the entire test dataset.

The second benchmark involves a fluid flow system governed by the 2D shallow-water equations. This describes the evolution of a 2D incompressible flow on the surface of the sphere and it is commonly used as a benchmark in climate modeling. Here we adhere to the dataset and problem setup established in PDEArena, allowing us to perform fair comparisons with several state-of-the-art deep learning surrogates.

Tablepresents the results of CViT against several competitive and heavily optimized baselines.
Our proposed method achieves the lowest relativeerror.
It is also worth noting that the reported performance gains are achieved using CViT configurations with a significantly smaller parameter count compared to the other baselines. This highlights the merits of our approach that enables the design of parameter-efficient models whose outputs can also be continuously queried at any resolution. Additional visualizations of our models are shown in Figureand.

In addition, here we perform extensive ablation studies on the hyper-parameters of CViT. The results are summarized in Figure. As shown in Figure(a), we observe that a smaller patch size typically leads to better accuracy, but at higher computational costs. Moreover, Figure(b) demonstrates that the model performance is significantly influenced by the type of coordinate embeddings used in the CViT decoder. We compare our proposed grid-based embedding against a small MLP and random Fourier features. The grid-based embedding achieves the best accuracy, outperforming other methods by up to an order of magnitude. This result is in agreement with the theoretical insights presented in Appendix.

We also investigate the impact of the resolution of the associated grid. Figure(c) reveals that the best results are obtained when the grid resolution matches the highest resolution at which the model is evaluated. As another direct empirical evidence of theoretical results in Appendix,
Figure(d) shows the CViT model’s sensitivity to the hyper-parameterused for computing interpolated features; too smallvalues can degrade predictive accuracy. Finally, in Appendix Figure, we observe minor improvements by increasing the latent dimension of grid features, or the number of decoder attention heads. Hence
the overall model performance remains robust to variations in these hyper-parameters.

Taken together, these findings not only justify our design choices for CViT but also provide general insights for the development of neural operators. They suggest that future research in this field should pay close attention to the interplay between spatio-temporal tokenization, coordinate representation, and the inherent multi-scale nature of physical systems. Such considerations could lead to even more effective architectures for a wide range of scientific machine learning tasks.

Our third benchmark corresponds to predicting the evolution of a 2D buoyancy-driven flow, depicting a smoke volume rising in a bounded square domain. The underlying governing equations are the incompressible Navier-Stokes equations coupled with a passive scalar transport equation. For a fair comparison with various neural operators and other state-of-the-art deep learning models, we use the dataset generated by PDEArena, and follow the problem setup reported in Hao.

Our main results are summarized in Table, indicating that CViT outperforms all baselines we have considered. Notably, the previous best result (DPOT-L (Fine-tuned)) is achieved with a much larger transformer-based architecture, which involves pretraining on massive diverse PDE datasets followed by fine-tuning on the target dataset for 500 epochs. Here we also note that DPOT was pretrained and fine-tuned using a rollout loss, which directly optimizes for the multi-step prediction task on which the models are evaluated. In contrast, CViT was trained using a one-step loss without any rollout finetuning. This difference in training objective significantly favors DPOT for rollout evaluations across all benchmarks.
Furthermore, CViT exhibits remarkable parameter efficiency. CViT-S, with only 13M parameters, achieves accuracy comparable to the largest pretrained model (1.03B). Additionally, CViT shows good scalability; as the number of parameters increases, performance improves. These findings strongly support the effectiveness our approach in learning evolution operators for complex physical systems.
Additional results and sample visualizations are provided in Figure, as well as Figureandin Appendix.

Our final benchmark focuses on learning the density fieldsgoverned by a coupled 2D diffusion-reaction equation (DR). This PDE, commonly used in chemistry, models substances reacting and diffusing across a spatial domain, illustrating chemical reaction processes and resulting in diverse spatial patterns. For a fair comparison, we use the dataset from PDEBenchand follow the problem setup described by.

Tablepresents our main results. Consistent with previous findings, CViT-L achieves the best performance across all baselines. CViT models outperform other approaches with comparable or fewer parameters, demonstrating good scalability and parameter efficiency.
Representative rollout predictions are provided in Figureand(see Appendix). Our predictions show excellent agreement with the corresponding ground truth.

Interestingly, we note that the solution of Diffusion-Reaction equations appears simpler than that of the Navier-Stokes equation dataset, resulting in uniformly lower test errors for various baselines in the DR benchmark.
In particular, OFormer outperforms GNOT in both examples, despite having comparable parameters. We postulate that this performance gain is due to the use of random Fourier features in OFormer, facilitating more efficient learning of complex functions. This observation further demonstrates the importance of coordinate embedding in designing neural operators and indirectly highlights the effectiveness of our proposed grid-based embedding.

SECTION: Discussion
This work introduces the Continuous Vision Transformer (CViT), a novel neural operator architecture that leverages advances in computer vision to address challenges in learning complex physical systems. CViT combines the strengths of vision transformers and continuous function representations, achieving state-of-the-art accuracy on challenging benchmarks in climate modeling, fluid dynamics and reaction-diffusion processes. Our approach demonstrates the potential of adapting advanced computer vision techniques to develop more flexible and accurate machine learning models for physical sciences. The key innovations of CViT include: (a) a vision transformer encoder for capturing multi-scale spatial dependencies in input functions, (b) a trainable grid-based positional encoding for flexible representation of query coordinates, and (c) a query-wise cross-attention mechanism ensuring consistent evaluation at arbitrary resolutions. These design choices ensure that CViT maintains the desirable properties of a well-defined conditioned neural field (as discussed in Appendix), while offering improved flexibility and performance (as discussed in Appendix).

Our empirical results across various PDE benchmarks demonstrate that CViT often outperforms larger models with fewer parameters and without extensive pretraining. This highlights the merits of our approach in designing parameter-efficient models that can be continuously queried at any resolution. The broader impact of this work lies in its potential to accelerate scientific discovery through more efficient and accurate simulations of complex physical systems, with applications ranging from climate modeling to engineering design.

Despite its promising performance, the proposed CViT architecture can be further improved in multiple areas. Firstly, like most transformer-based models, CViT’s self-attention blocks scale quadratically with the number of tokens, posing computational challenges for high-dimensional or high-resolution data. Recent advancements in computer visionare tackling these scalability issues, and these ideas can be transferred to our setting to improve CViT’s efficiency for larger-scale problems. Secondly, transformer-based models like CViT generally require large training datasets for optimal performance and may struggle in data-scarce scenarios without careful regularization. To address this, future work could explore leveraging CViT’s ability to reconstruct continuous output functions in conjunction with physics-informed loss functionsfor more data-efficient training and improved generalization. Lastly, while our current experiments treat input functions as sequences of images, many practical applications in scientific computing involve complex geometric structures and diverse input modalities such as unstructured meshes or point clouds. Addressing these cases requires developing appropriate tokenization schemes, and recent work inhas taken steps in this direction. Extending CViT to handle such diverse input modalities represents an important avenue for future research.

Building on the success of CViT, several promising directions for future research emerge. One key area is the exploration of more efficient attention mechanisms to improve scalability to higher-dimensional problems. Additionally, investigating the potential of pre-training strategies, similar to those employed in DPOT, could further enhance CViT’s performance and generalization capabilities across diverse PDE systems. Finally, extending CViT to handle 3D problems and developing techniques for multi-resolution training and evaluation could significantly broaden its applicability in scientific computing domains.

The broader impact of this work lies in its potential to fuel the development of resolution-invariant foundation models for accelerating scientific discovery and enable more efficient and accurate simulations of complex physical systems, with applications ranging from climate modeling to engineering design.

SECTION: Acknowledgements
We would like to acknowledge support from the US Department of Energy under the Advanced Scientific Computing Research program (grant DE-SC0024563). We also thank the developers of the software that enabled our research, including JAX, Matplotlib, and NumPy.

SECTION: Ethics Statement
Our contributions enable advances in accelerating the modeling and emulation of complex physical systems. This has the potential to significantly impact fields such as climate science, fluid dynamics, and materials engineering by providing more accurate and efficient simulation tools. While we do not anticipate specific negative impacts from this work, as with any powerful predictive tool, there is potential for misuse. We encourage the research community to consider the ethical implications and potential dual-use scenarios when applying these technologies in sensitive domains.

SECTION: Reproducibility Statement
The code used to carry out the ablation experiments is provided as a supplementary material for this submission. If the paper is accepted, we plan on making our entire code-base publicly available on GitHub.

SECTION: References
SECTION: Nomenclature
Tablesummarizes the main symbols and notation used in this work.

SECTION: Neural Fields & Conditioned Neural Fields
A neural field is a function over a continuous domain parameterized by a neural network. Recently, the computer vision community has adopted neural fields to represent 3D spatial fields, such as neural radiance fields (NeRFs), spatial occupancy fields, and signed distance functions. These fields represent functions defined over continuous spatial domains, with NeRFs additionally taking an element of a continuous ray space as input. In this paper, a point in the domain of a neural field is referred to as aquery point, here denoted by. Conditioned neural fields allow these fields to change based on auxiliary inputs, often represented as latent codes, without the need to retrain the entire field; see Figure. The latent code affects the forward pass by modifying the parameters of the base field through either global conditioning, where the forward pass is affected uniformly across all query points, or local conditioning, where the modifications depend on the specific query point.

Global conditioning in a neural field refers to modifying the forward pass only by the inputand in a uniform manner over the entire query domain. This can be achieved
through concatenation, where a global latent code is appended to the query vector and passed together through an MLP. Alternatively, a hypernetwork could accept the auxiliary input and determine the neural field’s parameter values based on this input. However, modifying every parameter of the base field for different auxiliary inputs can be computationally expensive. For example, feature-wise Linear Modulation (FiLM), which originates from conditional batch normalization, has been proposed to modify only the sine activation function parameters in a SIREN network. This technique has been used for global conditioning in methods such as-GAN.

Local conditioning occurs when the latent code, which modifies the base field’s parameters, is a function of the input query, i.e.,. This results in query-dependent field parameters that can vary across the query domain.
A common approach to generate local latent codes is to process the image or scene with a convolutional network and extract features from activations with receptive fields containing the query point. This can be done using 2D convolutions of projected 3D scenesor 3D convolutions. Mullerlearn features directly on multiresolution grid vertices and create local features via nearest grid point interpolation for each grid. Chancreate features along three 2D planes and interpolate features from projections onto these planes. DeVrieslearn latent codes over patches on a 2D “floorplan” of a scene. Other methods divide the query domain into patches or voxels and learn a latent codefor each patch or voxel.

SECTION: Neural Operators as Conditioned Neural Fields
Here we demonstrate that many popular operator learning architectures are in fact neural fields with local and/or global conditioning. While connections between architectures such as the DeepONet and the Fourier Neural Operator have been described previously, they are typically formulated under certain architecture choices which allow these architectures to approximate one another. In contrast, here we show that, by viewing these architectures as conditioned neural fields, they are explicitly related through their respective choices of conditioning mechanisms and base fields.

SECTION: Encoder-Decoder Neural Operators
A large class of operator learning architectures can be described as encoder-decoder architectures according to the following construction. To learn an operator, an input functionare first mapped to a finite dimensional latent representation through the encoding map. This latent representation is then mapped to a callable function through a decoding map. The composition of these two maps gives the architecture of the operator approximation scheme,. The class of encoder-decoder architectures includes the DeepONet, the PCA-based architecture of, and NoMaD.

These encoder-decoder architectures can be seen as neural fields with a global conditioning mechanism by viewing the role of the decoder as an operator which performs the conditioning of a base field, with a latent code derived from a parameterized encoder,.

For example, in a DeepONet, the base field is a neural network(trunk network) appended with a last linear layer, and the decoder map conditions the weights of this last layer via the output of the encoding map(branch network); see Figure(a) for a visual illustration.
In other words, the decoder map is a weighted linear combination ofbasis elements, where the weights are modulated by a global encoding of the input function, yielding outputs of the form.
The PCA-based architecture ofcan be viewed analogously using as basis elements the leadingeigenfunctions of the empirical covariance operator computed over the output functions in the training set.

Seidmandemonstrated how encoder-decoder architectures can employ nonlinear decoders to learn low-dimensional manifolds in an ambient function space. These so-called
NoMaD architectures typically perform their conditioning by concatenating the input function encoding with the query input, i.e.,; see Figure(b) for an illustration.

SECTION: Integral Kernel Neural Operators
Integral Kernel Neural Operators form another general class of neural operators that learn mappings between function spaces by approximating the integral kernel of an operator using neural networks. They were introduced as a generalization of the Neural Operator framework proposed by Li.
The key idea behind here is to represent the operatoras an integral kernel,,
whereis a kernel function.
In practice, the kernel functionis parameterized by a neural network, and the integral is then approximated using a quadrature rule, such as Monte Carlo integration, Gaussian quadrature, or via spectral convolution in the frequency domain.

A single layer of the GNOis given by

whereis a trainable weight matrix, andis a local message passing kernel parameterized by. As illustrated in Figure(c), the GNO layer is a conditioned neural field with local and global conditioning on the input function. The base field uses a fixed positional encodingthat maps query coordinatesto input function values at neighboring nodes, i.e.,, followed by a linear layer. The encoding width equals the maximum number of neighboring nodes, with zeros filling tailing entries for queries with fewer neighbors. The GNO layer is conditioned globally via the parameterized kernelmodulating the linear layer weights, and locally via a position-depended bias termadded as a skip connection. The layer outputsare finally obtained by summing the linear layer outputs and the skip connection, then applying a nonlinear activation function.

The FNO introduced a computationally efficient approach for performing global message passing in GNO layers assuming a stationary kernel. Leveraging the Fourier transform, a single layer of FNOis given by

whereandare trainable weight matrices,is the Fourier transform truncated to the firstmodes, andis the left inverse of this operator. We show that the FNO layer can be viewed as a conditioned neural field employing both local and global conditioning on the input function. Without loss of generality, we demonstrate this for a one-dimensional query domain. To this end, note that the convolutional part of the FNO layer (equation) can be re-written as (see Appendixfor a derivation)

wheredenotes the truncated Fourier transform of, andanddenote the real and imaginary parts of a complex vector. We may interpret this transformation ofas a linear transformation (which depends on) acting on the positional encoding,

The resulting expression (equation) is then acted on with a position dependant bias term, followed by a pointwise nonlinearity. In this manner, we see that an FNO layer is a neural field with a fixed positional encoding (firstFourier features), a global conditioning of the weights by the Fourier transform of, and a local conditioning acting as a bias term by; see Figure(d) for an illustration. This neural field interpretation also suggests an alternative way for implementing FNO layers by explicitly using equationto compute the inverse Fourier transform, thereby allowing them to be evaluated at arbitrary query points instead of a fixed regular grid.

In practice, GNO and FNO layers are stacked to form deeper architectures with a compositional structure. These can also be interpreted as conditioned neural fields, where the base field corresponds to the last GNO or FNO layer, while all previous layers are absorbed into the definition of the conditioning mechanism. Analogously, one can examine a broader collection of models that fall under the class of Integral Kernel Neural Operators, such as.

SECTION: The FNO layer as a conditioned neural field
Recall that the mapis the Fourier transform truncated to the firstmodes andis the left inverse of this operator,

Recall Euler’s formula,

When the (complex) Fourier coefficientscome from a real valued signal, the imaginary components in the reconstruction equationcancel and we are left with only real values. In this case, if we decompose eachinto real and imaginary parts,, then using equationwe rewrite equationas

This allows us to view the convolutional part of the FNO layer equationas

wheredenotes the truncated Fourier transform of, andanddenote the real and imaginary parts of a complex vector.

∎

SECTION: Theoretical Insights on Coordinates embeddings
Without loss of generality, we consider an MLP with scalar inputs and outputs. Specifically, letbe the input coordinate,and. An MLPis recursively defined as follows

with a final linear layer defined by

whereis the weight matrix in-th layer andis an element-wise activation function. Here,represents all trainable parameters of the network. In particular, we suppose that the network is equipped with Tanh activation functions and all weight matrices are initialized by the Glorot initialization scheme, i.e.,for. Moreover, all bias parameters are initialized to zeros.

In particular, ifis real valued (i.e.), its Lipschitz constant is the maximum norm of its gradienton its domain set.

By Theorem 1 and the chain rule, the Lipschitz constant of MLPs have an explicit formula

In Eq. equation, the diagonal matricesare difficult to evaluate, as they may depend on the input valueand previous layers. Fortunately, most major activation functions are 1-Lipschitz. More specifically, these activation functions have a derivative. Hence, we may replace the supremum on the input vectorby a supremum over all possible values:

From the above derivation, we immediately obtain that the Lipschitz constant of a MLP is inherently tied to the weight matrices of its hidden layers. MLPs are known to suffer from spectral bias, struggling to learn high-frequency functions efficiently. One reasonable explanation is thatis bounded by the product of its parameter norms, which can only increase gradually during training by gradient descent. Consequently, higher frequency components of the target function are learned later in the optimization process. Random Fourier featureshave been proposed as a potential solution to this spectral bias issue. In the following theorem, we demonstrate that both random Fourier features and our proposed position embedding can substantially increase the network’s Lipschitz constant at initialization. This enhancement enables more efficient learning of complex, fine-scale signals from the early stages of training.

(a) Let. Then we have

Since,

whereis the Gamma function.

For large, this can be approximated by:

(b) We observe that

Similar to the proof of (a), we have

For large, this can be approximated by:

(c) To estimate the Lipschitz constant of, we apply Theorem, which reduces the problem to estimating its first-order derivative:

For any given, there exists a uniquesuch that. We can then decomposeas follows:

Let us first estimate. Since allare bounded, we consider, as eachis a translation ofby. By differentiation, we obtain:

Settingyields. Consequently,achieves its maximum value ofatand its minimum value ofat. Therefore, we can boundas follows:

To estimate, recall that we assume. Forand fixed, we havefor a unique integer, anddecreases asmoves away from. Then:

Therefore, we have

Since,

Therefore, we conclude that

To obtain a lower bound for, we proceed as follows:
Without loss of generality, assume. Let, whereachieves its maximum. Then

We can bound each term as follows:

and

Note thatgoes to 0 asgoes to infinity. Sois bounded with respect to.
For, we similarly estimate:

Thus, combining these estimates, we conclude that

∎

Our theorem yields key insights into the Lipschitz constants of various coordinate embedding methods. For trivial coordinate embeddings (linear layer MLP), the Lipschitz constant is approximately 1. This has no impact on the network’s global Lipschitz constant, resulting in the network remaining susceptible to spectral bias.

In the case of random Fourier features, the Lipschitz constant can be improved through two main approaches. First, by increasing the standard deviation of the Gaussian used for sampling the frequency matrix. Second, by increasing the network width. This observation implies a trade-off between network width and the frequencies used in the Fourier features.

For our proposed coordinate embeddings, the Lipschitz constant primarily depends on the parameterin the interpolation process. This dependence on a single parameter potentially offers more straightforward control over the Lipschitz constant compared to Fourier features.

These findings significantly impact neural field design and optimization using different coordinate embedding techniques. They provide a quantitative basis for comparing embedding methods’ capabilities, particularly in addressing the spectral bias inherent in standard MLPs. The straightforward control of the Lipschitz constant in our proposed method (via) may offer advantages in model tuning and optimization.

SECTION: Experimental Details
SECTION: Training and evaluation
We use a unified training recipe for all CViT experiments. We employ AdamW optimizerwith a weight decay. Our learning rate schedule includes an initial linear warm-up phase ofsteps, starting from zero and gradually increasing to, followed by an exponential decay at a rate offor everysteps.
The loss function is a one-step mean squared error (MSE) between the model predictions and the corresponding targets at the next time-step, evaluated at randomly sampled query coordinates:

wheredenotes the-th variable of the-th sample in the training dataset, evaluated at a query coordinate, anddenotes the corresponding model prediction. It is worth noting that our objective function is a one-step loss, which differs significantly from the rollout loss used in training DPOTs
All models are trained foriterations with a batch size.
Within each batch, we randomly samplequery coordinates from the grid and corresponding output labels.

We observe certain training instabilities in CViT models, where the loss function occasionally blows up, causing the model to collapse. To stabilize training, we clip all gradients at a maximum norm of 1. If a loss blowup is detected, we restart training from the last saved checkpoint.

After training, we obtain the predicted trajectory by performing an auto-regressive rollout on the test dataset. We evaluate model accuracy using the relativenorm, as commonly used in Li:

where the norm is computed over the rollout prediction at all grid points, averaged over each variable of interest.

SECTION: Model Details
For the 1D advection equation, we create a tiny version of CViT to ensure the model size is comparable to other baselines. Specifically, we use a patch size of 4 to generate tokens. The encoder consists of 6 transformer layers with an embedding dimension of 256 and 16 attention heads. A single transformer decoder layer with 16 attention heads is used.

For the shallow water equation and Navier-Stokes equation, the CViT configurations are detailed in Table. While we use a patch size ofby default, we use a smaller patch size ofwhen training CViT-L for the Navier-Stokes problem. We find that using a smaller patch size better captures the small-scale features in flow motion, leading to improved accuracy.

For the DeepONet, the branch network (encoder) is an MLP with 4 hidden layers of 512 neurons each. The trunk-net (decoder) also employs an MLP with 4 hidden layers of 512 neurons.

The encoder consists of 4 hidden layers with 512 neurons each, mapping the input to a latent representation of dimension 512. The decoder, also an MLP with 4 hidden layers of 512 neurons, takes the latent representation and maps it to the output function.

Following the comprehensive experiments and ablation studies in PDEArena, we adopt the optimal Dilated ResNet configuration reported in their work. This model has 128 channels and employs group normalization. It consists of four residual blocks, each comprising seven dilated CNN layers with dilation rates of [1, 2, 4, 8, 4, 2, 1].

Based on comprehensive experiments and ablation studies in PDEArena, we select the two strongest U-Net variants reported in their work:and. For both architectures, we use one embedding layer and one output layer with kernel sizes of. Besides, we use 64 channels and a channel multipliers ofand incorporate residual connections in each downsampling and upsampling block. Pre-normalization and pre-activations are applied, along with GELU activations. For, attention mechanisms are used in the middle blocks after downsampling.
For U-F2Net, we replace the lower blocks in both the downsampling and upsampling paths of the U-Net architecture with Fourier blocks. Each Fourier block consists of 2 FNO layers with modes 16 and residual connections.

Following the comprehensive experiments and ablation studies in PDEArena, we adopt the optimal UNO of 128 channels.

For the 1D advection equation, our FNO model employs 3 Fourier neural blocks, each with 256 channels and 12 Fourier modes. The output is projected back to a 256-dimensional space before passing through a linear layer that produces the solution over the defined grid.

For the shallow water equation, we employ the best FNO model from comprehensive experiments and ablation studies in PDEArena. Specifically, we use the FNO consisting of 4 FNO layers, each with 128 channels and 32 modes. Additionally, we use two embedding layers and two output layers with kernel sizes of, as suggested in Li. We use GeLU activation functions and no normalization scheme.

For the Navier-Stokes equation, we follow the problem setup in DPOT, which differs from the setup in PDEArena. Therefore, we directly report the results from DPOT.

We directly report the results from DPOT. Detailed implementations can be found in their paper.

SECTION: Linear Advection Equation
We consider the one-dimensional linear advection equation

with periodic boundary conditionsgiven an initial conditionwith the advection velocity. To generate discontinuous initial conditions, the initial conditionis assumed to be

wherea centered Gaussian,

Heredenotes the Laplacian onsubject to periodic conditions on the space of spatial mean zero functions. Morevoer,denotes the inverse length scale of the random field anddetermines the regularity of. For this example, we setand.

We make use of the datasets released by Hoop. This dataset consists of 40,000 samples of discretized initial conditions on a grid ofpoints.

We follow the problem setup by Hoop. Our objective is to predict the solution profile at time. We compare the CViT model’s performance against several strong baseline neural operators: DeepONet, NoMaDand Fourier Neural Operators. For the training and evaluation, we considered a split of 20,000 samples used for training, 10,000 for validation, and 10,000 for testing.

For all models, we use a batch size of 256 with a grid sampling size of 128, except for the FNO, which uses the full grid size of 200. The models are trained using the AdamW optimizerwith an exponential decay learning rate scheduler. The models are trained for 200,000 iterations, and the best model state is selected based on the validation set performance to avoid overfitting. The final performance is evaluated on the test set of 10,000 samples.

Due to the discontinuous nature of the problem, the relative L2 norm may not properly reflect the performance of the models. Instead, a more suitable metric for this task is the total variation, defined as

The total variation quantifies the integrated difference between the magnitudes of the gradients of the predicted solution and the ground truth, providing a better indicator of a model’s ability to capture and preserve discontinuities in the solution.

Tablepresents a summary of our results. We notice that the CViT model achieves the lowest mean, median and worst-case relativeerrors, outperforming the other architectures on this metric. Furthermore, when considering the total variation metric, the CViT model exhibits competitive performance for the mean and median total variation values, and achieves the lowest prediction error the worst-case sample in the test dataset.

SECTION: Shallow-Water equations
Letdenote the velocity andinterface height which conceptually represents pressure. We defineand divergence. The vorticity formulation is given by:

subject to the periodic boundary conditions. Hereis Coriolis parameter andis the gravitational acceleration, andis the dynamic layer thickness.

The dataset is generated by PDEArenausingon a regular grid with spatial resolution of, and temporal resolution of. The resulting dataset contains 6,600 trajectories with a
temporal spatial resolution.

We follow the problem setup reported in PDEArena. Our goal is to learn the operator that maps the vorticity and pressure fields from the previous 2
two time-steps to the next time-step. All models are trained with 5,600 trajectories and evaluated on the remain 1,000 trajectories. We report the relativeerrors over 5-steps rollout predictions.

For training CViT models, please refer to section. For training other baselines in Table, we follow the recommended training procedure and hyper-parameters presented in PDEArenaSpecifically, we use the AdamW optimizer with a learning rate ofand a weight decay of. Training is conducted for 50 epochs, minimizing the summed mean squared error. We use cosine annealing as the learning rate schedulerwith a linear warm-up phase of 5 epochs. An effective batch size of 32 is used for training.

In our experiments, we matched the resolution of the embedding grid to the dataset for convenience. However, our model’s performance is not significantly affected as long as the embedding grid roughly matches the dataset resolution.

To validate this, we conducted experiments with three different grid resolutions:193 , and. We performed these experiments using the shallow water equation example under the same hyper-parameter settings. The resulting relativeerrors are summarized below:

The results demonstrate negligible variation in error across different resolutions. This empirical evidence supports our claim that CViT’s performance is robust to small variations in grid resolution, suggesting that precise matching between the embedding grid and dataset resolution is not critical for model efficacy.

SECTION: Navier-Stokes equation
We consider the two-dimensional incompressible Navier-Stokes equations in the velocity-pressure formulation, coupled with a scalar field representing a transported particle concentration via the velocity field. The governing equations are given by:

whereis the scalar field,is the velocity field, and andis the kinematic viscosity. In addition, the velocity field is affected through an external buoyancy force termin thedirection, represented as.

The 2D Navier-Stokes data is generated by PDEArena, which is obtained on a grid with a spatial resolution ofand a temporal resolution of. The simulation uses a viscosity parameter ofand a buoyancy factor of. The equation is solved on a closed domain with Dirichlet boundary conditionsfor the velocity, and Neumann boundariesfor the scalar field. The simulation runs for, sampling every. Each trajectory contains scalar and vector fields at 14 different time frames, resulting in a dataset with 7,900 trajectories.

We follow the problem setup reported in Hao. We aim to learn the solution operator that maps the passive scalar and velocity fields from the previous 10 time-steps to the next time-step. The models are trained with 6,500 trajectories and tested on the remaining 1,300 trajectories. We report the resulting relativeerrors over 4-steps rollout predictions.

We directly report the results as presented in DPOT. For comprehensive details on the training procedures, hyper-parameters, please refer to their original paper.

SECTION: Diffusion-reaction equation
The 2D diffusion-reaction equation is given by

whereis the the activator anddenotes the inhibitor. Hereandare the diffusion coefficient for the activator and inhibitor, respectively,andare the activator and inhibitor reaction function, respectively. The domain of the simulation includes.
The reaction functions for the activator and inhibitor are defined by:

where, and the diffusion coefficients for the activator and inhibitor areand, respectively. The initial condition is generated as standard normal random noiseforand.

We use the dataset generated by PDEBench, where discretized intoand, as well as the downsampled version for the models training with, and, the spatial discretization is performed using the finite volume method, and the time integration is performed using the built-in fourth order Runge-Kutta method in the scipy package.

We follow the problem setup reported in Hao. We aim to learn the solution operator that maps the activator and inhibitor fields from the previous time-steps to the next time-step. The models are trained with 900 trajectories and tested on the remaining 100 trajectories. We report the resulting relativeerrors over rollout predictions.

For training CViT models, please refer to section. It is worth noting that for this specific task, we employ an initial learning rate of, different from theused in other experiments.

We directly report the results as presented in DPOT. For comprehensive details on the training procedures, hyper-parameters, please refer to their original paper.

SECTION: Computational Cost
All experiments were performed on a single Nvidia RTX A6000 GPU. Average training times varied between 5 hours and 60 hours, depending on the task, input resolution, model size, and patch size. The following table summarizes the training times for different models. We use a brief notation to indicate the model size and the input patch size: for instance, CViT-L/16 refers to the "Large" variant with ainput patch size.