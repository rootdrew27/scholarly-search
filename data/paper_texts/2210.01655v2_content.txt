SECTION: Encoder-Decoder RNNs for Bus Arrival Time Prediction

Arrival/Travel times for public transit exhibit variability due to factors like seasonality, traffic signals, travel demand
fluctuation etc. The developing world in particular is plagued by additional
factors like lack of lane discipline, excess vehicles, diverse modes of transport, unreliable schedules etc. This renders the bus arrival time
prediction (BATP) to be a challenging problem especially in the developing world. A data-driven model based on a novel variant of Encoder-Decoder (OR Seq2Seq) recurrent neural networks
(RNNs) is proposed for BATP (in real-time). The model
intelligently incorporates spatio-temporal (ST) correlations in a unique
(non-linear) fashion distinct from existing approaches. Existing Encoder-Decoder (ED) approaches for BATP blindly map time to the sequential aspect of ED, while ignoring crucial data characteristics and
making some restrictive model assumptions. Our approach in contrast is not straightforward and effectively tackles these issues.
We exploit the geometry of the dynamic real-time BATP problem to enable a novel fit with the
ED structure, distinct from existing ED approaches.
Further motivated
from accurately modelling past congestion influences from downstream sections, we additionally propose a bidirectional layer at the decoder (something unexplored in other time-series based ED application contexts). The effectiveness of the proposed architecture
is demonstrated on
real field data collected from challenging traffic conditions, while bench-marking against state-of-art baselines. The proposed architecture is not limited to transportation, but can also be employed for multi-step time-series forecasting (sales/demand forecasting under exogenous inputs like price).

SECTION: IIntroduction

Public transit system is a crucial component to administer the overall transport system in urban cities across the world. Having a quality system would make it attractive for commuters and can in-turn mitigate mounting traffic volumes and congestion levels, which is a universal problem across the urban world. A quality system would entail sticking to well-designed schedules to the extent feasible while providing quality predictions in real-time. Such accurate estimates can help commuters better plan their bus-stop arrival
while avoid unnecessary wait times. Quality Bus travel time predictions can also assist commuters decide between taking a bus or some other alternate mode of transport. Quality BATP estimates can also benefit travel administrators take corrective action when bus schedules are violated.

BATP literature is more than one and a half decades old. It continues to be a challenging
research problem in the
developing world, in particular.
Factors contributing to this include (1) absence of lane discipline (2) in-homogeneity of
traffic (i.e. transport modes can include bicycles, two wheelers, four wheelers, heavy vehicles like trucks, buses and so on) with dedicated lanes absent for specific modes
of transport.
We refer to this asmixed trafficconditions. Another issue is the lack of reliability of bus schedules[42], especially in the context of India where most cities experience mixed traffic conditions.
The bus schedules even if available tend to get outdated due to constant changes in traffic conditions and infrastructure. This makes timetables extremely unreliable, leading to ad-hoc waiting times for passengers. Hence providing accurate arrival time predictions become even more important in such cases.
The real data considered in this paper is from a bus route in Delhi[42], the capital of India which experiences mixed-traffic conditions.
Any google-map based bus arrival time query (in most cities in India including Delhi) has till recently mostly returned a constant prediction independent of the
date or time of
query. These constant estimates seem to be based on some pre-fixed schedules which are unfollowable given the complex traffic conditions as explained above.
Further, ETA (Expected time of arrival) solutions are still being continuously improved upon by Google at a network level across the world for different modes of urban transport[1,2].
On account of the above factors,
BATP continues to be a challenging research problem[3]especially under mixed traffic conditions[4,5].

Over the years, there have been diverse approaches proposed for BATP. Data-driven approaches have been a dominant class of methods for BATP.

In most of these approaches, an entire route is segmented into smaller sections(or segments) either uniformly[6]OR into non-uniform segments connecting
consecutive bus-stops.
Depending on the method and the installed sensing infrastructure, the data input can be entities like speed, density, flow, travel time etc.
In this work, we consider
scenarios where input data comes only from travel times experienced across these segments/sections.
AVL (automatic vehicle location) data captured by GPS sensing caneasilyprovide such travel times.

Gaps and Contributions:Over the years, researchers have explored a wide spectrum of methods under the broad umbrella of data-driven approaches. These include ARIMA models[7], linear statistical models like Kalman filters[4,8], support vector machines[9,10,11], feed-forward ANNs[12,2],
recurrent neural networks[13,14], CNNs[5], temporal difference learning[15]and so on. Most of the existing methods suffer from a range of
issues
like (i)insufficient utilization of historical
data for model calibration[16,17,6]OR (ii)ignoring spatial correlations[8,18,10](iii) not exploiting temporal correlations([12,19]) (iv)
not exploiting real-time information enough([20]), (v)segment the time-axis into uniform bins, which can lead to inaccurate
predictions[13,14]. There has been some recent work on exploiting
spatio-temporal correlations[4,11,5,13,14]as well in this direction.

From an RNN literature perspective, there’s been recent work where people have explored ED (also known as Seq2Seq) architectures for real-valued data[21,22](time-series (TS) in particular).
A natural way to employ Seq2Seq for BATP would be to segement the time-axis into uniform bins[13,14]and learn a sequential model in time.
This approach ignores the continuous nature of data in the temporal dimension and makes an unrealistic assumption that section travel times are constant across time bins (see Remark).
Our approach intelligently addresses this drawback while also respecting the temporal continuity and space-time asymmetry, in BATP data.
Further, proposed approach is not evident due to difference in structure of available data between BATP and traditional time-series.

The current work proposes a novel ED architecture (different from classical machine translation architecture OR existing
ED approaches for time-series)
which is also distinct from all existing BATP approaches (in particular from ED based BATP approaches also[13,14]). It exploits current real-time
spatio-temporal correlations and historical seasonal correlations for nonlinear modelling and prediction. Specifically our contributions are as follows.

We intelligently recast the real-time BATP problem to a novel and unique variant of Encoder-Decoder architecture with real-time spatio-temporal inputs and historical
seasonal inputs carefully placed in the architecture. The key is in recognizing that BATP inherently involves sequential training data with variable length input-output pairs, which ED framework can handle. The proposed ED model’s sequential aspect is mapped to the spatial dimension of BATP, while the temporal aspects of BATP are captured by feeding the associated inputs as decoder inputs in a space synchronized fashion.

Travel times from the just traversed sections of current bus (constitute the spatial correlations) are fed as inputs to the
encoder. While real-time information coming from closest previous bus’s travel times across subsequent sections (constituting
temporal correlations) are fed in a synchronized sequential fashion into the decoder as additional inputs.Note that these synchronised inputs at the decoder are absent in the classic ED application for machine translation[23,24]. The section travel times (of current bus) across subsequent sections are the prediction targets which are neatly mapped to the decoder outputs sequentially.Weekly seasonal correlations are also incorporated via additional inputs from the closest trip of the previous week.

We propose a bidirectional layer at the decoder as this can now capture (for a given section) the possible (upstream) influence of past
congestions (in time) from subsequent sections, propagating backward in space (along the bus route). This novel feature of our ED variant is unexplored
in both traditional ED and other time-series based variants of ED to the best of our knowledge.

Effectiveness of the proposed approach is illustrated on actual field data collected from a route in Delhi, where mixed traffic condition
are very common. The results
clearly demonstrate superior performance of our approach (across sub-routes of diverse lengths)
in comparison torecent state-of-art baselines.

The rest of the paper is organized as follows. Sec.IIdescribes the related work in detail both from the perspective of (i) BATP literature and (ii) ED based RNN approaches. Sec.IIIexplains the technical contribution in detail. In particular it describes the proposed architecture and technically motivates how the architecture can be derived to solve BATP. Sec.IVdemonstrates the effectiveness of the proposed architecture on one route from Delhi by bench-marking against four carefully chosen state-of-art baselines. We provide (i) a brief discussion as to how our proposed architecture can be also be used in other applications and (ii) concluding remarks in Sec.V

SECTION: IILiterature Review and Related Work

The BATP literature has not only seen diversity in the range of techniques used, but also in the kind of data input employed for prediction.
A range of data inputs like speed, travel times, weather, flow information, crowd-sourced
data[26], scheduled time tables[25]and so on have been considered for BATP.
One can broadly categorize the range of approaches into two classes:
(i) traffic-theory based (ii) data-driven. Given the proposed approach is data-driven, we stick to reviewing related data-driven approaches.
While Sec.II-Adescribes data-driven approaches for BATP, Sec.II-Bdiscusses related ED based RNN approaches. Finally, Sec.II-Cplaces the proposed architecture in perspective of all related work.

SECTION: II-AData-driven methods for BATP

Unlike the traffic-theory based approaches which model the physics of the traffic, data-driven methods employ a
coarse model (based on measurable entities) that is sufficient for predictive purposes.
Most approaches learn to estimate necessary parameters of a suitable predictive model from past historical
data, which is further employed for real-time BATP. There are a few approaches which employ a
data-based model but do not perform full-fledged learning based on historical data.

Without Learning:One of the earliest approaches without learning was proposed in[27]using a Kalman filter. As inputs, it used previous bus travel times and travel times from previous day (same time). It has an arbitrary choice of parameter in its state space model while only capturing temporal dependencies.
The subsequent approaches consider a linear state-space model involving travel times andcalibrate(or fix) the data-based model parameters in real time. They choose their
parameters either based on (a)
data from previous bus[16,6]or (b)an appropriate optimal travel-time data vector from the historical data-base[28].

Explicit Learning:As mentioned in the introduction, there are a variety of approaches learning from historical data. For instance,
support vector regression[10]and feed-forward
ANNs[18]were employed
to capture temporal correlations via multiple previous bus travel times.
Employing link length (a static input) and rate of road usage and speed (dynamic inputs),[20]proposes an SVR based prediction.
However current bus position OR previous bus inputs are not considered there.
A speed based prediction scheme is proposed in[29]which uses a weighted average of current bus speed and historically averaged section speed as inputs. As previous method, it ignores
information from previous bus.
A dynamic SVR based prediction scheme is proposed in[9]which exploits spatio-temporal (ST) correlations in a minimal manner. In particular, it considers current bus
travel time at the previous section and previous bus travel time at the current section.

A single feed-forward ANN model is built to predict travel times between any two bus stops on the route in[12]. On account of this, target travel time variable’s dynamic range would be very large and can lead to poor predictions for very short and very long routes.
An approach using (non-stationary) linear
statistical models which captures ST correlations was proposed in[4]. It uses a linear kalman filter for prediction. Linear models here are used to
capture spatial correlations. The temporal correlations come from the (currently plying) previous bus section travel time. Another approach using linear statistical models and exploiting real-time temporal correlations (from previous buses) was proposed in[8]. A nonlinear generalization of[4]using support vector function
approximators capturing ST correlations was proposed in[11]. Recently, a CNN approach capturing ST correlations
was proposed
in[5]. It uses masked-CNNs to parameterize the predictive distribution, while a quantized travel-time is used as CNN outputs.

[13]proposes a novel approach by combining CNNs and RNNs in an interesting fashion. In particular spatial correlations from the
adjacent sections of the 1-D route are captured by the convolutional layer,
while the recurrent structure captures the temporal correlations. It employs a convolutional-RNN based
ED architecture
to make multi-step predictions in time.[14]considers an attention-based extension of[13].[30]employs a simplified RNN with attention
but no state feedback (even though weight sharing is present across time-steps). It only captures single time-step predictions. A common feature of all these RNN approaches is that the time axis is
uniformly partitioned into time bins of a fixed width.

A recent computationally interesting approach where BATP is recast as a value function estimation problem under a suitably constructed Markov reward process is proposed in[15]. This enables
exploring a family of value-function predictors using temporal-difference (TD) learning.

SECTION: II-BRelated ED based RNN approaches

The ED architecture was first successfully proposed for language translation applications[23,24]. The proposed architecture was relatively simple with the
context from the last time-step of the encoder fed as initial state and explicit input for each time-step of the decoder. Over the years, machine
translation literature has seen intelligent improvements over this base structure by employing attention layer, bidirectional layer etc. in
the encoder. Further, the ED framework has been successfully applied in many other tasks like speech recognition[31], image captioning etc.

Given the variable length Seq2Seq mapping ability, the ED framework naturally can be utilized for multi-step (target) time-series prediction where
the raw data is real-valued and
target vector length can be independent of the input vector. An attention based ED approach (with a bidirectional layer in the encoder) for
multi-step TS prediction was proposed in[22]which could potentially capture seasonal correlations as well. However, this architecture doesn’t consider exogenous inputs. An
approach to incorporate exogenous inputs into predictive model was proposed in[21], where the exogenous inputs in the forecast horizon are fed
in a synchronized fashion at the decoder steps. Our approach is close to the above TS approaches.

SECTION: II-CProposed approach in perspective of related approaches

From the prior discussion, one can summarize that many existing approaches either fail to exploit historical data sufficiently OR fail to capture
spatial or temporal correlations.
The rest of the approaches do exploit spatio-temporal correlations in different ways[9,4,11,5,13,14], but suffer their own
drawbacks. For instance,[9]while exploits the previous bus travel time at the current section (temporal correlation), completely ignores
when (time of day) the traversal happened. The spatial correlation here comes from current bus travel time of only one previous section.[4](denoted as LNKF in our experiments) addresses the issues of[9]as follows. To better capture spatial correlations, it considers current
bus travel time measurements from multiple previous sections. The temporal correlations here also take into account the previous bus’s proximity
by assuming a
functional (parameterized) form
dependent on current section travel time and start time difference. It adopts a predominantly linear modelling approach culminating in a
Linear Kalman filter for prediction. As explained earlier, a support-vector based nonlinear generalization of[4]is considered in[11](referred to as SVKF in our experiments). It learns the potentially non-linear spatial and temporal correlations at a single-step level and then employs an extended kalman
filter for spatial multi-step prediction. Compared to our non-linear ED (Seq2Seq) approach here,[4]considers mainly a linear modelling. While[11]adopts a non-linear modelling, the model training happens with single-step targets in both[4,11].However,
both these KF approaches adopt a
recursive sequential multi-step prediction which can be prone to error accumulation. On the other hand, our ED approach circumvents this issue of
both these KFs by training with vector targets where the predictions across all subsequent sections are padded together into one target-vector.

CNN approach of[5]models travel time targets as categorical values via a soft-max output layer. Hence it is sensitive to the quantization level. A coarse quantization can lead to high errors when the true target value is exactly between two
consecutive levels. A fine quantization on the other hand leads to numerous outputs. This in turn would increase the number of weights to be learnt and lead to a potentially
imbalanced multi-class problem. Our approach in contrast models targets as real-valued.

All LSTM approaches[13,14,30]bin the time-axis into fixed width intervals.
The method in[8]also bins the time-axis and builds temporal models at each section while only exploiting temporal correlations.
This strategy makes an inherent assumption that section travel times
are constant for a fixed width time interval (minute in particular).However, this assumption can be pretty unrealistic and restrictive during peak hours (in particular) when the traffic conditions are more dynamic.
Our approach on the other hand doesn’t make any such restrictive assumptions and we model time as continuous valued.

While[13](referred to CLSTM in our experiments) also uses an ED architecture for prediction, it employs sequential aspect of RNNs to model time (unlike our method). In contrast,
our sequential RNN (ED) captures the spatial dimension
of the problem. Accordingly our decoder output models the subsequent section travel times of the current bus.
In contrast, a-D CNN is used in[13]to capture spatial correlations. To capture temporal correlations, our method feeds the entry and travel times at subsequent sections of
the closest previous bus as decoder inputs in a space synchronised fashion. Further we also use a bidirectional layer at the decoder to capture possible
upstream propagating congestion influences. This makes our ED approach very different from CLSTM[13].Overall, there is no symmetry in the spatial and temporal aspect of AVL data which makes our proposed ED variant very different from CLSTM.

The TD approach of[15](as explained earlier) where a value function estimation of a suitable Markov reward process (MRP) is carried out, is clearly
distinct from our approach here. The travel-time across each section is modeled as the one-step reward. For each destination section (or bus stop), a MRP is constructed with all preceding sections (along with features like time of day etc.) encoded as states, while the destination section is the final state.This approach while conceptually interesting performs poorly for short to mid-range sub-routes.

BusTr[2]models the bus-stop dwell time and run time across a segment separately using a feed-forward ANN (FFN), where the FFN weights are shared across
road segments and bus stops. The inputs to the FFN are the (i)speed forecast based on current real-time traffic from google maps and (ii)features based on location embedding,
both of which are unused in our approach. The speed forecast used is that of cars, whose speed based travel times are linearly transformed to that of bus while the
linear weights are modelled as the output of the FFN whose weights are learnt during training.Overall BusTr differs from our method in most aspects like the inputs
and targets used for prediction and the predictive model.

Compared to the ED based TS prediction approaches[22,21], one novel feature is the use of a bidirectional layer at the decoder (unexplored to the
best of our knowledge in TS approaches). This feature is strongly motivated from the BATP application as explained in detail in Sec.III-E2. Also,
in contrast to[22,21], we employ additional inputs at the decoder to factor real-time temporal and weekly seasonal
correlations, something absent in[22,21].

SECTION: IIIMethodology

This section is organized as follows. Sec.III-Adescribes data preliminaries while Sec.III-Bdescribes the various potential correlations in the data that can influence BATP. Sec.III-Cstates the dynamic real-time prediction problem and describes the various inputs and notations. Sec.III-Ddescribes how BATP can be intelligently recast into a novel ED framework with spatio-temporal and seasonal inputs carefully placed.

SECTION: III-AData Preliminaries

Data Input:The given bus route is segmented uniformly into sections.
Along the given route, travel times experienced across each of these sections for all concluded trips, constitute our input training data. The observed section
travel times, include both (i)dwell time at the possible bus-stops in the section and (ii)running time across the section.
As explained in the introduction, travel times were obtained from AVL data captured via high frequency GPS based sensing.

Uniform Segmenting:We chose this for two reasons. (i)There is prior work[6,17]where researchers have adopted uniform segmenting and predicted
between any two bus stops, and
reported good performance.
(ii)Ease of testing across multiple bus-routes:Substantially extra book-keeping would be needed when Non-uniform segmenting is employed (where section ends correspond to bus-stop locations) (iii) Ease of adapting section-level predictions to the bus-stop level as explained next.

Our proposed approach can also be used as it is when the route is segmented in a non-uniform fashion (where travel times between two successive bus-stops will be the section travel times).We strongly believe that the results
in the non-uniform case will be similar in trend to the uniform
case results reported here.

Adapt to bus-stop level:Also, the predictions based on uniform segmenting which predict between any two segments can be easily adapted to predict between any two bus-stops. Specifically, given any two bus stopsand, we could consider the segment start in which bus-stoplies and perform our proposed ED based prediction till the end of the segment which contains bus-stop. We
would now need to subtract the expected dwell time at bus-stopand the expected semi-segment travel times at the start and end segment of the multi-step prediction. The
semi-segment lengths will depend on the position of the bus-stopandin their
respective segments.

SECTION: III-BCapturing Spatio-Temporal and Seasonal Correlations

Motivation:One of the factors influencing the section travel timeat section, could be its preceding section travel times. A justification for this can be as follows.
The preceding section travel times can provide strong hints of propagating congestions moving downstream along the route OR upcoming
congestions (captured by above-average travel times) at the
subsequent sections across which travel times need to be predicted. Patterns present in the historical data between
section travel times can also be captured by this.

Further, in addition to the section travel times of the previously traversed sections of the currently plying bus, travel times experienced by
previous buses (most recent) across the subsequent sections would be indicative of the most recent (real-time) traffic condition on the subsequent sections. This information can
help better estimate the potential travel times
to be experienced by the current bus
in the subsequent sections ahead. We indicate the associated section travel times byand the section entry times by, from the closest previous bus. The section entry timeessentially tell us when the respective section travel timestranspired. The section entry time information is important because larger the difference betweenand the current time(OR time of query), lesser the influence ofon, the entity of interest.

In addition to the above real-time information, given strong weekly patterns in similar traffic data[32]in general, we propose to exploit information from a historical trip from the previous week whose start time is closest to that of the current trip. We indicate associated section travel times byand section entry times by. This information would capture the weekly seasonal correlations in the data and would potentially enhance the predictive quality of the model.

SECTION: III-CDynamic Real-time Prediction Problem

BATP, the dynamic real-time prediction problem can be formally stated as follows in view of the just described inputs potentially influencing
prediction.
Given (a)real-time position of current bus
(say at the end of section) (b)current time (equivalent to, the current bus’s entry time into section)
(c)current bus’s previous section travel times
(d)section travel times (ahead of section) of the closest previous bus and (e)section travel times (beyond section) from a historical trip from the previous week (but same weekday) with the
closest
trip start time to that of the current trip, the task is to estimate all section travel times beyond sectionof the current bus.

Fig.1gives a clear pictorial spatial layout of all the relevant input entities that influence prediction and the associated target
variables of interest.denotes the section index of the current bus position (top bus in Fig.1), whiledenotes the total number of sections.denote the traversed section travel times of the current bus.are the target variables (marked with a shade).
They denote the section travel times of current bus across the subsequent sections, which need to be predicted. Similarly,, denote section travel times across subsequent sections of the closest previous bus (middle bus in Fig.1), whiledenotes the associated section entry times. The bottom bus in Fig.1denotes the closest trip from the previous week, same weekday and its associated
section travel and entry times along the entire route are clearly indicated.
The main symbols employed in this paper have been summarized in TableI.

Given current positionand current time, which is also the entry time of the bus into section(i.e.), we wish to
learn an input-output functionof the below form.

The inputs have been grouped intocategories (based on the style of underlining). The first category corresponds to the current bus
information, namely its current position, its section travel times along traversed sections (correspond to spatial correlation). The second category is the section travel
and entry times from the closest previous bus across all subsequent sections (correspond to temporal correlations). The third category includes section travel time from
all sections of the closest previous week trip, while its section entry times from only the subsequent sections (correspond to weekly seasonal correlations). Note we don’t use the previous section travel
times from the previous trip as the current trip travel times across the previous sections are more recent.

SECTION: III-DMotivating the proposed ED Variant Architecture

Traditional ED:The ED architecture was originally employed for variable length pairs of input-output sequences. The original Seq2Seq idea was to employ two distinct RNN layers referred to as an Encoder (colored in red) and Decoder (colored in blue) respectively, as shown in Fig.2. The first RNN layer takes the input sequence as input and the state computed at the last step of the unfolded structure is fed as initial state of the second layer. This state can also be fed as an input at every step of the second layer (decoder). The output sequence whose length is independent of the input sequence is the output of the unfolded decoder.

In the earliest machine translation context, the input could correspond to a sentence from a
particular language, while the output could be its translation in another language. Each word essentially comes from a categorical space and
one needs sophisticated word2vec[33,34]representations before feeding the transcribed words into the RNN. In our setting the raw data is already
a real number and hence can be fed directly into the RNNs.

Our prediction problem (BATP) can be viewed as a spatial multi-step prediction problem,where atstep we can either predict (i)the travel time across thesegment OR (ii)travel time to reach end ofsegment. We stick to the former in this paper.

The important point to note from eqn.1is that both the input length and the output length of thefunction changes with,
the current bus Position. For instance, the output sequence length for a bus positionis (). Similarly the contribution to the input sequence length from
the current bus real-time inputs is. This means the training data for BATP actually has a clear variable length input-output nature.
Given the variable length Seq2Seq mapping ability of the ED framework, this can aptly be utilized for BATP with variable length input and outputs.

So the spatial multi-step (target) prediction problem
we encounter has both variable-length inputs and variable-length vector valued targets, with vector size equal to the number of sections ahead ().
We rewrite eqn. (1) by reorganizing its inputs as follows
which aids us in clearly associating the inputs and outputs of
the regression functionto the proposed
ED architecture.

All the previous section travel times from the current bus and the previous week trip have been grouped. These two pairs of inputs
are fed as encoder inputs unfolded up tosteps (Fig.2), which makes the input dimension vary with. In the second group, we bring together section travel
times and entry times of theclosestprevious bus and an appropriate previous week trip. These inputs in pairs of four are fed as additional inputs
at each step of the decoder, where the decoder is unfolded intosteps, making the output dimension also vary with. The intuition is that not just the subsequent section travel
time, but also the time at which the traversal happened (entry time into that section) has an influence. Closer the entry time of the previous bus
to the current bus’s likely entry time, higher is its influence. The idea is that the model learnt would capture this influence from the data. In this architecture, the current bus’s likely entry time into sectionwould be inherently represented in the hidden state.

The GPS/AVL based travel-time data is naturally discrete in the spatial dimension, because we have travel-time information available either across sections OR between two consecutive bus-stops as described earlier. On the other hand this data is naturally continuous in temporal dimension as trips can happen anytime during the day.
So it makes more sense to map the (discrete) spatial aspect of the problem to the discrete sequential aspect of the Seq2Seq (or ED) framework. Further, real-time BATP needs to predict travel times across all subsequent sections (from the current section). This spatial and sequential multi-step target aspect of BATP can be exactly mapped to
the multi-step sequential decoder outputs. The temporal correlations coming from the previous bus are fed as decoder inputs in a space synchronized fashion, while the weekly seasonal historical inputs are clearly split between the encoder and decoder inputs without any redundancy. Our ED framework hence also avoids discretizing time as in[13,14,30].

SECTION: III-EED Variant with Bidirectional Decoder

Between LSTM[35]and GRU[36]RNN unit choices, both of which have a gating mechanism to check vanishing gradients and have persistent memory, we choose GRU in this paper. GRU unit is currently
very popular in various sequence prediction
applications[37,38,39,40]as the building block for RNNs. Moreover, compared to LSTM it has lesser gates, in turn leading to lesser weight parameters.
The hidden state of a single hidden layer (simpler) plain RNN unit can be written as

where,are the weight matrices associated with the state at the previous stepand the current input () respectively,denotes sigma function.
The hidden state of a GRU based cell (for one layer) can be computed as follows.

whereis update gate vector andis the reset gate vector. We obtain the plain RNN unit if these two gates were absent,.is
the new memory (summary of all inputs so far) which is a function ofand, the previous hidden state. The reset signal controls the
influence of the previous state on the new memory. The final current hidden state is a convex combination (controlled by) of the new memory and the memory at the previous
step,. We use back-propagation through time (BPTT) to train all associated weights,,,,,.

We further propose to use a bidirectional layer at the decoder. The motivation for this comes primarily from this application. To predict,
the unidirectional architecture as in fig.2considers the previous bus’s travel times up to sectiononly. However, the
previous bus’s travel times in subsequent sections beyondcan provide indicators of recent congestions further down in the route.These recent
congestions can in turn potentially propagate backward in space and strongly influence the travel time of the current bus at section.To
capture such eventualities, we use a bidirectional layer as given in fig.3.

In the GRU-cell defining equations (eqn. (4)-(7)), the state-update essentially follows the below equation

where for each time-step the state information flows from left to
right. In a bi-directional setting, we have an additional state-vectorand map, with an update with reverse information flow from right to left as
follows.

State at step,, is a concatenation. Note thatlikeis governed by the same GRU-cell defining equations
(eqn. (4)-(7)) with possibly different weight values. Each inputin Fig.3is
actually the concatenation of all inputs at the(each) step of the decoder in Fig.2. In particular,

whereis output of the append block in Fig.2.
Also note initial states
() and () are equal and initialized to. Finally,, whereis a feed-forward map.

SECTION: III-FTraining Data Preparation

Preparation of the training data for training our proposed ED models involves some extra effort. Specifically, we need inputs from the closest previous bus of the same day. We cannot just pick
the closest previous bus based on the start time of the trip. The closest previous bus at every subsequent section can be potentially different. Bus bunching in the data can make the scenario pretty complicated. For simplicity, let us assume there is no bus bunching. Then the immediate previous bus, at current time,may be a few section ahead. For those few sections, the closest previous bus
section traversal will come from this bus. But for sections beyond the current position of this immediate previous bus, we will have to look at buses which started before this immediate previous bus. Hence for every subsequent section, we need to search for the most recent bus (just before) which traversed that section. We need to comparewith the entry time into the section from each of the trips and pick that trip whose entry time is beforeand closest to. Recall this will form as a part of the input to the decoder. Computing this field of the input for each subsequent section of a training example will be, whereis the no. of trips on that day. In a general bus bunching scenario, one needs to search over all trips of that day. For each, there aresuch subsequent sections. So for each trip, one needs to perform thissearchtimes. This furher needs to be done across all trips and all training days. Ifdenotes the number of days of training data and ifdenotes the average no. of trips per day, then the complexity of data preparation now will be. Since this is a one-time pre-training step, its not a problem. Even if one wants to retrain with new data later, this effort need not be repeated on old data.

SECTION: IVResults

Data:We tested and bench-marked our method on one bus route (Route 399) from Delhi, India in detail. A pictorial view of the route is provided in App.A. The route was uniformly segmented into sections of lengthm resulting in a total ofsegments. The section width was chosen keeping in mind (a)the actual number of bus-stops and (b)the number of resulting sections ().
Having too many
sections can be challenging on the model for long sub-route prediction, while long section length would mean poor predictions on short sub-route predictions.
For every week, data from Mon to Sat was considered for training. Saturday data was also included as it also happens to be a working day for a large segment of
people in Indian conditions.
Further, Sunday was excluded as a previous study[32]under similar conditions provides evidence of Sunday traffic being distinct.
We bench-marked on data collected from all trips over two months (Sep-Oct). We filtered the noise from the raw GPS
measurements before using it for training our models. Filtering was performed based on simple route projection by exploiting the known route information.
For training, we used the firstweeks of data, while the final () week’s data was kept aside for testing.

Evaluation was carried out based oncomplementary metrics: Mean Absolute Error (MAE) and Mean Absolute Percentage Error (MAPE).Percentage error is Absolute Error divided by
true prediction expressed in percentage.While MAE provides a user
understandable clock time difference in seconds, MAPE is a scale independent metric.
Generally, accurancy of short route prediction is crucial for commuters planning their arrival on time to the bus-stop. Generally, such commuters will be planning to reach their closest bus-stops on time. On the other hand, accurate mid and long route predictions is crucial for commuters deciding whether to board the bus or take an alternative mode of transport.

SECTION: IV-ABench-marking Details

Proposed Approaches:We denote our proposed ED approaches as EDU (unidirectional decoder) and EDB (bidirectional decoder). The bidirectional model version can lead to many more parameters in the decoder (in comparison to the unidirectional version) for a similar number of hidden
nodes in the GRU cell. For consistency in the number of learnable parameters, the number of hidden nodes in the GRU-cell of the bidirectional decoder is kept lower so that
the overall number of parameters in the bidirectional decoder matches that of the unidirectional decoder.

Baselines:In this paper, we benchmark the proposed methods (with or without bidirectional layer at the decoder) againstrecent state-of-art baselines all of which capturing spatio-temporal (ST) correlations in a distinct way:

(a)LNKF[4], which learns spatio-temporal correlations (post a log transformation) using linear statistical models first followed by a linear kalman filter prediction approach

(b)SVKF[11], which learns spatio-temporal correlations using nonlinear support-vector approximations followed by a extended kalman filter prediction approach.

(c)DpAR[41]many-to-many architecture inspired from[41](an RNN approach for sequential (time-series) prediction with possible exogenous inputs). The current bus’s section travel time from previous section (akin to previous sequential input of DeepAR) and
previous bus’s section travel time from current section (like the exogenous input of
DeepAR) are fed as inputs to predict the current bus’s current section travel time at each time step. This baseline (indicated as DpAR from now on) captures
ST correlations in a distinct way.

(d)CLSTM[13]a current interesting spatio-temporal approach utilizing Seq2Seq to capture temporal correlations and Convolutional layer to capture spatial correlations.

BPTT was used to train all the deep learning algorithms namely DpAR, CLSTM, EDU and EDB. All these methods use Adam optimizer with batch size=32. To tackle over-fitting, early stopping was used for
DpAR, EDU and EDB, while the default batch normalization (as prescribed in[13]) was used for CLSTM. For LNKF training (model building), we used a least squares regression on the log transformed inputs. For SVKF training, support vector regression with a Gaussian kernel was used, while a grid search was employed to narrow down on the hyper-parameters,and C.

Model training (either for the proposed approaches OR the baselines considered) is carried out separately in an offline fashion using historical data of the previous few months.
Here we chose two previous months. The learnt model in conjunction with real-time inputs from the current bus and closest previous bus (and a historical seasonal trip from previous week) is now employed for dynamic arrival time prediction in real-time.

Justification of baselines:Please note LNKF and SVKF are recent learning-based spatio-temporal approaches which also capture the spatial sequential aspect of BATP in their predictive models
like our approach, but by performing a Kalman-filter based spatial multi-step prediction. SVKF in particular is a recent interesting nonlinear approach using support vector approximations for model building. CLSTM and DpAR are two recent DL approaches which make them a natural choice for baselining. Owing to the following reasons, we do not benchmark our method against some of the other
recent approaches like[2],[15],[8]discussed in related work.
BusTr[2]considers run-time and dwell time separately, while takes very different inputs like speed forecasts, location embeddings etc.
which are very hard to procure and compute for the data and route on which we bench-marked.
The performance of the TD approach of[15]on the other hand was very poor on short and mid-length sub-routes.
CLSTM is a nonlinear model which captures temporal correlations on lines similar to[8]by segmenting the time axis. While[8]captures linear temporal
correlations only, CLSTM additionally captures spatial correlations also via a convolutional layer making it a stronger baseline compared to[8].
Overall our choice of baseline methods is current and enables a
diverse comparison.

Assessing significance of Error differences statistically:We have conducted a Z-test based significance assessment (across all relevant experiments) under MAPE/MAE differences
(EDB vs EDU/Baseline) with a significance level of 0.1 to reject the null hypothesis. The mean error metric is evaluated by averaging
at-least 30 samples in all experiments and hence a Z-test is sufficient.

Model Building Details:Recall that Fig.2takes current position () also as input and builds a unified model. One issue with the unified model is that the section
number has to be one-hot encoded with a large number of binary inputs (equal to the number of sections, abouthere). This can lead to huge number (quadratic increase) of weights while the ability to generalize across a large number of sections (current positions) can be challenging. Empirically we observe a poor performance in this approach.
A possible intuitive explanation could be that the unified model has to generalize across allwhile also handling a huge variation in encoder/decoder unfolded lengths for different. To tackle this, we build a common model across everyconsecutive sections. In this way, we avail the variable (input-output) length feature of ED while the weights introduced due to one-hot encoding of the position is also under control.
We have built models starting from section, where the first model is trained with input-output pairs forranging from. In this way we build 6 models to cover the entire route, where each model can generalize acrossconsecutive sections for current bus position ().

SECTION: IV-BTwo-step (section) ahead Prediction (Short Routes)

Day Level Comparison:We compare two-step ahead predictions (for short routes) of EDU and EDB with all existing methods at a day level. Fig.4illustrates that EDB, our bidirectional proposed variant outperforms EDU and most of the state-of-art baselines consistently
at a-step level.
Fig.4(a)and Fig.4(b)provide the comparisons in terms of MAPE and MAE respectively.
In particular, the MAE prediction improvements of EDB over CLSTM are statistically significant (based on Z-test as described earlier) ondays, while the two methods have
similar performance (statistically) on the remaining two days. Compared to DpAR, EDB’s improvements are statistically significant ondays while performance is similar on the remaining two days.
EDB performs better (statistically) on all days compared to EDU, LNKF, and SVKF. The MAPE prediction improvements of EDB are similar in trend to the MAE case. A slight exception here is in comparison to DpAR, where EDB’s predictions are better ondays, similar onday, while inferior to DpAR ondays.
In terms of the best-case improvements, EDB performs the best with an advantage up to 10.21%, 12.54%, 4.03%, 7.78%
and 8.93% over LNKF, SVKF, DpAR, CLSTM and EDU approaches respectively.
Similarly in terms of MAE, EDB performs the best with an advantage up to
29.87s, 53.88s, 30.81s, 34.11s and 19.81s over LNKF, SVKF, DpAR, CLSTM and EDU approaches respectively.
Overall, we observe reasonable improvements from our method, EDB, based on both metrics.

SECTION: IV-CMulti-Step Prediction

We now test our learnt models on longer sub-routes, where sub-routes are spread across the entire route. Our method must be able to provide quality real-time predictions
between any two bus-stops (or sections) of the bus route.
We evaluate performance based on both metrics. Each sub-figure in Fig.5shows comparison of MAPE values for anpair, whereis the
current bus position andis the destination section. This means for a given,is varied in steps offrom. The only exception here is for the maximumwhich is(as the route ends there).
Fig.5(a)provides MAPE results for. Fig.5(b)provides results for, while Fig.5(c)provides results for.
MAE/MAPE is calculated by averaging across all trips and days in the test
set by keeping the start section and end section fixed.
We note that the proposed EDB mostly performs better than LNKF, SVKF, DpAR, CLSTM and EDU.
This inference is based on both MAPE and MAE metrics (Fig.5and Fig.6).
EDB in particular, as in the
2-step case performs the best. At the MAPE level, compared to CLSTM, of the 21pairs considered, EDB outperforms CLSTM onpairs, has (statistically) similar performance onpairs while does poorer than CLSTM on only onepair. Compared to DpAR, EDB outperforms DpAR onpairs, has (statistically) similar performance onpairs while does poorer than DpAR on only onepair. Compared to LNKF, SVKF and EDU, EDB outperforms all of them (statistically) on allpairs. Specifically, for a-step ahead prediction, EDB achieves MAPE improvement by
up to 12.49%, 12.92%, 5.71%, 3.71% and 8.61% over LNKF, SVKF, DpAR, CLSTM and EDU respectively. For a-step ahead prediction, EDB reduces MAPE by up
to 9.83%, 9.64%, 8.45%, 3.45% and 7.08% in comparison to LNKF, SVKF, DpAR, CLSTM and EDU respectively.
For a-step ahead prediction, EDB reduces MAPE by up
to 8.00%, 7.93%, 3.94%, 2.61% and 6.59% in comparison over LNKF, SVKF, DpAR, CLSTM and EDU respectively.

On similar lines, Fig.6(a)provides MAE results for. Fig.6(b)provides results for, while Fig.6(c)provides
results for. Please observe in these figures how the MAE generally increases with the length of the sub-route (i.e.) inline with the intuition
that error increases with prediction horizon. As before, EDB performance is the best. The trends are similar as in the MAPE case. EDB does significantly better than CLSTM and DpAR onandpairs respectively, while DpAR never does better and CLSTM does better on only onepair. EDB as before outperforms LNKF, SVKF and EDU on allpairs. Specifically, for a-step ahead prediction, EDB achieves MAE improvement by
up to 95.89s, 112.04s, 31.15s, 24.3s and 40.53s over LNKF, SVKF, DpAR, CLSTM and EDU respectively. For a-step ahead prediction, EDB reduces MAE by up
to 122.4s, 133.05s, 99.63s, 35.29s and 75.41s in comparison over LNKF, SVKF, DpAR, CLSTM and EDU respectively.
For a-step ahead prediction, EDB reduces MAE by up
to 146.78s, 157.17s, 50.75s, 35.25s and 106.76s in comparison over LNKF, SVKF, DpAR, CLSTM and EDU respectively.

Overall, our results indicate that our bidirectional variant, EDB, performs best on routes of varied lengths. Our results also indicate that EDU’s performance is poor compared to some of the baselines and hence not up-to the mark. This strongly vindicates the necessity of a bidirectional layer at the decoder as in EDB, which
potentially capture influence of past congestions from downstream sections on the route.

In the plots whenever some of the baselines have high errors, we have avoided showing the associated bar heights completely as this adversely affects the visual
comparison of the bars in the error range of our proposed approaches EDB and EDU. As a result we see some clipped bars with actual error values higher than the
max-axis range.

SECTION: VDiscussion & Conclusion

In this paper we proposed a novel variant of Encoder Decoder (Seq2Seq) RNN approach with (i)bidirectional layer at the decoder and (ii)inputs carefully placed in a non-redundant fashion across the encoder and decoder, for Bus arrival time prediction (BATP). In particular,

To recognize that an ED based approach can be employed for real-time BATP by mapping
sequential aspect of ED to the spatial aspect of the problem, as proposed here, is not immediately evident.The geometry of real-time BATP, in particular the variable length feature of input-output training data enabled an interesting natural fit
with ED prediction framework to simultaneously predict travel times across subsequent
sections of the currently plying bus.

We technically motivated in steps (in Sec.III-Cand Sec.III-D) as
to how one can arrive at our novel ED architecture (with carefully chosen relevant inputs)
incorporating both current spatio-temporal correlations and seasonal correlations.
The real-time spatio-temporal correlations and weekly
seasonal influences were intelligently incorporated into the proposed predictive model via non-redundant inputs at both the encoder and decoder.

In the traditional ED, the only input at each step of the decoder is the same context vector
(which is the state of the last sequential-step of the encoder). While in our proposed ED,
we have additional distinct inputs at each step of the decoder coming from the closest (w.r.t
the query time) previous bus and closest trip from previous week (same weekday). Since each step of
the decoder maps to a unique subsequent section, the (closest) previous bus’s entry time
and section travel time are fed as a distinct input at the decoder step
associated with the same subsequent section (essentially in a space synchronized fashion).

We propose a bidirectional layer at the decoder as this can now capture (for a given section) the possible influence of past congestions (in time) from the subsequent (downstream) sections
propagating backward in space (along the bus route). This novel feature of the bidirectional layer at the decoder is absent in both (i)traditional ED and (ii) other time- series
applications of the ED framework.

We demonstrated via detailed experiments the utility of our approach on a bus route from challenging mixed traffic
conditions by looking at prediction accuracy via two complementary metrics MAPE and MAE, along
sub-routes of a wide range of lengths.
We also ran tests of statistical significance to make sure
the improvements we are observing in favour of our method are indeed statistically significant. Our EDB variant (which uses bidirectional layer at the
decoder) does better than the EDU variant (which uses unidirectional layer at the decoder).
and many other carefully chosen state-of-art approaches for the same problem.

Other Applications:The proposed ED framework
with a bidirectional decoder can potentially have applications in multi-step time-series forecasting. For instance, it can be used in multi-step sales prediction for domains like retail, CpG (Consume packaged goods) etc.Previous sales and price (that transpired in the recent past just before the forecast horizon) would be sequentially fed as encoder inputs. A-step unfolded decoder’s outputs match the sales targets of a-step ahead forecast horizon. If future promotional information/prices across the multi-step forecast horizon is
available, it could be fed as decoder inputs in a synchronized fashion. The point is that a buyer may decide to postpone buying certain products depending on the upcoming promotions and his current need, which means
future promos can potentially influence past sales in the forecast horizon. This anti-causal influence can rightly be captured by our novel ED variant which uses a bidirectional variant at the decoder.
In that sense, our proposed ED variant is
general and has other applications.

As future work, we would explore utility of the
proposed architecture in domains like demand prediction for retail and so on. Another potential future work could be to exploit additional inputs for BATP like speed, flow
etc. and a suitably refined ED architecture to incorporate these inputs. We will also explore applying transformer and its variants to the encoder-decoder framework proposed in this paper for BATP.

SECTION: Acknowledgement

The authors thank Prof. Pravesh Biyani and his team from IIIT Delhi[42]for kindly sharing real field AVL data, which made our bench-marking
possible. This data is available on request for anyone. The authors also thank Rohith Regikumar (researcher, TCS Research) for his support during bench-marking.

SECTION: References

SECTION: Appendix ARoute Visualization on Map