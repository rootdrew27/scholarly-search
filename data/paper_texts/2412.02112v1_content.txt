SECTION: Machine Learning Methods for Automated Interstellar Object Classification with LSST
The Legacy Survey of Space and Time (LSST), to be conducted with theObservatory, is poised to revolutionize our understanding of the Solar System by providing an unprecedented wealth of data on various objects, including the elusive interstellar objects (ISOs). Detecting and classifying ISOs is crucial for studying the composition and diversity of materials from other planetary systems. However, the rarity and brief observation windows of ISOs, coupled with the vast quantities of data to be generated by LSST, create significant challenges for their identification and classification.
This study aims to address these challenges by exploring the application of machine learning algorithms to the automated classification of ISO tracklets in simulated LSST data.
We employed various machine learning algorithms, including random forests (RFs), stochastic gradient descent (SGD), gradient boosting machines (GBMs), and neural networks (NNs), to classify ISO tracklets in simulated LSST data.
Our results demonstrate that GBM and RF algorithms outperform SGD and NN algorithms in accurately distinguishing ISOs from other Solar System objects. RF analysis shows that many derived Digest2 values are more important than direct observables (right ascension, declination, and magnitude) in classifying ISOs from the LSST tracklets. The GBM model achieves the highest precision, recall, and F1 score, with values of 0.9987, 0.9986, and 0.9987, respectively.
These findings lay the foundation for the development of an efficient and robust automated system for ISO discovery using LSST data, paving the way for a deeper understanding of the materials and processes that shape planetary systems beyond our own. The integration of our proposed machine learning approach into the LSST data processing pipeline will optimize the survey’s potential for identifying these rare and valuable objects, enabling timely follow-up observations and further characterization.

SECTION: Introduction
TheObservatory, formally called the Large Synoptic Survey Telescope, is set to revolutionize the field of astronomy when it begins operations in 2025with its unprecedented wide-field survey capabilities. The survey will generate a vast amount of data, enabling research in diverse areas of astrophysics, including the discovery and characterization of new Solar System objectssuch as interstellar objects. To date, only two ISOs have been discovered (excluding interstellar meteors): 1I/‘Oumuamua and 2I/Borisov.

1I/‘Oumuamua was discovered coincidentally as an unknown object moving at a high apparent rate of motion. Due to its high near-Earth object (NEO) Digest2 score, the object was posted to the Near-Earth Object Confirmation Page(NEOCP) of the Minor Planet Center(MPC), which enabled rapid follow-up observations from multiple sites around the world. Within a few days, the heliocentric orbit was deemed to be undoubtedly hyperbolic. At the same time, 1I/‘Oumuamua was classified as an NEO due to its perihelion distance of less than 1.3 astronomical units (AU).

After its discovery, astronomers noticed 1I/‘Oumuamua’s peculiar physical properties, such as its extremely elongated shapeand its lack of cometary activity. These characteristics sparked an intense debate about its origin and composition. The motion of 1I/‘Oumuamua has not yet been fully explained, with several studies proposing different explanations for its nongravitational acceleration.

Conversely, 2I/Borisov was discovered as a new comet (seeand references therein), and like other new comet discoveries, the object was posted to the MPC’s Possible Comet Confirmation Page(PCCP). This again enabled rapid follow-up observations and early orbit determination, which proved that the comet has a highly hyperbolic orbit with respect to the Sun. Therefore, the second ISO was also a coincidental discovery, with its cometary activity drawing the attention of astronomers.

However, if an ISO’s orbit is not known and it is observed as a short intra-night object, it can be easily missed or misclassified as another type of object. This emphasizes the need for an automated approach for efficiently detecting and classifying ISOs. Additionally, the vast quantities of data that will be produced by LSST, especially in the first few years as new “background" objects — particularly main belt asteroids (MBAs) — are discovered, will further impede our ability to identify possible ISOs.

This will be particularly challenging in the first few years of LSST operations as most of the objects seen will be new discoveries, dominated by small MBAs.
Traditional methods of data analysis cannot feasibly handle such massive datasets in a timely manner. This is where machine learning (ML) becomes crucial. Machine learning techniques are powerful tools for automatically processing and analyzing large volumes of data, identifying patterns, and making predictions with high accuracy and efficiency.

In the context of ISO detection and classification, ML algorithms can be trained to recognize the unique motion characteristics of ISOs amidst a vast sea of Solar System objects. These algorithms can rapidly sift through the data, flagging potential ISOs for further analysis and follow-up observations. By automating the identification process, ML not only accelerates the discovery of new ISOs but also improves the reliability and consistency of detections.

Therefore, to address the challenge of automatically flagging candidate ISOs for follow-up observation, we explored and evaluated several state-of-the-art ML algorithms for automated tracklet classification, including random forests, stochastic gradient descent, gradient boosting machines, and neural networks. By comparing the performance of these algorithms on simulated LSST data, we aim to identify the most effective approach to accurately classifying tracklets and distinguishing ISOs from other Solar System objects. The results of this study will facilitate the development of a robust and efficient automated system for ISO discovery and characterization using LSST data.

SECTION: The search for interstellar objects
The existence of ISOs has been theorized for decades. In the early stages of the Solar System, a large quantity of planetesimals and debris was ejected due to the instability of the dynamical system and the gravity of the giant planets. Like small planetesimals, larger bodies such as planets (so-called free-floating planets) can be ejected from their parent systems.

Several studies derived upper estimates of the spatial density of ISOs around the Sun before the discovery of 1I/‘Oumuamua and 2I/Borisov. Some estimates relied on ongoing Solar System surveys, their pointing data and depth, such as LINEARor Pan-STARRS. However, without a single ISO discovered, the estimates varied by orders of magnitude, betweenandfor a 1-km ISO.

The discovery of 1I/‘Oumuamua and 2I/Borisov allowed a better constraint to be placed on the spatial density of both active and inactive ISOs:predicted‘Oumuamua-like objects closer than Neptune at any given time, whilepredicted the 3-sigma number density of similar sized ISOs betweenand.derived the number density to be similar toandderived a number density of. Meanwhile,used the data from both discovered ISOs and derived a density offor slightly larger, 250-meter ISOs, and determined the slope of the size-frequency distribution of ISOs, in terms of actual size (km), to be.

Other works explored the potential of the LSST for discovering and characterizing ISOs and other unique Solar System objects. LSST’s unprecedented limiting magnitude of aboutin g-bandand sky-coverage of approximately half of the sky during the survey, offer a unique opportunity to detect the interstellar interlopers.

predicted that LSST will detect 1-3 ISOs of 1I/‘Oumuamua’s size and properties per year.estimated that LSST could detect between 0 and 70 ISOs per year, depending on their albedo and size-frequency distribution, thus covering a wide range of possibilities.

These studies collectively demonstrate the growing interest in the detection and characterization of ISOs, as well as the potential of the LSST to significantly advance this field. However, they fail to directly address the challenge of identifying ISOs in LSST data with high confidence and in a timely manner, which is critical for effective characterization. While ISO candidates can eventually be identified post-processing or through analysis by the MPC, rapid identification is crucial for follow-up observations, especially for objects on transient trajectories like 1I/‘Oumuamua, where early detection would have allowed for a more detailed characterization.
By leveraging synthetic LSST data provided by theScience Platform (RSP), we aim to contribute to this ongoing research effort by employing ML algorithms as a means to automatically flag potential ISO candidates for follow-up observation among the large quantities of daily alerts. The next sections describe our methodology, model development, and evaluation.

SECTION: Methodology
LSST Solar System products will be delivered in several forms: real-time alerts will provide large amounts of individual transients (400,000 to 5 million per night), and a daily batch of tracklets will be shared with the MPC. Tracklets are short sequences of observations of the same object observed two or more times per night, and they can be used to determine the object’s approximate orbit (or range of potential orbits) and to classify them as NEOs, MBAs, or other types of objects, such as ISOs.

LSST will submit to the MPC both individual tracklets and linkages of tracklets that represent an object that has been observed on three or more nights, but they will not submit unlinked individual detections.
Additionally, LSST will identify known objects and submit them with their designations to the MPC. The LSST catalog of derived orbits will also include photometric and light-curve information, although at present we have no plans to make use of such data. Although intra-night linking has been widely used by surveys such as WISE Moving Object Pipeline Subsystem, Pan-STARRS Moving Object Processing System, or Zwicky Transient Facility’s Moving Object
Discovery Engine, the efficiency of the inter-night linking by LSST, which currently utilizes the HelioLinC method, has not yet been proven for hyperbolic orbits. Consequently, the ability to link hyperbolic orbits and thus identify ISOs remains uncertain.

Our work focuses on analyzing the intra-night tracklets of unidentified objects as observed by LSST. Specifically, we used directly reported LSST “observables” — the right ascension, declination, and magnitude at a given epoch — and derived values such as the sky-plane velocity and motion direction and the apparent position with respect to the opposition. We also employed Digest2, using its output as additional input for our ML models. In this section we describe our data sources, processing, feature selection process, and their derived values employed by ML models for the purpose of automatically classifying ISO tracklets.

SECTION: LSST input data
We utilized the LSST DP0.3 Solar System object simulation data, which contains a 1-year () and 10-year () quasi-realistic distribution of LSST pointings with simulated detections of Solar System objects, including both real (discovered) objects from the Minor Planet Center Orbit Database (MPCORB) and the synthetic Solar System model. The simulations collectively contain more than 13 million synthetic orbits, including approximately 12,000 hyperbolic (ISO) orbits. Data are distributed as Astronomical Data Query Language (ADQL) databases available through the RSP, each with four tables: DiaSources (simulated astrometric and photometric measurements for detected Solar System objects), MPCORB (catalog of real and synthetic orbits), SSObject (table of LSST-linked Solar System objects), and SSSource (Solar System source information corresponding to specific difference image detections).

Tableillustrates the number of detections by category in the 1-year LSST simulation data.
Although the synthetic model should realistically balance the ratio of different orbital types based on object size, the ISO population is significantly exaggerated in quantity. For this reason, we downloaded all data from the 1-year dataset and only the ISO detections from the 10-year dataset, thus boosting the total number of ISO samples from 3,306 to 14,151. Figureshows the size-frequency distribution of synthetic ISO orbits: synthetic ISOs have H in a range of 18-23, representing roughly objects of a size of between 100 meters to 1 kilometer for an assumed albedo of 0.1.

SECTION: Boosting the sample count of synthetic ISO tracklets
Our initial dataset had about 6 million tracklets, of which only 14,151 (0.24%) were ISOs. The remaining tracklets were other celestial objects — a highly imbalanced dataset.

Highly imbalanced data in classification problems significantly impacts the performance and reliability of predictive models. In scenarios where the distribution of classes is skewed, traditional algorithms can exhibit a bias toward the majority class, leading to an inadequate representation and misclassification of the minority class. This imbalance can distort the learning process, as models may prioritize minimizing errors on the more prevalent class, consequently neglecting the rare yet potentially more critical class.

To address this imbalance, we sought to boost the number of ISO samples and then randomly sample an equal number of non-ISOs to form a new, balanced dataset.
We downloaded the heliocentric ISO orbits from thesimulation, which contain 12,148 Keplerian hyperbolic orbits.

To significantly increase the number of ISO tracklets, we created a simplistic LSST-like pseudo-survey. First, we propagated 12,148 ISO orbits to the initial epoch of the 10-year survey (to the local midnight) and then to a second epoch one our later, thus creating two-detection 1-hour tracklets for each orbit. This approach allowed us to generate a larger number of synthetic ISO tracklets that closely resembled the expected observations from the LSST survey.

Subsequently, we computed the ephemerides for each day over the next 10 years, using the following constraints to simulate a detection:

a limiting V-band magnitude of 24.5,

a minimum apparent lunar elongation of 90 degrees,

a minimum solar elongation of 60 degrees,

a minimum object altitude of 20 degrees,

allowing only detections with a negative declination or with a declination greater than 0 but an ecliptical latitude of less than 10 degrees, mimicking the LSST survey area as seen in Fig..

We considered a tracklet valid when the same object fulfilled the mentioned constraints and was detected twice on the same night. To create a dataset independent from the original one but maintaining the same orbits, we shuffled the absolute magnitudevalues, ensuring that the size-frequency distribution remained the same. This custom synthetic dataset of ISO tracklets was then added to the LSST-generated tracklets. The total number of generated ISO tracklets is displayed in Table.

SECTION: Digest2
Digest2is a robust and efficient short-arc orbit classifier for small Solar System bodies, primarily utilized for the identification and prioritization of NEO candidates for follow-up observations.
Digest2 operates by analyzing tracklets, employing statistical methods for motion analysis and initial orbit determination. Each object processed by Digest2 is assigned a “D2” score (often referred to as the NEO score) ranging from 0 to 100, representing a pseudo-probability that a tracklet belongs to an NEO. In addition to the D2 NEO score, Digest2 outputs scores for 14 additional orbit classes (see Table 8 in). There are two independent scores for each class, “raw” is the score with respect to the entire model population as if all objects have been discovered, and “noid” score is the score with respect to the undiscovered portion of a given population.

Though Digest2 is regularly used to tag NEO candidates, the code has not been fully utilized to identify objects of other orbital categories despite its ability to do so. Therefore, we sought to build on Digest2 by exploring whether its output values could aid in the task of classifying ISOs.

One of the key questions we had was whether the output from Digest2 would be important in classifying ISOs. That is, would the orbital categories output by Digest2 serve as important input features for our ML models when determining whether a tracklet belongs to an ISO?

To explore this, we employed the RF algorithm to generate feature importances, which measure the contribution of each feature to the model’s predictive performance. During our analysis, we noticed that indeed many of the features identified as having high importance were produced by Digest2, rather than those that were derived or obtained directly from the simulated LSST data. This is evident from Fig., which shows that nine out of the ten most important features identified using the RF method were from Digest2.
Among the highest-ranked features were those related to Jupiter-family comets (“raw” Digest2), Hildas (“noid” Digest2), inner main belt, and “Interesting” categories. Importantly, these features often relate to celestial objects with high eccentricity (Jupiter-family comets and Interesting) or to distant objects that have slow motion (Jupiter-family comets and Hildas). This suggests that these characteristics likely play a key role in identifying ISOs, which are known to have highly eccentric (hyperbolic) orbits and can have inclinations at any angle. Further explanation of the Digest2 algorithm and its output can be found in.

Having confirmed that Digest2 output will serve as important input for our models, the next steps involved preprocessing our data and integrating the Digest2 output, which we describe next.

SECTION: Data preprocessing
As mentioned in Sect., we downloaded all of the one-year LSST DP0.3 Solar System object simulation data and only ISOs from the ten-year simulation.

We then processed the downloaded individual detections using known object designations. Each detection was given a custom tracklet ID (), which we derived by combining the modified mpcDesignation with the integer part of the modified Julian date (MJD) plus a constant offset of 0.5. Eachhas a length of 12 characters.

The data were then filtered to ensure that each object had a minimum of two detections per night, and then grouped by theirto form tracklets. That is, we define a tracklet as the same object observed two or more times per night.
The tracklets were labeled by the nature of their orbits: ISOs and everything else. In our work, we assumed the tracklet linking efficiency is ideal, and we did not account for false tracklets (mislinked objects or object-noise linkages) such as discussed in.

The apparent magnitude in the observed filter band was converted to an approximate V-band magnitude (vmag) using a conversion factor specific to each filter. The detections were then grouped by their uniqueidentifier.

For each tracklet (detection group), we selected the first and last detections (skipping those where the MJDs were the same) and derived quantities such as the rate of motion, position angle, ecliptical latitude, opposition-centered ecliptical longitude, and solar elongation. Thecolumn was created to indicate the class of the celestial object, with a value of 0 or a 1 assigned to each tracklet based on the leading characters of the modified mpcDesignation column, which we modified to start with an “I” for ISOs or a “1” for all other obit classes.
The processed LSST data were compiled into a new dataset and merged with the pseudo ISO tracklets described in Sect..

The next step involved using Digest2. Digest2 ingests tracklets, represented by observational data, in so-called MPC1992 format.
We converted previously prepared LSST observations to MPC1992 format, particularly the 12-character,,(),(),, andinto the MPC1992 format, with the LSST observatory code. The resulting format was generated with full-precision in,, magnitude and the epoch. For this, the Digest2 source code was slightly altered so that the program could ingest 12-character. We computed 13 Digest2 parameters in both “raw” and “noid” modes for each of our synthetic tracklets, resulting in 26 features, and concatenated the output with our dataset (see Sect.for the derived quantities).

Next, we removed duplicate entries based on thecolumn. During this data cleaning phase, we noticed that some detections had apparent magnitudes fainter than the limiting magnitudesand we therefore removed a few percent of the detections. The remaining data were sorted in ascending order byand MJD to establish a consistent sequence of observations. Irrelevant columns, includingand MJD, were dropped, and the other columns were renamed for clarity.
Our final dataset is described in Table.

SECTION: Model training and evaluation
Having identified the key features and completed data preprocessing, we split the dataset into training, testing, and validation subsets using a two-step process. The data were first divided into training (80%) and temporary (20%) sets using a fixed random seed of 42 for reproducibility. The temporary set was then further split equally into testing and validation sets using the same random seed.

Within each subset, we separated the target variable () from the feature variables. The target variable represented the class or category we aimed to predict (i.e., non-ISO vs. ISO), while the feature variables encompassed all the remaining columns that would be used as input to the ML models.

SECTION: Model selection
Using these data, we trained and evaluated several ML models for ISO detection: GBMs, RFs, SGD, and NNs.

The GBM algorithm is an ensemble learning method that builds a series of weak learners, typically decision trees, sequentially to correct errors made by previous models. GBM is known for its high predictive accuracy and ability to handle complex, nonlinear relationships in data.

The RF algorithm is another ensemble method that constructs multiple decision trees and combines their outputs for prediction. RF is particularly effective at reducing overfitting through its use of bagging and random feature selection, making it robust across various types of datasets.

The SGD algorithm optimizes the model by updating weights incrementally using randomly chosen data points, making it computationally efficient for large datasets. Although it requires careful tuning, SGD can quickly converge to good solutions in high-dimensional spaces where other models may struggle.

Neural networks, with their layered architecture, are capable of capturing complex, nonlinear relationships. NNs learn hierarchical feature representations through back-propagation, making them particularly suited for tasks with intricate patterns, though they often require more data and computational resources to reach optimal performance.

SECTION: Evaluation results
Figurepresents the confusion matrices for our chosen models, illustrating their classification performance.

The GBM model exhibited high accuracy with minimal false-positives and false-negatives, indicating strong performance in ISO detection. Similarly, the RF model performed well but showed slightly more false-positives. The SGD model had a higher false-positive rate compared to GBM and RF, suggesting a lower effectiveness in ISO detection. The NN model performed adequately but had a slightly lower accuracy than GBM and RF.

To assess the models’ effectiveness in identifying ISOs while minimizing false positives and false negatives, we measured key performance metrics for each model, including F1 score, precision, recall, and accuracy for both ISO and Not-ISO classes. Precision measures the proportion of true ISOs among all objects classified as ISOs by the model. Indeed, a high precision indicates that when the model classifies an object as an ISO, it is likely to be correct. Recall, however, measures the proportion of true ISOs that are correctly identified by the model out of all the actual ISOs in the dataset. A high recall suggests that the model is able to detect a large percentage of the ISOs present.
The F1 score is the harmonic mean of precision and recall, providing a balanced measure of the model’s performance. It is particularly useful when the dataset has an uneven class distribution, as is the case with ISOs being rare compared to other celestial objects (although, we ensured that our data were balanced before model training). Accuracy measures the overall correctness of the model’s predictions, considering both true positives and true negatives.

As Tableillustrates, the GBM and RF models yielded the highest accuracy and balanced performance across all metrics, while the SGD and NN models showed lower accuracy. The results reveals that the GBM model was most effective in distinguishing ISOs from other Solar System objects.

SECTION: Validation on nightly datasets
To assess the performance of our models in a realistic scenario, we validated them on three randomly selected nights from the simulated data, representing typical tracklet counts per year (around 20,000 tracklets per year). Our goal was to minimize confusion and false positives, given the vast quantity of unknown tracklets that LSST will produce. The nights chosen were:

Night 60313: No ISO, representing a typical night.

Night 60543: Containing 13 ISOs, with a highly exaggerated number of ISOs.

Night 60358: Containing exactly one ISO, simulating a prospective night where a single ISO could be discovered.

The selected data were excluded from the training, testing, and validation datasets, and the models were retrained using the same hyper parameters used in initial training. The results in Tableindicate that GBM consistently performed well across various datasets, while other models exhibited varying degrees of effectiveness. A closer look at the GBM results shows that on night 60313, where there were no ISOs in the dataset, the GBM correctly identified 0 ISOs and produced just 19 false positives. On night 60543, the GBM model labeled all 13 ISOs with only one false positive. On night 60358, where one ISO was present, it was correctly identified by the GBM, along with 4 false positives.

SECTION: 1I/‘Oumuamua and 2I/Borisov
To evaluate the performance of our models on real-world examples of ISOs, we generated two new datasets containing tracklets from the first known ISOs, 1I/‘Oumuamua and 2I/Borisov, for a single night (Table). Despite the challenging nature of the data, the models demonstrated some ability to correctly identify the ISOs.The SGD model achieved the highest true-positive rate for ‘Oumuamua, correctly identifying 46 out of 50 instances, whereas the RF model performed best for Borisov, correctly identifying 103 out of 712 instances. However, the lack of true-negatives and the presence of false-negatives highlight the difficulty in confidently identifying ISOs from such limited observations. Additionally, the LSST dataset is very differ from current surveys that typically have limiting magnitudes down to +22.5, while LSST will survey significantly deeper (+24.5), thus providing an order of magnitude more unknown faint objects not seen by current surveys.

SECTION: Discussion
Our models demonstrated strong performance on the simulated LSST data, and their application to real-world examples of 1I/‘Oumuamua and 2I/Borisov yielded promising results while highlighting areas for improvement. Notably, the models successfully flagged both ‘Oumuamua and Borisov as potential ISOs without generating any false positives. This achievement is significant as minimizing false positives is crucial to ensure that valuable telescope time is not wasted on follow-up observations of misclassified objects.

The models’ ability to correctly identify ‘Oumuamua and Borisov as ISOs, even with limited observations, underscores their potential for detecting these rare and significant celestial objects. However, the models struggled to achieve high true-positive rates and low false-negative rates for these specific cases, indicating the need for further enhancement to confidently identify ISOs from limited data.

These results emphasize the importance of collecting more comprehensive data on ISOs to improve the models’ performance and generalizability. The limited number of observations and the challenging nature of the data pose significant difficulties for the models in confidently identifying ISOs. With only a few detections available for each ISO, the models have limited information to learn from and make accurate predictions. This is evident in the results for 1I/‘Oumuamua and 2I/Borisov, where the models struggle to achieve high true-positive rates and low false-negative rates.

To enhance the models’ performance in confidently identifying ISOs, several improvements and additional data sources could be considered:

Collecting more observations of known ISOs: Increasing the number of observations for confirmed ISOs like 1I/‘Oumuamua and 2I/Borisov would provide the models with more examples to learn from, improving their ability to recognize the unique features of ISOs.

Collaborating with other observatories and surveys: Sharing data and combining observations from multiple telescopes and surveys could help create a more comprehensive dataset of ISO detections, increasing the diversity and quantity of examples available for training the models.

Incorporating additional features: Extending the feature set to include more physical and morphological properties of ISOs, such as color, spectral characteristics, and light curves, could provide the models with additional discriminating information to improve their classification performance.

Investigating the extendedness of ISOs: Extendedness can affect the quality of astrometry. For instance, typical comets exhibit activity by having a coma or extended tails that can shift the astrometric center, introducing uncertainties in position measurements. Understanding these effects is crucial, as the extended nature of an object can degrade the accuracy of the astrometric data and, consequently, affect the models’ ability to correctly link and identify ISOs. Importantly, moving detections made by LSST that are extended or differ significantly from the stellar point-spread-functions will be flagged immediately and distributed as LSST alertswell before any linking is made.

Exploring transfer learning techniques: Leveraging knowledge gained from other asteroid and comet detection tasks could help improve the models’ performance on the limited ISO data available. Transfer learning techniques could be employed to adapt pretrained models to the specific task of ISO detection.

Evaluating uncertainties in the LSST pipeline: Assessing uncertainties in the LSST pipeline is critical, especially regarding their impact on ISO linking and identification. LSST data’s astrometric uncertainties may significantly challenge the differentiation between interstellar and Solar System objects. Even minor positional errors could result in inaccurate orbit determinations or object misclassifications. Furthermore, it is vital to analyze the correlations among orbit fit accuracy, determination, and linking precision. Errors in these areas can cascade through the ISO identification process, potentially complicating detection efforts. Comprehensive examination of these correlations will lead to refined, more reliable models. However, a complete evaluation of LSST uncertainties must await the publication and availability of actual observational data.

Continuously updating the models: As new ISOs are discovered and more data become available, regularly updating the models with the latest observations would help them stay current and improve their performance over time.

By addressing these challenges and incorporating additional data and techniques, the models’ ability to confidently identify ISOs could be significantly enhanced, enabling a more reliable detection and characterization of these rare and important celestial objects.

SECTION: Conclusion
In this study we explored the application of ML algorithms for the automated classification of ISO tracklets in simulated data from the upcoming LSST survey. Our analysis with RFs shows that the Digest2 values are far more important for classifying ISOs than direct observables supplied by LSST data. The GBM and RF models outperform the SGD and NN models in accurately distinguishing ISOs from other Solar System objects. When evaluated on the simulated data, the GBM model achieved the highest precision, recall, and F1 score, making it the most effective approach for identifying these rare and elusive objects. The models were then applied to three randomly selected nights of LSST data and were able to identify all synthetic ISOs. The SGD and RF models performed best on ‘Oumuamua and Borisov, respectively. All models produced a relatively low false-positive rate (from a few to a few dozen). However, given that thousands of tracklets will be generated nightly, this low false-positive rate will be manageable. To further improve the performance and generalizability of our models, we have outlined several potential ways forward (see Sect.).

As LSST begins operations, it will generate an unprecedented wealth of data, presenting both challenges and opportunities for the astronomical community. The ability to quickly and accurately identify ISO candidates amidst the vast quantity of tracklets will be crucial for enabling timely follow-up observations and further characterization of these unique objects.

In conclusion, our work lays the foundation for the development of an automated ISO tracklet classification system that can be applied to new data collected in the upcoming LSST era. By developing and implementing efficient and robust classification systems, we can unlock the full potential of LSST in discovering and characterizing these rare and valuable objects, paving the way for advances in our understanding of the materials and processes that shape planetary systems throughout the cosmos.

SECTION: References