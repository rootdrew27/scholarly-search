SECTION: Comprehensive and Comparative Analysis between Transfer Learning and Custom Built VGG and CNN-SVM Models for Wildfire Detection
Contemporary Artificial Intelligence (AI) and Machine Learning (ML)
research places a significant emphasis on transfer learning, showcasing
its transformative potential in enhancing model performance across
diverse domains. This paper examines the efficiency and effectiveness
of transfer learning in the context of wildfire detection. Three purpose-built
models – Visual Geometry Group (VGG)-7, VGG-10, and Convolutional
Neural Network (CNN)-Support Vector Machine(SVM) CNN-SVM – are rigorously
compared with three pretrained models – VGG-16, VGG-19, and Residual
Neural Network (ResNet) ResNet101. We trained and evaluated these
models using a dataset that captures the complexities of wildfires,
incorporating variables such as varying lighting conditions, time
of day, and diverse terrains. The objective is to discern how transfer
learning performs against models trained from scratch in addressing
the intricacies of the wildfire detection problem. By assessing the
performance metrics, including accuracy, precision, recall, and F1
score, a comprehensive understanding of the advantages and disadvantages
of transfer learning in this specific domain is obtained. This study
contributes valuable insights to the ongoing discourse, guiding future
directions in AI and ML research.

SECTION: 
Transfer learning has emerged as a focal point in contemporary Artificial
Intelligence (AI) and Machine Learning (ML) research due to its transformative
impact on model performance across diverse domains.
The collective efforts of leading companies and research institutions
underscore the pivotal role transfer learning plays in enhancing efficiency
across various facets of human life. This surge in popularity can
be attributed to the adaptability and efficiency transfer learning
imparts to AI and ML applications. In the context of AI/ML, transfer
learning refers to leveraging pretrained models initially trained
on a source dataset and applying them to a target dataset with shared
domain characteristics. Notably, in computer vision,
models are often trained on various iterations of the ImageNet dataset, which comprises an extensive array of object
classes, including animals, everyday objects, and specific species
of flora and fauna. This dataset continually evolves, incorporating
new classes and images to enhance its comprehensiveness.

Researchers have dedicated significant efforts to developing models
capable of accurately classifying objects within the ImageNet dataset,
achieving remarkable accuracies often exceeding.
For professionals engaged in specific classification tasks, such as
identifying microorganisms or various car models, transfer learning
offers a notable advantage. Rather than undertaking the laborious
process of training a model from scratch, practitioners can access
pretrained neural network weights and adapt them to specific domain-related
tasks. Transfer learning presents broad applicability across diverse
fields of study, including computer vision, Large Language Models
(LLMs), language translation, and chatbots.

SECTION: 
: Transfer learning significantly impacts
computer vision by leveraging pretrained models on extensive datasets
such as ImageNet. This approach expedites the learning process, enhancing
efficiency in tasks such as object detection, image segmentation,
and facial recognition. The ability
to transfer knowledge from one visual domain to another enables models
to discern intricate patterns and features with remarkable accuracy.: In natural language processing
and LLMs, transfer learning has revolutionized the landscape. Models
like Bidirectional Encoder Representations from Transformers (BERT)
are pretrained on vast corpora, enabling them to grasp intricate language
nuances and contextual relationships. These pretrained language models
serve as a foundation for diverse Natural Language Processing (NLP)
tasks, including sentiment analysis, text summarization, and question
answering.: Transfer learning proves
instrumental in language translation tasks. By pre-training models
on multilingual datasets, these models gain an understanding of language
structures and semantics across different languages. Fine-tuning for
specific language pairs leads to more accurate and contextually relevant
translations, contributing to the development of more accessible and
effective communication tools.: The development
of intelligent chatbots benefits significantly from transfer learning.
Pretrained models, equipped with extensive linguistic knowledge, comprehend
user queries, understand context, and generate coherent responses.
This approach mitigates the need for exhaustive training on specific
dialog datasets, allowing developers to create chatbots adept at natural
language understanding and generation.

SECTION: 
Utilizing pretrained models offers substantial benefits in terms of
data efficiency, as these models are initially trained on extensive
and varied datasets, enabling them to grasp general features and patterns.
This proves advantageous when dealing with limited labeled data for
a particular task, as the pretrained model has already acquired useful
representations from a broader context. Transfer learning further
streamlines the process by taking a pretrained model and fine-tuning
it on a task-specific dataset, leading to faster convergence and requiring
less labeled data compared to training from scratch. The efficiency
gains extend to computation time and resources, as training large
neural networks from the beginning is computationally intensive, whereas
pretrained models save time by having completed a significant portion
of the learning process. Additionally, pretrained models serve as
effective feature extractors, particularly leveraging lower-level
features that are transferable across different tasks. The models’
ability to generalize well to diverse inputs, especially when the
pre-training dataset aligns with the target domain, contributes to
improved performance on new, unseen data. Furthermore, in scenarios
involving related but not identical domains, pretrained models support
domain adaptation through fine-tuning, enabling effective performance
on specific tasks within the target domain. The collaborative nature
of the research community enhances accessibility, with many open-source
pretrained models in computer vision available for practitioners,
fostering the development and utilization of state-of-the-art models
for diverse applications.

SECTION: 
This paper applies and studies the performance measure of transfer
learning in the context of wildfire detection. To assess the performance
measure of transfer learning utilization, three custom-built models,
namely, Visual Geometry Group (VGG) VGG-7, VGG-10, and Convolutional
Neural Network (CNN)-Support Vector Machine(SVM) CNN-SVM are compared
relative to three pretrained models – VGG-16, VGG-19, and Residual
Neural Network (ResNet) ResNet101. The proposed study shows that transfer
learning can successfully capture the complexities of wildfires, incorporating
challenging variables (e.g., time of day, varying lighting conditions,
and diverse terrains) as presented in Fig.. In
this paper, we show how transfer learning can address the intricacies
of the wildfire detection when compared to custom-built models trained
from scratch. Performance metrics, such as accuracy, precision, recall,
and F1 score, are used to provide a comprehensive understanding of
transfer learning advantages and disadvantages in the wildfire detection
domain.

SECTION: 
The rest of the paper is organized as follows: Sectiondescribes the problem formulation and dataset preprocessing. Sectionillustrates the research methodology and segmentation.
Sectionpresents custom built CNN-SVM, VGG-7,
and VGG-10, and pretrained VGG-16, VGG-19, and ResNet101. Sectionillustrates the comparative results, performance
analysis, and test cases. Finally, Sectionconcludes
the work.

SECTION: 
Wildfires pose as a significant natural calamity, capable of causing
widespread devastation if not promptly detected and addressed during
their early stages. Originating from seemingly innocuous
sources like a dry tree in the forest, these fires can rapidly escalate,
engulfing natural habitats and leading to casualties, both human and
animal. Recognizing the urgency of
early detection, research in wildfire detection has gained paramount
importance, driven by the advancements in AI and ML techniques. Drone
is important player in our daily life applications, in particular
vision-based activites.
Among the various methods, drone surveillance has emerged as a popular
and effective approach with advanced perceptionand perception-based control algorithmswith an overall objective of following regulated safety and regulation
protocols. Several well-established models
for image classification, including AlexNet, InceptionNet, LeNet,
and ResNet, have demonstrated efficacy in the realm of wildfire detection.
However, a critical consideration is that these models are pretrained
on datasets like ImageNet, which do not inherently include wildfire
instances. Consequently, leveraging these pretrained models for wildfire
detection necessitates fine-tuning them for the specific characteristics
of the wildfire domain and further training on a customized fire/no-fire
dataset. This process is crucial to ensure the models’ adaptability
and accuracy in identifying wildfire-related features.

The alternative approach involves training models from scratch, omitting
the advantages offered by transfer learning (see the schematic representation
in Fig..(a)). Transfer learning entails taking
models pretrained on a broad dataset and adapting them to a specific
task. In the context of wildfire detection, the focus is on comparing
the results obtained by building a model from scratch against a model
with pretrained weights. In this paper, we compare
VGG pretrained network and VGG custom network. This comparative analysis
aims to shed light on the performance disparities between the two
methodologies. The study delves into the intricacies of wildfire detection,
considering the nuances associated with building a model from scratch
and the benefits derived from leveraging pretrained weights. The evaluation
encompasses factors such as detection accuracy, computational efficiency,
and the overall effectiveness of the models in real-world scenarios.
By comprehensively comparing these two approaches, the research aims
to provide valuable insights that can inform decision-making in wildfire
detection systems.

Additionally, the paper explores the domain dependencies between the
target dataset, specific to wildfire instances, and the source dataset
used for pre-training the models. Understanding these
dependencies is vital for optimizing model performance, as the characteristics
of the source dataset may influence the model’s ability to discern
relevant features in the target domain. This paper contributes to
the ongoing discourse on wildfire detection by conducting a thorough
comparative analysis of building models from scratch and utilizing
pretrained weights. By looking at the advantages and
potential drawbacks of each approach, the study offers practical guidance
for researchers and practitioners involved in developing effective
wildfire detection systems. Furthermore, the investigation into domain
dependencies enhances the understanding of the factors influencing
model adaptation and generalization, contributing to the broader field
of AI/ML applications in disaster management.

SECTION: 
Compiling an adequate wildfire image dataset presents formidable challenges
owing to its scarcity and constrained accessibility.
The infrequent occurrence of wildfires, coupled with safety considerations
and the urgent response required during active incidents, hinders
the systematic capture of diverse and representative images. Notably,
government restrictions on the use of real wildfire images, particularly
those depicting environmental and human impacts, further contribute
to the scarcity of suitable datasets. Ethical considerations surrounding
the utilization of such images add another layer of complexity to
dataset acquisition. Thus, researchers and practitioners
engaged in wildfire detection confront significant difficulties in
assembling a sufficiently extensive and varied dataset. The limited
availability of images, safety constraints, and regulatory restrictions
collectively impede the comprehensive development and training of
machine learning models essential for effective wildfire detection
and management. Thus, in this paper a custom dataset has been created
consisting of a mixture of individual images downloaded from the internet
and the FLAME dataset available to download from IEEE data port. For
this custom dataset two classes namely fire and non-fire have been
defined. Fig.shows a few samples from both the
classes of the custom dataset.

The ImageNet dataset (Fig..(b)) stands as a monumental
resource in the realm of computer vision, comprising an extensive
and diverse collection of labeled images. Created by researchers at
Princeton University, ImageNet encompasses millions of high-resolution
images, covering a vast array of object categories. Each image in
the dataset is meticulously annotated, providing invaluable ground
truth labels for various objects, animals, and scenes. ImageNet has
been a catalyst for significant advancements in image classification
and object recognition, serving as a benchmark for evaluating the
performance of machine learning models.

ImageNet’s influence is notably attributed to its annual Large Scale
Visual Recognition Challenge (ILSVRC), a competition that has spurred
the development of state-of-the-art deep learning models. Pioneering
models like AlexNet, VGGNet, InceptionNet, and ResNet have been trained
and benchmarked on ImageNet, showcasing their efficacy in classifying
and recognizing objects within diverse visual contexts. The ImageNet
dataset aids in generalizing models for wildfire detection by leveraging
pretrained models on diverse objects. Although ImageNet
lacks wildfire images, the learned features from generic objects can
be harnessed. Using transfer learning, a pretrained model’s lower
layers capture universal features, serving as a foundation. Fine-tuning
on a custom wildfire dataset tailor the model to recognize fire-related
patterns. This approach capitalizes on the model’s prior knowledge
from ImageNet, enhancing its adaptability and generalization to identify
wildfires, even when specific wildfire images are scarce during initial
training.

SECTION: 
This study contrasts non-trained models developed from scratch, specifically
tailored for diverse landscapes such as jungles, mountains, and arid
regions. The three newly crafted models include
CNN-SVM, VGG-7, and VGG-10. In comparison, pretrained models sourced
from the ImageNet dataset, namely VGG-16, VGG-19,
and ResNet, are examined.

SECTION: 
The CNN-SVM model combines CNNs and SVMs for image classification.
CNNsextract
hierarchical features, and SVMs act as a classifier. Tableillustrates the model architecture. This specific configuration, revealed
in extensive testing of diverse setups, was chosen due to its optimal
results across test, train, and validation accuracies. The model’s
architecture was meticulously tailored to align with the characteristics
of the present dataset, ensuring a robust and effective model addressing
the complexities inherent in the data.

SECTION: 
VGG-7 and VGG-10 are custom made models built with a structure similar
to VGG-16 and VGG-19. These models are gained by dropping pooling
layers and convolution layers with a high number of filters. VGG-16
is a complex deep neural network that aims at recognizing massive
amounts of features pertaining todifferent classes in the
ImageNet dataset. It is not designed to be trained from ground zero
on a considerably small dataset with only two classes, in this case
- fire and non-fire. Thus, after repetitive trials, it proved to be
ineffective while training the VGG-16 architecture without pretrained
weights. Another drawback to training a complex architecture like
VGG-16 and VGG-19 from scratch is the high amount of time and memory
power required. Hence, models like VGG-7 and VGG-10 were customized
to fit the requirements of wildfire detection and for comparison purposes.
Their architecture schematics are presented in Table 2 And Table 4
for VGG-7 and VGG-10, respectively.

SECTION: 
VGG-16 and VGG-19, being pretrained models on the ImageNet dataset,
serve as a foundation for further training through transfer learning. The weights, obtained from the Keras application library,
are initially optimized for a distinct domain. In this study, all
layers, except the top layers (input and output), are set to be untrainable
to preserve the pre-existing knowledge. To streamline and expedite
the learning process, a modification is introduced by consolidating
two dense layers into a single dense layer, enhancing efficiency.
Given the optimized nature of the weights, this adjustment aims at
producing faster and more effective learning while adapting to the
nuances of wildfire detection. The output layer undergoes a transformation,
transitioning from 512 dense nodes to a singular node. This alteration
necessitates a change in the activation function fromto linear, aligning with the specific requirements of the binary classification
task involving fire and non-fire instances. By leveraging the pretrained
weights and optimizing the network architecture, this tailored approach
ensures the transferability of knowledge from ImageNet to the targeted
wildfire detection domain. The reason for these modifications lies
in achieving a balance between computational efficiency and the model’s
capacity to grasp the distinctive features relevant to the task, thereby
maximizing the benefits of transfer learning for enhanced wildfire
detection capabilities. The architecture is demonstrated
by table 5 and table 6 for VGG-16 and VGG-19, respectively.

SECTION: 
ResNet, or Residual Neural Network, is a deep learning architecture
renowned for addressing vanishing gradient issues in very deep networks.
ResNetemploys residual blocks, allowing direct paths
for information flow and facilitating the training of extremely deep
neural networks. ResNet101, an extension of ResNet, employs 101 layers
in its deep neural network architecture. It introduces residual blocks
with skip connections, addressing vanishing gradient issues and facilitating
training of extremely deep networks. The model’s depth enables capturing
intricate features, enhancing its performance in complex visual recognition
tasks. For this paper, this model has been modified similar to the
other pretrained VGG models, with its output layer modified to converge
from 512 nodes to a single node for this binary classification task.

SECTION: 
SECTION: 
The hardware used for building and testing these models are: GPU –
GTX 1660 TI MaxQ design, CPU – AMD Ryzen 9 4900HS, Software –
Python 3.11.4, TensorFlow 2.9.1, Keras 2.9.0, Libraries - NumPy, PILLOW,
MATPLOTLIB. Breakdown of dataset images in the training and validation
set are as follows: Dataset training are made of 3,629 total images
(2,080 fire images and 1,549 non-fire images) while dataset validation
are made of 385 total images (215 fire images and 170 non-fire images).

SECTION: 
The architectures of VGG-7, CNN-SVM, VGG-10, VGG-16, and VGG-19 is
detailed in Table. The pretrained ResNet101
parameters include total parameters of 43,707,777, trainable parameters
of 1,049,601, and non-trainable parameters of 42,658,176. As presented
in Table, the evaluation of custom models,
specifically VGG-7 and VGG-10, alongside pretrained models, VGG-16
and ResNet101, reveals compelling insights into their performance
in wildfire detection. The custom VGG-7 demonstrates an impressive
validation accuracy of, coupled with a low loss of.
Similarly, the VGG-10 model exhibits a validation accuracy of,
with a slightly higher loss of. Comparatively, the pretrained
VGG-16 stands out with an exceptional validation accuracy of,
accompanied by a notably lower loss of. On the other hand,
the pretrained ResNet101 exhibits a validation accuracy of,
with a comparatively higher loss ofas shown in Table. The high validation accuracies achieved
by both custom and pretrained models underscore their efficacy in
accurately classifying wildfire instances. The custom models VGG-7
and VGG-10, show robust performance, with accuracy exceeding,
indicating their suitability for the specified task. In contrast,
the pretrained VGG-16 outperforms them all, achieving near-perfect
accuracy, highlighting the advantages of leveraging pre-existing knowledge
from the ImageNet dataset. The pretrained ResNet101 shows a slightly
lower validation accuracy of, suggesting that while ResNet101
excels in various image recognition tasks, its performance may vary
in the context of wildfire detection. These loss values provide additional
insights into the models precision, with lower loss values indicating
more accurate predictions.

In Tablethe values of performance metrics
for all the chosen models for comparison is presented. These metrics
provide an insight on how effective a model is respective to the situation
being investigated. Various situations include, but not limited to,
ability to detect wildfires, ability to avoid false alarms, proper
classification of labels into respective classes of fire and non-fire,
etc. Notably, the pretrained models, especially VGG-16, exhibit superior
overall performance, excelling in recall, accuracy, and precision.
VGG-16 stands out for its remarkably low false positive rate ()
and false negative rate (), showcasing its effectiveness
in minimizing both false alarms and missed wildfire instances. VGG-19
closely follows, consistently performing well across all metrics,
including a low false positive rate ofand a false negative
rate of. In contrast, ResNet101, while delivering decent
results, lags behind the VGG models, notably in accuracy ()
and recall (). Fig.showcases the model
evaluation graphs for all the models. Fig..(a)
of VGG-7 show a steady training and validation curve. Whereas, the
other custom built models (Fig..(b) and.(c))
represent anomalies in their validation phase. The pretrained models
(Fig..(d),.(e), and.(f))
take longer to converge to the solution, but are more accurate than
the custom built models. These fluctuations in curves are a result
of their prior knowledge being fine tuned to address the current problem.

SECTION: 
Tablesummarizes the performance of wildfire
detection models across different architectures. Custom models VGG-7,
VGG-10, and CNN-SVM, along with pretrained models VGG-16, VGG-19,
and ResNet101, were evaluated against a dataset of 550 test cases,
comprising 325 fire instances and 225 non-fire instances. The metrics
include true positive, false positive, false negative, and true negative
values. Notably, pretrained VGG-16 excelled with 324 true positives,
2 false positives, 1 false negative, and 223 true negatives, showcasing
its robust performance in accurately detecting wildfires. Turning
our attention to the custom models, CNN-SVM emerges as a standout
performer with the highest recall (), underscoring its robust
wildfire detection capabilities. VGG-7 and VGG-10, while demonstrating
commendable performance, particularly in precision and accuracy, exhibit
slightly higher false positive rates (and, respectively)
and false negative rates (and, respectively) compared
to their pretrained counterparts.

SECTION: 
These findings underscore the notable advantages of employing pretrained
models, especially VGG-16 and VGG-19, which achieve optimal wildfire
detection outcomes with minimal false positives and false negatives.
The incorporation of false positive and false negative rates throughout
the analysis enhances the practical relevance of our findings. For
instance, VGG-16’s exceptional performance, characterized by a false
positive rate of, indicates its ability to significantly
reduce false alarms, crucial for minimizing unnecessary interventions.
Simultaneously, the low false negative rate () implies a
high sensitivity in detecting actual wildfires, essential for timely
responses. Such insights provide valuable guidance for decision-makers,
emphasizing the trade-offs between false positives and false negatives
based on specific needs. This analysis contributes meaningfully to
ongoing discussions on optimizing AI/ML applications in disaster management,
aligning theoretical considerations with the practical implications
of model selection in real-world wildfire scenarios.

SECTION: 
In conclusion, the evaluation of wildfire detection models provides
insights into their performance. Custom built models trained from
the beginning can be very task specific. Images of wide areas of forests
or Mediterranean landscapes, do not contain diverse objects in the
frame in an ideal scenario. Although, objects like fall coloured trees,
that portray an orange-red hue may confuse the model into predicting
a false positive. Another example of a real scenario could be man-made
objects like watch towers, fences, flag poles or flags being a part
of the captured image in a forest, that could confuse the model not
trained to detect these objects. Whereas, a pretrained model trained
for wildfire instances with prior knowledge of otherclasses
of objects could avoid these false alarms. This makes pretrained models
to be more generalized for real-life scenarios. One major advantage
that custom built models have over pretrained models is the computational
speed. Pretrained models have the capability to detect thousands of
classes due to their deep neural network. The deeper the neural network,
higher are the number of computations required before determining
the end result. Thus, pretrained models that contain deep neural networks
with higher number of layers than a custom-built model, are slower
at computational speed. This makes custom-built models more suitable
for real-time applications.

For further research, exploring hybrid models that amalgamate the
strengths of custom and pretrained architectures could enhance detection
capabilities. Investigating domain-specific fine-tuning for pretrained
models and evaluating their adaptability to dynamic wildfire scenarios
will be crucial. Additionally, delving into ensemble approaches to
leverage diverse models for improved accuracy and reliability could
be a promising avenue.

SECTION: References