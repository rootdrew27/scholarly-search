SECTION: Deep Learning Modeling Method for RF Devices Based on Uniform Noise Training Set

As the scale and complexity of integrated circuits continue to increase, traditional modeling methods are struggling to address the nonlinear challenges in radio frequency (RF) chips. Deep learning has been increasingly applied to RF device modeling. This paper proposes a deep learning-based modeling method for RF devices using a uniform noise training set, aimed at modeling and fitting the nonlinear characteristics of RF devices. We hypothesize that a uniform noise signal can encompass the full range of characteristics across both frequency and amplitude, and that a deep learning model can effectively capture and learn these features. Based on this hypothesis, the paper designs a complete integrated circuit modeling process based on measured data, including data collection, processing, and neural network training. The proposed method is experimentally validated using the RF amplifier PW210 as a case study. Experimental results show that the uniform noise training set allows the model to capture the nonlinear characteristics of RF devices, and the trained model can predict waveform patterns it has never encountered before. The proposed deep learning-based RF device modeling method, using a uniform noise training set, demonstrates strong generalization capability and excellent training performance, offering high practical application value.

SECTION: IIntroduction

As integrated circuits (ICs) continue to scale up in size and complexity, modeling radio frequency (RF) chips faces increasingly challenging demands. The primary issues in this domain can be broadly categorized into two aspects: first, the diversity of RF chip types, which makes traditional modeling methods time-consuming and resource-intensive; second, the significant nonlinearities exhibited by RF chips, which traditional techniques struggle to model effectively. To address these challenges, neural networks (NNs) have been introduced as an alternative approach to RF chip modeling. Neural networks are particularly suited to this task due to their broad applicability and ability to learn from relevant data, enabling them to fit a wide range of RF devices. In recent years, deep neural networks (DNNs) have emerged as an effective tool for modeling the nonlinear characteristics of RF devices, thanks to their powerful feature extraction capabilities. As a result, increasing numbers of researchers and engineers have turned to neural networks to overcome the limitations of conventional methods.

IC modeling is generally classified into two primary categories: transistor-level modeling and behavioral-level modeling. Some studies have focused on transistor-level models, where the physical parameters of transistors and operational frequencies are used as inputs to predict performance indicators, such as S-parameters or time-domain outputs, of RF chips using neural networks[1,2,3]. However, these models are typically specific to particular chip types and involve complex procedures requiring detailed physical characteristics. In contrast, behavioral-level modeling treats RF integrated circuits as “black boxes,” using neural networks to create input-output models[4,5,6,7,8,9,10,11,12,13]. While behavioral-level models are generally less accurate than transistor-level models, they offer the advantage of being simpler and faster to construct, making them well-suited for modeling various types of chips. Additionally, behavioral modeling does not require detailed circuit internals, and training and testing data are more readily available. Furthermore, these models tend to exhibit better interpretability. Behavioral-level modeling also reframes the RF modeling task as a sequence feature extraction and prediction problem, where the objective is to create a model that captures the input-output sequence characteristics effectively.

In the context of time-series data prediction, various neural network architectures have been applied to IC modeling, and numerous studies have explored improvements to these architectures. Early research often utilized simpler models, such as Random Forests and Multi-layer Perceptrons (MLPs) for RF chip modeling[4,8]. As research advanced, deeper neural networks were introduced, significantly improving model performance[1,6]. With deep learning becoming more mainstream, Recurrent Neural Networks (RNNs) emerged as the most widely used time-series prediction model for RF device modeling[2,9,10,14]. Additionally, more advanced architectures, such as Long Short-Term Memory (LSTM) networks[11], Transformers[7], AutoEncoders[12], and Residual Networks (ResNets)[6], have been shown to be highly effective in time-series prediction tasks. These studies demonstrate that a wide range of neural network structures can be successfully applied to input-output sequence prediction, yielding promising results in RF device modeling.

Despite these advances in neural network architecture, another critical factor influencing the efficiency and comprehensiveness of IC modeling is the dataset used for training. Dataset construction involves two main challenges: the data sources and the waveform features.

The sources of datasets typically include simulation data, public datasets, and measured data. Many researchers rely on simulation waveforms as training data[1,2,9,10,15]. However, since simulation conditions often do not fully reflect real-world environments, simulation data may not reliably predict model performance in actual applications. Thus, relying solely on simulated data might not effectively capture the real-world behavior of RF chips. Some researchers have turned to publicly available databases[5,6,7,11], though these datasets typically cover fewer types of integrated circuits and may not meet the diverse modeling and testing needs of all RF devices. In contrast, measured datasets are less commonly used[8], primarily because they require specialized hardware and significant experimental effort to construct. However, measured data offers a more accurate reflection of RF chip behavior in real-world environments, making models based on such data more reliable and practical.

In addition to the data source, the waveform features of the dataset are also crucial in determining modeling performance. Common waveform types include sine waves, square waves, audio waveforms, and modulated waveforms. Given the nonlinear nature of RF devices, the performance of these devices can vary significantly under different frequency bands and power conditions. Consequently, to train a neural network capable of learning the full range of an RF device’s behavior, the training set should ideally encompass the chip’s performance across various frequencies and input amplitudes. While sine waves cover the full amplitude range, they are limited to a single frequency point in the frequency domain, making them more suitable as a test set rather than a training set. Square waves, with multiple harmonic components, can cover a broader frequency range by adjusting parameters such as rise time and duty cycle, which is why they are often favored as training waveforms[1,2,14,9]. However, square waves tend to focus on peak regions in the time domain, which may hinder the model’s ability to capture fine-grained time-domain characteristics. To address this limitation, some researchers have turned to more complex waveforms, such as modulated or audio waveforms, for training[5,6,8], with experimental results showing that these waveforms can help models better extract the chip’s characteristics.The suitability of different waveform types for various applications is summarized in TableI.

Previous studies have used waveforms with inherent ”information” as training sets. Regardless of the waveform complexity, deep neural networks are capable of learning the underlying chip features. Based on this premise, we propose two hypotheses: first, waveforms that provide broader frequency and amplitude coverage contain more information; and second, neural networks can effectively extract features from even the most complex waveforms. Based on these assumptions, this paper introduces an innovative approach: using uniform noise as the training dataset. The time-domain histogram and frequency spectrum of uniform noise are shown in Figure1, where the signal is uniformly distributed across both amplitude and frequency domains, theoretically covering all information across various frequencies and amplitudes. If the neural network can extract meaningful features from uniform noise, it will be capable of comprehensively modeling the RF chip’s characteristics.

Building upon this hypothesis, the paper presents a complete IC modeling methodology, which includes system design, data collection, data processing, and model training. The proposed testing system is capable of modeling various RF chips, demonstrating strong versatility. Using an RF amplifier as an example, three deep neural network architectures—AutoEncoder, ResNet, and Mamba—are applied for training and validation. Experimental results show that these models can successfully learn the characteristics of RF chips from uniform noise, and the trained models are capable of predicting the performance of RF devices under different waveforms, validating the effectiveness and universality of the proposed method.

The goal of this work is to design a simple yet effective IC modeling solution that facilitates chip testing and modeling tasks. The paper is organized as follows: Chapter 2 discusses the modeling method, including data collection, dataset generation, data processing, and model training; Chapter 3 presents the experimental setup, where the proposed method is validated using data from the PW210 RF amplifier in both the time and frequency domains; Chapter 4 concludes with a summary of the results, highlighting the effectiveness and advantages of the proposed approach.

SECTION: IIModeling Method Design

This section provides a detailed description of the RF chip modeling method proposed in this paper, which consists of four key components: data acquisition system setup, dataset generation, dataset processing, and model training conditions.

SECTION: II-AData Acquisition System

The collection of time-domain waveform information for RF chip modeling is facilitated by a coordinated setup comprising a waveform generator, an oscilloscope, and a host computer. The hardware connections for the data acquisition system are illustrated in Figure2, with an abstract connection diagram shown in Figure3.

The data collection process follows these steps: Initially, the host computer configures the acquisition parameters, including waveform type, number of test points, sampling rate, and the number of acquisitions. Once the configuration is complete, the host computer calculates and generates the digital signals, sending both the waveform data and control commands to the arbitrary waveform generator via a network port. The waveform generator then converts the digital signal into an analog form and outputs it through two ports: one is connected to the input of the chip under test, while the other is connected to one channel of the oscilloscope. The chip’s output is connected to the second channel of the oscilloscope. Once both oscilloscope channels have stabilized and received the waveform data, the host computer triggers a single acquisition on the oscilloscope. The collected data is saved in CSV format to an external storage device, such as a USB flash drive. By repeating this procedure, the required number of training and testing datasets can be generated.

SECTION: II-BDataset Generation

In order to meet the requirements for various training and test datasets, the host computer must generate different types of signals. The generation methods for each signal type are described below:

Uniform noise signals are generated by randomly sampling within a specified amplitude range. The mathematical expression for this is:

whereis the noise sample generated within the range,is the amplitude of the noise, andis the number of samples.

Narrowband noise signals are created by constructing a complex frequency spectrum within a target frequency band. The spectrum is populated with random values, and frequencies outside the target band are set to zero. The time-domain signal is obtained by performing the inverse Fourier transform of this frequency spectrum, expressed as:

Here,represents the frequency-domain signal,andare the real and imaginary components of the uniform random values, with, andandare the start and end frequencies of the narrowband noise. The time-domain signalis obtained by applying the inverse Fourier transform to.

The time-domain signalis normalized to ensure that its amplitude falls within the range, and then scaled according to the target amplitudeusing the following equation:

Sine waves are generated based on a specific frequency, amplitude, and offset. The mathematical expression for a sine wave is:

whereis the amplitude of the sine wave at time,is the amplitude,is the reference frequency,is the frequency offset, andis the time, withand, whereis the sampling rate.

To generate different variations of sine waves, adjustments are made tofor amplitude changes, tofor frequency shifts, and tofor dual-tone signals, by adding two sine waves with different frequencies.

SECTION: II-CDataset Processing

The dataset processing step involves two main operations: delay compensation and dataset normalization, which are essential for improving model accuracy and ensuring proper training.

Due to transmission line delays, chip delays, and other factors, the output data collected may be delayed relative to the input data. To correct this, cross-correlation is used to adjust for the delay effects. The cross-correlation functionis calculated as:

This function computes the similarity between the input signaland the output signalfor various delay values. By analyzing the cross-correlation for different values of, the delay point corresponding to the maximum correlation can be identified. In the case of a reverse amplifier, the delay point corresponds to the minimum negative value of the cross-correlation. Once the delay is identified, the data is corrected, ensuring proper alignment between the input and output signals, as shown in Figure4.

RF integrated circuits are highly nonlinear, and the input-output data ranges can vary significantly between different chips. To address this, normalization is applied to standardize the data. Linear normalization is used to scale the data within the range [0, 1], according to the formula:

This normalization ensures that the data is standardized, improving the performance of the neural network models during training.

Each waveform file contains approximately 50,000 data points. To prepare these for model training, the data is sliced, and 2048 points are randomly selected as prediction points. The corresponding input data consists of 1024 points taken from the previous time steps. Thus, each test set has the dimensions [2048, 1024, 1], where 1024 points form the input data, which is used to predict the next point in the sequence. By selecting a window size of 1024 points, the model can capture signal features over a longer time range, improving robustness and enabling the extraction of higher-dimensional amplitude and frequency domain characteristics.

SECTION: II-DModel and Training Conditions

In this study, we selected three typical deep learning network architectures—AutoEncoder, ResNet, and Mamba—to verify the effectiveness and robustness of the proposed method. These three network architectures have been widely discussed and analyzed in existing literature[11,16,17], and their design and characteristics have been elaborated in detail. Therefore, this paper will not go into redundant descriptions of these networks. The focus of this experiment is to investigate whether these networks can capture and learn the characteristics of the signal contained in uniform noise.

To ensure fairness and comparability of the experiments, we standardized the input window size for the waveform prediction task to 1024 for all three networks. This choice ensures consistency in data input and is also aligned with the typical processing scale used in waveform prediction tasks. Treating these network models as feature extractors, we modified the last layer of each model, adding a fully connected layer to output a single predicted value in order to predict a specific point in the target waveform.

For the loss function, we selected Mean Squared Error (MSE) as the optimization objective, which is a standard loss function widely used in waveform prediction. MSE effectively measures the difference between the predicted and actual values, helping the model gradually optimize prediction accuracy.

whereis the true value,is the predicted value, andis the number of samples.

The activation function used in the models is the Sigmoid Weighted Linear Unit (SiLU), which is effective for the nonlinear nature of waveforms, as illustrated in Figure5.

The Adam optimizer was used for training. The Adam optimizer combines momentum and adaptive learning rate methods by computing the first and second moment estimates of the gradients, allowing the model to converge more quickly and stably during training.

whereandare the decay rates for momentum and RMSProp,is the learning rate, andis a small constant to prevent division by zero errors.

To further improve training efficiency and the model’s generalization ability, we incorporated Batch Normalization (BN) layers into the network architecture. BN standardizes the input to each layer, effectively alleviating the issues of vanishing and exploding gradients during training, accelerating convergence, and thus enhancing overall training performance. The BN formulas are as follows:

whereis the input,andare the mean and variance of the current batch,andare the learned scaling factor and bias term, andis a small constant to prevent division by zero.

In summary, this paper designs and experimentally validates the effectiveness and universality of the three network architectures in the uniform noise learning task.

SECTION: IIIExperiment and Training Results

In this experiment, the Device Under Test (DUT) was the PW210 amplifier produced by PreWell. This amplifier was selected due to its distinct nonlinear characteristics, which enable effective testing of the uniform noise training capability and model generalization performance. The signal source used was the Tektronix AWG7082C arbitrary waveform generator, while the Tektronix MSO64 oscilloscope served as the signal monitoring device. Both instruments are programmable, allowing for convenient control through a host computer.

This section first outlines the dataset design scheme based on this amplifier, followed by validation of the method’s effectiveness and model prediction accuracy from both time-domain and frequency-domain perspectives.

SECTION: III-ADataset Design

The test system constructed in the previous section is universal, requiring only adjustments based on the characteristics of the current chip to design the dataset, after which training and testing can proceed. According to the amplifier’s datasheet, the maximum input power for the PW210 amplifier is 10 dBm, with a linear operating range from -20 dBm to 5 dBm, and a nonlinear operating range from -5 dBm to 5 dBm. The amplifier’s input impedance is 50 ohms. To convert between amplitude and dBm values, we use the following equation:

whereohms andis the amplitude. The factorin the formula accounts for both the positive and negative half-cycles, while the division byconverts power from watts to milliwatts.

Using equation15, we can calculate the following amplitude and dBm relationships:

10 dBm corresponds to a 2 Vpp sine wave,

-5 dBm corresponds to a 0.25 Vpp sine wave,

5 dBm corresponds to a 1.12 Vpp sine wave.

To cover both the linear and nonlinear regions, the amplitude of the uniform noise is set to 1.2 Vpp, while the amplitude of the band-limited noise in the time-domain test is set to 1 Vpp.

In the frequency domain, the amplifier’s three primary parameters are:

Gain-frequency characteristics,

Gain-power characteristics, and

Output Third-Order Intercept Point (OIP3).

These frequency-domain characteristics are shown in Figure6.

For typical amplifier operation, we refer to the above charts in the datasheet to obtain performance data for the relevant frequency bands. When testing with multiple sine waves of different frequencies and spanning the full frequency range, we can calculate the gain and OIP3 values for each waveform at various frequency points. Connecting these points in the frequency domain should, in theory, recreate the graph presented in the datasheet.

Based on the amplifier’s linear operating range, frequency-domain parameters, and other relevant information, the dataset design is summarized in TableII. The reason for using narrow-band noise in the time-domain test set is that narrow-band noise exhibits more complex behavior in the time domain, making it more challenging to predict. This characteristic better demonstrates the model’s predictive capabilities. The waveforms used in the frequency-domain test set are designed to assess the model’s performance across the entire frequency range, thereby replicating the frequency-domain parameter charts from the datasheet.

SECTION: III-BTime Domain Training Results

In this section, three different neural network architectures were trained using time-domain data. The first 200 samples of uniform noise were used as the training set, while the subsequent 50 samples served as the validation set. The batch size was set to 256, and the model was trained for a total of 100 epochs. After training, the model’s performance was evaluated on the narrow-band noise test set. The resulting training and testing errors are summarized in TableIII. From the results, it can be observed that all three models fit the training data well and successfully generalized to other types of test sets. Among the tested models, ResNet performed the best in terms of both training and testing error.

To further evaluate the performance of the trained ResNet model, it was used for time-domain testing. The task was to predict the uniform noise from the validation set and the band-limited noise from the test set within the frequency range of 900 MHz to 1 GHz. A total of 5000 consecutive points were predicted, with the first 500 points plotted as the time-domain waveform. Subsequently, an FFT was performed on all 5000 points to obtain the frequency-domain spectrum, with the results shown in Figure7.

From the time-domain plot in Figure7, it is clear that the model’s predictions are quite accurate in phase, but there is some amplitude error. This is consistent with the frequency spectrum of the uniform noise, which shows a certain degree of attenuation in the high-frequency components. This could be attributed to transmission line losses and the oscilloscope’s high-frequency cutoff. In the frequency-domain plot of the band-limited noise (Figure7), it is evident that the model accurately predicts the frequency characteristics, capturing even the nonlinear harmonics. This suggests that the model has successfully learned the nonlinear characteristics of the RF device to some extent.

SECTION: III-CFrequency Domain Testing Results

The frequency-domain parameters of the amplifier mainly include gain and OIP3.

The calculation method for gain is as follows:
First, the trained ResNet model is used to predict 5000 continuous points from 100 sine waves. Afterward, a Fourier Transform (FFT) is applied to the input signal:

The frequency with the largest amplitude in the spectrum is identified:

The corresponding amplitude is:

The amplitude is converted to power (in dBm) using equation15, denoted as.
The power of the output signal (whether measured or predicted by the model) is computed in the same manner, denoted asand, respectively. The gain is calculated as:

and the predicted gain by the model is:

For the gain-frequency curve, the frequency and gain at the frequency point with the maximum spectral amplitude are recorded, resulting in 100 gain-frequency points. The gain-frequency curve predicted by the ResNet model is shown in Figure8. It can be seen that the prediction fits well with the measured data up to 2.5 GHz, but there is about a 0.5 dB deviation above 2 GHz.

For the gain-input power curve, 100 gain-input power points were calculated and plotted. The gain-input power curve predicted by the ResNet model is shown in Figures9and9. At 0.9 GHz, the prediction is quite accurate, but at 1.9 GHz, there is about a 1 dB error at low amplitudes. The error is mainly due to the high-frequency components in Figure7, which are affected by hardware limitations. The model has less training data for higher frequencies, and the amplitude it has learned contains some inaccuracies, leading to this error.

OIP3 refers to the output power at which the linear portion of the output signal equals the power of the third-order intermodulation product. The calculation principle of OIP3 is shown in the diagram:

OIP3 cannot be measured directly and must be calculated through derivation. The derivation process is as follows:

1. The first-order output power (linear portion):

whereis the first-order coefficient andis the input power.

2. The output power of the third-order intermodulation component:

whereis the third-order coefficient andis the input power.

3. By subtracting equations21and22, we get:

4. When the first-order output power equals the third-order intermodulation product’s output power, i.e., at the third-order intermodulation cutoff point, we have:

5. Solving these equations gives us the final OIP3 calculation formula:

Since the frequency difference between the first and third-order components is small (about 2 MHz), additional FFT points are required to distinguish these two frequencies. The formula for calculating the frequency resolution is shown in equation26:

whereis the sample rate andis the number of FFT points.
With an oscilloscope sample rate of 25and FFT points set to 25,000, the frequency resolution is 1, which effectively distinguishes the two signals.

The OIP3 prediction by the ResNet model is plotted in Figure11. The overall error in the OIP3 prediction is around 2 dBm, primarily due to issues with predicting the third-order intermodulation. The magnitude of the third-order intermodulation is very small, leading to larger errors in dBm. This explains the observed discrepancy in the OIP3 prediction.

SECTION: III-DSummary of Testing Results

The test results clearly demonstrate that the models trained using the uniform noise training set are highly effective in learning the characteristics of RF devices, with some error margins, in both the time and frequency domains. Notably, the model is also capable of predicting band-limited noise, sine waves, and dual-tone signals, which were not part of the training data. This strongly supports the earlier hypothesis that uniform noise, covering the full amplitude and frequency range of RF device performance, allows neural networks to successfully learn and capture the characteristics of RF devices.

Furthermore, the experiments validate the approach of using multiple time-domain sine waves across the entire frequency range to test frequency-domain performance. This method has proven to be effective within a specific error margin and can be used for comprehensive and detailed model performance testing.

However, there are some limitations with the proposed method. The data collection process is subject to hardware constraints, which introduce certain errors. Despite this, we believe these hardware-related issues can be addressed, and the proposed approach remains practical and feasible.

SECTION: IVConclusion

This paper presents an innovative deep learning-based approach for modeling RF devices using a uniform noise training set. The effectiveness of this method has been experimentally validated. The model, trained on the noise training set, is capable of accurately predicting various types of signals, showing strong performance in both time and frequency domains.

The key achievements of this paper are:

A uniform noise training set and corresponding test set are established. The uniform noise training set offers several significant advantages: various neural network architectures can effectively extract features from it; it applies to a wide range of different chipsets; it captures the complete characteristics of RF devices, enabling models trained on uniform noise to predict other previously unseen waveforms; and it is relatively easy to generate and collect.

A comprehensive deep learning-based RF device modeling methodology is designed, covering four essential aspects: data acquisition system setup, dataset generation, data processing, and model training conditions. The dataset design and experimental validation, using the PW210 as an example, were successfully completed. The methodology is generalizable and can be applied to model various RF devices when combined with the uniform noise training set.

The design proposed in this paper successfully addresses two major problems in RF integrated circuit modeling, as discussed at the beginning:

The complexity of different chip types: The solution is adaptable to various chipsets and neural network models.

The challenge of nonlinear fitting: The uniform noise training set captures the full performance characteristics of RF chips, allowing deep learning techniques to model nonlinear behavior effectively.

The experiments have thoroughly demonstrated that the proposed method is effective, stable, and reliable, offering substantial practical value.

SECTION: References