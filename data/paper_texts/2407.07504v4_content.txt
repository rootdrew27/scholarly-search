SECTION: Pan-cancer Histopathology WSI Pre-training with Position-aware Masked Autoencoder
Large-scale pre-training models have promoted the development of histopathology image analysis. However, existing self-supervised methods for histopathology images primarily focus on learning patch features, while there is a notable gap in the availability of pre-training models specifically designed for WSI-level feature learning. In this paper, we propose a novel self-supervised learning framework for pan-cancer WSI-level representation pre-training with the designed position-aware masked autoencoder (PAMA). Meanwhile, we propose the position-aware cross-attention (PACA) module with a kernel reorientation (KRO) strategy and an anchor dropout (AD) mechanism. The KRO strategy can capture the complete semantic structure and eliminate ambiguity in WSIs, and the AD contributes to enhancing the robustness and generalization of the model. We evaluated our method on 7 large-scale datasets from multiple organs for pan-cancer classification tasks. The results have demonstrated the effectiveness and generalization of PAMA in discriminative WSI representation learning and pan-cancer WSI pre-training. The proposed method was also compared with 8 WSI analysis methods. The experimental results have indicated that our proposed PAMA is superior to the state-of-the-art methods. The code and checkpoints are available at https://github.com/WkEEn/PAMA.

SECTION: Introduction
Digital pathology images have witnessed a significant explosion of whole slide images (WSIs) analysis with deep learning. Artificial intelligence framework promotes computer-aided diagnosis for cancer sub-typing, histopathology image retrieval, gene mutation prediction, survival prediction, etc.

Over the past few years, Transformer structures have made impressive gains in the field of natural language processing.
Subsequently, many recent studies have further facilitated the WSI analysis by taking advantage of the Transformer to capture and aggregate long-range information.
High-capacity Transformer models have also promoted the development of self-supervised learning. Self-supervised learning pre-trains a large model on proxy tasks to mine enormous amounts of unlabeled data for potential features and then fine-tunes the model on limited data for specific downstream tasks. The emergence of large-scale models has benefited from the Transformer structure and feature mining of massive data through self-supervised learning,, BERT, CLIP, SAM, and GPT series. There are an increasing number of studies fine-tuning the pre-trained models on histopathology images, which achieved promising performance in various tasks.

The efficient utilization of unlabeled data firmly fits the trend of pathology image analysis, since there has been an explosion in the volume of pathology image data with the establishment of large open data projects (, the cancer genome atlas program) and the development of online consultation platforms. In this situation, histopathology image foundation models are established based on self-supervised learning frameworks. Typically, Huanget alapplied CLIPfor
multimodal pathology language-image pre-training (PLIP) based on the public data from medical forums. Similarly, Luet alpre-trained a large-scale visual-language foundation model using over 1.17 million image-caption pairs for histopathology analysis. Ikezogwoet alcreated a multimodal histopathology dataset QUILT-1M within 1M paired image-text samples for CLIP pre-training.
Nevertheless, the models applied in the above studies were originally designed for natural images and language pre-training.
Meanwhile, most of the current self-supervised methods for histopathology images focus on learning features of image patches. The substantial resolution of gigapixel WSIs makes it challenging to build an end-to-end framework for WSI-level representation learning. Currently, there is still a lack of available models that can take full advantage of the abundance of histopathology WSIs.

In this paper, we propose a novel self-supervised learning framework named position-aware masked autoencoder (PAMA) for WSI-level representation learning and pan-cancer pre-training. For the very first time, we propose the slide-level mask image modeling (MIM) proxy task that involves spatial structure to reconstruct WSI representation in feature space. Meanwhile, we embed relative distance and orientation information into slide representation and propose a novel cross-attention module with an orientation dynamic updating strategy and an anchor dropout mechanism.
We collected 7 large-scale datasets of multiple organs to evaluate the effectiveness and generalization of our proposed framework with slide-level representation learning and multi-organ pre-training and compared it with 8 SOTA WSI analysis methods. The experimental results have demonstrated that PAMA is effective in histopathology WSI pre-training and downstream tasks, including cancer sub-typing and biomarkers prediction.

We summarize the contribution of the paper in three aspects.

We propose a novel self-supervised learning framework based on the position-aware masked autoencoder named PAMA for WSI pre-training. We train PAMA on the slide-level MIM proxy task to reconstruct WSI representation in the feature space which can sufficiently mine the semantic features of histopathology slides from a large amount of unlabeled data.

We propose the anchor-based position-aware cross-attention (PACA) module to enable bidirectional communication between the local and global information of WSIs. An anchor dropout mechanism is introduced for augmentation to facilitate the robustness and generalization of PAMA. Meanwhile, the relative distance and orientation information are embedded into slide features to maintain comprehensive spatial semantics. Additionally, we introduce a kernel reorientation (KRO) strategy to dynamically update the main orientation of anchors for better obtaining complete semantic structure and eliminating ambiguity.

We evaluated the proposed method on 7 large-scale datasets containing 13,685 WSIs from multiple organs for multiple diagnostic tasks. The results demonstrate that pan-cancer pre-training facilitates PAMA’s significant progress in fine-grained WSI-level tasks, including biomarkers prediction and cancer sub-typing. Furthermore, PAMA achieves the best performance over the other 8 SOTA methods.

A previous version of the paper has been published in the conference paper.

SECTION: Related works
SECTION: MIL based methods
The WSI is gigapixel large-scale image data which makes it challenging to apply the end-to-end deep learning framework to analyze WSIs as in the case of natural scene images. Two-stage methods are generally employed in slide analysis, involving the extraction of patch features and aggregation of WSI-level representation.

Multiple instance learning (MIL) has become the typical solution for slide representation aggregation. For instance, Liet alproposed a dual-stream framework to integrate the instances and applied a pyramidal fusion mechanism for multiscale WSI features.
Some studies have introduced new techniques into the aggregation stage to describe the spatial structure of WSI.
Graph Attention MILand LAGE-Netconstructed the graph structure of patches to encode local relationships. However, the methods were difficult to capture long-range spatial information.
Thereby, Transformer methods based on the self-attention mechanism are introduced into MIL to aggregate the global features of WSIs.
The Transformer structure is adapted to gather long-range features and comprehend overall structural connections, making it suitable for large-scale WSI analysis. TransMILand SETMILleveraged some CNN blocks and spatial encoding modules to aggregate local information and used the self-attention model for global messaging.
These methods disregarded the isotropic characteristics of pathology images, potentially resulting in ambiguous position encoding. To address this problem, KATconstructed hierarchical masks based on local kernels to preserve multi-scale relative distance information in training. However, these masks were manually specified, which means they are not trainable and lack dynamic orientation information.

SECTION: Self-supervised learning
Self-supervised learning methods have gained considerable interest in computer vision, frequently concentrating on diverse proxy tasks for pre-training without any manual annotations. The label-free approaches facilitate patch representation learning to release resource consumption from fine-grained annotation. Some works focused on context-based methods, such as predicting pathology image cross-stain, predicting the resolution sequence ordering in WSI, and constructing associations between proximity and feature similarity. Other methods leveraged generative models to build proxy tasks that implicitly learn features by minimizing the reconstruction loss in the pixel space, like SD-MAEand MAE-MIL. More approaches applied contrastive learning to enhance patch feature learning. CTransPathproposed a semantically relevant contrastive learning framework that compares relevance between instances to mine more positive pairs. TransPathused BYOLarchitecture due to its negative sample independence and proposed a token-aggregating and excitation (TAE) module for capturing more global information.
Chenet alused DINOv2, a state-of-the-art self-supervised learning method based on student–teacher knowledge distillation for pre-training large ViT architectures, for large-scale visual pre-training on 100,426 histology slides. Vorontsovet alpresented a million-image-scale pathology foundation model, Virchow, pre-trained on data from approximately 100,000 patients corresponding to approximately 1.5 million WSIs. There are also many studies introduce multimodal data into self-supervised pre-training for histopathology image representation learning.
However, these patch-level representation learning methods treated patches as independent entities, thereby destroying the integrity of the semantic information in the WSI. Furthermore, under conditions of limited annotation information, such an approach would yield over-fit the slide-level aggregation model.

HIPTinvestigated the novel concept of slide-level self-supervised learning, representing a significant challenge. Chenet alconstructed a two-stage self-supervised framework in which DINOis utilized to pre-train patches (256×256) and then another DINO is pre-trained for the regions (4096×4096) of WSIs. HIPT leveraged the hierarchical structure inherent in WSIs to construct a multi-level self-supervised learning framework. By doing this, the framework learned high-resolution image representations, enabling it to benefit from the plentiful unlabeled WSIs. This contributes to an increase in the accuracy and robustness of tumor recognition.
Recently, Xuet alproposed Prov-GigaPath, a slide-level representation leaning framework pre-trained on 171,189 slides originated from more than 30,000 patients covering 31 major tissue types.
Nevertheless, the ViT backbone employed for HIPT ignores the structural characteristics of large-scale pathology images. Additionally, the multi-stage pre-training may result in the accumulation of bias and error, reducing the performance of the final model.
Prov-GigaPath applies LongNetas a slide aggregator, leveraging its design for extremely long sequences. However, Prov-GigaPath does not account for the unique characteristics of WSIs, particularly their spatial structure.

SECTION: Pan-cancer analysis
There is inter-patient heterogeneity across different types of cancer which means tumors of different cancer types may share underlying similarities. Therefore, pan-cancer analysis of large-scale data across a broad range of cancers can potentially improve disease modeling by exploiting these pan-cancer similarities. A growing number of works are focusing on building pan-cancer analytical models and related databases through computational pathology. Komuraet albuilt a universal encoder for cancer histology through a deep neural network. It allows for genomic feature prediction from histology images across various cancer types. Yuet alemployed deep transfer learning to quantify histopathological patterns in 17,355 WSIs from 28 cancer types. Subsequently, they correlated these patterns with matched genomic, transcriptomic, and survival data. PanNukeis an open pan-cancer histology dataset for nuclei instance segmentation and classification across 19 different tissue types. However, there is still a lack of a pan-cancer analysis model that can utilize a large number of unlabeled WSIs for slide-level feature learning.

SECTION: Methods
SECTION: Overview
We propose the position-aware masked autoencoder (PAMA) following the self-supervised learning protocol shown in Fig..
After data pre-processing, we construct spatial and structural information of WSIs for their slide-level representation. Our proposed PAMA encodes the slide representation into a latent space and then decodes the latent feature back to the origin feature space for reconstructing the slide-level representation. The proxy task of reconstructing position-aware slide-level representation trains the PAMA to capture complicated semantics and improve generalization.

SECTION: Positon-aware Masked autoencoder (PAMA)
MAEis a promising paradigm for image representation learning. We introduce masked autoencoder into histopathology slide-level representation learning. Unlike natural scene images, histopathology digital images are scale-varying and semantically complex which is challenging to capture the complete semantic structure and eliminate ambiguity.
To combat the limitation, we propose a position-aware structure to construct slide representation. Firstly, patch features of a slide are extracted, which is formulated as, whereis the number of patches in the slide andis the dimension of the patch feature.
Inspired by the way to describe spatial information in KAT, multiple anchors are selected by clustering the location coordinates of all patches for profiling local structural semantics. The learnable vectors are assigned for these anchors formulated as, whereis the number of anchors in the slide withrepresenting the expected number of patches per cluster. Additionally, a polar coordinate system is constructed where each anchor is regarded as a pole. In this system, every patch has explicit relative distance and angle definitions to each anchor. Therefore, we defineandto represent the relative distance matrix and the relative polar angle matrix of a WSI, respectively. We equate the polar and distance values into bins to ensure adaptation to scale-varying slides, so the inputs are discrete integers, similar to the positional index of each token in Transformer.
Specifically,andcorrespondingly denote the relative distance and relative polar angle of the-th patch to the-th anchor. Based on the above, a WSI is formulated as.
We leverage the anchor-based and position-aware data structure to represent a WSI, which can adaptively maintain the spatial integrity and semantic enrichment of scale-varying slides across multiple organs.

Our proposed position-aware masked autoencoder is shown in Fig.(I). Some patch tokens of the original WSI feature are randomly masked with a high ratio (, ratio) and these tokens including their corresponding spatial information are removed.
The remaining (, unmasked) tokens are fed into our encoder.
Each encoder block is shown in Fig.(I)(c), which is formulated as follows

wheredenotes multilayer perception,is our proposed position-aware cross-attention module which will be detailed later, andis the index of the block. Our encoder maps the sparse WSI features into a latent representation and meanwhile maintains the spatial information.

We adopt an asymmetric design in the decoder. The input to the decoder is a complete set of tokens, consisting ofand the masked tokensas shown in Fig.(I)(d). Theare initialized with trainable vectors and the corresponding spatial embeddings are added.
For reconstructing the WSI representation, we decodeinto the original feature space and calculate the loss only on the masked tokens between the reconstructed and original features as shown in Fig.(I)(f).
The proxy task to predict masked tokens based on the sparse WSI feature can assist our PAMA in acquiring adaptive WSI-level representation while guaranteeing the integrity of spatial information and pathology semantics.

Referring to the MAEstructure, we append atoken before all patch tokens to represent the learned slide feature and feed thetoken into the task-specific head for inference. In the pre-training phase, thetoken does not participate in loss computation, but it consistently communicates with anchors and gathers global information. Subsequently, the pre-trained parameters of thetoken will be used for fine-tuning and linear probing. Finally, we calculate the mean squared error (MSE) on the masked tokens between the reconstructed and original features.

SECTION: Position-aware cross-attention (PACA)
We propose the position-aware cross-attention (PACA) module to build bidirectional message passing between anchors and patches. Fig.(II) illustrates the structure of PACA. From the perspective of anchors, different local regions should respond dynamically to all patches as below:

whereare trainable parameters anddenotes the dimension of the head output,andare the transformation functions that respectively map the distance and polar angle to corresponding learnable embedding values,is the softmax function andis the index of layer. We apply two transformation functions to embed polar and distance into vectors, respectively, to ensure that the positional information is continuous and trainable. We add position embeddings as bias in softmax function to effectively facilitate the module to capture global information, drawing inspiration from the Graphormer.

Symmetrically, each patch token updates its representation by catching the local region information from all anchors as below:

The transmission of local information and perception of global information occurs promptly due to the two-way communication between patches and anchors. The model maintains the semantic and structural integrity of the WSI and prevents representation collapse in the local area throughout the training process with the embedding of relative distance and polar angle information. Regarding efficiency, the computational complexity of self-attention is, whererepresents the number of patch tokens. Conversely, our proposed PACA has a complexity of, whererepresents the number of anchors. It is important to note that when, the complexity is nearly, which exhibits a linear correlation with the WSI’s size.

SECTION: Kernel Reorientation (KRO)
In natural scene images, there is a directional conspicuousness of semantics. For example, in a church, it is more common for the door to be positioned below the windows rather than above. However, histopathology images do not have an absolute definition of the main direction. The meaning of a WSI remains invariant under rotation and flipping. Namely, it is isotropic. Embedding orientation information with a fixed polar axis will result in ambiguities in multiple slides. Therefore, we propose the kernel reorientation (KRO) strategy to dynamically update every anchor’s main polar axis.

As shown in Fig, we illustrate the KRO strategy in detail. Regarding the polar angle matrixduring the-th block, the initial polar axis is defined as the horizontal direction for all the anchors. For each anchor, the orientation is divided intoequal bins. For example, if, each bin corresponds to asector. During the processing of PACA, an attention score matrix of all anchors to patches formulated asis obtained which reflects the contribution from patches to anchors. Based on the matrix, we calculate the attention histogram on the orientation for each anchor by summarizing the attention score of all patches within each orientation bin. Then, the bin with the max score is selected as the new polar main axis,, the reorientated polar axis. Based on the new axis of anchors, we update the polar angle of patches and obtain the updated matrix. The detailed algorithm is outlined in Algorithm.

SECTION: Anchor Dropout (AD)
We defined anchors following the over-saturated strategy, which is similar to neurons in the neural network. The anchors are clustered based on spatial coordinates, which are proxies of local region information. Fixing the anchor position of the WSI across training epochs will result in losing the flexibility of local relationships and redundancy. Inspired by the neurons dropout mechanism, we introduce anchor dropout to enhance the robustness and generalization of the model and relieve the over-fitting in the WSI pre-training. The dropout is applied before Eq.with the following equations

whereis the probability of dropout,is a vector of independent Bernoulli random variables each of which has a probabilityof being 1, andmeans returning a subset ofbased on the corresponding index in.

SECTION: Experiments
SECTION: Datasets
We collected four public large-scale datasets from the cancer genome atlas (TCGA) program and three in-house datasets to evaluate our method, which are introduced as follows:

contains 659 WSIs of renal cell carcinoma (RCC) patients, which are categorized into 3 subtypes including kidney renal clear cell carcinoma (KIRC), kidney renal papillary cell carcinoma (KIRP), and kidney renal chromophobe cell carcinoma (KICH).

contains 3,064 WSIs of non-small cell lung cancer (NSCLC) patients from the TCGA program, which are categorized into 3 subtypes including tumor-free (Normal), lung adenocarcinoma (LUAD), and lung squamous cancer (LUSC).

contains 531 in-house WSIs of lung adenocarcinoma for epidermal growth factor receptor (EGFR) gene mutation identification, which are categorized into 4 subtypes including EGFR 19del mutation, EGFR L858R mutation, Non-common driver mutations (Wild type), and other driver gene mutations.

contains 3,654 in-house WSIs of endometrial pathology including 8 categories, namely well/moderately/low-differentiated endometrioid adenocarcinoma (WDEA/MDEA/LDEA), squamous differentiation endometrioid carcinoma (SDEC), plasmacytoid endometrioid carcinoma (PECA), clear cell endometrioid carcinoma (CCEC), mixed-cell endometrioid adenocarcinoma (MCEA), and tumor-free (Normal).

contains 705 WSIs of lung adenocarcinoma with EGFR gene mutation, which are categorized into 2 subtypes including EGFR mutation and Wild type.

contains 279 in-house WSIs of human epidermal growth factor receptor-2 (HER2) protein and gene expression in breast cancer patients, which are categorized into 4 subtypes including the IHC score of 1+, the IHC score of 2+, the IHC score of 3+, and the IHC score of 0 (Normal).

contains 4,793 unlabeled WSIs containing 10 cancer types from 7 primary sites as shown in Table, which is collected from TCGA program designedly for evaluation of generalization for out-of-domain pre-training.

These datasets, except for TCGA pan-cancer dataset, consist of 8,892 WSIs from multiple organs and can be used for studies such as cancer sub-typing, molecular status prediction, and gene mutation prediction, which are all slide-level tasks. We randomly divided every dataset into training, validation, and testing subsets according to the ratio of 6:1:3, where the training sets were used for multi-organ pre-training and task-specific fine-tuning, validation sets were used to do early stop, and results on the testing sets were reported for evaluation. We describe the task definitions on these datasets and the utilization of the data under the multi-organ pre-training strategy as shown in Table, where tasks are categorized into in-domain and out-of-domain conditions based on whether or not the fine-tuning data is involved in the pre-training process.

SECTION: Experimental setting
During the WSI-level representation pre-training stage, we did not involve any supervised information. The pre-trained encoder will be utilized as the slide representation extractor for various downstream tasks.
We applied DINOto pre-train and extract all patch features and also utilized the released foundation model PLIPas the patch feature extractor on the magnification under 20× lenses.

We first pre-trained our model on multi-organ datasets and then evaluated the performance on six task-specific datasets with two conditions, where the in-domain condition is that fine-tuning datasets are involved in the pre-training, otherwise is the out-of-domain condition.
Subsequently, we validated the effectiveness of WSI representation learning and conducted comparison experiments with other SOTA methods to showcase the superiority of PAMA.
In the end, the ablations and parametric experiments demonstrate the significance of the proposed modules and strategy. Accuracy (ACC), the area under the ROC curve (AUC), and the F1 score were used as metrics to evaluate performance.

We implemented all the methods in Python 3.8 with PyTorch 1.7 and Cuda 10.2. Our experiments were conducted on a computer cluster with ten Nvidia Geforce 2080Ti GPUs.

SECTION: Effectiveness for in-domain pre-training
In this experiment, we pre-trained PAMA within the training sets of five datasets, i.e., TCGA-RCC, TCGA-NSCLC, USTC-EGFR, Endometrium-3k, and TCGA-EGFR, which are regarded as in-domain datasets.
Then, we evaluated the performance of the pre-trained model on the test sets of the in-domain datasets to show the effectiveness of PAMA in learning representation from abundant unlabeled histopathology image data.

Table.shows the results with diffident training strategies using DINOpatch features and PLIPpatch features, wheremeans to directly train the PAMA encoder in a weakly supervised way,refers to pre-training PAMA on the current single dataset and then fine-tuning it with task labels, andrefers to pre-training PAMA on the multi-organ dataset and then fine-tuning it with task-specific labels.

For every dataset under DINO features, pre-training on the single dataset can increase ACCs by 0.17% to 22.75%, increase AUCs by 0.31% to 2.15%, and increase F1 score by 0.33% to 19.63% for different tasks.
Multi-organ pre-training further promotes the performance of the model. Specifically, the ACCs/AUCs increase by 29.61%/4.77%, 8.49%/1.85%, 0.81%/1.12%, 5.84%/2.74%, and 3.43%/4.61% on the Endometrium-3k dataset, TCGA-NSCLC dataset, TCGA-RCC dataset, USTC-EGFR dataset, and TCGA-EGFR dataset, respectively.
As for the PLIP features, pre-training on the multi-organ datasets can increase ACCs by 1.36% to 17.25%, increase AUCs by 0.93% to 25.28%, and increase F1 score by 1.62% to 17.44% for different tasks.
These results demonstrate the proposed method can effectively promote the WSI encoder in optimizing the use of abundant unlabeled WSI data and enhancing representational abilities.

Our model gains even more significant improvement on the Endometrium-3k dataset, where the data is extremely unbalanced. Fig.(a) exhibits that the data of LDEA and PECA are less than half of MEDA data, while SDEA, CCEA, and MCEA are even less than ten WSIs. Datasets with long-tailed categories often lead to model bias problems.
Fig.(d) shows that multi-organ pre-training increased AUCs by 0.04, 0.09, 0.07, 0.27, and 0.12 for categories of LDEA, SDEC, PECA, CCEC, and MCEA, respectively, when compared with the direct training. It demonstrates that PAMA pre-trained on multiple organ datasets can enhance the model generalization ability to significantly relieve the model bias problem.

Molecular characterizations manifest as more latent features that are not visible in histopathology images, and thus molecular status prediction by WSIs is a more challenging task. Pre-training on the single dataset improves the ACCs/F1 score on the USTC-EGFR dataset and TCGA-EGFR dataset by 3.90%/6.88% and 1.14%/19.63%. It demonstrates that WSI-level self-supervised learning can obtain more discriminative implicit semantic features. Furthermore, directly fine-tuning the multi-organ pre-trained model on the two datasets contributes to an increase in F1 scores by 15.78% and 24.07%. Such a significant improvement indicates that multi-organ pre-training can mine the general semantic information of histopathology images, and thereby can complete various challenging tasks more effectively and efficiently. This demonstrates the ability of our proposed method to be more practical and meaningful in building computer-aided pan-cancer diagnosis systems.

SECTION: Generalization for out-of-domain pre-training
We additionally collected a large-scale pan-cancer dataset from TCGA as the out-of-domain data to evaluate the generalization of PAMA pre-training. We pre-trained PAMA and a SOTA method, namely Prov-GigaPath, on the pan-cancer dataset without any labels, and then fine-tuned the encoder on six downstream tasks completely independent of the pan-cancer dataset. The results are represented asandin Fig.. We conducted the experiment using PLIPpatch features and therepresents the results ofstrategy in Table.

In Fig., the performance ofdecrease by no more than 0.02 in AUCs and no more than 1.6% in ACCs compared with. Especially on TCGA-NSCLC dataset and TCGA-RCC dataset, the AUCs decreased by less than 0.003, where there is nearly no degradation in performance of pre-training PAMA with the out-of-domain data. The results demonstrate that PAMA exhibits substantial out-of-domain generalization capabilities.

are superior toin AUCs by 0.004 to 0.132 and in ACCs by 0.97% to 4.33% for different tasks. It displays a better capacity of our method in characterizing and analyzing unseen data in comparison to Prov-GigaPath.

Furthermore,achieves comparable and superior performance compared with pre-training on the single dataset results in Table. The results effectively demonstrate PAMA’s ability to mine information from extensive amounts of unlabeled data, facilitating potential of the framework for more general histopathology image analysis tasks.

SECTION: Effectiveness of semi-supervised WSI classification
Then, we conducted experiments to assess the effectiveness of WSI-level self-supervised learning under conditions with limited WSI labels. The results are presented in Fig., which compares the performance obtained with varying ratios of training WSIs with labels.
We re-implemented MAEfor slide-level feature learning as the baseline. Additionally, we applied the proposed distance and polar angle embedding into the self-attention module of MAE, denoted as MAE+ in Fig.. To ensure the objectivity of the comparisons, we employed the method in the original paperto fine-tune the HIPT. Additionally, we re-implemented BYOLas the contrastive learning-based self-supervised slide-level learning for comprehensive comparison with the MIM framework.

It shows that PAMA is consistently superior to MAE, HIPT and Prov-GigaPathacross all label ratios. Prov-GigaPath utilizes DINO V2to extract patch features and uses LongNetas slide aggregator for pre-training. LongNet was originally designed for extremely long sequences like over 1B+ tokens. However, Prov-GigaPath has not considered any properties of WSI, especially spatial structure information. In sufficient data conditions, it is not even better than HIPT. With the volume of our datasets, the performance of Prov-GigaPath, which is not specifically designed for WSI characteristics, does not differ much from plain MAE, but still has a large margin from PAMA. The above results demonstrate the effectiveness of PAMA in pre-training WSI representations and the MIM frameworks are more efficient than the contrastive leaning framework for slide-level learning.
PAMA obtains optimal stability in AUCs with label ratios reducing from 85% to 10%. This is of great practical value as it reduces the reliance on a massive number of labeled WSIs for training a robust WSI analysis model. Meanwhile, we can employ unlabeled WSIs with the assistance of PAMA to enhance the capabilities of the WSI analysis models. HIPT is a two-stage pre-training model that is slightly less effective than the one-stage MAE. This illustrates that the discontinuous gradient back-propagation of a multi-stage pre-training model led to an accumulation of biases. In addition, the MAE+ outperforms MAE. It indicates our proposed distance and polar angle embedding can capture more complete spatial information of WSI than the original position encoding of ViT.

SECTION: Comparison with other weakly supervised methods
We compared PAMA with four self-supervised frameworks, BYOL, MAE, HIPT, and Prov-GigaPath, and four SOTA weakly supervised methods, including DSMIL, TransMIL, SETMIL, and KATon the Endometrium-3k and TCGA-NSCLC datasets for slide-level classification. The results are shown in Tableand.

Overall, our proposed PAMA is superior to the second-best method with increased AUCs/ACCs(%) of 0.051/5.49, 0.029/6.05, 0.024/5.97, 0.017/5.40, and 0.013/5.19 on the Endometrium-3k dataset with 10%, 35%, 65%, 85% and 100% labeled data, and increased AUCs/ACCs(%) of 0.027/6.74, 0.017/6.09, 0.015/5.68, 0.012/5.76, and 0.011/2.83 on the TCGA-NSCLC dataset with 10%, 35%, 65%, 85% and 100% labeled training data, respectively.

DSMILintroduced a dual-stream architecture with trainable distance measurement for instances and applied a pyramidal fusion framework for multiscale WSI features, which, however, did not consider the spatial structure of tissue. The absolute structural encoding reduces the performance of DSMIL from other methods. TransMIL and SETMIL leveraged CNN blocks to aggregate local information and then built Transformer structures for long-range global feature aggregation. KAT considered the spatial adjacency of patches and manually defined the fixed hierarchical masks based on local kernels to maintain relative distance information. None of the three methods embedded relative orientation information into slide representations, which causes a significant performance gap compared with PAMA. We re-implemented BYOLwith ViTbackbone for slide-level feature learning based contrastive learning. Contrastive self-supervised learning frameworks like BYOL rely on extensive and effective augmented views to mine the discriminative representations. However, there are no efficient published WSI-level view augmentation methods currently and we applied random sample patches to construct different views of the WSI. WSI views based on random patch sampling are struggling to efficiently capture semantic information. It results in even worse performance than some weak-supervised methods.
Self-supervised learning methods based on MIM, namely, MAE and Prov-GigaPath, surpass these SOTA weakly supervised methods. It reconfirms the effectiveness of WSI-level representation pre-training.

Additionally, PAMA fine-tuned on 35% labeled data on the two datasets can achieve comparable results with other methods trained on 100% labeled data. It demonstrates that PAMA is capable of utilizing limited data more effectively, decreasing the reliance on large amounts of labeled data for training high-capacity models.

SECTION: Ablation studies
We conducted ablation studies on the Endometrium-3k dataset to verify the significance of our relative spatial embedding and strategy shown in Table.. When the polar angel embedding of anchors was removed, we observed the AUC and ACC(%) dropped by 0.016 and 6.39. It is notable that if we applied the polar embedding without the KRO module, the AUC and ACC(%) dropped by 0.029 and 6.87, which means that indexing angles with a fixed polar axis will lead to ambiguous semantic information in WSIs. KRO strategy can dynamically update every anchor’s main polar axis to disambiguate structure information in slides. The relative distance embedding can maintain scale-varying WSIs in a semantic consistency space. The AUC and ACC(%) decreased by 0.022 and 6.75, respectively, when the distance embedding was discarded. When we constructed the slide representation neither with the distance nor polar angle embeddings, the performance had a significant drop of 0.034/7.96 in the AUC/ACC(%). These results prove that the proposed modules can effectively and efficiently acquire spatial information to maintain semantic integrity and consistency in WSIs. Furthermore, the AUC and ACC(%) decreased by 0.004 and 3.83, respectively, when the AD was discarded. This indicates that anchor dropout contributes to better generalization performance.

SECTION: Hyperparameter analysis
To verify the design of the PAMA framework, we performed a series of parametric experiments on the Endometrium-3k dataset, where only the current parameter was tuned in each set of experiments and the remaining parameters were fixed. The results are shown in Fig..

:is the ratio of masked patches to remove before we feed the remaining tokens into the PAMA encoder during pre-training. We find that masking nearly 75% tokens to reconstruct the slide representation can help the model obtain a promising performance in Fig.(a). Reducing the masking ratio limits the model’s reconstruction space, whereas an excessively high ratio sacrifices fundamental contextual information.

:is the probability of randomly discarding anchors for data augmentation. Different reserved anchors can lead to the diverse structural representations of the WSI. Fig.(b) indicates that PAMA with dropoutanchors achieves the best performance. The model performs stable when the probability is higher than, which demonstrates that discarding a wide range of anchors will cause the basic information of the WSI to be missed.

:denotes the number of patches per anchor clustering cluster. Increasing the value ofwill enable the anchor to capture a wider range of contextual information, whereas reducing its value will result in the generation of more anchors which means a higher computational amount. Based on Fig.(c), we setfor balancing performance and resource consumption.

:is the number of orientation bins,,means each bin holds aangle range. Asincreases, the anchor can provide more precise structural information due to the detailed division of orientation intervals. However, this enhancement comes at the cost of increased computational consumption. Based on Fig.(d), we setfor balancing performance and resource consumption.

SECTION: Visualization
We further assessed the interpretability of our proposed framework with visualization. We present a well-endometrioid adenocarcinoma slide and the annotation by pathologists as shown in Fig.(a-b). Fig.(c-f) show the heatmap and polar attention distribution based on anchors in each PACA block without pre-train and during fine-tuning after pre-training with single-organ and multi-organ datasets. In the early stage (, block 1) during fine-tuning after multi-organ pre-training as shown in Fig.(III), anchors initially focus on identical pathological tissues as the observation regions. Through supervised WSI label fine-tuning, the anchor’s attention consolidates on high-risk cancerous tissues and attains stability in which the KRO strategy takes a crucial role in adaptively updating the polar axis that is illustrated by the yellow sector in the radar chart. In the process without pre-train as shown in Fig.(I), the regions of interest of both anchors in the normal and cancerous tissues are diffuse. After pre-training with the single-organ dataset as shown in Fig.(II), the anchor in the positive area can gradually converge to the cancerous tissues. With the contribution of multi-organ pre-training as shown in Fig.(III), anchors’ areas of interest are more comprehensive and precise.

Fig.exhibits the multi-head attention heatmap based on anchors during multi-organ pre-training.
We observe that an anchor located in the negative region is assigned a higher attention score to negative tissue, whereas a positive anchor is given greater attention to cancerous tissue, which means the anchors focus on tissues that share similarities with their features. This behavior enables PAMA to comprehensively describe patterns in histopathology images. From the perspective of the heads, some heads focus on more sparse areas (, head 7 and head 8), while others concentrate on more dense areas (, head 5 and head 6). It is observed that the distance and polar angle range of each head’s attention varies and complements each other. This demonstrates that our proposed anchor-based cross-attention module can obtain diverse semantic information without introducing supervision.

SECTION: Discussion
Most of the current large-scale pathology foundation models focused on patch-level representation learning. A few works focused on slide-level foundation models, such as HIPTand Prov-GigaPath, but they disregarded the properties of WSIs, especially the complex spatial semantic information. We introduced the spatial semantic completeness of WSI into the pre-training process, enhancing the slide representations of PAMA to become more semantically complete and generalized.

Data-driven pre-training strategy following foundation modelsfacilitated PAMA for pan-cancer analysis. In this paper, we focused on model design and pan-cancer dataset construction. The proposed position-aware cross-attention model with a dynamical reorientation strategy captures the intrinsic semantic representation of WSIs across various cancer types rather than focusing on any specific tumor or organ. Moreover, the framework was pre-trained to obtain the morphological consistency across multiple cancers based on the broad data including over 13.6k WSIs of 22 cancer types covering 11 organs from multiple medical centers. In future work, it will be necessary to further investigate the spatial properties of pan-cancer and to employ explicit designs to mine its semantic information, such as constructing loss function.

We evaluated the generalization of PAMA across various downstream tasks, including tumor sub-typing, gene mutation prediction, and biomarker status grading. Additionally, out-of-domain datasets were constructed to further demonstrate that the pre-trained model can generalize to datasets not included in the pre-training process. Technically, our pre-training process is task-agnostic, allowing the model to be fine-tuned for specific tasks on any downstream task based on pathology WSIs, which is similar to the released foundation pre-training models. Furthermore, we will explore more general downstream tasks for histopathology image analysis based on the PAMA pre-trained model to facilitate its clinical adoption value.

SECTION: Conclusion
In the paper, we focused on self-supervised WSI-level representation learning and proposed the position-aware masked autoencoder (PAMA) for WSI pre-training. The proposed anchor-based position-aware cross-attention (PACA) module leverages the bidirectional communication between the local and global information to capture WSI semantic features. We also introduced a kernel reorientation (KRO) strategy to dynamically update the main orientation of anchors to eliminate ambiguity for WSI representation learning. Additionally, we collected seven large-scale datasets from multiple organs and evaluated the effectiveness and generalization of PAMA for pan-cancer analysis. The comprehensive experimental results have demonstrated that the proposed method is superior to the state-of-the-art methods and efficiently facilitates the analysis of pan-cancer. The current work has two limitations that can be improved: (1) the collected multi-organ datasets do not yet contain comprehensive cancer types and need to be further expanded for pan-cancer analysis, and (2) the PAMA structure currently relies only on pathology image data, and we need to further introduce multimodal data, such as genomics, to participate in the pre-training process to facilitate cancer diagnosis. In the future work, we will focus on these challenges to enhance our work.

This work was partly supported by Beijing Natural Science Foundation (Grant No. 7242270), partly supported by the National Natural Science Foundation of China (Grant No. 62171007, 61901018, and 61906058), partly supported by the Fundamental Research Fund for the Central Universities of China (grant No. YWF-23-Q-1075), partly supported by the Anhui Provincial Natural Science Foundation (Grant No. 2408085MF162), partly supported by Emergency Key Program of Guangzhou Laboratory (Grant No. EKPG21-32), partly supported by Joint Fund for Medical Artificial Intelligence (Grant No. MAI2023C014), and partly supported by National Key Research and Development Program of China (Grant No. 2021YFF1201004).

SECTION: References