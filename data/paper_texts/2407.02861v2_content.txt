SECTION: A Self-Supervised Task for Fault Detection in Satellite Multivariate Time Series

In the space sector, due to environmental conditions and restricted accessibility, robust fault detection methods are imperative for ensuring mission success and safeguarding valuable assets. This work proposes a novel approach leveraging Physics-Informed Real NVP neural networks, renowned for their ability to model complex and high-dimensional distributions, augmented with a self-supervised task based on sensors’ data permutation. It focuses on enhancing fault detection within the satellite multivariate time series. The experiments involve various configurations, including pre-training with self-supervision, multi-task learning, and standalone self-supervised training. Results indicate significant performance improvements across all settings. In particular, employing only the self-supervised loss yields the best overall results, suggesting its efficacy in guiding the network to extract relevant features for fault detection. This study presents a promising direction for improving fault detection in space systems and warrants further exploration in other datasets and applications.

SECTION: 1Introduction

Today’s world is increasingly reliant on satellite technology for navigation[hofmann2007gnss], communication[rahmat2014technology], and scientific studies[martini2021domain,deep_space_1]. It is therefore important to ensure the reliability and longevity of these assets. The challenges presented by the space environment, characterized by extreme temperatures, radiation exposure, and limited, if not absent, maintenance opportunities, underscore the critical importance of fault detection in satellite systems[HASAN2022100806,faults_type]. Traditional approaches often rely on predetermined rules or thresholds, which can be inadequate for capturing the complex and dynamic nature of faults in such demanding conditions, or costly model-based approaches[schein2006rule,4512019].

To address these challenges, in recent years we have witnessed a surge of studies in Artificial Intelligence (AI) methodologies for fault detection in space systems, which have shown promising results in automatically identifying and diagnosing anomalies in satellite data. Among these methodologies, the Physics-Informed Real NVP model introduced by[aim2024]demonstrated its ability to model complex distributions while incorporating domain-specific knowledge.

This model integrates principles of physics, specific to the considered dataset, ADAPT[adapt_paper], into the loss function, enabling the model to capture underlying physical relationships within the data. By leveraging the Normalizing Flow family[norm_flow,9089305]and affine coupling layers[dinh2014nice], this model excels in representing high-dimensional distributions, making it well-suited for analyzing multivariate satellite data.

Given the scarcity and cost of labeled data in this sector,
self-supervision offers the advantage of leveraging unlabeled data to guide the learning process, enhancing the model’s ability to extract meaningful features relevant to fault detection[zhang2024self]. These approaches typically rely on creating pretext tasks that provide supervisory signals for model training. Their success depends on the effectiveness of the designed pretext tasks, which can be categorized into various paradigms, such as contrastive learning and generative learning[liu2024self]. Contrastive methods, like SimCLR[pmlrv119chen20j], focus on learning representations by encouraging the model to distinguish between similar and dissimilar data points. Conversely, generative approaches, such as Masked Autoencoders[zhang2022survey], train models to reconstruct the original data from a corrupted version, forcing them to capture essential features.

Self-supervised tasks should be carefully chosen to exploit the specific structure of the data at hand and steer learning toward robust representations. Examples from other fields include object recognition across different domains using jigsaw puzzles as a self-supervised task[jigsaw_puzzle]or augmentation-aware self-supervised task in the discriminator network of a GAN for robust representation learning[NEURIPS20236464638c].

Time series data presents unique challenges for self-supervised approaches due to their sequential nature and the importance of capturing temporal dependencies. Traditional methods primarily focus on inter-sample relationships, neglecting the crucial intra-temporal structure within a single time series.

Recent advancements address this gap by incorporating self-supervised tasks to learn inter-sample and intra-temporal relationships[fan2020self,time_permutation]: SelfTime[fan2020self]proposes a framework that explores these relationships simultaneously. It considers separate reasoning heads within the model to analyze both the similarities between different time series and the relationships between time steps within a single series.

The challenges become even more complex when dealing with multivariate time series, where multiple interconnected variables evolve over time. Graph Neural Networks (GNNs) offer a promising solution in this domain[zhang2024self], as they can capture the relationships between different variables.[saeed2019multi]applies transformations (permutation, scaling, etc.) on sensor data and subsequently tries to differentiate them as a training method for human activity detection.

Recognizing the potential of self-supervised learning techniques to augment existing methodologies, we propose the integration of a self-supervision task into the fault detection process for satellites’ Electrical Power System (EPS). We propose to permute the input sensor’s measurements (i.e. channels), but differently from[saeed2019multi], which only aimed at detecting a generic permutation among other transformations, we ask the network to sort them by predicting the permutation’s index, similarly to what is done in[jigsaw_puzzle]with image patches.

To the best of our knowledge, this is the first time that the prediction of the permutation applied to the time series features, i.e. sensor’s data, is used in the space sector as a self-supervision task, and this is the first study that performs extensive experiments to understand its effect in a multi-task setting and as a standalone loss. To summarize, the contributions of this paper are:

we introduce a self-supervised task for fault detection in multivariate systems, demonstrating its effectiveness in the space domain;

we evaluate the above-mentioned task in multiple settings, showing its effectiveness both for pre-training and in multi-task training;

we show that when used as a standalone loss this self-supervised task leads to better results on ADAPT[adapt_paper]demonstrating its relevance especially when labels are not available.

Through these contributions, this paper aims to advance the state-of-the-art in satellite fault detection towards more resilient and reliable spacecraft.

SECTION: 2Methodology

Here we delve into the description of the model and the losses used.

The self-supervision loss is computed by permuting the order of the dataset’s columns () (seeFigure1), and asking the model to predict the permutation applied.

In particular, the loss function is

whereis the number of samples,is the number of permutations,is the label (1 ifis the correct permutation, 0 otherwise),is a vector composed by concatenating 50 rows of the dataset after the application of the given permutation,is the Real NVP model anda fully-connected layer (seeFigure2).

We applied our loss to the configuration proposed by[aim2024]: a Real NVP[realnvp_paper]neural network trained with a physics-informed loss, for fault detection.

Real NVP enables the learning of complex, high-dimensional distributions by mapping data to a simpler latent space. Unlike other Normalizing Flow models, Real NVP employs affine coupling layers to capture local dependencies and diverse modes in data, facilitating the generation of realistic samples. Each coupling layer transforms one set of variables while keeping the other unchanged through invertible functions, usually implemented as neural networks. This approach allows for efficient inference and generation of samples.

We tested our self-supervised loss by using it in three different settings, shown inFigure2:

Multi-task: a multi-task training loop where both losses were used simultaneously;

Pre-Training: a self-supervised pre-training step followed by a fine-tuning step in which[aim2024]’s final loss was used, i.e. our Main Loss;

Only self-supervision: the self-supervision task was used as a standalone loss during training.

In all settings, to compute the self-supervision loss the architecture was augmented with a fully connected layer (), with a number of output units equal to the number of permutations () to predict the permutation’s index among a given set through a softmax activation function.

SECTION: 3Experimental Setup

In the following, we provide an overview of the architecture used, the dataset considered for the experiments, some implementation details, and the metrics selected to evaluate our solutions.

Architecture: we used the Real NVP with 4 coupling layers[dinh2014nice], where the neural networks used as translation functions (t) and scale functions (s) are made up of 2 fully-connected layers with 32 units and a final fully-connected layer with as many units as the dimension of the inputs. As activation, thetnetworks have a linear function, while thesneural networks have the tanh function.

Dataset: We used ADAPT[adapt_paper], a dataset created by NASA Ames Research Center to evaluate EPS fault detection algorithms. We generated 7 splits by randomly splitting the provided files between training and testing data decreasing the number of samples by 66% with respect to those used in[aim2024]to deal with a more challenging task and to demonstrate the efficacy of our method in conditions where labeled data is scarce and expensive. In all settings we also consider a different configuration (complete dataset), in which we used the complete dataset, excluding the test set of the current split, to train the self-supervision task.

Implementation Details: All models have been trained and evaluated on an Intel Xeon Scalable Processors Gold 6130 with 5 different random seeds on all 7 splits using as input a time window of 50 timestamps. Each training was performed keeping 30% of the training data as validation set and using it for early stopping. Before training, the dataset was scaled between 0 and 1. The self-supervised task requires the permutation of the input features. Given the high number of possible permutations, we decided to create a few sets of permutations of different sizes as follows: for each set, given its target sizeP, we randomly permuted the columns for a number of times well abovePand then kept thePpermutations with higher entropy. Specifically, we compute

whereis the number of sensors present in the dataset (Figure1),andindicate distinct permutations,() represents the sensor’s index moved in positionby permutation(). When selecting thepermutations we aim to maximize, as this ensures greater positional deviation from the features’ true positions and distinctiveness from other permutations within the set.

Metrics: During inference, the fully connected layer was removed, allowing for the direct use of the log-likelihood values outputted by the Real NVP model’s distribution layer () to evaluate the effect of the self-supervised loss. We computed the Area Under the Receiver Operating Curve (AUROC), which measures the model’s ability to distinguish between classes by calculating the area under the curve generated by plotting the True Positive Rate against the False Positive Rate with various thresholds; the F1-score, which balances precision and recall by considering both false positives and false negatives; and the False Positive Rate at a 95% true positive rate (FPR95), which indicates the rate of false alarms when the true positive rate is high.

SECTION: 4Results

InTable1we show, for each setting and configuration, the results obtained evaluating the model on the 7 test sets with 5 different random seeds.

All the experiments shown inTable1performed better than the baseline, i.e. the neural network and loss proposed by[aim2024]showing that the self-supervised task is useful in driving the network toward the relevant features.

Additionally, the results show that in all settings thecomplete datasetconfiguration leads to better results in all metrics, but FPR95 inmulti-task. This is expected as more data is used. More interesting are the results obtained when training using only the self-supervised loss with the complete dataset, which leads to the best results overall. We believe this is because, differently from the final loss in[aim2024], this loss uses both nominal and faulty data, successfully learning representative features about sensor correlations from both.

Moreover, the experiments showed that the use of a bigger dataset for the self-supervised task always led to an increase in the number of permutations needed for the best results. This may be due to the hardness of the chosen task, which requires a high number of samples to be successfully learned in all cases.

SECTION: 5Discussion

We present a self-supervised task based on feature permutations to pre-train a Physics-Informed - Real NVP neural network for fault detection in multivariate time series. The experiments are performed on several custom splits of the ADAPT dataset.

The results show that using this self-supervised loss leads to improvements with respect to those that can be obtained with previous studies when dealing with a small dataset. This demonstrates the contribution of this work towards more data-efficient AI models, a particularly relevant feature in the space sector, due to the complexities involved in creating a fault detection dataset. Moreover, the proposed task has also been shown to be useful in multi-task settings, as well as a standalone loss.

We believe that the last case is particularly interesting, and we plan on further investigating it to understand the differences between the features extracted by the Real NVP model trained with it and those obtained from the models trained with the log probability and the physics-informed loss. Moreover, we plan on further analyzing the effect of the number of permutations on the self-supervision task in all settings. Finally, the results show that there may be room for additional improvements by using a higher number of samples to pre-train models using bigger sets of possible permutations.

SECTION: ACKNOWLEDGMENT

This work has been developed with the contribution of the Politecnico di Torino Interdepartmental Centre for Service Robotics (PIC4SeR https://pic4ser.polito.it) and Argotec SRL. This publication is part of the project PNRR-NGEU which has received funding from the MUR – DM 117/2023. Computational resources were provided by HPC@POLITO (http://hpc.polito.it).