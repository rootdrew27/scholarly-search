SECTION: TurboSVM-FL: Boosting Federated Learning through SVM Aggregation for Lazy Clients

Federated learning is a distributed collaborative machine learning paradigm that has gained strong momentum in recent years. In federated learning, a central server periodically coordinates models with clients and aggregates the models trained locally by clients without necessitating access to local data. Despite its potential, the implementation of federated learning continues to encounter several challenges, predominantly the slow convergence that is largely due to data heterogeneity. The slow convergence becomes particularly problematic in cross-device federated learning scenarios where clients may be strongly limited by computing power and storage space, and hence counteracting methods that induce additional computation or memory cost on the client side such as auxiliary objective terms and larger training iterations can be impractical. In this paper, we propose a novel federated aggregation strategy,TurboSVM-FL, that poses no additional computation burden on the client side and can significantly accelerate convergence for federated classification task, especially when clients are “lazy” and train their models solely for few epochs for next global aggregation. TurboSVM-FL extensively utilizes support vector machine to conduct selective aggregation and max-margin spread-out regularization on class embeddings. We evaluate TurboSVM-FL on multiple datasets including FEMNIST, CelebA, and Shakespeare using user-independent validation with non-iid data distribution. Our results show that TurboSVM-FL can significantly outperform existing popular algorithms on convergence rate and reduce communication rounds while delivering better test metrics including accuracy, F1 score, and MCC.

SECTION: Introduction

With the increasing importance of data privacy, a giant stride in distributed machine learning has been observed in recent years. As one promising distributed machine learning paradigm, federated learning (FL) has been growing at an astounding rate after its introduction(McMahan et al.2017). In the common FL settings, data is distributed over numerous end clients, while the central server possesses no data by itself. After the server initiates a model and sends the model to clients, each client trains the model locally using its own data. The server periodically aggregates the locally trained models and synchronizes local models of clients with the latest aggregated one. With such a process, FL provides a primary privacy guarantee to a large extent since the server does not require data sharing and is hence preferred in many privacy-preserving scenarios where sensitive data is utilized.

Based on the characteristics of participating entities, FL can be further categorized into cross-silo FL and cross-device FL(Kairouz et al.2021). In cross-silo FL, the target clients are often large-scale institutions such as hospitals, data centers, educational organizations, and high-tech companies. Such stakeholders commonly possess decent resource for computing, storage, and internet connection, while the number of attending institutions is relatively low. Therefore, the probability that each client takes part in all aggregation rounds is high. In contrast to cross-silo FL, cross-device FL focuses more on training on end-user devices like smartphones and personal computers using user data. The scale of participating clients in cross-device FL can be fairly large, while each client may be strongly limited by its computing power and connectivity. As a consequence, only a (small) portion of clients could share their models during a global aggregation. An additional critical aspect of cross-device FL is that each client might only contain data collected from a single user, which exacerbates data heterogeneity across clients.

Despite recent advancements in FL, its implementation in practice is still facing some challenges. Among these, the slow convergence is a primary concern: a significantly greater number of aggregation rounds are often needed to reach convergence compared to non-FL setups. Several factors contribute to this inefficiency according to(Wu et al.2023), such as client drift caused by data heterogeneity(Karimireddy et al.2020), lack of adaptive optimization(Reddi et al.2020), and the increase in model complexity and data size. One trivial solution proposed in(McMahan et al.2017)is to increase client computation load by a larger number of local training iterations. Although this solution vastly speeds up the convergence, it multiplies the computation load on the client side, which can be problematic when clients are constrained by computing power, like in cross-device FL case. Other existing solutions mainly target at either client drift or adaptive optimization. The former often requires to optimize additional objective functions on the client side, which in turn also increases the client computation load and even the need for storage, while the latter can be particularly hard to tune because it is often necessary to decide the choice of optimizers and learning rates jointly between server and clients. There also exist solutions that require additional data on the server side, which may increase the risk of privacy leaks if not handled properly.

In this paper, we focus on embedding-based neural network classifiers, which means the input samples are encoded into the same space as class representations and their similarity determines the probability of the sample belonging to the class(Yu et al.2020). We propose a novel federated aggregation strategy for classification tasks called TurboSVM-FL. TurboSVM-FL induces no additional computation cost or storage consumption on the client side compared to the vanilla FL algorithm, and shows great potential in reducing communication rounds, especially when clients are “lazy” and train their local models for very few iterations. TurboSVM-FL extensively exploits the property of support vector machine (SVM) and consists of three steps. Firstly, TurboSVM-FL reformalizes classification while treating client models in a model-as-sample way, and fits SVMs using latent class embeddings. Then, it conducts selective aggregation on latent class features that form support vectors. Lastly, TurboSVM-FL applies max-margin spread-out regularization on aggregated class representations upon SVM hyperplanes. By adopting adaptive methods in max-margin spread-out regularization, TurboSVM-FL can also benefit from adaptive optimization. The main contributions of this work can be summarized as follows:

We introduce a novel perspective to interpret classification in FL setting and a model-as-sample strategy, which lay the foundation for further FL improvements such as selective aggregation and outlier detection.

We propose a novel federated aggregation algorithm named TurboSVM-FL that vastly boosts convergence for federated classification tasks using deep neural networks. The proposed method extensively exploits support vector machine (SVM) to conduct selective model aggregations and max-margin spread-out regularization.

We conduct experiments on various benchmarks in user-independent validation and show the potential of TurboSVM-FL in reducing communication cost. The benchmarks contain three different tasks covering image classification and natural language processing with non-iid data distribution over clients.

SECTION: Related Work

SECTION: Federated Learning

The concept of FL was originally introduced in(McMahan et al.2017). Unlike centralized learning where the goal is to fit an optimal model on a collection of data, FL aims to train a model that delivers superior performance across data subsets. In the remaining of this work, we narrow down our focus to federated classification tasks. In a federated classification task withclasses andclients, denote the local dataset of each client aswith, whereis a sample point of class. Letwithdescribe the collection of local datasets andbe the objective function measured on the samplewith model. Then, the goal of centralized learning is to find an optimal modelthat satisfies:

In contrast, FL aims to fit a model that performs optimally across clients:

The typical workflow of FL can be broken down into three steps. First, a server initializes a model and broadcasts this model to all clients. Then, each client trains the received model on its own dataset forepochs and sends the trained model back to the server. In the next step, the server aggregates locally trained models into a new global model and synchronizes clients with the latest global model. The last two steps are repeated for multiple rounds until convergence. The first federated aggregation algorithm, FedAvg, was introduced in(McMahan et al.2017)and applies weighted average over client models:

whereanddenote the aggregated global model and the local model of-th client, respectively.

One of those challenges that FL is facing is the large amount of aggregation rounds needed to approach convergence. While increasing local training iterationscan significantly advance convergence, it also vastly increases the computation load on the client side, which can be extremely problematic in cross-device FL. Many follow-up works aim to speed up FL convergence, and they can be mainly categorized into two groups. The first group endeavor to address client drift(Karimireddy et al.2020)caused by data heterogeneity, while the other group attempt to benefit FL with adaptive learning methods, which we describe as follows.

SECTION: Client Drift in Federated Learning

Client drift(Karimireddy et al.2020)describes the phenomenon that client local models approach individual local optima rather than global optima and their average is drifted away from global optima as well, which is caused by data heterogeneity across client local datasets and can dramatically impact convergence behavior. Various recent works attempt to solve client drift on the client side. SCAFFOLD(Karimireddy et al.2020)introduces a control variate term to stabilize gradient update. FedProx(Li et al.2020)proposes an additional loss term based on L2 distance between global modeland client modelduring local training. MOON(Li, He, and Song2021)and FedProc(Mu et al.2023)suggest the use of contrastive learning to combat data heterogeneity. The former introduces an objective based on latent features extracted respectively by the global model, current client model, and previous client model, while the latter penalizes the dissimilarity between latent features and class representations. A common drawback of the aforementioned methods lies in that they increase either computation burden or memory consumption or even both on the client side, which can be quite a challenge for end-user devices like smartphones and tablets.

There also exists works that aim to solve client drift on the server side. For instance, FedAwS(Yu et al.2020)addresses an extreme data distribution case where clients may have only data from a single class. FedAwS utilizes spread-out regularizer(Zhang et al.2017)and raises a penalty term based on cosine similarities among class embeddings on the server side.

SECTION: Adaptive Federated Learning

In centralized learning, advanced adaptive and momentum-based optimization techniques such as AdaGrad(Duchi, Hazan, and Singer2011), Adam(Kingma and Ba2014), and Yogi(Zaheer et al.2018)have shown great success in convergence acceleration. In contrast, in vanilla FedAvg, client models are trained with stochastic gradient descent(Robbins and Monro1951; Kiefer and Wolfowitz1952)and server aggregation is (weighted) averaging. Numerous works have been devoted to benefiting FL with advanced server-side optimizers. As a forerunner in this field,(Reddi et al.2020)proposed a family of adaptive aggregation methods called FedOpt. Different from weighted average in Equation3, FedOpt computes pseudo-gradient(Chen and Huo2016; Nichol, Achiam, and Schulman2018)from client models and updates the global model with a chosen optimizer:

whereindicates the learning rate. Depending on the choice of optimizer, FedOpt can be derivated into multiple variants. For instance, in(Reddi et al.2020), the researchers introduced FedAdaGrad, FedAdam, and FedYogi with their names indicating the choice of optimization technique. FedAMS(Wang, Lin, and Chen2022)suggests the use of AMSGrad(Reddi, Kale, and Kumar2019)optimizer on the server side, which is an improved version of Adam. According to(Wang et al.2021a), it can be hard to tune FedOpt-family methods due to the additional implementation of optimizer on the server side, and it is often necessary to search for optimal learning rates jointly for client optimizer and server optimizer.

Compared to server-level adaptive learning, adaptive optimization on the client side is less studied. Client adaptivity poses its own challenges, particularly due to the potential for the states of client optimizers to significantly diverge from each other as a result of data heterogeneity. To address this challenge,(Wang et al.2021b)proposes to reset client optimizer status in each global round, while LocalAMSGrad(Chen, Li, and Li2020)and FAFED(Wu et al.2023)suggest the sharing and aggregation of client optimizer states similarly to client models. These methods can be meaningless if clients are limited by computation resource and can only train their local models for few epochs.

SECTION: Support Vector Machine

Support vector machine (SVM)(Cortes and Vapnik1995)is a widely-used and robust supervised learning model that can be used for both regression and classification tasks. Unlike traditional linear classifiers, where the decision boundary is a linear combination of all data points, the separating hyperplane of SVM is a combination of selected samples, which are also called support vectors and lie the closest to the decision boundary. While common classifiers minimize solely the classification objective, SVM struggles to control the trade-off between discriminative error minimization and margin maximization while allowing some misclassifications. The margin refers to the distance between the support vectors of different classes and the decision boundary. The primal problem of SVM can be formalized as:

wheredefines the distance of a misclassified sample to its correct margin plane. The coefficientcontrols the magnitude of regularization. A smallerprioritizes larger margins and may result in a greater number of support vectors.

It is important to note that there are several prior works that integrate FL and SVM, such as(Bakopoulou, Tillman, and Markopoulou2021; Navia-Vázquez, Díaz-Morales, and
Fernández-Díaz2022; Bemani and Björsell2022). Our approach is distinctly different from them in the sense that our algorithm leverages SVM to improve global aggregation and offers a solution to the problem “how to FL”. In contrast, in previous works, SVM serves as the core model to be trained in FL and thus addresses the question of “what to FL”.

SECTION: Methodology

In this paper, we propose a novel federated aggregation algorithm for classification task called TurboSVM-FL that is able to boost convergence significantly. TurboSVM-FL sophisticatedly leverages SVM to conduct selective aggregation and max-margin spread-out regularization. By adopting an adaptive optimizer, TurboSVM-FL can also benefit from adaptivity. Compared to vanilla FedAvg(McMahan et al.2017), TurboSVM-FL requires no additional computation, storage, or communication cost on the client side. A pseudocode for TurboSVM-FL is given in Algorithm3, and a graphical illustration is depicted Figure1.

In the following, we present our algorithm in detail, starting by reformalizing the classification task as “finding nearest neighbor”. We reduce our discussion to embedding-based deep learning networks and ignore the logit activation, which means the modelcan be divided into two parts:and, with, whereis the feature encoder that maps inputto a latent representation inandis the last projection layer containing class embeddings. In a classification task withclasses,will be of shapeand is also called logit layer. Then, the class inferenceof a sampleis indifferent from finding the nearest neighbor toinwithbeing the-th row inindicating the class embedding of class. Implicitly, the metric used to measure distance is vector inner product, and the choice of nearest neighbor is regardless of activation function and loss function. For simplicity, we ignore bias terms, and the class inference can then be represented as:

Hence, training the last layer in classification can be regarded as encouraging the correct class embedding to approach instance embedding while discouraging all other class embeddings to be close.

Next, TurboSVM-FL treats client models as sample points for a secondary classification task at higher level, and fits SVM using these samples. The SVM is constructed as a multi-class classification amongclasses, and the SVM training samples are exactly the collected class embeddings, i.e.,. In other words, for each class, there aresample points, and each sample point is the-th row of the weight matrix of the logit layer from a client model.

In vanilla FL, the class embeddings in the logit layer of the global model are obtained by averaging client models, in other words,. Due to data heterogeneity among clients, the class embeddings of some clients can be drifted away from global optima and hence seriously disturb the aggregation. TurboSVM-FL addresses this problem with the help of support vectors during global update. SVM aims at a margin-maximization decision boundary that is a linear combination of selected samples, which are also called support vectors. The support vectors can be regarded as the most informative samples of each class and function similarly to contrastive anchors. In other words, fitting SVM is to some extent equivalent to selective aggregation over samples. TurboSVM-FL brings this property to federated aggregation by averaging only class embeddings that form support vectors, as depicted in Algorithm1.

Moreover, TurboSVM-FL employs spread-out regularization across projected global class embeddings to maintain the margin-maximization property. This is crucial for two reasons: first, although support vectors are the most informative data points, they are close to decision boundary and can be misclassified; second, the weights used during FL aggregation may differ from the coefficients assigned to support vectors during SVM fitting, which could undermine the SVM property. Spread-out regularization like in(Yu et al.2020)offers the potential to distinguish class embeddings. Nevertheless, we propose that omnidirectional regularization is not the most efficient method. Instead, we leverage once again the SVM property, namely we project the aggregated embeddings back onto the SVM decision boundaries, and penalize the similarities among projected embeddings:

whereis the normal of the separating hyperplane for classesandretrieved from fitted SVM.

In(Yu et al.2020), the authors proved that the classification error can be upper-bounded by the separation of class embeddings. We extend their analysis for TurboSVM-FL by showing that by applying selective aggregation and max-margin spread-out regularization, TurboSVM-FL effectively enlarges the difference between projected logits. For simplicity, we narrow down to binary classification and denote the distance relaxation terms for embeddings of each class asand, respectively. Letbe the decision boundary of the fitted SVM. Then, under further simplification that all class embeddings serve as support vectors and all clients have same amount of samples, given a new positive sample, the difference between the positive and negative logits when projected oncan be bounded as follows:

whereis the SVM relaxation term for. By averaging support vectors and applying max-margin spread-out regularization,TurboSVM-FL reducesandin essence according to SVM theory, and the term above that bounds logit distance from below is hence increased. A more detailed analysis of this is given in the Appendix.

Since projections onto the same axis are always co-linear, the common cosine similarity between them is always either 1 or -1 and thus not meaningful. We hence use Gaussian function as a similarity measurement because of its outstanding capability(Yang et al.2021)as similarity kernel:

TurboSVM-FL then optimizes class embeddings regarding the objectiveand can benefit from adaptivity and momentum with a proper choice of optimizer. The max-margin spread-out regularization part of TurboSVM-FL is illustrated in Algorithm2. The pseudocode for the whole algorithm is given in Algorithm3.

SECTION: Experiments and Results

We benchmarked TurboSVM-FL on three datasets against six FL algorithms, including FedAvg(McMahan et al.2017), FedAdam(Reddi et al.2020), FedAMS(Wang, Lin, and Chen2022), FedProx(Li et al.2020), MOON(Li, He, and Song2021), and FedAwS(Yu et al.2020). In this section, we provide task descriptions and results. For more details such as reproducibility and model structures, we redirect readers to the Appendix and our GitHub repository111https://github.com/Kasneci-Lab/TurboSVM-FL..

SECTION: Tasks

We benchmarked TurboSVM-FL on three different datasets covering data types of both image and nature language, namely FEMNIST(LeCun1998; Cohen et al.2017), CelebA(Liu et al.2015), and Shakespeare(Shakespeare2014; McMahan et al.2017)(Table1). The task in FEMNIST dataset is handwritten digit and letter classification using grayscale images. The number of classes in FEMNIST is 62 (10 digits, 26 lowercase letters, and 26 uppercase letters) and the resolution of images is. The CelebA dataset containsRGB images of faces of celebrities, and the task is binary classification between smiling and non-smiling faces. The Shakespeare dataset consists of scripts of different roles from Shakespeare’s works, and the task is next-character prediction given an input string of length 80. The number of unique characters and symbols in this dataset is 80. All three datasets can be acquired on LEAF(Caldas et al.2018). For the two image classification tasks, CNN models were implemented, while for the language task LSTM model was utilized. We adopted the model structures as given in LEAF. Details about data distributions and models can be found in the Appendix.

We also adopted the data split given in LEAF. More specifically, we conductedtrain-test-split in a user-independent way, which means we had a held-out set of clients for validation rather than a fraction of validation data on each client(Wang et al.2021a). The main reason for conducting user-independent validation is that such a test is a more valid approach for unseen data and, thus, more representative for real-world applications. Moreover, it is more challenging to fit a model in a user-independent setting compared to a user-dependent data split.

SECTION: Results

To compare the convergence rate of different FL algorithms, we reported two groups of metrics: number of global aggregation rounds needed to reach certain validation accuracy (70% for FEMNIST and CelebA, 50% for Shakespeare), and the achieved F1 score, accuracy, and MCC (Matthews Correlation Coefficient) after 100 aggregation rounds. The results are given in Tables2and3, and also visualized in Figures2, 4 and 5 (Appendix) for each task respectively.

Our results clearly indicate that on FEMNNIST and CelebA datasets TurboSVM-FL yields a significantly faster convergence in contrast to other FL methods, while on the Shakespeare dataset TurboSVM-FL slightly outperforms others. Compared to the baseline FedAvg, TurboSVM-FL successfully reduces the number of global rounds by 62.2%, 49.3%, and 14.9% to reach the same test accuracy as given in Table2. When all FL methods are run for the same rounds, TurboSVM-FL yields in much better test metrics on both image classification tasks in comparison to other methods, while its performance is a fair match to the adaptive algorithms on the next-character prediction task. Moreover, we show in Figure 4 that while adaptive FL methods like FedAdam and FedAMS are not stable, TurboSVM-FL can still robustly benefit from adaptivity on the server side.

SECTION: Impact of Embedding Size on Selectivity

We further explored the impact of embedding size on the number of client models that form support vectors. To approach this, we ran experiments on the FEMNIST dataset with varying embedding size and number of participating clients. We recorded the number of support vectors for class 1 at 200th round in Table4.

It is clear that a higher embedding size is associated with better performance and fewer support vectors when there exist enough participating clients, while a scarcity of clients can lead to full use of class embeddings as support vectors. Furthermore, larger embedding size also leads to higher complexity and burden, which needs to be balanced off depending on the specific tasks.

SECTION: Discussion

As TurboSVM-FL focuses on class representations on the server side while other parts of the global model are still aggregated with average and client training is done with vanilla SGD, the use of TurboSVM-FL in combination with other FL algorithms is promising. For instance, on the client side FedProx can be applied to counteract data heterogeneity, while on the server side, class embeddings are aggregated with TurboSVM-FL. Another example is the use of adaptive FL methods like FedAdam for encoder aggregation while logit layers are aggregated with TurboSVM-FL. Moreover the idea of model-as-sample can be further explored, for example, for anomaly client detection and client clustering.

TurboSVM-FL is particularly suitable for cross-device FL where edge devices are often constrained by computation and storage resources, but its improvement is also not excluded from cross-silo case. A typical application scenario of TurboSVM-FL is federated transfer learning, where a pre-trained model like VGG16 and Resnet50 is adopted, and all of the layers except the last few ones are frozen. In this case, each client only needs to train and share the last few layers, which makes TurboSVM-FL extremely efficient. The capability of TurboSVM-FL is also not constrained to single-output tasks. For multi-output tasks such as multi-label classification and multi-task learning, TurboSVM-FL can also be applied. To approach this, separate classification heads for different tasks should be implemented where the backbone encoder shares its weights among tasks, and then TurboSVM-FL should be applied to each head in parallel.

One improvement direction of TurboSVM-FL is to relax the implicit assumption about linear separability of class embeddings with kernelization during SVM fitting and class inference. A piloting ablation study is included in the Appendix in this regard. Furthermore, while posing no additional computation cost on the client side, TurboSVM-FL requires the server to be powerful such that it can fit SVMs efficiently, especially when the SVMs are in one-vs-one (OVO) pattern. We chose OVO instead of OVR (one-vs-rest) mainly for two reasons: 1. in general, OVO performs better than OVR; 2. for TurboSVM-FL, OVO never suffers from class imbalance while OVR always does, since the numbers of samples for each class are always the same. Although OVO imposes more computation on the server side, we think that to approach FL, a powerful server is a must-have, and OVO is no burden for such a server. In case the number of classes is large, the computation burden can be further resolved by sampling a proportion of classes on which SVMs are fitted.

SECTION: Conclusion

In this work, we proposed a novel federated aggregation strategy called TurboSVM-FL, which extensively exploits SVM to conduct selective aggregation and max-margin spread-out regularization for class embeddings and can vastly reduce communication rounds. We tested our approach on three publicly available datasets, and our results show that TurboSVM-FL outperforms existing FL methods largely on convergence rate regarding various metrics.

SECTION: Acknowledgements

We acknowledge the funding by the Deutsche Forschungsgemeinschaft (DFG, German Research Foundation) – Project number KA 4539/5-1.

SECTION: References

SECTION: Appendix AAppendix

SECTION: Implementation

Our implementation of TurboSVM-FL and instructions for reproducing experiment results can be found on our GitHub repository (https://github.com/Kasneci-Lab/TurboSVM-FL).

SECTION: Analysis

It is hard to give an analysis to the convergence rate of TurboSVM-FL directly. Instead, we provide informal descriptive analysis to how TurboSVM-FL is potential to reduce misclassification error. In(Yu et al.2020)it is proven that misclassification error is related to the separation of class embeddings and that the cosine contrastive loss with spread-out regularization surrogates misclassification error, which inspire our work. For detailed proof in this direction, we redirect readers to(Yu et al.2020).

To simplify the analysis, we narrow down to binary classification without loss of generality and ignore all bias terms. In a federated classification task withclients, denote the class embeddings of positive and negative classes asandrespectively. Letbe the indicator of whether a class embedding is used as support vector anddenote the sample size of client. Then, the aggregated class embeddings can be given asand. Letbe the decision boundary of SVM fitted onandbe the corresponding SVM relaxation terms, i.e.:

where the first objective termcorresponds to margin maximization and the second term allows each sample to be away from its correct margin up to distance. Given a new sample with extracted feature, without loss of generality, assume its true label is positive. Further, we assumeis a “good” sample and can be not only correctly but also “well” classified, which meanswith. Letfor all. We then take a look into the difference between the positive and negative logits when class embeddings are projected onto SVM separating hyperplane, i.e.:

When we optimize the aggregated class embeddingswith max-margin spread-out regularization in TurboSVM-FL, we reduceandin essence according to SVM theory, and the term above that bounds logit distance from below is hence increased. As discovered in(Yu et al.2020), a larger distance between class embeddings or logits has the capability to reduce the probability of misclassification. Therefore, the max-margin spread-out regularization on class embeddings is potential to reduce misclassification error when class embeddings are projected onto SVM decision boundary. The effect also propagates to the case when class embeddings are not projected ontogiven.

SECTION: Experiment Environment

We implemented TurboSVM-FL and other FL methods with PyTorch and ran experiments on multiple computers. All computers are equipped with exactly the same hardware (32 GB RAM, Intel i7-13700K, NVIDIA RTX 4080 16 GB), operating system (WSL2 Ubuntu 22.04.2 LTS), and software (Python 3.10.12, PyTorch 2.0.1 for CUDA 11.7).

SECTION: Randomness

All our experiments were replicated five times with different random seeds fromeach time. The random seed applies to,, andto guarantee reproducibility. We reported the mean and standard deviation (std) over five seeds for each metric.

SECTION: Data Distribution

The histograms of number of samples per client of each dataset are given in Figure3.

SECTION: Model Architectures

The FL benchmark framework LEAF(Caldas et al.2018)provides standard model in Tensorflow for each task. We translated all these models into PyTorch and kept their architectures as given in LEAF. Detailed model architectures are described in Tables5,6,7in the Appendix. For all tasks, the activation function for logit layer is softmax, while the classification objective is cross entropy, regardless of whether the classification task is binary or multi-class.

SECTION: Hyperparameters

In the process of hyperparameter tuning and experimentation, we set the client epochto 1 and the number of participating clientsto 8 by default to simulate “lazy” clients. We also ran experiments withand. The results of these experiments can be found in the Appendix.

One key hyperparameter for TurboSVM-FL is the regularization coefficientfor SVM fitting. We tested three different strategies for this coefficient, namely linearly increasing, linearly decreasing, and constant. Among these three strategies, linearly increasing yields the best model performance. Our explanation to this phenomenon is that as training procedure progresses, more client models approach their optima and hence become more informative. A decreasing regularization factor tends to result in an increasing number of support vectors, which matches the increase of client model informativity. We then implemented this strategy as default. Specifically, the regularization coefficient is set toin the beginning and is successively reduced in each global aggregation round.

Another SVM-related factor is whether the SVMs are fitted in one-vs-one (OVO) pattern or one-vs-rest (OVR) pattern. By default, our method trains SVM in OVO pattern, which means that one binary SVM is trained for each class pair, and in total,SVMs are trained for a multi-classification task withclasses. We choose OVO instead of OVR mainly for two reasons. Firstly, OVO performs better than OVR in general. Secondly, for TurboSVM-FL , OVO never suffers from class imbalance while OVR always does, since the numbers of samples for each class in the higher level SVM problem are always the same. Although OVO imposes more computation on the server side, we think that to approach FL, a powerful server is a must-have, and OVO is no burden for such a server. In case the number of classes is large, the computation burden can be further resolved by sampling a proportion of classes on which SVMs are fitted.

When implementing all seven FL algorithms, we followed the recommendations provided in(Reddi et al.2020; Wang et al.2021a)on the choice of optimizers, namely: the optimizer on the client side is SGD, while Adam is applied on the server side for all methods that require a server-level optimizer during central aggregation, including FedAdam, FedAMS, FedAwS, and TurboSVM-FL. For each task, we first ran a grid search for optimal client learning rates infor FedAvg. Then, we fixed the client learning rate to its optima and conducted a grid search for optimal global learning rates in the same range. As FedAMS is an improved version of FedAdam, we applied the same global learning rate for them. The details of learning rates are listed in Table8in the Appendix. Moreover, we decided the sizes of mini-batch based on the sample histograms (Figure3). The final batch sizes are 64 for FEMNIST, 8 for CelebA, and 64 for Shakespeare. The coefficients for additional penalty terms were set toandrespectively for FedProx and MOON.

SECTION: Additional Experiment Results

The results for the experiments using the CelebA dataset and the Shakespeare dataset with default settings () are plotted in Figures4and5. The results corresponding to varying number of participating clients () are given in Tables9and10. The results regarding varying number of client local training epochs () are given in Table11.

SECTION: Kernelization

We extended the vanilla TurboSVM-FL with kernelization during SVM fitting and investigated the influence of kernel on model performance. Specifically, we benchmarked polynomial kernelof different degrees (), rbf kernel, and sigmoid kernelon the CelebA dataset with all coefficientsand biasesset to 1.0. The experiments were run with a single random seed for 200 global aggregation rounds. The number of participating clientsin each aggregation round was 8, and each of them trained its local model forepoch. The obtained results are given in Table12.

For polynomial kernel, the degree and server learning rate have a large impact: a higher degree and higher server learning rate generally lead to better F1 but also overfitting, mostly due to the simplicity of the task (binary) and the scarcity of participating clients (only 8). In comparison, the rbf kernel and sigmoid kernel are not sensitive to server learning rate when coefficient and bias are 1, and both kernels do not yield improvement. Our results show that kernelized SVM can be used for TurboSVM-FL, and we believe with kernelization, more complex FL tasks can be addressed.