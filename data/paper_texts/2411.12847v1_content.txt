SECTION: mDAE : modified Denoising AutoEncoder formissing data imputation

This paper introduces a methodology based on Denoising AutoEncoder (DAE) for missing data imputation. The proposed methodology, called mDAE hereafter, results from a modification of the loss function and a straightforward procedure for choosing the hyper-parameters. An ablation study shows on several UCI Machine Learning Repository datasets, the benefit of using this modified loss function and an overcomplete structure, in terms of Root Mean Squared Error (RMSE) of reconstruction. This numerical study is completed by comparing the mDAE methodology with eight other methods (four standard and four more recent). A criterion called Mean Distance to Best (MDB) is proposed to measure how a method performs globally well on all datasets. This criterion is defined as the mean (over the datasets) of the distances between the RMSE of the considered method and the RMSE of the best
method. According to this criterion, the mDAE methodology was consistently ranked among the top methods (along with SoftImput and missForest), while the four more recent methods were systematically ranked last. The Python code of the numerical study will be available on GitHub so that results can be reproduced or generalized with other datasets and methods.

SECTION: 1Introduction

With the rapid increase in data collection, missing values are a ubiquitous challenge across various domains. Data may be missing for several reasons. For instance, it was never collected, records were lost or merging several datasets failed. It is then generally necessary to deal with this problem before performing machine learning methods on these data. Several options are available to address this issue, including removing or recreating the missing values. Removing rows or columns containing missing data results in a considerable loss of information when missing data is distributed across multiple locations in the dataset. One usually prefers missing-data imputation, which consists of filling missing entries with estimated values using the observed data. Missing data imputation is a very active research area(Van Buuren,2018; Little & Rubin,2019)with more than 150 implementations available according toMayer et al. (2021). This paper focuses on state-of-the-art imputation methods categorized as standard machine learning, deep learning or optimal transport. Methods based on standard machine learning include, among others, k-nearest neighbours(Troyanskaya et al.,2001), matrix completion via iterative soft-thresholded SVD(Mazumder et al.,2010), Multivariate Imputation by Chained Equations(Van Buuren & Groothuis-Oudshoorn,2011)or MissForest(Stekhoven & Bühlmann,2012). Methods based on deep learning include, among others, Generative Adversarial Networks(Goodfellow et al.,2014; Yoon et al.,2018), Variational AutoEncoders(Kingma & Welling,2013; Ivanov et al.,2018; Mattei & Frellsen,2019; Peis et al.,2022)and methods based on Denoising AutoEncoders(see e.g. the review of Pereira et al.,2020). One can also mention the recent works ofMuzellec et al. (2020); Zhao et al. (2023)based on optimal transport.

This paper proposes a modified Denoising AutoEncoder (mDAE) dedicated to imputing missing values in numerical tabular data. AutoEncoders (AE)(Bengio et al.,2009)are artificial neural networks used to learn efficient representation of unlabeled data (encodings) and a decoding function that recreates the input data from the encoded representation. Denoising AutoEncoders (DAEs) were first proposed byVincent et al. (2008)to recover, from noisy data, the original data without noise by corrupting the inputs of a standard AE. For example, inputs can be corrupted by masking noise where a fixed proportion of the inputs are randomly set to 0. DAEs, initially proposed for extracting robust features in the deep learning context, have also been used for missing data imputation(see e.g. Duan et al.,2014; Gondara & Wang,2018; Ryu et al.,2020). Indeed, DAEs, designed to recover a clean output from a noisy input, are naturally suited as an imputation method by considering missing values as a particular case of noisy input. The review ofPereira et al. (2020)covers 26 papers that use AEs and their variants (DAEs and VAEs) for the imputation of tabular data. In all these articles, exceptBeaulieu-Jones & Moore (2017), the reconstruction of missing data with DAEs boils down to applying a DAE to pre-imputed data (e.g., by mean imputation). Pre-imputation solves the problem of loss functions that cannot handle missing values and require all features to be complete. However, in doing so, DAEs learn to reconstruct pre-imputed values, which does not seem relevant. In the same spirit asBeaulieu-Jones & Moore (2017), we propose to deal with this problem by modifying the loss function to ignore pre-imputed missing values. We show in an ablation study that using this modified loss function in the mDAE methodology results in better reconstruction of missing values than using the unmodified loss function on pre-imputed data, thus showing the contribution of the mDAE method compared with previous imputation methods based on DAEs.
Moreover,Pereira et al. (2020)points out that the vast majority of these methods do not present justifications for the decisions performed for the choice of the structure of the DAE and the choice of the hyper-parameters. Most choices are based on empirical guesses, while just a few exceptions use grid-search approaches. Following the recommendations ofPereira et al. (2020), we propose a general and reproducible grid-search methodology for choosing the hyper-parameter and the structure. Moreover, the ablation study provides recommendations for structure and hyper-parameter selection that can be used when the grid-search approach is too computationally expensive.

As mentioned above, the proposed mDAE methodology is evaluated via an ablation study to check the relevance of some of its components (modification of the loss function, choice of the hyperparameter by cross-validation, and overcomplete structure). The importance of each component is evaluated using the Root Mean Squared Error (RMSE) of reconstruction of missing values artificially added to 7 datasets from the UCI Machine Learning RepositoryDua & Graff (2017). As far as we know, there are no standard benchmark datasets for missing data imputation; the 26 papers studied in the review paper ofPereira et al. (2020)almost all use different datasets. Here, we have chosen 7 of the 23 UCI Machine Learning Repository datasets recently used byMuzellec et al. (2020)for imputation methods comparison. These 7 datasets had to be all numerical (as the mDAE method is suited for numerical missing values only), with different sizes, and not too numerous (to avoid the experimental setup being time-consuming and impractical). This ablation study has two objectives. Firstly, the benefits of using the modified loss function will be shown, and thus, the mDAE method will be compared with standard DAE imputation approaches. Secondly, to show the benefit of choosing an overcomplete structure for the DAE and to verify the benefit of choosing the hyper-parameter by optimization in a grid.

After this ablation study, the mDAE method is compared with eight other imputation methods (4 based on standard machine learning and 4 based on deep learning and optimal transport) along with the reference method of mean imputation. The 10 imputation methods are compared using again the Root Mean Squared Error (RMSE) of reconstruction of missing values artificially added to the 7 datasets used in the ablation study. Moreover, as inMuzellec et al. (2020)andZhao et al. (2023), three missing data mechanisms are considered (Missing Completely at Random, Missing At Random, Missing Not At Random). The RMSE scores of the 10 methods are then computed for each of the 7 datasets (and different percentages and mechanisms of artificial missing data). To make results easier to interpret, we propose a new criterion called Mean Distance to the Best (MDB) to measure how a method performs globally well on all datasets (for a given percentage and a given mechanism of artificial missing data). This criterion is defined as the mean (over the datasets) of the distances between the RMSE of the considered method and the RMSE of the best method. It is equal to 0 if the RMSE of the method is the best for all datasets, and it increases if the RMSE of the method is far from the RMSE of the best method, on average, over the datasets.
If the proposed mDAE method sometimes gives the best RMSE score (for a given dataset), it is not true for all datasets. Considering all datasets, the MDB criterion ranks (for all configurations considered in this numerical study) three methods based on standard machine learning and the mDAE methodology in the top 4 positions (for all configurations considered in this numerical study). More precisely, the mDAE method is generally placed second or third for this criterion (alternating with the missForest method), with the SoftImput method always ranked first. It should be noted that the 4 recent methods based on deep learning and optimal transport are always ranked in the last positions, quite far from the best methods.

According toPereira et al. (2020), most papers that use DAEs to impute missing data report better results than SOTA (State Of The Art) methods. However, very different methodologies with different datasets and different SOTA methods were used in these papers, making a general conclusion difficult. One of the contributions of this article is to propose a comparison methodology that is as accurate and reproducible as possible so that other researchers can use it with other datasets or imputation methods using Python codes that will be available on GitHub.

SECTION: 2The mDAE method

AutoEncoders (AE)(Bengio et al.,2009)are well-known artificial neural networks used to learn efficient representation of unlabeled data via an encoding function and to recreate the input data via a decoding function.
Here, we are dealing with the special case of tabular numerical data, and we suppose that these data have been normalized so that thefeatures have zero mean and unit variance. This normalization via feature standardization is more appropriate here than normalizing the values between 0 and 1, as is often done when using autoencoders.
The input of the AE is a then set ofobservationsinwhich forms the rows of a standardized data matrixof dimension, whereis the number of features. The encoding functionof a basic autoencoder (see Figure1) transforms an inputinto a latent vector:

whereis a weight matrix,is a bias vector andis an activation function (e.g., ReLU or sigmoid). The decoding functionthen transforms the latent vectorinto an output:

whereand. Here, the activation functionin the output layer must be the identity function, since we are trying to reconstruct inputs that take their values in. In fact, the sigmoid (resp. ReLu) activation function gives output values between 0 and 1 (resp. positive values) which is not appropriate here.

In general, autoencoders have more than one hidden layer and the parametersof the encoder andof the decoder, are learned by minimization of the so called reconstruction loss. With standardized numerical data, the reconstruction loss usually used to learn weights and biases of an autoencoder is the L2 loss defined by:

whereis the loss function defined here as the squared Euclidean distance between the inputand its reconstruction, andis the Frobenius norm between the data matrixand its reconstructed matrix. Note that this criterion favors the reconstruction of features (columns of) with high variance. It is therefore important that the data matrixis standardized.

Denoising AutoEncoders (DAE)(Vincent et al.,2008)are autoencoders defined to remove noise from a given input. To do this, an autoencoder is trained to output the original data using corrupted data in the input. The masking noise, for instance, is a corrupting process where each observationis corrupted by randomly setting a proportionof its components to zero. Letdenotes this corrupted version of. The lossis here slightly different from the one in (1) as it compares the inputwith the outputobtained with corrupted observations(see Figure2). Thereconstruction loss (1) writes then for DAEs:

Note that the proportionof the masking noise is a hyper-parameter that may need to be calibrated.

SECTION: 2.1Imputing missing values using the mDAE methodology

Although DAE methods were first proposed for extracting robust features in the deep learning contextVincent et al. (2008), they have also been used for missing data imputation(see e.g. the review of Pereira et al.,2020). Indeed, as DAEs had been defined to reconstruct noisy data, they were naturally suited to reconstruct missing data, the missing data then being considered as noise.

AsPereira et al. (2020)point out in their review article, almost all works using DAEs to impute missing data boils down to applying a DAE to pre-imputed data (e.g. by mean imputation). Letbe now the incomplete standardized data matrix (the data matrix with missing values). Pre-imputation ofby the mean of each feature simply consists of replacing missing values with 0 since the data are standardized and, therefore, the feature means are all equal to 0. The pre-imputed data matrixwrites then as the projection ofonto the observed entries:

whereis the set of indiceswhere the valuesare not missing. The DAE is then trained to reconstruct the pre-imputed data matrixby minimization of the reconstruction loss (2) which in this case is:

whereis now the reconstruction of the pre-imputed matrix. After training, the missing values in X are replaced by those reconstructed inand the imputed data matrix is:

whereis the set of indiceswhereis missing.

If using a pre-imputed matrixsolves the problem of the loss function that is unable to handle missing values, minimizing the reconstruction loss (3) learns the DAE to reconstruct zeros at the locations of the missing values, which is irrelevant (see Figure3). Our proposal is then not only to apply a DAE to the pre-imputed data matrix as in previous works, but also to modify the reconstruction error (3) to skip these locations (see Figure4). This methodology, herafter called mDAE, performs a DAE on standardized and pre-imputed data, using the following loss function:

SECTION: 2.2Choice of the hyper-parameter

The hyper-parameterof the mDAE methodology for missing values imputation, is the proportion of zeros used to corrupt the data with the masking noise (red crosses inin Figure4). This hyper-parameter can be chosen randomly in a grid of valuesin. Alternatively, it can be chosen through an optimized procedure to minimize an error of reconstruction of the missing values. For that purpose, the non-missing values of the original data are split into two sets: a training set to learn the parameters and a validation set to estimate the error of reconstruction of missing values. Letbe the subset of indicesof the validation set, drawn randomly from the set of observed entries. For each value ofin the grid, the error of reconstruction of the missing values is estimated using the following procedure:

The parameters of the mDAE are learned on the training setby minimization of the reconstruction loss:

whereis the set of observed entries minus those drawn at random for the validation.

The mean squared error (MSE) of reconstruction of the missing values is estimated on the validation set by:

whereis the matrix reconstructed with the mDAE learned on the training setandis the cardinal of the validation set.

The previous two steps are repeatedtimes (for thedraws of missing values) and the mean of the errors of reconstruction of the missing values is performed to get a more robust estimation.

SECTION: 2.3Choice of the structure

Two families of structures are known for autoencoders. The undercomplete case where the hidden layer is smaller than the input layer and the overcomplete case where it is bigger. If overcomplete structure is not relevant with autoencoders, it is well-known that denoising autoencoders work well with overcomplete structures. Here, a grid of 6 simple structures (2 undercomplete and four overcomplete) is suggested to choose the "best" structure when using the mDAE method (see Figure5). For each structure in this grid, the error of reconstruction of the missing values is estimated on validation data, using the same procedure as for the selection of the hyper-parameter(see section2.2). Ideally, the hyper-parameterand the structure should be chosen simultaneously by exhaustively considering all possible combinations. However, alternative grid search exists, for instance, by sampling a given number of candidates from the parameter space.

SECTION: 3Numerical study

The first part of this numerical study concerns the properties of the mDAE methodology. More specifically, an ablation study is conducted to verify the relevance of the choices made to construct this methodology. The second part compares the mDAE method with other well-known or more recent methods for imputing missing data.

All comparisons are made using seven complete tabular datasets (without missing values) chosen among 23 datasets of the UCI Machine Learning Repository, recently used byMuzellec et al. (2020)for imputation methods comparison. These 7 datasets (see Table1) have been chosen to be all numerical (as the mDAE method is suited for numerical missing values only), with different sizes and not too numerous (to avoid the experimental setup being time-consuming and impractical).

To evaluate the imputation methods, a certain proportion of each dataset is first artificially replaced by missing values. The artificial missing values are drawn using either the MAR (Missing At Random), the MCAR (Missing Completely At Random) or the MNAR (Missing Not At Random) mechanism(see e.g. Rubin,1976). Note that the MCAR and MAR missing values were generated using a logistic masking model as implemented in the GitHub repository ofMuzellec.

Then, for a given maskof artificial missing values, the performance of the method is evaluated using the Root Mean Squared Error (RMSE) between the initial data matrixand the reconstructed data matrixon:

whereis the number of artificial missing values. To get more robust results, the process is repeatedtimes withsets of artificial missing values drawn randomly using one of the three generation mechanisms. Finally, a method is evaluated by the mean and standard deviation of thevalues of RMSE obtained with a certain proportion of artificial missing data and a certain mechanism of missing values (MAR, MCAR or MNAR).

Note that all the results presented in this section are reproducible using Python code, which will be available on GitHub.

SECTION: 3.1Ablation study of the mDAE methodology

An ablation study is a methodology used to evaluate the importance of different components of an algorithm, by comparing the results obtained with and without this component. Here, the following components of the mDAE methodology are studied:

the use of the modified reconstruction loss (5) rather than the standard loss (3),

the use of an optimized value of the hyper-parameter(as described section2.2) rather than a value chosen randomly in,

the use of an overcomplete structure (the 5th structure in Figure5) rather than an undercomplete structure (the 2nd structure in Figure5).

Table2shows the results of the ablation study for the seven datasets and 20% of MCAR artificial missing values. The mean value over thesets of artificial missing values (the standard deviation) of the RMSE of reconstruction of the artificial missing values is calculated for each dataset with the mDAE method, with the method deprived of its modified loss function (i.e. with a standardloss function), with the method deprived of its optimized choice of(i.e. with a random choice), with the method deprived of its overcomplete structure (i.e. with an under complete structure). Each time, the loss of imputation quality (i.e. the increase of the mean RMSE) is measured between the mDAE without one of the three components (the modified loss, an optimized choice ofor an overcomplete structure) and the complete mDAE. For instance, for the breast cancer dataset, using the standardloss increases the mean RMSE of.

The first row in Table2shows that the mDAE methodology with its three components (modified loss function, optimized choice ofand overcomplete structure 5 of Figure5) constantly reconstructs missing data better, except for climate data, where modifying the loss function does not improve the results. It should be noted that this last result is consistent with those obtained byMuzellec et al. (2020), who found that, for the climate dataset (and 30% MCAR), the 5 imputation methods compared in their article gave no better results (in terms of RMSE) than imputation by the mean.

The second row in Table2shows the improvement (in terms of RMSE) when using the modified loss function rather than simply a DAE on pre-imputed data (as in previous works). Not using the modified loss function increases the RMSE for the breast and seeds datasets by up to 50%, thus showing the contribution of the mDAE methodology.

The third row shows that using a random value of the hyper-parameterrather than an optimized one deteriorates the imputation quality for all datasets, but to a lesser extent (between 1 and 8% increase in RMSE). The gain obtained by choosing the bestin a grid rather than randomly inis insignificant. This is an important result, as it allows the user to randomly choose the hyper-parameterinto save computation time when necessary.

The fourth row shows that using an undercomplete structure rather than an overcomplete one clearly increases the RMSE to around 35% for two of the seven datasets. The choice of the structure is a central issue when using DAEs. This result can, therefore, be used to recommend the choice of an overcomplete structure and avoid the search for an optimal structure in a grid. Figure6completes the results of Table2by looking at the results for the 6 different structures given Figure5. It shows that here, the two undercomplete structures always give poorer results than the four overcomplete ones.

Finally, the results of ablation studies for other types of artificial missing values (MAR and MNAR) and other proportions of artificial missing values (20% and 40%) are given in AppendixA. These results confirm the importance of the modification of the loss function, the importance of choosing an overcomplete structure, and the more relative importance of choosingin a grid search rather than a random one.

SECTION: 3.2Comparison with other methods

This section compares the mDAE method with four relatively classic and four more recent methods (see Table3). The four first methods are KNN ((Troyanskaya et al.,2001)) where missing values are replaced by a weighted average of the-nearest neighbours, SoftImput(Mazumder et al.,2010)based on iterative soft-thresholded SVD, and two iterative chained equation methods(Van Buuren & Groothuis-Oudshoorn,2011)which model features with missing values as a function of the others: the missForest method(Stekhoven & Bühlmann,2012)is based on Random Forests and the BayesianRidge method is based on ridge regressions, to estimate at each step the regression functions. The four others (more recent) methods in Table3are GAIN(Yoon et al.,2018)which is an adaptation of Generative Adversarial Networks (GAN)(Goodfellow et al.,2014)to impute missing data, MIWAEMattei & Frellsen (2019)which is an adaptation of Variational AutoEncoders (VAE)(Kingma & Welling,2013), and two methods using optimal transport: the algorithm called Batch Sinkhorn Imputation proposed byMuzellec et al. (2020), and the method TDM proposed byZhao et al. (2023).

For KNN and SoftImpute, the hyperparameters
are selected through cross-validation. According to the implementations used for the two chained equation methods, the hyperparameters of the Bayesian ridge regressions are estimated during the fits of the model. The hyperparameters of the Random Forests are 100 trees, and all features are considered when looking for the best split (i.e., bagged trees). The hyperparameter settings recommended in the corresponding papers and implementations are used for the four last methods. For the mDAE method, the settings studied section3.1(choice ofby crossvalidation and the overcomplete structure 5 of Figure5) are used. More favourable settings for the mDAE method would have been to selectand the structure by cross-validation on all possible parameter combinations. This approach was not adopted for computation time reasons in this numerical study.

With these settings of hyperparameters, the eight methods of Table3, as well as the mDAE method and the basic mean imputation method, are compared in Figure7on the 7 datasets and 20% of MCAR artificial missing values. The mean value (the standard deviation) of the RMSE of reconstruction of the artificial missing values is plotted for each dataset and each method.

We note in Figure7that certain methods like SoftImpute (si), missForest (rf) or mDAE work reasonably well on all datasets (no dataset where the RMSE value is much worse than others). It can also be noted that the mDAE method gives better or equivalent results on the 7 datasets than the four methods based on neural networks and optimal transport (gain, miwae, skh and tdm).

But no method always wins. In order to measure how a method performs globally well on several datasets, we propose to use a new metric called Mean Distance to the Best (MDB) hereafter. Ifdenotes the number of datasets andthe number of methods, the MDB of a methodis defined by:

whereis the RMSE obtained with the methodon the dataset.interprets as the mean (over the datasets) of the distances between the RMSE of the methodand the RMSE of the best method. It is equal to 0 if the methodis the best for all datasets. It increases if the quality of the methodis far from the quality of the best method, on average over the datasets.

Figure8shows the MDB obtained with 20% of artificial MCAR missing values and the quality (the RMSE) of the methods plotted Figure7. This figure shows that the two best methods according to this criterion are SoftImput (si) and missForest (rf). The mDAE method is the 3rd best method. The Figures9,10and11in AppendixBshow the results with 40% of artificial MCAR missing values, and with 20% or 40% of MAR and MNAR missing values. With these different proportions and types of missing data, the top four remains SoftImput, missForest, mDAE and BayesianRidge. SofImpute is always in first place, tied once (40% MAR) with mDAE. The mDAE and missForest methods are generally one or the other in second and third position. The same type of results can be obtained for other proportions of artificial missing values using Python codes that will be available on GitHub. The results obtained, for instance, with 10% of MCAR artificial missing values (see Figure12in AppendixB) confirm that the mDAE methodology and the three methods SoftImput, BayesianRidge, missForest, rank (according to the MDB criterion) ahead of the KNN, ahead of the two methods gain and miwae (based on deep learning) and ahead the two methods skh and tdm (based on optimal transport). The poor results of the four more recent methods based on neural networks and optimal transport (gain, miwae, skh and tdm) can be explained by the difficulty of choosing the best hyper-parameters, the default configurations recommended by the authors having been used here.

SECTION: 4Conclusion

This article proposes a methodology for missing data imputation, based on DAE, as well as a procedure for choosing the hyper-parameters (the proportion of noiseand the structure of the network). An ablation study of this method was performed with different datasets, different types and proportions of missing data. It showed the relatively small improvement of the results when the hyper-parameteris chosen by cross-validation rather than randomly. On the contrary, using an overcomplete rather than an undercomplete network seems appropriate. A specific study is still required to confirm this result, which would enable to recommend the use of a randomand an overcomplete structure.

Then, a numerical study compared the proposed mDAE method with eight other standard or recent missing values imputation methods. The results showed the good behavior of SofImput, mDAE and missForest. A new criterion called Mean Distance to the Best (MDB) was used to compare the methods globally over all the considered datasets and to rank them. The four most recent methods based on deep learning and optimal transport were systematically found in the last four positions for all types and proportions of artificial missing values. One might think these methods give better results with image or natural language processing data. This should be tested more thoroughly. The Python code for this numerical comparison will be made available on GitHub so that it can be reproduced with other datasets or completed with other methods.

Finally, the specific features of the mDAE method should make it possible to consider block-wise missing values by imposing a block-wise structuring of the masking noise. This type of missing data is frequent, for instance, with Electronic health records, longitudinal studies or time series data, where failures in sensors and communication can result in a loss of multiple consecutive data points.

SECTION: References

SECTION: Appendix AAppendix

SECTION: Appendix BAppendix