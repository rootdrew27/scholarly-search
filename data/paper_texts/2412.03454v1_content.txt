SECTION: Decoding Long-duration Gravitational Waves from Binary Neutron Stars with Machine Learning: Parameter Estimation and Equations of State

Gravitational waves (GWs) from binary neutron stars (BNSs) offer valuable understanding of the nature of compact objects and hadronic matter. However, their analysis requires substantial computational resources due to the challenges in Bayesian stochastic sampling.
The third-generation (3G) GW detectors are expected to detect BNS signals with significantly increased signal duration, detection rates, and signal strength, leading to a major computational burden in the 3G era.
We demonstrate a machine learning-based workflow capable of producing source parameter estimation and constraints on equations of state (EOSs) for hours-long BNS signals in seconds with minimal hardware costs. We employ efficient compressions on the GW data and EOS using neural networks, based on which we build normalizing flows for inferences. Given that full Bayesian analysis is prohibitively time-intensive, we validate our model against (semi-)analytical predictions.
Additionally, we estimate the computational demands of BNS signal analysis in the 3G era, showing that the machine learning methods will be crucial for future catalog-level analysis.

Introduction—The detection of gravitational waves (GWs) from binary neutron stars (BNSs)Abbottet al.(2017a,2019a,b)has brought valuable insights into numerous problems in fundamental physics and astrophysicsAbbottet al.(2019a); Deet al.(2018); Mooleyet al.(2018); Capanoet al.(2020); Nichollet al.(2017); Abbottet al.(2018a); Annalaet al.(2018); Kasenet al.(2017); Margalit and Metzger (2017); Abbottet al.(2017c); Baymet al.(2018); Kasliwalet al.(2017); Annalaet al.(2020); Bausweinet al.(2019); Dietrichet al.(2020). In particular, neutron stars (NSs) experience deformation due to the strong tidal forces during the late stages of binaryinspiral, revealing properties of hadronic matter in their extremely dense cores which have not been probed by any other experiments or observations. This makes BNS systems ideal probes of the equation of state (EOS) of NSs, shedding light on strong nuclear interactions in extreme conditionsAbbottet al.(2018a); Annalaet al.(2018); Capanoet al.(2020); Deet al.(2018); Baymet al.(2018); Annalaet al.(2020); Bausweinet al.(2019); Dietrichet al.(2020). Proposed third-generation (3G) GW detectors, including Einstein TelescopePunturoet al.(2010)and Cosmic ExplorerReitze and et al (2019), are expected to detect overBNS events per year with enhanced signal-to-noise ratios (SNRs)Borhanian and Sathyaprakash (2022); Branchesiet al.(2023), offering remarkable potential for groundbreaking discoveries in fundamental particle physics.

However, a series of computationally intensive analyses are required for this purpose.After a BNS is detected, itssource parameters, including component massesand tidal deformability parameters, must be estimated from GW dataDeet al.(2018); Dietrichet al.(2020). For current detectors, this is achieved through stochastic sampling under the Bayesian inference frameworkVeitchet al.(2015), which is the main bottleneck in data analysis due to its high time and hardware costs. WithCPUs, it could take up to hours to days to analyze short-duration (s), low SNR () signals in current detectors. Moreover, the time cost of parameter estimation (PE) scales up with both SNR and signal duration. BNS signals in the 3G detectors may persist for hours due to the improved low-frequency sensitivity, rendering PE exceptionally slow. Although a number of acceleration methods have been proposed, including reducing the size of the dataVinciguerraet al.(2017); Morisaki (2021), speeding up the likelihood evaluationCanizareset al.(2013,2015); Smithet al.(2016); Cornish (2010); Zackayet al.(2018); Leslieet al.(2021), and developing more efficient samplersWilliamset al.(2021); Wonget al.(2023), limited progress has been made toward full PE for such signalsin 3G detectors.Smithet al.(2021)demonstrated the feasibility of using reduced-order-quadratureCanizareset al.(2013,2015); Smithet al.(2016)to analyze long BNS signals and achieved 1600 CPU hours inference time. However, their experiment does not account for the Earth’s rotation, which is important for localizing long signalsZhao and Wen (2018); Hu and Veitch (2023a)and adds additional computational demands to likelihood evaluations.Wonget al.(2023)employed relative binning (also known as heterodyned likelihood)Cornish (2010); Zackayet al.(2018); Leslieet al.(2021)and a gradient-based sampler, achieving 9600 CPU hours inference time for BNS events with potential GPU acceleration, however their example pertains to current detectors and assumes aligned-spin of the BNS system.

The subsequent inference of the EOS, which depends on the source PE, also requires Bayesian stochastic samplingAbbottet al.(2018a). The EOS describes the relationship between pressure () and density () of NS matter, which can be parameterized by piecewise polytropicReadet al.(2009)or spectralLindblom (2010)representations. Posterior samples from PEcan beused to infer parameters of these EOS representations, leading to the constraints of therelation and reflecting the fundamental properties of hadronic interactions. The EOS inference alone can take tens to hundreds CPU hours per event, bringing further burden for the 3G catalogs.

Optimistically assuming 1000 CPU hours to process each event (PE+EOS) and 150 W CPU power, processing a catalog ofBNS events would consume 200 million CPU hours, 30 GWh of electricity and 4.8 million USD in electricity charges per analysis run. This is a substantial burden on current international computing clusters, considering that the LIGO-Virgo-KAGRA (LVK) Computing InfrastructureBagnasco (2023)has fewer than 50k CPU cores - not to mention the budget constraints and environmental impacts. A more detailed estimation of computational costs for 3G detectors can be found in Ref.Hu and Veitch (2024), where the authors obtain similar magnitudes.

Machine learning methods have shown considerable potential in efficient GW data analysis, including signal detectionGebhardet al.(2019); Schäferet al.(2023); Skliriset al.(2020), parameter estimationGabbardet al.(2022); Daxet al.(2021); Langendorffet al.(2023)and subsequentastrophysicalanalysesMcGinnet al.(2024); Stachurskiet al.(2024); Ruheet al.(2022). Specifically, conditional normalizing flows (CNFs)Kobyzevet al.(2020); Papamakarioset al.(2021)are widely used as density estimators to approximate the true posterior distribution, which is traditionally obtained by Bayesian sampling. A CNF is a type of neural network that learnsconditionaldifferentiable and invertible transformations to convert thetarget posteriordistribution to asimpler latentdistribution(e.g. a multivariate Gaussian), dependent on observed data.
It can take observational data as condition, and use it as part of the inputs to predict a conditional mapping between the latent and target distributions.
During inference, samples can be rapidly drawn from the latent distribution and mapped back to the target posterior givenacondition. A series of its successful applications in GW parameter estimation and subsequent probes into fundamental physics, primarily focusing on current detectors or short duration signals, can be found in Refs.Green and Gair (2021); Daxet al.(2021,2023); Gupteet al.(2024); Daxet al.(2024). Notably,Daxet al.(2024), applies CNFs to BNS signals, which is made possible using heterodyning and multibanding, along with a prior conditioning algorithm to train networks adaptable to different mass priors. We adopt a similar framework, but focus on longer signals and higher SNRs which represent the most challenging case in 3G detectors.

In this work, we develop a CNF-based analysis pipeline capable of generating full parameter estimation (with GW phase marginalized) for long signals from precessing BNSs in the 3G GW detectors, and generating EOS estimation within a second on a single GPU. The structure of the pipeline is shown in Fig.1. The first CNF is conditioned on the preprocessed and compressed GW strain data to generate source PE, and the second CNF uses the PE results to infer the NS EOS. Details are provided below.

Parameter space (prior)—BNS parameters, especially the chirp mass, can be tightly constrained by 3G detectorsBorhanian and Sathyaprakash (2022); Branchesiet al.(2023). We find it is extremely challenging to train a model to cover a wide range of chirp mass and SNR, as the posterior is much narrower than the prior (training parameter space). To address this, we divide the parameter space to several regions and train a parameter estimation model for each. As an example, we consider two SNR ranges, 20-50 (low SNR) and 200-500 (high SNR). The former includes the majority of relatively informative BNS events in the 3G era, while the latter represents the louder ones. The detector frame chirp mass is sampled uniformly betweenandfor low SNR prior, andandfor high SNR prior. Given our detector configuration - one triangular ET at ET-D sensitivityHildet al.(2011)atthe existingVirgo site and two 40-km CEs at CE2 design sensitivityReitze and et al (2019)at Hanford and LivingstonAbbottet al.(2017d)- these mass and SNR ranges correspond to source-frame chirp masses consistent with current knowledge of BNS systems. The redshifts of low-SNR and high-SNR BNSs areand, respectively. The mass ratiois sampled uniformly between 0.5 and 1. The dimensionless spins are isotropic with the maximum magnitude of 0.05. Tidaldeformabilityparameters are parameterized asandWadeet al.(2014), whereis uniform between 0 and 1600 following the estimates from GW170817Abbottet al.(2019a), andis uniform within its allowed range, which is determined by component masses andsuch that both components have positive deformability parameters. A wider prior for tidal parameters would benefit the applicability of our model in low mass scenarios, but here we start with 1600 as a proof-of-concept. The prior for extrinsic parameters follows common choices except for luminosity distance: We sample the SNR uniformly in the target SNR band, then scale theaccordingly. This ensures the models consistently encounter similar loudness levels, reducing the number of outliers that are difficult to learn. Although our prior distribution is not perfectly aligned with those used in traditional parameter estimation, this data-independent discrepancy can be removed by importance samplingDaxet al.(2023); Nitz (2024).

Data preprocessing and compression—Considering a frequency band starting from 5 Hz, a three-hour-long BNS signal () with sampling rate of 2048 Hz has roughly 12 million data points,far too many to be used in traditional sampling algorithms.As the GW frequency increases during inspiral, a multibanding schemeVinciguerraet al.(2017); Morisaki (2021), i.e. adaptively adjusting the sampling frequency, is an effective way of reducing the data size and accelerating analyses. We propose a novel multi-banding scheme that adaptively selects frequency nodes and resolutions, ensuring that each band’s resolution is precisely tuned to the needs of BNS signals.
In particular, we divide the full bandwidth into bands containing roughlydata points each, and search from the high frequency cut-off(1024Hz for this work) to lower frequencies until the first frequencysuch that

whereis the time-to-merger function to 3.5 post-Newtonian orderBuonannoet al.(2009), andis a safety factor that enlarges the effective band duration, ensuring that the frequency resolution is high enough to cope with different source parameters and the potential errors in. The frequency resolution in the bandis given by

which corresponds todata in the time domain.
This process is repeated to obtainand the corresponding, until the lower frequency bound reaches the 5 Hz cut-off. This scheme reduces the 12 million data points to approximately 6000 in 81 bands. The selected frequency nodes are shown as black dots in fig.2.

Singular Value Decomposition (SVD) is used to further compress the data by projecting it onto linear bases that represent the waveform space. However, a BNS waveform is highly oscillatory in the frequency domain, making SVD inefficient. FollowingDaxet al.(2024), we employ heterodyning (relative binning)Cornish (2010); Zackayet al.(2018); Leslieet al.(2021)to reduce the oscillation in the data (Fig.2). Specifically, we multiply the signal by a phase factor, which is the inverse of the leading term of the oscillations in GW waveform. This effectively smooths the waveform and improves the compression rate of SVD. With our restricted prior, we can retain the first 128 SVD bases sorted by singular values and reconstruct the zero-noise signal with a median mismatch ofand maximum mismatch of.

Neural networks are then used to further compress the SVD projection of data from multiple detectors. For cross-validation, we explore two types of neural networks for embedding: a residual networkHeet al.(2015)of Multi-Layer Perceptrons (MLPResNet) and a Vision Transformer (ViT)Dosovitskiyet al.(2021). However, due to the larger memory requirement of ViT, we only perform the cross-validation in low-SNR models. The five data streams from the 1ET+2CE network are compressed into a vector of length of 128, which is used to condition CNF for parameter estimation.

Training the parameter estimation model—The training set should comprehensively cover the parameter space, which, in analogy to template bank generationSathyaprakash and Dhurandhar (1991); Brownet al.(2012); Harryet al.(2016); Nitz and Wang (2021), becomes more challenging in low mass, high SNR and high dimension scenarios. Meeting all these factors, we find that large amount of training data is necessary to avoid overfitting.

GW strain data (signal and random Gaussian noise) is simulated on-the-fly during training using the waveform modelIMRPhenomPv2_NRTidalDietrichet al.(2019). Sky location parameters, coalescence time and SNR are randomly generated for each simulation, ensuring an infinite number of possible samples. The remaining 12 parameters are drawn from the prior before training and are used to calculate GW waveform. We save the SVD projections of the waveforms for loading during training. A total of 64 million samples are used to train low-SNR models, and 100 million samples are used for high-SNR models. Waveforms are projected to the detectors with the Earth’s rotation effects included. The CNF model used for PE is a neural spline flowDurkanet al.(2019). Each PE model (embedding network and a CNF) has roughly 160 million learnable parameters with 96 million belonging to the normalizing flow, and all parameters optimized jointly by minimizing the negative log-likelihood. We train the networks for 2-3 weeks on an NVIDIA A100 GPU. Further technical details are given inHu (2024).

The chirp mass used for heterodyning is assumed to be perfectly known when obtaining SVD bases, but it is not known in inference. FollowingDaxet al.(2024), during training, the GW data is heterodyned withinstead of the exact chirp mass, where small perturbationenables the network to deal with inaccuracies in heterodyning. We setuniformly distributed infor low-SNR models andfor high-SNR models.is also given as a condition to the normalizing flow. During inference, the entire chirp mass prior can be divided into several segments of length 0.001 (or 0.0002), with the segment yielding the highest likelihood being selected.

Parameter estimation results—We infer 16 out of the total 17 BNS parameters, with the coalescence phase marginalized by excluding it from the normalizing flow while still incorporating its underlying variations in the data. Example posteriors from low-SNR models are given in Fig.3. Each posterior consists of 5000 samples drawn withins on an NVIDIA 3080Ti GPU. The models provide precise estimation of source parameters and correctly capture some parameter degeneracies, such as those between mass ratioand effective spin. As a cross-check, the two low-SNR models demonstrate good agreement.

Ideally, PE should be examined with several full PE runs using stochastic sampling. However, full PE of precessing BNS sources for the 3G detector network with the Earth rotation included had been a largely under explored domain. Therefore, instead of meticulous comparison of posterior distributions, we assess the correctness of our PE models based on two criteria: precision and accuracy.

The precision, i.e., how tight the source parameters should be constrained, is examined with Fisher matrix formalismFinn (1992)and a semi-analytical Bayesian localization algorithmSealGWHuet al.(2021); Hu and Veitch (2023a).TheFisher matrix formalism predicts the PE precision under high-SNR and Gaussian approximation, whileSealGWgives better source localization as the sky parameter distributions are often non-Gaussian. However, we find the Fisher matrixisnot perfectly reliable for the 17-dimensional problem as it predicts uncertainties of some parameters greater than their physical ranges. This is a common problem with the Fisher matrixformalismBorhanian and Sathyaprakash (2022); Vallisneri (2008). However, it can still serve as a useful diagnostic tool that provides a sense of the PE precision.

Selecting the parameters for which the Fisher matrix gives reasonable results, the comparison is shown in Fig.4.
For most parameters, the ratio of statistical uncertainties peaks at 1, indicating agreement between the flow models and analytical predictions. Low-SNR flow models yield more precise estimations on chirp mass than the Fisher matrix, likely due to the inaccuracies in Fisher matrix in low-SNR, high dimensional scenarios, which improve in the high-SNR case. All flow models give broader constraints on coalescence time than the Fisher matrix. We observe that the CNF posteriors reveal a correlation between the tidal parameterand coalescence time, which Fisher matrix does not capture. This correlation, arising fromthe effect of tidal deformation on the final stage of coalescencecan be reproduced by reducing the Fisher matrix dimensionality, though at the expense of underestimating statistical uncertainties. Therefore, we conclude that the Fisher matrix could be inaccurate on coalescence time, but we can not rule out the possibility of the model not being optimally tuned.
We also note that the Fisher matrix is evaluated at the injection parameters instead of the maximum likelihood parameters, which introduces a theoretical bias in the Fisher matrix estimates and broadens the spread of the uncertainty ratio.

Ourflow models are able to provide precise localization of BNS sources with sky area mostly consistent withSealGW. The last column in fig.4compares the searched area, which measures the accuracy of source localization.Theflow models outperformSealGWin localization accuracy especially in high SNR scenarios, likely due to approximations used inSealGW.

A more direct evaluation of PE accuracy is the p-p test which examines the self-consistencySideryet al.(2014), in the sense thatconfidence interval should successfully predictof events. The p-p plots are shown in Fig.5. All models pass the p-p test.

Constraining equations of state—FollowingMcGinnet al.(2024), we train another CNF based on RealNVPDinhet al.(2017)to infer the NS EOS.
The EOS used for training is generated using the publicly available code CUTERDaviset al.(2024), which uses a semi-agnostic approach with a meta-model constrained by nuclear theory at low density, and piecewise polytropes at high density.
We generate physically plausible BNS source parametersfrom each EOS. The CNF, conditioned on the BNS source parameters, is trained to infer a 12 dimensional representation of the EOS compressed by a convolutional auto-encoder, along with hyperparameters of each EOS, includingmaximum allowed pressure and energy density. Thetrainedauto-encoder can then reconstruct theEOSbyproviding the 12 dimensional representation.

We simulate two BNS events with identical underlying EOS but differing network SNRs of 39 and 390 and then perform parameter estimation with our PE models. The resulting posterior samples are passed to the EOS inference model to generate EOS posteriors (samples of 12D representation plus hyperparameters), which are then decoded into pressure-density relationships using the auto-encoder (Fig.6). We successfully recover the underlying EOS in both cases, with tighter constraints in the high-SNR scenario as expected. The EOS inference takes less than one second, greatlyreducingthe computation cost compared with traditional stochastic sampling.

Discussions—We demonstrate a reliable machine learning based analysis pipeline for long BNS signals in the 3G GW detectors. While certain tasks could be prohibitively slow for traditional methods, our approach processes each event in under a second on a single GPU. This efficiency is crucial for enabling catalog-level analyses in the 3G era.
Assuming one second sampling time and one minutes pre- and post- processing CPU time for PE+EOS analysis per event, the energy cost for analyzing the catalog mentioned in the introduction reduces to 508 kWh, costing approximately 81 USD.
For the training cost, assuming 500 models to cover the parameter space, and each requiring two weeks of training, the training would cost 25.2 MWh and 4000 USD, totaling 25.7 MWh and 4100 USD together with inference. This is more than a thousand times less than traditional methods.
Our model, therefore, presents a feasible and exciting opportunity to advance population-level knowledge of hadronic matter and NS, along with other follow-up science such as cosmologyAbbottet al.(2017c); Soares-Santoset al.(2019); Abbottet al.(2021a), astrophysical populationAbbottet al.(2019b,2021b,2023), stochastic backgroundAbbottet al.(2017e,f,2018b), etc.
We also note that the 500 models could be an overestimation according to Ref.Daxet al.(2024), in which the authors have shown that the CNF framework can be trained on a wider prior, which further reduces the computational costs.

Several potential improvements could enhance our models further. For example, instead of randomly drawing parameters to build training sets of PE models, we could find a more efficient training set that has a smaller size and reduces the training cost. Additionally, importance sampling could be used to improve the accuracy of PE. For EOS inference, combining multiple events would significantly tighten the EOS constraints, as the true underlying EOS would pass posterior parameter regions of all BNS events. Intuitively, this is a more effective way to improve EOS constraints than improving the SNR, because a single tight posterior region still allows a certain level of flexibility in EOS. We also note that the EOS could be constrained better with a higher frequency cutoff in PE.

Looking ahead, there is also a pressing need to adapt these algorithms to more realistic scenarios expected in the 3G detectors. This includes addressing challenges including time variations in noise, overlapping signals, etcHimemotoet al.(2021); Pizzatiet al.(2022); Relton and Raymond (2021); Reltonet al.(2022); Samajdaret al.(2021); Hu and Veitch (2023b), ensuring that the analysis methods remain robust and reliable under all conditions. These improvements and challenges will be explored in our future work.

Acknowledgments—The authors would like to thank Nihar Gupte, Maximilian Dax, Xue-Ting Zhang, and Michael Puerrer for helpful discussions and suggestions. The authors are grateful for computational resources provided by the LIGO Lab at Caltech which is supported by National Science Foundation Grants PHY-0757058 and PHY-0823459. QH is supported by STFC grant ST/Y004256/1 and CSC. JV is supported by STFC grant ST/Y004256/1.

SECTION: References