SECTION: Agent-OM: Leveraging LLM Agents for Ontology Matching

Ontology matching (OM) enables semantic interoperability between different ontologies and resolves their conceptual heterogeneity by aligning related entities. OM systems currently have two prevailing design paradigms: conventional knowledge-based expert systems and newer machine learning-based predictive systems. While large language models (LLMs) and LLM agents have revolutionised data engineering and have been applied creatively in many domains, their potential for OM remains underexplored. This study introduces a novel agent-powered LLM-based design paradigm for OM systems. With consideration of several specific challenges in leveraging LLM agents for OM, we propose a generic framework, namely Agent-OM (Agent for Ontology Matching), consisting of two Siamese agents for retrieval and matching, with a set of simple OM tools. Our framework is implemented in a proof-of-concept system. Evaluations of three Ontology Alignment Evaluation Initiative (OAEI) tracks over state-of-the-art OM systems show that our system can achieve results very close to the long-standing best performance on simple OM tasks and can significantly improve the performance on complex and few-shot OM tasks.

PVLDB Reference Format:PVLDB, 18(1): XXX-XXX, 2025.doi:XX.XX/XXX.XX††This work is licensed under the Creative Commons BY-NC-ND 4.0 International License. Visithttps://creativecommons.org/licenses/by-nc-nd/4.0/to view a copy of this license. For any use beyond those covered by this license, obtain permission by emailinginfo@vldb.org. Copyright is held by the owner/author(s). Publication rights licensed to the VLDB Endowment.Proceedings of the VLDB Endowment, Vol. 18, No. 1 ISSN 2150-8097.doi:XX.XX/XXX.XX

PVLDB Artifact Availability:The source code, data, and/or other artifacts have been made available athttps://github.com/qzc438/ontology-llm.

SECTION: 1.Introduction

Large language models (LLMs) are pre-trained with an enormous corpus of common knowledge and therefore have powerful generative capabilities. Despite the success of using LLMs in a wide range of applications, leveraging LLMs for downstream tasks still has several challenges. (1) LLMs are pre-trained models that do not capture late-breaking information. (2) LLM hallucinations are often observed in domain-specific tasks and hamper their reliability. LLMs often generate unsound responses that are syntactically sound but factually incorrect(Ji et al.,2023). (3) LLMs are good models of linguistic competence, but have shown limited capabilities in non-linguistic tasks, such as planning and routing(Valmeekam et al.,2022). LLMs are originally designed for sequential question-answering, but most real-world tasks are designed with complex logic rather than following a single path.

To overcome the limitations of LLM customisation for downstream tasks, LLM-based autonomous agents have become a prominent research area. In the field of artificial intelligence (AI), the notion of agents was first introduced in the famous Turing Test(Turing,2009), referring to intelligent computational entities that can display human-like behaviours. Such AI agents have fallen short of human-level capabilities, as they can only act on simple and heuristic policy functions learnt from constrained environments and they lack efficient central control to simulate the human learning process(Wang et al.,2024). LLMs, with remarkable success in demonstrating autonomy, reactivity, proactivity, and social ability, have attracted growing research efforts aiming to construct AI agents, so-called LLM agents(Xi et al.,2023).

The core concept of LLM agents is to employ the LLM as a controller or “brain” rather than as a predictive model only (a.k.a Model as a Service). LLM agents extend LLM’s capability with advanced planning, memory, and pluggable tools, and allow LLMs to communicate with open-world knowledge(Weng,2023). (1) Planning breaks down a complex task into simpler and more manageable subtasks. LLMs can also receive feedback on plans and perform reflection and refinement. The most practical technique used for LLM planning is chain of thought (CoT)(Wei et al.,2022). (2) Tools allow LLMs to call external resources for additional information. They are often invoked by LLM actions. (3) Memory provides context to inherently stateless LLMs, including short-term and long-term memory. Short-term memory can be considered as context information obtained from planning and tools via in-context learning (ICL)(Brown et al.,2020). Long-term memory often uses database storage with retrieval-augmented generation (RAG)(Lewis et al.,2020)to retain information. Unlike fine-tuning, where models need to be retrained to learn new context data, ICL/RAG instead augments the LLM prompts with new information. ICL/RAG is more scalable for working with dynamic information. Almost 90% of use cases can be achieved by ICL/RAG-based search and retrieval(Microsoft Azure,[n.d.]). A recent paper(Ovadia et al.,2024)demonstrates that RAG surpasses fine-tuning across a wide spectrum of knowledge-intensive tasks.

Ontology matching (OM) is a classic alignment task, aiming to find possible correspondences between a pair of ontologies(Euzenat and Shvaiko,2013). OM systems are developed to automate this matching process. There are two dominant design paradigms for OM systems: traditional knowledge-based OM systems that implement pre-defined logic and expert knowledge; and more recent machine learning-based OM systems that transform the matching task into machine-enhanced learning and prediction. The former expert systems require intensive expert knowledge, while the latter predictive systems need a large amount of high-quality data to train the model. The prevalence of LLMs and LLM agents has driven many successful domain-specific applications. However, in the context of OM, using LLMs and LLM agents is currently under-explored. Leveraging LLMs and LLM agents for OM tasks is not an intuitive task; the challenges will be presented in the Related Work section.

This paper introduces a novel agent-powered LLM-based design paradigm for OM systems. We propose a generic framework and implement it with a proof-of-concept system. The system extends the LLM capability beyond general question-answering, offering a powerful problem solver for OM tasks. The system includes tools that facilitate information retrieval, entity matching, and memory storage. The system is compared to state-of-the-art OM systems, achieving considerable matching performance improvements across three Alignment Evaluation Initiative (OAEI) tracks. Specifically, this paper makes the following contributions:

We introduce a new agent-powered LLM-based design paradigm for OM systems and propose a novel Agent-OM framework. It consists of the following key components:

A LLM acts as a central “brain” to link different modules and instruct their functions via prompt engineering;

A pair of planning modules use CoT for OM decomposition;

A set of OM tools use ICL/RAG to mitigate LLM hallucinations;

A shared memory module uses dialogue and hybrid data storage to support the search and retrieval of entity mappings.

We implement our proposed Agent-OM framework in a proof-of-concept system. The system deals with several critical downstream challenges in leveraging LLM agents for OM, such as cost-effective entity information retrieval, matching candidate selection, and search-based matching functions.

The experimental results of the system show that Agent-OM achieves results very close to the best long-standing performance on simple OM tasks and significantly improves matching performance on complex and few-shot OM tasks.

An ontology contains classes, properties, and individuals. In this paper, we consider only classes and properties, and individuals are excluded. Possible logical relations between classes (respectively properties) can be equivalence () and subsumption (either). In this study, we only consider the logical relation of equivalence () between classes/properties.

The rest of the paper is organised as follows. Section2reviews related work. We illustrate the design of our agent-powered LLM-based OM framework in Section3and present implementation details in Section4. Section5and6evaluate the system, with a discussion in Section7. We discuss the limitations and future work in Section8and9, respectively. Section10concludes the paper.

SECTION: 2.Related Work

OM is typically a non-trivial but essential alignment task for data integration, information sharing, and knowledge discovery(Shvaiko and Euzenat,2013). While matching is a prerequisite for interoperating applications with heterogeneous ontologies, OM systems are designed to partially or fully automate matching. The traditional approach using knowledge-based OM systems, such as LogMap(Jiménez-Ruiz and Cuenca Grau,2011; Jiménez-Ruiz et al.,2011), AgreementMakerLight (AML)(Faria et al.,2013,2014), and FCA-Map(Zhao et al.,2018; Li et al.,2021)has been shown to be precise and effective. However, it is resource-hungry and labour-intensive. It is often difficult to find domain experts to evaluate the matches, and any group of experts may not be able to cover all domain concepts that an expert system requires. A new approach uses machine learning (ML), implemented in systems such as BERTMap(He et al.,2022), LogMap-ML(Chen et al.,2021), and VersaMatch(Fürst et al.,2023). ML-based OM systems employ the concept of training and testing in ML, using ontology entities as features for model training or for fine-tuning and then using the model to predict additional correspondences. Specifically, the leading system BERTMap uses a common language model originating from natural language processing (NLP) (i.e. BERT(Devlin et al.,2019)).

Although ML-based approaches have shown a significant improvement in matching performance, their training-testing paradigm is not feasible for LLMs. The number of parameters used in LLMs is much larger than those of common language models. This means re-training the entire LLM is usually infeasible, and fine-tuning such a large model requires a number of samples that may be infeasibly large for OM. A survey in(Zong and Krishnamachari,2022)implies that 1000 is a reasonable number of training samples to fine-tune GPT-3, but generally speaking, a domain ontology has only around 100-200 entities. Furthermore, currently some LLMs are only accessible through a web service. This means that training or fine-tuning LLMs risks leaking sensitive information, while synthetic data, on the other hand, makes it difficult to ensure training quality.

Early studies using LLMs for OM can be found in(He et al.,2023a)and(Norouzi et al.,2023). Both works use a purely prompt-based approach via ChatGPT. The prompts are structured as a binary question: given an entity from the source ontology and an entity from the target ontology, the LLMs perform a classification task to determine whether these two entities are identical or not. A similar approach is also used in OLaLa(Hertling and Paulheim,2023)and(Babaei Giglou et al.,2023a), but their candidate generation is integrated with text embedding extractor models. The authors of(Amini et al.,2024)explore the potential of using LLMs for complex ontology OM challenges.

LLM agents begin to take shape in AutoGPT(Auto-GPT,2024)and BabyAGI(Nakajima,2024). The recent release ofOpenAI GPTs(OpenAI,[n.d.]a),Microsoft Copilot(Microsoft,[n.d.]a)andCopilot Studio(Microsoft,[n.d.]b)sparked an interest in “the world of LLM agents”. Building applications with LLM agents allows users to build their own custom GPTs to support custom business scenarios. In ontology-related tasks, LLM-driven agents have shown impressive performance in automating manual activities in the broader task of ontology engineering(Zhang et al.,2024a; Babaei Giglou et al.,2023b). These works pay attention to the use of conversational dialogue to enhance the agent’s capability with human feedback. While this is suitable for tasks that require humans to be in the loop, such as collecting competency questions in ontology engineering or validating extended terms in ontology learning, modern OM seeks to automate a complex task with minimal human intervention. Contrasting with these works, our aim is to design a new infrastructure that is able to instruct LLM agents to use planning to decompose a complex task into steps and to use tools to facilitate automated matching (a.k.a. function calling), instead of purely using agent-based conversational dialogue, even when specialised as ontology-oriented dialogue like(Payne and Tamma,2014; Zhang et al.,2024b).

We introduce our novel agent-powered LLM-based design paradigm for OM systems. We have two generic agents; each one is self-contained and designed to instruct LLMs to use extensive planning, memory, and tools, thus unlocking their generative capacity to handle various types of OM tasks in different contexts. Meanwhile, as a key enabler for precise decision-making, we also limit the current LLM’s flaws in hallucination, context understanding, and non-linguistic reasoning. Several OM-related tools have been created for this purpose. These tools enable LLM agents to simulate a traditional OM system, automating the entire matching process without human intervention. The overall infrastructure offers high scalability and allows extensive customisation. To the best of our knowledge, this study is the first to introduce an LLM-agent-based framework for OM tasks.

SECTION: 3.Matching with LLM Agents

Given a source ontology () and a target ontology (), OM aims to find an alignment (A) that contains a set of pairs-matched entities. A classical matching process has two main steps: retrieval and matching. The retrieval step involves retrieving internal information from the ontology itself () and external information from a domain-specific thesaurus (). The matching step involves selecting the matching candidates (), running the matching algorithms (), and refining the matching results (). A classical OM can be formulated as:

Figure1shows the architecture ofAgent-OM, our LLM-based agent-powered OM framework. It retains the original input and output of the classical OM but modularises the two main steps with autonomous LLM agents, namely Retrieval Agent () and Matching Agent (). We call these two LLM agents “Siamese” because they have their own planning modules and related tools but share memory. The memory is responsible for storing the information retrieved from the Retrieval Agent () and facilitating the search of the stored information by the Matching Agent (). Therefore, an agent-based OM is formulated as:

For each autonomous agent, the workflow is described as follows. The planning module decomposes a complex task into several subtasks and defines the order of subtasks and tools to be invoked. The plan is stored in the dialogue and passed to the LLMs. LLMs then invoke the tools to perform the subtasks. The tools may communicate with each other, with intermediate results stored in the dialogue. The tools can also access the database via the CRUD (create, read, update, and delete) functions provided. The entire workflow is driven by LLM prompts. We use solid lines to show the actual workflow controlled by the LLMs, and dotted lines to show the implicit link between a subtask and its corresponding tool activated by the LLMs.

SECTION: 3.1.Retrieval Agent

The Retrieval Agent is responsible for extracting entities from the ontologies, eliciting their metadata and ontology context information, and storing them in the hybrid database. For each entity extracted from the source and target ontologies, the planning module generates the instruction for retrieving the relevant information and feeding it into the LLMs to invoke the corresponding retrieval tools. The tools used in the Retrieval Agent include Metadata Retriever, Syntactic & Lexical & Semantic Retriever, and Hybrid Database Store with Content Embedder, described as follows.

Metadata Retriever (): The metadata retriever collects the metadata of the input entity from the ontology, including itscategory(i.e. either from thesourceontology or from thetargetontology) andtype(i.e.named classorproperty).

Syntactic Retriever (): The syntactic retriever is responsible for providing a unified text preprocessing result. A common text preprocessing pipeline consists of tokenisation, normalisation, stop-words removal, and stemming/lemmatisation(Anandarajan et al.,2019). According to our prior study(Qiang et al.,2024), only tokenisation and normalisation help both matching completeness and correctness. The other two pipeline methods, stop-words removal and stemming/lemmatisation, could cause unwanted false mappings. For this reason, our syntactic retriever considers only tokenisation and normalisation. We select white spaces to separate the words so that the outputs are short sentences that are easier for LLMs to interpret.

Lexical Retriever (&): We consider three key aspects of the entity’s lexical information: the general meaning (), the context meaning (), and the content meaning (). In the context of OM, the general meaning is traditionally generated from Wikidata(Vrandečić and Krötzsch,2014)or similar corpus-based knowledge bases (KBs). As LLMs are trained from these KBs, we use the prompt “What is the meaning of {entity_name}?” for the same function. However, using only the general meaning is not sufficient. Using the context constraint “in the context of {context}” is effective in domain-specific tasks. Popular GPT-based domain applications, such as Law-GPT(Liu et al.,2023)and Medical-GPT(Wang et al.,2023a), use similar approaches. Additionally, we also retrieve content information fromrdfs:label,rdfs:comment,skos:prefLabel, andskos:definitionproperties, where the ontology creators may add comments or explanations. These are also useful for retrieving the meaning of the entity.

Semantic Retriever (): The entity’s semantic information includes its basic triple-based relations and more complex logic-based axioms. In this paper, we only consider triple-based relations that can be verbalised into a more natural language-like presentation via a prompt-based verbalisation tool. Such verbalisation tools are not capable of handling complex logic-based axioms. These functions can only be achieved with external packages, such as OWL Verbaliser(Kaljurand,2007), Sydney OWL Syntax(Cregan et al.,2007), and the DeepOnto(He et al.,2024)verbalisation module(He et al.,2023b).

Hybrid Database Store with Content Embedder (): We use a hybrid database system consisting of a traditional relational database and an advanced vector database. Entity metadata, such as the entity’s category and type, are stored in the traditional relational database. In contrast, natural language-based content information, such as the entity’s syntactic, lexical, and semantic information, is vectorised via an embedding model and then stored in the vector database to enable similarity search based on relative distance in the embedding space. A unique key links these two databases.

SECTION: 3.2.Matching Agent

The Matching Agent is responsible for finding possible correspondences, ranking and refining the results according to different criteria, and selecting the most relevant candidate. For each entity extracted from the ontologies, the planning module generates the instruction for the matching types to be considered and feeds it into the LLMs to invoke the corresponding matching tools. The planning module first selects the source ontology as a starting point, extracting the entities from the ontology. Then, different matchers perform syntactic, lexical, or semantic matching functions to find the most relevant mappings to the input entity, using a hybrid database search across the relational and vector databases. A predicted mapping is based on a summarised profile measure of syntactic matching, lexical matching, and semantic matching, with matching validation. The same procedure applies to the target ontology as a starting point, and the results of the common candidates are combined. The tools used in the Matching Agent include Hybrid Database Search, Metadata Matcher, Syntactic & Lexical & Semantic Matcher, Matching Summariser, Matching Validator, and Matching Merger.

Hybrid Database Search (): The hybrid database search serves as an interface for the database accessible by the Metadata Matcher and Syntactic & Lexical & Semantic Matcher.

Metadata Matcher (): Given an input entity, the metadata matcher collects the type and category of the input entity from the relational database.

Syntactic & Lexical & Semantic Matcher (): Given an input entity, the syntactic & lexical & semantic matchers search for similar syntactic/lexical/semantic information respectively in the vector database using cosine similarity, defined for entitiesandas:

An extended search in the relational database is then used to filter the results based on the entity’s metadata.

Matching Summariser (): We use reciprocal rank fusion (RRF)(Cormack et al.,2009)to summarise the matching results. Viewing each of the syntactic, lexical, and semantic descriptions as a document, the purpose of reciprocal rank is to accumulate the inverse of the ranksof documentsover three ranking results from syntactic, lexical, and semantic matching, defined as:

is a constant parameter that is conventionally set to 0 as we do here. This ensures that the formula most highly rewards highly ranked entities. In our case, we are evaluating each entity that occurs in the top@k of each of the three rankings (i.e. syntactic matching, lexical matching, and semantic matching), and combining their results as an overall matching summary.

Matching Validator (): Validation is a critical step in minimising LLM hallucinations, as illustrated in SelfCheckGPT(Manakul et al.,2023)and Self-RAG(Asai et al.,2023). We also apply this method to the summarised results. We ask the LLM a binary question “Is {entity} equivalent to {predicted_entity}? Answer the question in the context of {context}.” to check whether the predicted entity is equivalent to the input entity in the provided context. For computational efficiency, we iterate the comparison from rank 1 toand select the highest-ranked match with a ”yes” answer for the matching merger step.

Matching Merger (): The matching merger is responsible for combining the results from a search of the source ontology and a search of the target ontology. In this study, we select only the correspondences found on both sides. As an agent-based system, this can be extended to use multi-agent negotiation via the correspondence inclusion dialogue(Payne and Tamma,2014).

SECTION: 4.Implementation Details

We implement our design of the framework in a proof-of-concept system. The components and their implementation are as follows:

LLMs: Our system supports a wide range of LLMs, including OpenAI GPT(OpenAI,2024), Anthropic Claude(Anthropic,2024), Meta Llama(Meta,2024), Alibaba Qwen(Alibaba,2024), Google Gemma(Google,2024), and ChatGLM(Zeng et al.,2024). We select 10 models for this study. 4 models are API-accessed commercial LLMs, while the other 6 are open-source LLMs. Table1gives the details. For API-accessed LLMs, we include two models of different sizes for each category. For open-source LLMs, we select models with similar sizes (7-9 billion parameters) from different categories. They are accessed via the Ollama library(Ollama,2024).

FamilyModelSizeVersionGPTgpt-4oN/Agpt-4o-2024-05-13gpt-4o-miniN/Agpt-4o-mini-2024-07-18Claudeclaude-3-sonnetN/Aclaude-3-sonnet-20240229claude-3-haikuN/Aclaude-3-haiku-20240307Llamallama-3-8b*4.7 GBOllama Model ID: 365c0bd3c000llama-3.1-8b*4.9 GBOllama Model ID: 46e0c10c039eQwenqwen-2-7b*4.4 GBOllama Model ID: dd314f039b9dqwen-2.5-7b*4.7 GBOllama Model ID: 845dbda0ea48Gemmagemma-2-9b*5.4 GBOllama Model ID: ff02c3702f32GLMglm-4-9b*5.5 GBOllama Model ID: 5b699761eca5* indicates open-source LLMs (date accessed: 2024-12-01).

Planning: We select the LangChain library(LangChain,[n.d.]). The library provides a wide range of agents. We select the tool calling agent (a.k.a function calling agent). At the time of writing, the LangChain package only supports this type of agent used with commercial API-accessed LLMs. To extend our framework to open-source LLMs, we employ the similar concept of “chain” to simulate tool calling agents for open-source LLMs.

Memory: (1) Short-term memory: We use a conversational dialogue to store the original intermediate output of each operating process, with no map-reduce applied. (2) Long-term memory: We select a hybrid database consisting of a traditional relational database and an advanced vector database. PostgreSQL(PostgreSQL Global Development Group,[n.d.]b)supports a standalone integration of the traditional relational database and the extended vector database using pgvector(PostgreSQL Global Development Group,[n.d.]a). We select OpenAI Embedding(OpenAI,[n.d.]b)for the content embedding in the vector database. Alternatives are VertexAIEmbeddings(Google Cloud,[n.d.])or Sentence-BERT(Reimers and Gurevych,2019), but the dimension of the embedding changes between different embedding models.

Tools: To demonstrate the flexibility of our framework, we present the usage of prompt-based tools and programming-based tools, as well as the tools that combine a mixture of prompt-based and programming-based tools.

SECTION: 4.1.Ontology Naming Conventions

In this work, the termentityis a general expression for ontology classes or properties (without specifying which). We useentity urito mean a fully expanded class name or property name with respect to its prefix. We useentity nameto mean a class name or property name without its prefix. For example,entity uriis “http://cmt#ProgramCommitteeChair” and theentity nameis “ProgramCommitteeChair”.

Naming conventions for entity names fall into two categories: the name has a natural language meaning (Type 1); or the name is a code (Type 2). We observe that LLMs can perform well with meaningful entity names (e.g. ProgramCommitteeChair and Chair_PC). Often in larger biomedical ontologies each entity name is a unique identifier or code, and the meaningful description of the entity is in its label or comment (e.g. MA_0000270 and NCI_C33736). For this type of naming convention, LLMs tend to generate the wrong synthesised label or comment corresponding to the code. For example, LLMs can mistakenly interpret the codes “MA_0000270” and “NCI_C33736” to be“limb” and “Extremity”, while the intended meanings of these two codes are “eyelid tarsus” and “Tarsal_Plate”.

To handle the variety of ontology naming conventions and standardise their usage in LLM-based OM, we use a unified naming convention in this study. For an entity with a unique identifier or code, we use its label or comment instead. For example, we use “eyelid tarsus” and “Tarsal_Plate” instead of “MA_0000270” and “NCI_C33736” respectively. In case the two ontologies reuse the same entity name, we add the type as a prefix for each entity. For example, if it were the case that ”ProgramCommitteeChair” appears in both the source ontology and the target ontology, the unique identifier for each entity would be like “026-Source-Class-ProgramCommitteeChair” and “042-Target-Class-ProgramCommitteeChair”.

SECTION: 4.2.Running Example

To demonstrate the usability of our framework, we choose the CMT-ConfOf alignment as a sample alignment. The CMT Ontology is the source and the ConfOf Ontology is the target. These two ontologies contain similar concepts related to conference organisation. The running example aims to find the best matching entity in the target corresponding to the entity “http://cmt#ProgramCommitteeChair” in the source.

Table2illustrates the actions performed by the Retrieval Agent. We use a prompt to invoke the Metadata Retriever, Syntactic & Lexical & Semantic Retriever, and Hybrid Database Store with Content Embedder in sequential order.

For the input “http://cmt#ProgramCommitteeChair” from the source ontology, the output of the Syntactic Retriever is “program committee chair”. The agent further invokes the Lexical Retriever to generate a detailed description: “In the context of a conference, ‘ProgramCommitteeChair’ refers to …”. The Semantic Retriever generates related triple relations, such as “ProgramCommitteeChair rdfs:subClassOf ProgramCommitteeMember”. These triples are verbalised using natural language: “ProgramCommitteeChair” is a subclass of “ProgramCommitteeMember”.

While each entity has its own syntactic, lexical, and semantic information, a naive approach to deciding if two entities are the same is to generate a binary question for every pair of entities as a prompt to the LLM: “Is Entity1 equivalent to Entity2? Consider the following: The syntactic information of Entity1 is… The lexical information of Entity1 is… The semantic information of Entity1 is… The syntactic information of Entity2 is… The lexical information of Entity2 is… The semantic information of Entity2 is… ” This approach has two limitations. (1) LLMs have token limits that restrict the number of tokens processed for each interaction. Combining all the retrieved information may exceed token limits. (2) The binary comparison is costly because the complexity of the comparison is the Cartesian product of the number of entities in the source ontology and the target ontology.

We bypass these limitations by (1) using an open question instead and (2) storing useful information in a searchable database. Figure2shows the entity metadata and content information stored in the relational database and the vector database, respectively. On one hand, the entity’s metadata is needed to find an exact match. In other words, the matched entity needs to have the same metadata as the target entity. For example, “http://cmt#ProgramCommitteeChair” is a class in the source ontology, so the matched entity should be a class in the target ontology. On the other hand, content information including an entity’s syntactic, lexical, and semantic information is used for a similarity-based match because they are usually retrieved as natural language, which can be more ambiguous than metadata. Similarity between natural language terms is commonly based on embedding vectors, for which the vector database enables fast similarity searches.

Tool: Metadata RetrieverInput:{entity_uri} = “http://cmt#ProgramCommitteeChair”Extract:{source_or_target} = “Source”, {entity_type} = “Class”Tool: Syntactic RetrieverInput:{entity_uri} = “http://cmt#ProgramCommitteeChair”Extract:{entity_name} = “ProgramCommitteeChair” based on {entity_uri}.Function Calling:cleaning(entity_name)Output:“program committee chair” (AI-generated content)Tool: Lexical RetrieverInput:{entity_uri} = “http://cmt#ProgramCommitteeChair”, {context} = “conference”Extract:{entity_name} = “ProgramCommitteeChair” based on {entity_uri}.{extra_information} based on {entity_name} related rdfs:label, rdfs:comment, skos:prefLabel, and skos:definition.Prompt:Question: What is the meaning of entity_name? Context:{context}Extra Information:{extra_information}Answer the question within the context and using the extra information.Output:“In the context of a conference, ‘ProgramCommitteeChair’ refers to…” (AI-generated content)Tool: Semantic RetrieverInput:{entity_uri} = “http://cmt#ProgramCommitteeChair”Function Calling:generate_subgraph(entity_uri)Output:subgraphPrompt:Verbalise triples into phrases using spoken language:{subgraph}Output:“The class ‘ProgramCommitteeChair’ is a subclass of ‘ProgramCommitteeMember’…” (AI-generated content)Tool: Hybrid Database Store with Content EmbedderInput:{entity_uri} = “http://cmt#ProgramCommitteeChair”, {source_or_target} = “Source”, {entity_type} = “Class”Extract:{entity_id} = “023-Source-Class-ProgramCommitteeChair”Query: Create a relational database and store entity’s metadata⬇DROPTABLEIFEXISTSontology_matchingCASCADE;CREATETABLE(entity_idVARCHAR(1024)PRIMARYKEY,entityTEXT,source_or_targetTEXT,entity_typeTEXT);INSERTINTOontology_matching(entity_id,entity,source_or_target,entity_type)VALUES({entity_id},{entity},{source_or_target},{entity_type});Input: {entity_syntactic} = “program committee chair”, {entity_lexical} = “In the context of conference, ‘ProgramCommitteeChair’ refers to…”,{entity_semantic} = “The class ‘ProgramCommitteeChair’ is a subclass of ‘ProgramCommitteeMember’…”,{matching_table} = ”syntactic_matching/lexical_matching/semantic_matching”Extract: {entity_embedding} based on {entity_syntactic}/{entity_lexical}/{entity_semantic}.Query: Create a vector database and store entity’s syntactic, lexical, and semantic information⬇CREATEEXTENSIONIFNOTEXISTSvector;DROPTABLEIFEXISTS{matching_table};CREATETABLE{matching_table}(entity_idVARCHAR(1024)NOTNULLREFERENCESontology_matching(entity_id),contentTEXT,embeddingvector(1536));INSERTINTO{matching_table}(entity_id,content,embedding)VALUES({entity_id},{entity_syntactic}/{entity_lexical}/{entity_semantic},{entity_embedding});Output:One relational database table (ontology_matching) and three vector database tables (syntactic_matching, lexical_matching, and semantic_matching).

Tool: Metadata Matcher with Hybrid Database SearchInput:{entity_uri} = “http://cmt#ProgramCommitteeChair”, {source_or_target} = “Source”{matching_table} = “syntactic_matching/lexical_matching/semantic_matching”Query: Get entity id⬇SELECTo.entity_idFROMontology_matchingoWHEREo.entity={entity_uri}ando.source_or_target={source_or_target}Output:{entity_id} = “023-Source-Class-ProgramCommitteeChair”Query: Get entity metadata⬇SELECTo.entity_type,m.content_embeddingFromontology_matchingo,{matching_table}mWHEREo.entity_id=m.entity_idANDo.entity_id={entity_id};Output:{entity_type} = “Class”, {content_embedding} = […]Tool: Syntactic & Lexical & Semantic Matcher with Hybrid Database Search and Similarity SearchInput:{content_embedding} = […], {matching_table} = “syntactic_matching/lexical_matching/semantic_matching”,{similarity_threshold} = 0.90, {top_k} = 3, {source_or_target} = “Source”, {entity_type} = “Class”Query: Search for similar entities⬇WITHvector_matchesAS(SELECTentity_id,1-(content_embedding<=>‘{content_embedding}’)ASsimilarityFROM{matching_table}WHERE1-(content_embedding<=>‘{content_embedding}’)>{similarity_threshold})SELECTo.entity_id,v.similarityassimilarityFROMontology_matchingo,vector_matchesvWHEREo.entity_idIN(SELECTentity_idFROMvector_matches)ANDo.entity_id=v.entity_idANDo.source_or_target!={source_or_target}ANDo.entity_type={entity_type}ORDERBYsimilarityDESCLIMIT{top_k};Output:{rankings} = [syntactic_matching: [], lexical_matching: [‘095-Target-Class-Chair_PC’],
semantic_matching: [‘103-Target-Class-Member_PC’, ‘092-Target-Class-Author’, ‘123-Target-Class-University’]]
(AI-generated content)Tool: Matching SummariserFunction Calling:reciprocal_rank_fusion(rankings)Output:{matching_summary} = [(1.0, [“095-Target-Class-Chair_PC”, “103-Target-Class-Member_PC”]), (0.5, [“092-Target-Class-Author”]), (0.33, [“123-Target-Class-University”])] (AI-generated content)Tool: Matching ValidatorInput:{context} = “conference”, {matching_summary} = […]Extract:Each {predicted_entity} from {matching_summary}. Stop on finding a “yes” answer.Prompt:Question: Is{entity}equivalent to{predicted_entity}? Context:{context}Answer the question within the context. Answer yes or no. Give a short explanation.Output:{entity_id} = “095-Target-Class-Chair_PC”“095-Target-Class-Chair_PC”: “Yes. In the context of a conference, the term ”program committee chair” is equivalent to ”chair PC.” Both refer to the individual responsible for leading the program committee, which is in charge of organizing and overseeing the review and selection of conference submissions.”“103-Target-Class-Member_PC”: “No. The program committee chair is not equivalent to a member of the program committee (PC). The chair is responsible for overseeing the entire review process, coordinating the activities of the PC members, and making final decisions on the conference program. In contrast, a PC member primarily reviews and evaluates submitted papers.” (AI-generated content)Query: Get entity⬇SELECTo.entityFROMontology_matchingoWHEREo.entity_id={entity_id}Output:{entity} = “http://confOf#Chair_PC”Tool: Matching MergerOutput:Merge entities found in the target ontology that are equivalent to “http://confOf#Chair_PC” in the source ontology.

Table3demonstrates the actions performed by the Matching Agent. We use a prompt to invoke the Metadata Matcher with Hybrid Database Search, Syntactic & Lexical & Semantic Matcher with Hybrid Database Search and Similarity Search, Matching Sunmmariser, Matching Validator, and Matching Merger in sequential order.

For a given entity “http://cmt#ProgramCommitteeChair” from the source ontology, the most relevant entity found by each matcher is stored in short-term memory and combined using the RRF function. The result of the Matching Summariser is a list of predicted mappings. The last step is to refine the predicted mappings. The Matching Validator asks a binary question to compare whether the given entity is the same or different to the predicted relevant entity in RRF-ascending order. Because the agent receives a “yes” answer for the first iteration of the entity “http://confOf#Chair_PC”, the Matching Agent outputs “http://confOf#Chair_PC” as the most relevant entity found in the target ontology. The Matching Merger combines the results from the same procedure applied in the search from “http://confOf#Chair_PC” in the target ontology. These two terms are considered as matched entities only if the mapping can be found bidirectionally (i.e. “http://cmt#ProgramCommitteeChair” is also found to be the most relevant entity in the source ontology for the search from “http://confOf#Chair_PC” in the target ontology).

SECTION: 5.Evaluation

SECTION: 5.1.Evaluation Criteria

In information retrieval, a common assessment for matching tasks is based on comparing predicted results with expected output. Precision and recall are used to measure the correctness and completeness of the matching, respectively. When adapting these measures to OM, the predicted results generated by the system are denoted Alignment (A), and the expected results provided by the domain experts are denoted Reference (R)(Do et al.,2003). Therefore, Precision and Recall for OM tasks are defined as:

Precision and recall are commonly combined into a single measure F1 score, defined as:

SECTION: 5.2.Evaluation of Three OAEI Tracks

In this section, we test our proof-of-concept system with three OAEI tracks containing different types of OM tasks. These include few-shot tasks with a small proportion of trivial correspondences (5.2.1Test Case), simple tasks with a large proportion of trivial correspondences (5.2.2Test Case 1 and5.2.3Test Case 3), complex tasks with a large proportion of non-trivial correspondences (5.2.2Test Case 2), with complex references (5.2.3Test Case 1), or requiring domain-specific knowledge (5.2.3Test Case 2). We report the evaluation metrics for the best-performing singular model gpt-4o and its hyperparameter settings over a single run. We ran multiple trials and found slight differences in the results due to the non-determinism of LLMs, but these differences are not significant with respect to the precision of the results we report. For all test cases in the three OAEI tracks, we select the hyperparameter settings of similarity_threshold = 0.90 and top@k = 3. See Section6.2for discussion on the hyperparameter settings of Agent-OM.

The OAEI conference track contains a pairwise alignment of 7 small and medium-sized conference-related ontologies with a total of 21 matching tasks(Cheatham and Hitzler,2014; Solimando et al.,2014,2017; Zamazal and Svátek,2017). In each alignment, the trial correspondences that can be used to train the models are very limited (commonly less than 10). All conference ontologies in this track use the Type 1 naming convention, where the names of classes and properties have meanings. In this study, we use the publicly available reference ra1-M3 as the reference (R), including class and property mappings.

Figure3compares Agent-OM with the 15 OM systems in OAEI 2022 and OAEI 2023. Agent-OM achieves above-average performance. Its overall F1 score ranks 3/13 in 2022 and 5/12 in 2023. We note that ra1-M3 is known to be missing valid equivalence mappings. We believe that Agent-OM could achieve better performance over a complete reference such as ra2-M3 or rar2-M3. These are not publicly available at the time of writing.

The OAEI anatomy track contains only a reference alignment of human and mouse anatomy, created and evolved from(Bodenreider et al.,2005; Beisswanger and Hahn,2012; Euzenat, Jérôme and Meilicke, Christian and Stuckenschmidt, Heiner and Shvaiko, Pavel and Trojahn, Cássia,2011). Both ontologies use the Type 2 naming convention, where the names of classes and properties are biomedical codes. We report the results of our evaluation in two test cases: alignment with trivial correspondences and alignment with non-trivial correspondences.

Test Case 1: The track originally contains a large proportion of trivial correspondences that have the same standardised labels (e.g., “femoral artery” and “Femoral_Artery”). Figure4compares Agent-OM with the results of the 12 OM systems in OAEI 2022 and OAEI 2023 for alignment with trivial correspondences. Almost all OM systems achieve relatively high precision and recall when matching with trivial correspondences. For Agent-OM, its overall F1 score ranks the second highest in 2022 and 2023.

Test Case 2: We remove these trivial correspondences from both the reference (R) and alignment (A) to focus the matching performance comparison on non-trivial correspondences. Figure5compares Agent-OM with the results of the 12 OM systems in OAEI 2022 and OAEI 2023 for alignment with non-trivial correspondences. We observe better performance by Agent-OM. The overall F1 score of Agent-OM is superior to the 11 traditional OM systems, better than the two LLM-based systems (OLaLa and SORBETMatch), and only behind one deep learning (DL)-based OM system (Matcha), which could have benefited from an unusual large training set available for this case.

The OAEI MSE track provides a reference alignment of ontologies in materials science and engineering(Engy Nasr,2020). The track contains three test cases aligning MaterialInformation(Ashino,2010), MatOnto(iNovex IRAD,[n.d.]), and EMMO(The European Materials Modelling Council (EMMC ASBL),[n.d.]). MaterialInformation and MatOnto use the Type 1 naming convention, while EMMO uses the Type 2 naming convention.

Test Case 1: This case provides a reference alignment for a small version of MaterialInformation and the medium-sized MatOnto. The challenge of this task arises due to the reference intentionally including several subsumption correspondences, when OM systems may mistakenly map subsumptions into equivalence relations. Figure6compares Agent-OM with the results of the 4 OM systems in OAEI 2022 and OAEI 2023. Agent-OM achieves the best performance, with the highest recall and F1 score.

Test Case 2: This case provides the reference alignment of the full version of the large MaterialInformation and the medium-sized MatOnto. The challenge of this task is to align many examples of specific terminology, abbreviations, and acronyms used in materials science. For example, “Au” stands for “Gold”, “Ag” stands for “Silver”, and “Cu” stands for “Copper”. Figure7compares Agent-OM with the results of the 4 OM systems in OAEI 2022 and OAEI 2023. Agent-OM achieves the best performance in precision, recall, and overall F1 score across the OAEI 2022 and OAEI 2023 results. We should expect an LLM-based matcher to have high recall on this test case due to its access to extensive training literature.

Test Case 3: This case provides the reference alignment of the full version of the large MaterialInformation and medium-sized EMMO. Unlike MatOnto used in Test Case 1 and Test Case 2, EMMO extends the upper ontology called Basic Formal Ontology (BFO). This means that the classes in EMMO are somewhat standardised according to the BFO classes. Figure8compares Agent-OM with the results of the 4 OM systems in OAEI 2022 and OAEI 2023. The matching performance of Agent-OM is the best of the OAEI 2022 results and second of the OAEI 2023 results. It is better than LogMap and LogMapLt and only behind the DL-based OM system Matcha.

SECTION: 6.Ablation Study

SECTION: 6.1.System Components

We compare Agent-OM with two simpler architectures where the OM is much more reliant on straightforward LLM use. (1)LLM only: Givenand, this approach extracts eachand. The matching decision is purely based on LLMs without any additional information. (2)LLM with context: Givenand, this approach extracts eachand their syntactic, lexical, and semantic information. The matching decision uses LLMs to determine whether two concepts are identical or not based on the information provided.

The experiment is run on the CMT-ConfOf alignment demonstrated in Section4.2. We use the GPT model gpt-4o with similarity_threshold=0.90. Figure9compares Agent-OM withLLM OnlyandLLM with Context.LLM Onlyshows low precision and recall.LLM with Contextpartially overcomes this deficiency by providing additional information, but token consumption is extremely high without optimising the matching candidate selection. Our Agent-OM architecture handles these two main challenges with tool calling agents and hybrid database searches. Note that the CMT-ConfOf alignment demonstrated here is a small alignment task, while Agent-OM is expected to be relatively more effective and efficient in large-scale OM tasks.

Figure10varies LLMs in Agent-OM on the OAEI Anatomy Track. In general, API-accessed models perform better than open-source models. The leading models, gpt-4o and claude-3-sonnet are both large API-accessed models. Among open-source models, gemma-2-9b achieves the best performance, while llama-3-8b is relatively poor. Curiously, although we see improved performance with llama-3.1-8b over its previous version, qwen-2.5-7b does not show an advantage over its previous version. This may be a side-effect of LLM developers optimising for tasks other than OM. We experimented with other LLMs derived from the Llama and Qwen families and generally found poor performance, possibly due to the fine-tuning for specific tasks.

We also test three different text embeddings in(OpenAI,[n.d.]b)on the OAEI Anatomy Track. The default length of the embedding vector is 1536 for text-embedding-ada-002 and text-embedding-3-small, and 3072 for text-embedding-3-large. We do not observe a significant difference arising from varying the text embeddings from text-embedding-3-small to text-embedding-3-large. We do not see that text-embedding-3-small and text-embedding-3-large perform better than text-embedding-ada-002.

The use of a hybrid database unlocks the potential for search-based OM. We defineandas the number of entities extracted from the source ontology () and the target ontology () respectively. In naive LLM-based OM, the matching is based on binary questions to compare each pair of entities fromandbased on their relevant information. The number of tokens consumed is(for retrieval and matching). In search-based OM, we first retrieve entity information fromandand store it in a hybrid database. Following our methods in Section4, the number of tokens consumed is(for retrieval) + 0 (for search) +(for validation) + 0 (for merge). Search-based OM is cost-effective because the inequalityalways holds in common OM task settings where. We also apply two approaches to reduce LLM hallucinations (i.e. false positive mappings in search results): validator and merger.

We employ a validator by asking the LLM to self-check the candidate correspondences. It is helpful in detecting two common types of false positive mappings: (1) non-existent mappings and (2) counter-intuitive mappings. Figure11compares precision, recall, and F1 score with and without validation in the three OAEI tracks we analysed. The matching results with validation generally achieved an improvement in precision and F1 score, with a slight decrease in recall (we only find one exception in the MaterialInformationReduced-MatOnto alignment). This is in line with the findings in CoT with self-consistency (CoT-SC)(Wang et al.,2023b), where the provision of a self-check can reduce LLM hallucinations. Note that our experiment set the similarity_threshold, so the improvement in matching performance is not statistically significant, but the matching validator will have a great impact on performance with lower similarity thresholds.

We apply a merge functioncombining the results ofandto improve the matching performance. Figure12shows the comparison of precision, recall, and F1 score in,, andin the three OAEI tracks we analysed. The merged matching results generally achieved a significant improvement in precision and F1 score, with a slight decrease in recall. The results are in line with the findings in RAG-Fusion(Raudaschl,[n.d.]), where providing two different paths to perform the same matching task can reduce LLM hallucinations.

SECTION: 6.2.Hyperparameter Settings

We test the similarity thresholdin the three OAEI tracks we analysed. The optimal similarity threshold appears to be, balancing the trade-off between precision and recall, thus achieving a higher overall F1 score (see an example comparing different similarity thresholds in the CMT-ConfOf alignment in Figure13). If we consider the similarity threshold as the required confidence interval (CI) for candidates for equivalence matching, this setting reflects the convention of accepting a 5%-10% probability of observing values outside the estimation.

We also test the top@k valuesin the three OAEI tracks we analysed. We observe thatanddo not provide enough candidates for the LLM to select, while appropriate correspondences are rarely found where. We recommend settingto balance the computational complexity and precision of the results. Note that we deal with the tie-break case where multiple entities have the same RRF scores. In such cases, the total number of entities tested may be greater thanbecause these equally-scored entities share the same ranking.

Ontologies are context-dependent conceptual models that follow different conventions and restrictions to reflect different application-level requirements(Shenghui Wang,2021). The hyperparameter settings can be adjusted for each specific OM task using reference mapping to achieve an optimal result. We observe that higher similarity thresholds and lower top@k values could result in high precision where most of the trivial mappings can be found, but some more obscure true mappings may be missed, lowering recall. On the other hand, lower similarity thresholds and higher top@k values could result in high recall, but the precision may be low as more false mappings are generated during the matching process. This indicates that the applied matching refinements (validator and merger) would be more powerful in settings with lower similarity thresholds and higher top@k values. We found in our extensive OAEI experiments that thresholdand top@kwas optimal. In the real-world application of Agent-OM to a matching problem with no reference, we advise choosing aandwithin these ranges.

SECTION: 7.Discussion

Google DeepMind classifies AI autonomy into 6 levels(Morris et al.,2024). We believe that the potential of LLM is not only as a consultant, a collaborator, or an expert to answer binary classification questions in OM tasks, but it can also be an agent to simulate human behaviour in performing OM tasks, including data preprocessing, data preparation, data analysis, and data validation. Higher autonomy reduces barriers to accessing LLMs in OM tasks.

Agent-based OM is more efficient than LLM-based OM. LLMs are computationally expensive. While LLM-based OM using binary classification questions has repetitive LLM prompting, agent-based OM leverages the vector database to store ontology retrieval results, reducing the financial cost of token consumption.

Agent-based OM is also more effective than LLM-based OM. LLM-based OM is commonly observed to have high recall and low precision. Due to the nature of its large knowledge base, it is possible to discover positive correspondences but also unavoidable false positive mappings. LLMs are zero-shot reasoners(Kojima et al.,2022), but they are also few-shot learners(Brown et al.,2020). Their capacity for reasoning depends on the richness of the information provided. With the assistance of autonomous agents for extensive planning, tools, and memory, agent-powered LLM-based OM systems can access more detailed information and therefore feature the following advantages:

Context Learning: LLMs have a large corpus of background knowledge. Given a context, LLMs can select relevant background knowledge and therefore perform better in lexical matching.

Transitive Reasoning: LLMs can reason on transitive relationships. They can also understand general and domain-specific scenarios and apply lexical validation when necessary.

Self Correction: LLMs have a strong capacity for self correction. Even given a wrong statement, LLMs have good judgment to automatically remove false mappings. For example, semantic matching can cause false mappings because it considers only the data structure and ignores the linguistic meaning of the entity. However, such a small piece of false information does not influence the correct truth that LLMs nevertheless learn.

Table4presents some examples of these unique characteristics. Despite the several success factors of agent-powered LLM-based OM systems, we also observe that:

(a) Context LearningPrompt: What is the meaning of chair? Give a short explanation.Answer: A chair is a piece of furniture designed for a person to sit on, typically featuring a seat, backrest, and often four legs. It can also refer to the position of leading or presiding over a meeting or organization, such as the “chair” of a committee. (AI-generated content)Prompt: What is the meaning of chair in the context of a conference? Give a short explanation.Answer: In the context of a conference, the term “chair” refers to the person who is responsible for leading and moderating a session or the entire event. This individual typically introduces speakers, manages the schedule, facilitates discussions, and ensures that the session runs smoothly and on time. The chair plays a crucial role in maintaining the flow of the conference and engaging the audience. (AI-generated content)(b) Transitive ReasoningPrompt: We know that paper is equivalent to submission, and submission is equivalent to contribution. Is paper equivalent to contribution? Please answer yes or no. Give a short explanation.Answer: Yes. If paper is equivalent to submission, and submission is equivalent to contribution, then by the transitive property of equivalence, paper is also equivalent to contribution. (AI-generated content)Prompt: We know that meta-reviewer is the subclass of reviewer, and reviewer is the subclass of conference member. Is meta-reviewer the subclass of conference member? Please answer yes or no. Give a short explanation.Answer: Yes. Since meta-reviewer is a subclass of reviewer, and reviewer is a subclass of conference member, by the transitive property of class inheritance, meta-reviewer is also a subclass of conference member. (AI-generated content)(c) Self CorrectionPrompt: We know that rejection is equivalent to submission, and submission is equivalent to contribution. Is rejection equivalent to contribution? Please answer yes or no. Give a short explanation.Answer: No. While the statements “rejection is equivalent to submission” and “submission is equivalent to contribution” suggest a transitive relationship, the context and meaning of each term can vary. Rejection typically implies a refusal or denial, whereas contribution implies adding value or participating positively. Therefore, without additional context to clarify how these terms are being used, rejection is not necessarily equivalent to contribution. (AI-generated content)

A matching process could be more complex. Although CoT may simulate how humans plan and perform tasks, it is still an incomplete model of human thought. Human reasoning employs a more complex network of thoughts, as humans tend to try different isolated paths (i.e. ToT, tree-of-thoughts(Yao et al.,2023; Long,2023)), explore multiple paths (i.e. GoT, graph-of-thoughts(Besta et al.,2024; Yao et al.,2024)), or algorithms (i.e. AoT, algorithm-of-thoughts(Sel et al.,2023)), and backtrack, split, or merge to find the optimal solution to the problem. For example, people may use discovered mappings as input to the next iteration.

Prompt engineering is the key to instructing efficient LLM agents. These prompts are currently hand-crafted. For prompt-based tools, different LLMs may have varying default chat templates. Finding generic hard prompts across all LLMs is almost impossible. However, we provide the simplest standardised version of the prompts from our experiments. The prompts used in our system currently support mainstream LLMs, such as OpenAI GPT models, Authropic Claude models, Meta Llama 3, Alibaba Qwen 2, Google Gemma 2, and ChatGLM 4. For those models not included in the list, we also provide an interface to add new LLMs to our system, but it may require minor code customisation to fit the LLMs used. We expect that our system will support more models via open-source community efforts in the future. We seek automatic prompt engineering and will consider using soft prompts in future versions.

LLM hallucinations can be mitigated, but cannot be eliminated. The accuracy of the RAG remains an open question. Human-in-the-loop may be a solution(Ouyang et al.,2022). Search optimisation for OM tasks, such as database indexing and cross-validation across databases, is an ongoing research area.

There is a trade-off between precision and recall. Strict rules could result in high precision where most of the implicit true mappings can be found, but they may miss some explicit true mappings. On the other hand, loose rules could result in a high recall score, but the precision score may become very low as more mappings are generated during the matching process.

For LLMs used for OM, we find a classical Moravec’s paradox: “hard problems are easy and the easy problems are hard” (p192)(Pinker,2003). Although Agent-OM performs well in complex and few-shot OM tasks, it is not outstanding on simple OM tasks. We will also consider integrating the LLM-based approach with traditional knowledge-based and machine learning-based approaches in such cases.

SECTION: 8.Limitations

We evaluate only the T-Box matching datasets that match named classes, object properties, and data type properties. A-Box matching datasets (including individual data instances) are not considered due to privacy concerns in our targeted application domain. Additional data engineering (e.g. data de-identification and fuzzing) may be required to apply LLMs to A-Box matching datasets to avoid personal and sensitive information exposure.

Due to the high cost of API calls for API-accessed commercial LLMs, experiments with the newest commercial models (e.g. gpt-o1-preview and claude-3-opus) are not included in this study. According to our findings in Section6.1.2, we hypothesise that these models could achieve better performance in OM tasks.

There may be additional resource requirements for running open-source LLMs locally. The run time for API-accessed commercial LLMs is controlled by the LLM providers.

SECTION: 9.Future Work

Multimodal OM: We have packaged our system into several natural language-based commands. It could be integrated with advanced LLM functions to support multimodal input, such as ontology diagrams and online seminars. The richer information sources might improve OM performance.

Multilingual OM: Agent-OM supports ontologies in multiple languages. We have tested it in the OAEI 2022 and 2023 Multifarm Track, a modified conference dataset translated into nine different languages. Results are not included here because there are few benchmarks; only two traditional systems’ results are available.

Small language models (SLM) for OM: SLM (e.g. gemma-2-2b(Google,2024)and phi-3-3.8b(Microsoft,2024)) are useful in resource-constrained devices but they have problematic tool interfaces at present.

SECTION: 10.Conclusion

In this paper, we introduce a new LLM-based design paradigm for OM systems. Agent-OM, an agent-powered LLM-based framework, is proposed and implemented with a proof-of-concept system. We compare our systems with state-of-the-art OM systems to perform different types of OM tasks. The system has shown a powerful capability to perform OM tasks at different levels of complexity, leveraging the potential of using LLM agents for OM. We also discuss our observations on the advantages and current limitations of using LLMs and LLM agents for OM tasks.

Our work focuses on pre-trained large foundation models that are impossible to retrain and hard to fine-tune. Our approach yields good results on LLMs for OM tasks without changing the LLM model itself, but by utilising CoT, ICL/RAG, and prompt engineering techniques. It is a simple, lightweight, and natural language-driven approach with high scalability. Agent-OM is all you need. While OM has been studied for two decades or more, we are now at a point where the goal of 100% accurate, fully-automated, and domain-independent OM seems to be within reach.

SECTION: References