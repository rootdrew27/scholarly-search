SECTION: Introduction
Predictive analytics uses statistical techniques and machine learning algorithms to analyze patterns in past data and predict future events or trends. It has become a powerful and profitable tool to address crucial business and societal challenges, such as personalized product recommendations, health monitoring, and financial fraud detection. Typically, companies collect massive data from individuals or organizations to train predictive models and maintain complete control over the acquired data. Recent privacy laws, including the European Union (EU)’s General Data Protection Regulation(GDPR), the California Consumer Privacy Act(CCPA) and Canada’s Consumer Privacy Protection Act(CPPA), outline ‘Right to Be Forgotten’ (RTBF) regulations. These RTBF regulations empower the data subjects to retract control over their own data and mandate predictive model holders to respond actively to erasure requests from data subjects.

Adhering to the RTBF regulations is crucial for companies deploying predictive models, as non-compliance can lead to substantial fines. For example, in 2020, Google was fined $8 million by the Swedish Data Protection Authorityand $670K by the Belgian Data Protection Authorityfor violating GDPR principles related to the RTBF. In addition, data subjects are often hesitant to share their data due to concerns over losing control and privacy risks. It is reported that, although 83% of consumers are willing to share their data in exchange for better-personalized services, 86% express growing concerns about data privacy. Moreover, a majority of Americans (eight-in-ten) feel they barely have control over the data collected about them by companies or the government. By granting individuals the right to fully erase their shared data, RTBF regulations can significantly mitigate these concerns and thus foster greater trust and willingness to participate in data sharing.

However, compliance with RTBF is non-trivial for companies using predictive models built from customer data. Simply deleting individual data samples is often inadequate to fully comply with these requests. It is also vital to update the predictive models trained on this data, as research has demonstrated that these models may retain some unique information about specific training samples. Consequently, effective data erasure in predictive analytics involves not only deleting individual data samples but also eliminating the information retained in the predictive model, making the model as if it had been trained without those samples. A straightforward approach to addressing this issue is to erase the requested data from the training set and retrain the model from scratch (i.e., naïve retraining). However, this method is often impractical, particularly when these data erasure requests are frequently made. For instance, since the EU’s RTBF ruling in 2014, Google has received over 2.4 million requests for data erasure from its intelligent search engine services; the UK Biobank, a critical repository of genetic and medical records used in numerous predictive models, has also reported sporadic requests for the data erasure from both its database and associated models. In such cases, naïve retraining is computationally prohibitive and impractical for responding to frequent data erasure requests, particularly when dealing with predictive models trained using extensive datasets.

Machine unlearningis an emerging paradigm aimed aterasing information about the requested removal data retained in predictive models. It seeks to expedite the data erasure process by partially retraining or adjusting the predictive model to produce anunlearned model that still delivers high-quality predictive services. Without resorting naïve retraining, machine unlearning expects the unlearned model to generate predictionswith those of the naïve retrained model while remaining distinguishable from the original model, to ensure effective anddata erasure. Overall, machine unlearning is suggested to achieve four key requirements: consistency, accuracy, efficiency, and verifiability.

Despite the progress in this area (we present these main ideas in Section), current machine unlearning methods prioritize the efficiency of data erasure, often neglecting the need for consistency and accuracy in the resulting models. For example, ensemble-based unlearning methods suggest that an ensemble model comprising multiple sub-models can efficiently manage data erasure requests by partially retraining the sub-models associated with the requested data. However, this often requires training sub-models with limited data, which may significantly compromise prediction accuracy. Distillation-based unlearning methods fine-tune a pre-established predictive model using certain reference models that exclude the data requested erasure, aligning the model’s outputs with those of the reference models and thereby facilitating efficient data erasure. Unfortunately, these methods face challenges in identifying reference models that closely resemble the naïve retrained models without fully retraining from scratch. As a result, they rarely produce unlearned models consistent with the naïve retrained ones, despite consistency being critical for compliance with privacy regulations.

In contrast, we emphasize that it is crucial to preserve model accuracy and consistency in machine unlearning to maintain service profitability and avoid penalties for non-compliance. To this end, we propose a novel framework that not only efficiently handles data erasure requests but also ensures that unlearned models retain high predictive accuracy and produce results consistent with those of the naïve retrained models. To the best of our knowledge, we are among the first in the business research community to address machine unlearning issues to achieve the RTBF within predictive analytics. Notably, our perspective of this here addresses compliance with privacy regulations while maintaining business value. We summarize our key contributions as follows:

We formulate a new holistic machine learning-to-unlearning problem comprising two closely related sub-problems: the predictive model construction and the unlearning request response. The first focuses on building high-performing models that are able to easily unlearn, while the second aims to design an unlearning method meeting the key unlearning requirements including consistency, accuracy, efficiency and verifiability.

We introduce a novel framework consisting of two innovative methods, reference-oriented ensemble learning (ROEL) and iterative information distillation (TID). The ROEL method trains each sub-model using the majority of the training data, leading to the construction of an accurate ensemble predictive model. This method also generates retrained-alike reference models without incurring additional computational overhead, preparing for efficient and consistent distillation-based unlearning. Besides, the TID method erases the information of samples requested unlearning from the relevant sub-models under the supervision of retrained-alike reference models. It also rectifies the sub-models using the remaining training data to retain predictive accuracy while further boosting efficiency through parallel computing.

Extensive experiments conducted on two datasets demonstrate that our framework can efficiently erase information from predictive models while preserving accuracy and delivering predictions consistent with those of naïve retrained models.

Finally, we analyze the implications of our work for information privacy management and offer several managerial insights for the community. For instance, we demonstrate that adopting our framework not only addresses immediate concerns related to data unlearning but also promotes long-term benefits by fostering a more trustworthy data ecosystem.

SECTION: Problem Formulation and Technical Foundations
In this section, we formally define the holistic machine learning-to-unlearning problem and present some critical technical foundations. The notations used in this work are summarized in Table.

SECTION: Problem Formulation
The machine unlearning process typically has two distinct stages: the predictive model construction and the unlearning request response. Figuredepicts the general machine unlearning process and illustrates the typical designs of prior methods at each stage. Below, we outline the key concepts involved in these stages and formally define our problem.

During this stage, providers collect data from various data subjects and train a satisfactory predictive model to offer predictive services. Letdenote the training dataset, whererepresents the overall data space. Here,anddenote the features and labels of samples in, respectively. In practice, providers may adopt arbitrary machine learning algorithms (e.g., neural networks, random forests, or linear models) and produce either a single or an ensemble predictive model. Letrepresent the predictive model trained on the datasetusing a specific algorithm. The predictive modelis often referred to as thefor unlearning purposes as well.

Once the predictive service is in use, providers may receive requests from data subjects to erase specific data samples. The data requested for erasure, referred to asand denoted by, may consist of one or more samples from the training data. To comply with the RTBF regulations, providers must ensure thatis thoroughly erased from the trained models, as these models may retain unique information of the training samples. The most straightforward approach is to retrain the model from scratch using the remaining data; however, this approach becomes computationally expensive, particularly with large datasets or complex models, making it impractical for frequent unlearning requests. Consequently, machine unlearning has emerged as an alternative to naïve retraining for erasing data’s information from a predictive model, with the goal of achieving the following desiderata:

Current research typically approaches machine unlearning as a single-stage problem, which can be categorized into two streams. The first stream assumes that providers have already established a predictive model and focuses on the unlearning request response stage by carefully modifying the existing model to erase unlearning data. Unfortunately, these predictive models are generally designed for high performance rather than ease of unlearning, making the unlearning process challenging and inefficient. The second stream mainly addresses the unlearning issue during the model construction stage. This stream of approaches aims to develop models capable of partial retraining when unlearning requests arise, allowing for selective retraining of model parts associated with the unlearning data. Nevertheless, without careful design of the unlearning response method, even partial retraining can still be time-consuming, especially when the unlearning data affects large portions of the model, necessitating extensive retraining. Additionally, the second stream does not sufficiently consider the model’s predictive performance in its design.

Unlike existing studies, we approach machine unlearning as a holistic problem encompassing both predictive model construction and unlearning request response. We highlight that predictive service providers can proactively account for unlearning needs during the model construction stage. Constructing the predictive model with foresight is essential for maintaining service performance and streamlining the unlearning response. Additionally, even with models specifically designed for easy unlearning, it remains crucial to tailor the unlearning response methods to guarantee the effectiveness and efficiency of the unlearning process. Below, we formally define our problem:

. Achieving all desiderata of machine unlearning is exceedingly challenging and sometimes impractical in certain scenarios. For instance, when handling a large amount of unlearning data, ensuring a consistent unlearned model may inevitably lead to its inaccuracy because the unlearned model is restricted to preserving knowledge derived from a smaller subset of the original training data. Notably, existing machine unlearning research has predominantly focused on meeting the requirements ofand, with less emphasis onand. However, from a business perspective, these two requirements are critical sincedirectly reflects the quality of predictive services, which produces profitability, andrelates to the effectiveness of unlearning and is crucial for ensuring compliance with privacy regulations, thereby helping providers avoid fines. As a pioneering business-oriented study in machine unlearning, we emphasize the importance of accuracy and consistency. Our goal is to develop an innovative machine unlearning method that not only enhances accuracy and consistency but also maintains efficiency and verifiability.

SECTION: Technical Foundations
In this section, we introduce some preliminaries of two crucial techniques commonly employed in previous unlearning studies, which will also form the basis of our design. They are ensemble learning and distillation learning.

Ensemble learning is a widely used machine learning technique that aims to achieve high-performing predictive models by combining multiple sub-models. A common ensemble approach typically partitions a training datasetinto several subsets, with each subset used to train a separate sub-model. The results of these sub-models are then aggregated to produce the final output of the ensemble predictive model.

Prior unlearning studies reveal the potential of ensemble learning for constructing models that are able to easily unlearn. Essentially, with ensemble-based methods, handling an unlearning request only requires partially retraining one or a few of these sub-models, making the retraining process more efficient. While these studies emphasize the ease of unlearning by partial retraining, they unfortunately neglect the quality of the model, which may lead to inaccurate prediction performance.

Distillation learning is a technique that fine-tunes a predictive modelunder the supervision of a reference model, aiming to align’s predictions on a set of distillation datawith those of. This technique is commonly used in model compression and knowledge transfer, where a well-trained large model serves as the reference to guide the training of a small, randomly initialized model. Specifically, the posterior probabilities produced by the reference modelare used as "soft targets" for training the small model. By ensuring that’s predictions are consistent with these soft targets, the knowledge acquired by the reference modelcan be effectively transferred to. Letdenote the features of distillation data. The objective of distillation learning is generally formulated as:

wherequantifies the difference between two models’ predictions.

While retraining a model from scratch is computationally expensive, fine-tuning is typically more efficient, as providers only need to slightly adjust the parameters with fewer data instead of training the entire model from the ground up. Therefore, recent seminal works delve into distillation learning techniques for machine unlearning. Ideally, distillation can assist in unlearning a target modelby fine-tuningunder the supervision of its naïve retrained modelas a reference model (i.e.,). Through fine-tuning, the goal is to obtain an unlearned modelwhose predictions align with those offor arbitrary datawith features. In general, the information of the unlearning data can be considered completely erased from the target model if its predictions on arbitrary data are consistent with those of the naïve retrained model. This can be achieved by solving the following optimization problem:

Nevertheless, without retraining the target model from scratch, its naïve retrained modelis not accessible as a distillation reference. Although previous distillation-based machine unlearning methods are highly efficient, they fail to identify an appropriate reference model, resulting in inaccurate and inconsistent unlearning models.

SECTION: Literature Review
Our study closely relates to two main research streams: information privacy management and machine unlearning. We review each of these streams and emphasize the key contributions and innovations of our work in this section.

SECTION: Information Privacy Management
Privacy management has been a key area of focus in Information Systems (IS) research for decades. Recently, the widespread adoption of artificial intelligence (AI) and machine learning has introduced both opportunities through predictive modeling and novel challenges for information privacy management. In response, a substantial body of IS research has emerged to address these challenges, which can be categorized into two primary streams: empirical studies aimed at understanding consumers’ privacy concerns and behaviors, and technical studies focused on developing privacy assurance techniques to protect sensitive information from privacy breaches.

Empirical studies on information privacy management focus on understanding the factors driving people’s privacy concerns and behaviors. For instance,explored the personalization-privacy paradox in the context of personalized smartphone advertising, examining how privacy impacts the process and content gratifications derived from personalization and how IT solutions can be designed to alleviate privacy concerns. While most studies considered only one or a few specific contexts,developed a conceptual and quantitative framework to examin the multiplicity of contexts and their impact on consumers’ cognition and perceptions of privacy. Additionally, some recent empirical work has studied the impacts of privacy laws and regulations on companies and individuals. Specifically,studied GDPR’s equilibrium impact using a dynamic two-period model of forward-looking companies and consumers. They found that privacy rights would reduce consumers’ hold-up concerns and raise (reduce) firm profit and social welfare when privacy breach risk is high (low).
Compared to these empirical studies, which focus on understanding or explaining privacy-related behaviors, we highlight that developing privacy-respecting AI technologies is one of the key managerial issues for IS researchers as well. In this research, we aim to design a novel machine unlearning method as a practical privacy assurance technique to efficiently and effectively protect the RTBF for data subjects in predictive analytics.

Technical research aims at designing privacy assurance techniques to shield personal private information from unauthorized access or inference through public data sources. In the early stages of IS development, privacy concerns centered around data flows, known as. For example, earlier studies demonstrated that consumers’ private information (e.g., identities) could be acquired by linking two publicly available datasets. To avoid such personal information leakage from unauthorized access, scholars developed techniques that "anonymize" datasets before data sharing by preventing any record from being linked to an individual while retaining the data value for analytic purposes. While these studies investigated privacy-preserving data sharing through anonymization, recent work has proposed leveraging secure multiparty computation technique in financial network analytics. This approach addresses data-centered privacy concerns by enabling institutions to locally compute on their real data without sharing it. With the rise of AI technologies, many organizations and companies started to use predictive analytic tools to unlock the value of their collected data. Nevertheless, despite the benefits, it has introduced new attack surfaces and shifted privacy concerns from data-centered to. These privacy concerns concentrate on the private knowledge that could be inferred from the collected data. For instance, the private information (e.g., location) of users in online social networks can be precisely inferred based on their publicly available data, even though they intentionally hide this information. As data anonymization methods have proven ineffective in preventing the inference of private knowledge, the vast majority of privacy assurance studies turned to other techniques, such as suppression and differential privacy. Suppression techniques selectively hide or obfuscate portions of users’ publicly available data, thereby preventing their private knowledge from being inferred by adversaries. Differential privacy, on the other hand, does not prevent adversaries from gaining insights but ensures that any knowledge obtained could have been inferred even without access to an individual’s specific data. While these privacy assurance techniques effectively thwart specific privacy attacks, their main objective is to prevent the acquisition or inference of private information. In contrast, our focus is to develop a technique that completely erases the information of requested data from predictive models to comply with the RTBF requirement. Tablesummarizes the recent technical research on information privacy management for comparison.

SECTION: Machine Unlearning Studies
Since the implementation of the RTBF regulation ruling by the highest court in the EU in 2014, there has been a lot of pioneering research in the field of machine unlearning. Specifically, existing machine unlearning methods can be categorized into three types: ensemble-based, theory-based, and distillation-based methods. Typically, ensemble-based methods design the predictive model construction stage to develop an ensemble model that is inherently easy to retrain and respond to the following unlearning requests by simply retraining parts of the model. Comparatively, theory-based and distillation-based methods focus on the unlearning request response stage and design various post-model modification approaches on pre-established predictive models to address data erasure requests.

Ensemble-based unlearning methods aim to reduce the computational costs of retraining by only retraining parts of the trained predictive model. To achieve this goal, they carefully designed the predictive model construction method to establish an ensemble predictive model. In particular,proposed the(i.e., SISA), which first randomly splits the training set into several non-overlapping subsets, and trains a sub-model on each subset separately. After that, the final prediction results are obtained from the aggregation of sub-models through majority voting or averaging. During the unlearning response stage, only the sub-models trained using unlearning samples are retrained. Based on the same core idea, RecEraserand GraphEraserintroduce ensemble-based unlearning methods to deal with unlearning requests in recommender systems and graphs, respectively. However, the ensemble-based methods may still face inefficiency problems when unlearning samples are spread across various subsets since they need to retrain numerous sub-models. Besides, partitioning the training dataset into too many disjoint subsets may result in sub-models being trained with insufficient samples, thereby leading to a decrease in model accuracy performance. Our framework also employs ensemble modeling to build predictive models, but it significantly differs in design from these methods. On the one hand, it ensures that each data subset contains the majority of the training samples, thus preventing the issue of diminishing the predictive accuracy due to undertrained sub-models. On the other hand, the modeling process is not aimed at facilitating retraining but is designed to efficiently and consistently accomplish the distillation-based unlearning process.

Theory-based methods design post-model modification approaches that modify the parameters of a pre-established predictive model premised in some theory. One stream of them precisely calculates the information of unlearning data retained in the target model; it then utilizes the differential privacy theoryto add noise on the parameters of the target model for generating an unlearned model that resembles the naïve retrained model. Nevertheless, these methods are only limited to simple algorithms,e.g., K-Means, or linear models. Another stream incorporates information theory such as Fisher and Shannon mutual information to establish model-independent data information estimation for machine unlearning. They employ Hessian or linearization approximations for complex models, and erase information of the unlearning data based on the approximated model parameters. However, these methods often introduce inconsistent unlearning results because of model approximations, and the information theory-based computation process remains costly.

Distillation-based methods fine-tune a pre-established predictive model by making its outputs of the data samples required to be forgotten aligned with some alternative references. Specifically, Relabelassigns new random labels to the unlearning data as their references. On the other hand, Forsakenuses outputs from some testing samples as references, distilling the unlearning samples by enforcing the target model to produce output distributions on these samples similar to those on the testing samples. Unlike Forsaken, which uses external testing sample outputs as references, recent works suggest generating references based on the unlearning samples themselves. For instance, Bad-Temploys a stochastically initialized model to produce random outputs for unlearning samples, guiding the target model to also generate random outputs. However, this approach can significantly reduce model accuracy as the stochastically initialized model diverges from a naïve retrained model. SCRUBuses the original trained model’s outputs on unlearning samples as references, aiming to make the target model’s outputs on these samples as dissimilar to the references as possible. AFSintroduces outputs with minimal membership leakage risks as references, adjusting the target model weights using an adversarial membership inference attack (i.e., MIA) module, which helps the target model produce outputs on unlearning samples that are resistant to MIAs. Although membership inference is commonly used as a verification mechanism for machine unlearning, resistance to MIAs does not necessarily imply that samples have been fully unlearned. Overall, existing distillation-based methods often employ unsuitable references that disrupt the true relationships between inputs and labels and fail to mimic the naïve retrained model, thereby leading to inaccurate and inconsistent unlearned models.

SECTION: Key Novelty of Our Study
Although privacy management has been a longstanding focus in business research community, to the best of our knowledge, we are among the first to address issue of machine unlearning for compliance with the RTBF regulations in predictive analytics. While there has been some research on machine unlearning, our literature review underscores several research gaps between existing approaches and our framework, as summarized in Table. A notable distinction is that, in addition to meeting the efficiency and verifiability goals of machine unlearning, we achieve high accuracy and consistency to preserve the quality of predictive services and comply with privacy regulations, thereby maintaining business value. In contrast, existing studies have not adequately considered these aspects, potentially resulting in profit losses and leading to non-compliance with the RTBF regulations. Furthermore, to satisfy all the desiderata of machine unlearning, we propose a holistic machine learning-to-unlearning framework, which integrates a novel model construction method and an innovative unlearning method. Specifically, we introduce a novel ensemble learning method that not only builds a highly accurate predictive model but also provides reference models that closely resemble naïve retrained models for the subsequent unlearning. Besides, we design a new distillation-based unlearning method specifically tailored to the established predictive model, enabling efficient unlearning while ensuring the verifiability of the results. Additionally, we leverage the remaining data to rectify the unlearned model, enhancing its overall accuracy.

SECTION: Proposed Framework
In this section, we propose a holistic machine learning-to-unlearning framework namednsemble-based ierativenformationistillation (ETID). Figurepresents an overview of ETID, which introduces two novel methods to address the predictive model construction and unlearning request response sub-problems. Particularly, in the first stage, we introduce a neweference-rientednsembleearning (ROEL) method to train an accurate ensemble predictive model and create retrained-alike models as reference models to facilitate subsequent distillation-based unlearning. In the second stage, we propose an innovative distillation-based unlearning method called ierativenformationistillation (TID) to address unlearning requests, which is tailored to our developed predictive model. Overall, ETID is meticulously designed to improve the consistency and accuracy of machine unlearning while maintaining efficiency and verifiability. The following sections elaborate on these two novel methods within ETID.

SECTION: Reference-Oriented Ensemble Leaning
Before addressing the predictive model construction sub-problem, we first determine an appropriate unlearning strategy to ensure the constructed predictive model can effectively support future unlearning responses. Based on the comprehensive analysis of the strengths and limitations of existing unlearning strategies discussed in Sectionand Section, we opt for distillation techniques over partial retraining and theory-based modifications. This is because of the ability of distillation methods to quickly erase data from large models trained on extensive datasets through fine-tuning and their adaptability across various machine learning models. However, a key challenge in developing effective distillation-based unlearning methods is the lack of suitable reference models closely resembling the naïve retrained model.

Consequently, in this section, we design a reference-oriented ensemble learning (ROEL) method to construct predictive models with high performance while easing the challenge of distillation-based unlearning. More specifically, by exploring the advantageous properties of ensemble learning, ROEL is designed to achieve a superior predictive model while generating retrained-alike reference models without requiring additional computational resources for future unlearning requests. Typically, an ensemble model comprising well-trained sub-models can attain satisfactory predictive performance; thus, unlike previous methods that train sub-models on small subsets of samples, ROEL ensures its sub-models are sufficiently trained with the majority of training samples. Furthermore, ROEL is well-structured so that its sub-models can mutually serve as retrained-alike reference models, which are critical for effective and efficient unlearning in the subsequent stage. Below we first define-alike and retrained-alike model, and then illustrate the design of ROEL.

Modelandare identical when; they are-alike if their shared training samples are one time more than the unique samples in the larger dataset betweenand.

Given these definitions, ROEL seeks to ensure that any of its generated sub-models can mutually serve as a retrained-alike model for the others, providing suitable reference models for distillation-based unlearning. In particular, ROEL begins by randomly partitioning the training datasetinto() non-overlapping parts of equal size, denoted as, where, for. Unlike the existing unlearning method SISAdirectly using each data part to train a sub-model, ROEL excludes one partat a time and combines the remainingparts into a subsetto train a sub-model. In this manner, ROEL generatesdata subsetsand subsequently trainssub-modelsusing the same algorithm. This approach ensures that each sub-model is trained on most of the training data, thereby enhancing overall model performance. Additionally, it guarantees that any two sub-models are at least-alike, meaning the amount of shared training data between them is larger than the unique data each excludes. Finally, the output of the ensemble predictive model is obtained by averaging the predictions of thesub-models:. The overview of ROEL is illustrated in Figure.

Proof. See Appendix A.1.

In the following we elaborate on the novelty and advantages of our ROEL method in comparison with the previous ensemble methods designed for unlearning. The previous methodaims to facilitate partial retraining by constructing numerous small sub-models, where each data sample is only associated with one sub-model. To facilitate efficient partial retraining, this method requires each sub-model to be trained on a small subset of the data, which often conflicts with the goal of producing accurate sub-models by using a sufficient amount of training samples. In contrast, our method is specifically designed to provide suitable reference models for distillation-based unlearning by constructing retrained-like models during the initial model construction stage without additional effort. By ensuring that each sub-model is adequately trained using most of the overall training data, our method achieves an accurate predictive model. At the same time, these sub-models through careful design can mutually serve as retrained-like reference models to effectively support unlearning.

SECTION: Iterative Information Distillation
We develop a new distillation-based method named ierativenformationistillation (TID) to handle unlearning requests of data subjects in the unlearning response stage. Benefited from our ROEL design, we are able to obtain retrained-alike reference models for our distillation process to guarantee the consistency of unlearning results without incurring additional computational costs. When a request is made to unlearn data, which may include multiple samples distributed across different data parts generated by ROEL, TID begins by grouping the unlearning samples within each part into separate unlearning subsets. The method then iteratively distills the information of each unlearning subset from the corresponding sub-models (i.e., target sub-models). Following this, TID rectifies the unlearned model through additional distillation steps to enhance its predictive performance and then updates the reference models. Figurepresents the flow diagram of TID.

To initialize the unlearning process, we first construct unlearning data subsets and prepare the reference model for each subset. The unlearning datais partitioned intounlearning subsetsbased on the samples’ membership in thedata parts generated by ROEL. Specifically, all unlearning samples that belong to data partare grouped into unlearning subset. We denote, whereif no unlearning data is present in data part.

It is important to note that for any non-empty, all sub-modelsgenerated by ROEL have been trained onand therefore must undergo unlearning. According to Proposition, sub-modelcan serve as a retrained-alike model of arbitrary sub-modelfor the unlearning data. Consequently,is identified as the reference model for unlearningfrom sub-modelthrough distillation-based unlearning. Then sub-modelis duplicated to create the reference modelfor unlearning.

The unlearning process is conducted iteratively by distilling the information of each unlearning subset. Specifically, each iteration involves several steps. First, we acquire a non-empty unlearning subsetand identify the corresponding reference modelalong with the target sub-models for distillation, denoted as. We then unlearnby distilling its information from each target sub-modelunder the supervision of. The goal of distillation is to align the predictions of the target sub-models on the unlearning data with those of the reference model. Notably, current RTBF regulations do not prohibit the use of unlearning datawhen processing unlearning requests, making it permissible for TID to leverage this unlearning data for distillation-based information erasure. This objective is formalized by the following optimization problem:

whererepresents the feature set of samples in;anddenote the output posterior probability distributions for the predictive task labels ofand, respectively; andis a general function that measures the difference between the outputs. By optimizing E.q., an unlearned model is obtained and used to update the original target sub-model,i.e.,.

Some unlearning data samples may retain unique information on the target model, while others may share common information with remaining data. During the distillation process, the shared information that can be learned from the remaining data might be inadvertently erased, potentially diminishing model accuracy. To preserve accuracy after unlearning, we rectify the model using the remaining data. Specifically, we distill the unlearned sub-models under the supervision of the actual labels of the remaining data, allowing the models to relearn the erased information of the remaining data:

whererepresents the remaining data for sub-model, andanddenote the labels and features of the remaining samples, respectively. With the rectification process, the unlearned target sub-models are further updated to rectified versions,i.e.,.

The reference models are duplicates of the original sub-models that involve the unlearning data. At the end of the unlearning process, we update the reference models by replacing them with the corresponding unlearned sub-models:

Proof. See Appendix A.2.

Propositionoutlines the conditions under which updated reference models can continue to function like retrained models for supporting future unlearning. When these conditions no longer apply — typically due to the erasure of a significant volume of data — we recommend introducing new data samples and retraining the model from scratch using ROEL. Potential strategies for adjusting the model with the newly added data are further discussed in the Conclusion and Discussion section.

While distillation techniques significantly reduce computational costs compared to retraining from scratch, our method can be further accelerated through parallel computing. Specifically, the information distillation and target sub-model updates in the iterative unlearning process can be parallelized. Additionally, both the model rectification and reference model update processes can also be executed in parallel.

SECTION: The property analysis on ETID
Below, we summarize the advantageous properties of ETID and how ETID adequately addresses the machine unlearning issue. ETID is the first holistic machine learning-to-unlearning framework that systematically addresses the unlearning issue at both the model construction and unlearning request response stages. It leverages the advantages of ensemble and distillation learning to overcome limitations in previous machine unlearning approaches. Specifically, in the first stage, ETID introduces the novel ROEL method, which not only constructs a high-performance predictive model but also prepares retrained-alike reference models for subsequent distillation-based unlearning without requiring extra effort, effectively resolving the lack of suitable reference models in earlier distillation-based methods. In the second stage, ETID proposes a new distillation-based approach, TID, specifically designed for the predictive model established by ROEL. TID utilizes the retrained-alike reference models to ensure unlearningduring information distillation. Unlike partial retraining techniques, distillation-based unlearning allows sub-models to be trained on sufficient data, ensuring the predictive model’s accuracy is maintained. Additionally, model rectification is employed to improve theof the unlearned model. TID maintainsby fine-tuning the sub-models instead of retraining them from scratch and by utilizing parallel computing techniques.

Following Definition, ETID is verifiable if its unlearned model is distinguishable from the target model. As ETID generates an ensemble model comprising multiple sub-models, it is verifiable as long as any of its unlearned sub-models is distinguishable from the corresponding target sub-model. Propositiondemonstrates theof ETID.

Proof. See Appendix A.3.

SECTION: Experiments
In this section, we experimentally validate the superiority of our ETID framework with two datasets. Below, we present our experimental setups and results.

SECTION: Experimental Setups
In reality, businesses may collect consumers’ historical shopping transaction data or images to train predictive models for consumer profiling or image classifications. In this work, we consider unlearning requests for erasing data from consumer profiling and image classification models, respectively. Following prior works, we apply the consumer shopping transactions dataset Purchase to build the profiling model with a 4-layer fully-connected neural network; we employ ResNet18to train the image classification model on the image dataset CIFAR100. Tabledescribes the statistics of the datasets. In particular, we randomly split the Purchase data set, 80% for training and 20% for testing; as for CIFAR100, we follow the commonly used setting to use 50,000 images for training and the remaining 10,000 images for testing.

Tablelists all the unlearning benchmarks to be compared with. As mentioned, while some existing methods design post-modification unlearning algorithms for a general single predictive model, others devise predictive model construction approaches to facilitate their responses to unlearning requests; our method provides a holistic framework from modeling to unlearning. In the experiments, we follow various designs of unlearning methods to train suitable target models for them. Specifically, we train a single target model (i.e., Target-Single) for benchmarks including Fisher, Relabel, Forsaken, Bad-T, and SCRUB; SISA and ETID propose their ensemble target model construction methods. Thus, we follow the SISA and ETID train two ensemble target models, respectively, which are denoted as Target-SISA and Target-ETID. Retrain-Single and Retrain-ETID denote the naïve retrained models of Target-Single and Target-ETID, respectively, used as references for efficiency comparisons. By adopting a partial retraining technique for unlearning, SISA itself is the naïve retrained model of Target-SISA.

Following the common practice, we utilized Kullback–Leibler divergence as the difference measurein distillation objective functions E.q.and E.q.. We randomly selected 1.0% of the training data as the unlearning samplesand set the number of sub-models (i.e.,) for the ensemble methods as 5 in the main experiments. We also varied these parameters for parameter sensitivity analysis. All experiments were conducted on an Ubuntu 18.04 server with an Intel(R) Xeon(R) silver 4210 CPU, 256 GB RAM, and a Tesla V100S GPU with 32 GB memory. All methods were implemented with Python 3.8.0 and Pytorch 1.7.0. We repeated each experiment five times and reported the mean and standard deviation results.

SECTION: Experimental Results
In this section, we first present the prediction performance of target models created by different model construction methods in Section. More importantly, we examine the unlearning performance of various unlearning methods under the default experimental settings across unlearning desiderata, including,,, and, from Sectionto. Lastly, we report additional results related to the parameter sensitivity analysis of our proposed framework in Section.

In this part, we design experiments to demonstrate the superior prediction performance of the target model constructed using our ROEL method. In particular, we compare the prediction performance of target models established by various model construction methods (e.g., Target-Single, Target-SISA and Target-ETID) on both the consumer profiling and the image classification tasks. It is worth noting that for each task, we apply the same machine learning algorithm to all target models (as described in Section), since our focus is on comparing the model construction methods. We use accuracy as the metric to evaluate the prediction performance of the models across various datasets, including remaining data, testing data, and unlearning data. Specifically, accuracy measures the ratio of correct predictions made by the model, defined as follows:

where,is a indicator function,is the model’s predicted task label with input features, andis the actual task label. A higher value ofindicates better prediction performance, implying that the target model can provide superior predictive services.

We list the accuracy results of target models established with different model construction methods in Table. From the results, we can see that Target-ETID using our proposed ensemble learning method ROEL gains much higher accuracy than Target-SISA using the ensemble learning presented in. Moreover, the accuracy of Target-SISA is even lower than that of Target-Single. In detail, for the Purchase dataset, Target-ETID’s accuracy with,, andis 1.32%, 4.41%, and 1.83% higher than that of Target-Single; while they are 6.62%, 5.57%, and 6.84% higher than those of Target-SISA. For the CIFAR100 dataset, Target-ETID’s accuracy results again outperform those of other methods. The accuracy results of Target-SISA only achieveon testing data andon unlearning data, which is considerably lower than the accuracy scores achieved by Target-Single. These observations strongly support the conclusion that ROEL, as implemented in Target-ETID, provides a significant advantage in training sub-models with adequate sample sizes, leading to overall higher model accuracy compared to both Target-SISA and Target-Single.

This experiment aims to evaluate the consistency of the unlearned model produced by our proposed framework compared to benchmark methods. Specifically, consistency is often measured by the distance in predictions between the unlearned modeland the naïve retrained model. Following the previous work, we use L2-distance as the metric of consistency, formally defined as:

We perform naïve retraining to obtainand then compare it withderived from an unlearning method to compute. A smaller value of the metricindicates higher consistency.

Tablereports the consistency evaluation results of unlearning methods over remaining data, testing dataand unlearning data. The results show that our method ETID derives much lower consistency metric values than all the other non-retrained methods on both Purchase and CIFAR100. For instance, as the best non-retrained benchmark method on Purchase, SCRUB’s consistency metric values over training, testing, and unlearning data are 26.7%, 83.9% and 40.4% larger than those of ETID, which demonstrates the superior consistency of ETID. Additionally, on the CIFAR100 dataset, ETID also achieves the best consistency results, with the metric values being 0.005, 0.130, and 0.204 over different data components. In comparison, SCRUB’s consistency metric values are substantially higher, with the values over testing and unlearning data being 70.0% and 93.1% larger than those of ETID, respectively. The results also reveal the evident inconsistency of Relabel and Bad-T over unlearning data, as these methods adopt unsuitable reference models. For instance, Bad-T exhibits particularly high consistency metric values on both datasets, which indicates poor consistency performance. Besides, we notice that the theory-based method Fisher attains a noticeably high actual consistency on CIFAR100 but struggles with lower consistency on Purchase. In contrast, Forsaken shows a moderate performance across both datasets but does not match the consistency levels achieved by ETID.

In all, this evaluation demonstrates that for distillation-based unlearning methods, finding an appropriate reference model is crucial to ensure the consistency of the unlearned model. It also validates that ETID can attain the highest consistency in addressing unlearning requests among all non-retrained methods, ensuring lowervalues across various data types and datasets.

In this experiment, we aim to examine whether the unlearned model produced by our proposed framework, ETID, can provide better prediction performance compared to benchmarks. Specifically, we first use ETID and benchmarks to obtain the corresponding unlearned models and then evaluate their prediction performance on the consumer profiling and image classification tasks. We also use accuracy defined in E.q.as the metric to assess the prediction performance of unlearned models.

Tableoutlines the accuracy results of unlearned models using various unlearning methods. We observe that our framework ETID significantly outperforms all the benchmark methods by achieving the highest accuracy results over remaining data, testing data, and unlearning dataon both Purchase and CIFAR100 datasets. In particular, on the Purchase dataset, ETID achieves perfect accuracy result on the remaining data with 1.000. For the testing data, ETID’s accuracy is 4.04% higher than that of SCRUB (the best performing benchmark method), and ETID surpasses SCRUB by 0.22% in accuracy over the unlearning data. Moreover, on the CIFAR100 dataset, ETID also leads the accuracy performance over various data components. In detail, on the testing data, the accuracy result of our method is 2.24% higher than that of the best performing benchmark, Relabel. For the unlearning data, ETID achieves the highest accuracy result with 0.776, which is also significantly higher than those accuracy results of all the benchmark methods.

Additionally, we observe that SISA presents poor accuracies, especially in the complex learning task on CIFAR100. The reason is that SISA splits the training data into distinct subsets with limited data to facilitate partial retraining, which easily causes insufficient training of its sub-models. For instance, the accuracy results of unlearned model produced by SISA are 0.657 and 0.533 on CIFAR100, which are notably lower compared to those of ETID. Besides, Relabel shows a noticeable drop in accuracy results on unlearning data on Purchase, which highlights its defect in maintaining high accuracy after responding to unlearning requests. Bad-T also demonstrates substantial accuracy losses on unlearning data, particularly on CIFAR100. These results emphasize the importance of selecting an appropriate reference model for distillation-based unlearning methods. It is crucial not only for maintaining the consistency of the unlearned model but also has a significant impact on the accuracy performance after responding to unlearning requests.

Overall, our proposed framework ETID demonstrates superior accuracy performance compared to other unlearning methods, and the superiority is even more significant in the more complex predictive task on CIFAR100, as evidenced by the larger gaps in accuracy metrics. These findings suggest that business companies can effectively offer accurate predictive services by using ETID to address unlearning requests. Such accurate predictive services can, in turn, help companies increase profitability by better meeting customer needs and optimizing decision-making processes.

This experiment evaluates the efficiency of the unlearning process within the ETID framework compared to benchmark methods. Specifically, we maintain the same running environment and record the time expense for each method’s unlearning process. We then compare their efficiency based on these time costs. Generally, the time cost of an unlearning method is expected to be significantly lower than that of retraining the predictive model from scratch. The lower the time cost, the higher the efficiency.

Tabledisplays the running time of various unlearning methods. In general, distillation-based methods are much faster than theory-based methods and SISA. ETID further accelerates the unlearning procedure and achieves optimal efficiency by employing distillation techniques with parallel computing. Notably, ETID reduces the unlearning time by 80.2% and 88.4% compared to the single naïve retrained model (Retrain-Single) on Purchase and CIFAR100, respectively. Specifically, on the Purchase dataset, ETID achieves a running time ofseconds when using serial computation andseconds with parallel computing. This is a significant reduction compared to Retrain-Single, which takesseconds. In contrast, the theory-based method Fisher takes a much longer time to complete the unlearning process, demonstrating dramatically higher computational overhead. Similarly, Bad-T incurs higher time costs than Retrain-Single atseconds, making it less practical for efficient unlearning. On the CIFAR100 dataset, ETID’s efficiency is even more pronounced. It achieves a running time ofseconds with parallel computing. In comparison, Retrain-Single requiresseconds. The distillation-based methods such as SCRUB also show competitive performance withseconds but still fall short of ETID’s efficiency. Notably, Fisher again shows significant inefficiency. As for SISA, it consumesseconds to erase the unlearning data, highlighting its impracticality for time-efficient unlearning.

These results indicate that some benchmarks, such as Fisher and SISA, consume more time than the naïve retraining method, rendering them impractical for real-world applications where time efficiency is critical. The superiority of ETID in terms of efficiency makes it a highly practical solution for addressing unlearning requests by ensuring minimal computational overhead among the unlearning methods.

In this experiment, we follow previous works to examine the verifiability of various unlearning methods by inferring the membership of the unlearning samples. Specifically, membership inference is performed on both the target and unlearned models to discern unlearning data as members of training data and testing data as non-members. The verifiability of an unlearning method can be confirmed by a significant difference in membership inference performance between the unlearned and target models. We employ the Area Under the Curve (AUC) score to evaluate membership inference performance (denoted as M-AUC) and compute the M-AUC differencebetween a target model and its unlearned model derived from an unlearning method. A significantsignifies the verifiability of the unlearning method. Detailed implementations of membership inference are presented in Section B of Appendix.

Tablesummarizes the results of verifiability examinations. We note that all evaluated unlearning methods exhibit verifiability as they all achieve a significant M-AUC differencebetween their target and unlearned models. Moreover, it is worth noting that an M-AUC nearing 0.5 indicates that unlearning data cannot be distinguished from testing data through membership inference. We notice some of the benchmarks yield a much lower M-AUC than 0.5. For instance, Bad-T shows an M-AUC ofandafter unlearning on Purchase and CIFAR100 datasets, respectively. This outcome occurs when membership inference identifies nearly all unlearning data as non-members but misclassifies some testing data as members. These findings suggest these methods likely over-unlearn the data by using some stochastic references and also interpret their low prediction accuracy for unlearning data.

We design experiments to investigate the parameter sensitivity of the proposed unlearning framework by altering the default number of sub-models () and the ratio of the unlearning samples to the whole training set (i.e., unlearning ratio, abbreviated as UR). Concretely, we keep other default settings unchanged, and conduct Experiment 1 to Experiment 4 with ETID by varying values ofamong, and varying the unlearning ratio among, respectively.

We report the unlearning performance of ETID with different values ofon Purchase and CIFAR100 in Tableand Table, respectively. It is worth noting that as the number of sub-modelsincreases, each sub-model has a larger training data size, and they share more training samples. From the results, we observe that the consistency metric decreases asincreases on both datasets, which means that a largerleads to higher consistency. This is reasonable since asincreases, the reference models we established are more similar to the target sub-model’s corresponding naïve retraining models due to more shared training samples, thereby demonstrating a higher consistency. Besides, we also note that the accuracy of the unlearned model derived from ETID improves asincreases. This can be attributed to two reasons: first, the increased size of subsets leads to more accurate sub-models; second, the increased number of sub-models results in a more powerful ensemble model. Despite the improvements, a largeralso comes with higher computational and storage costs. Therefore, it is important for model providers to select an appropriatebased on their needs and computational resources.

Tableand Tablepresent the performance of ETID with varying unlearning ratios (UR) on Purchase and CIFAR100, respectively. ETID exhibits stable performance across consistency, accuracy, efficiency, and verifiability with various unlearning ratio settings on both datasets. The results verify that our proposed framework ETID can effectively cope with unlearning tasks under different unlearning rates, maintaining high-performance standards across all aspects of machine unlearning desiderata. This robustness makes ETID a versatile and reliable choice for various unlearning scenarios, ensuring that companies can confidently implement unlearning protocols without sacrificing model performance or efficiency.

SECTION: Conclusion and Discussion
In this study, we respond to the urgent calls for the RTBF as stipulated in various recent privacy regulations like GDPR and implement RTBF in data-driven predictive services. Our work proposes a holistic machine learning-to-unlearning framework ETID to handle the data erasure requests for predictive models, by integrating a novel ensemble modeling method and a new iterative information distillation method. Using datasets corresponding to two business predictive services, we demonstrate that ETID surpasses several state-of-the-art machine unlearning methods, comprehensively fulfilling the desiderata of machine unlearning across all aspects.

Our work makes several research contributions to the extant literature. First, to the best of our knowledge, we are one of the first to investigate the machine unlearning problem within the realm of business research. By addressing this problem from a systemic perspective, our work proposes the first holistic machine learning-to-unlearning framework. This framework includes innovative designs at both the predictive model construction stage and the unlearning requests response stage, in contrast to existing methods that typically focus on unlearning designs at only one stage. Thus, our study contributes to the current IS literature by introducing a novel method to the expanding repertoire of techniques that address critical business and societal issues related to privacy protection. Second, in our proposed framework, we develop a novel ensemble learning method to build predictive models. On the one hand, it ensures that each sub-model is trained with most of the training data, avoiding the issue of low accuracy due to insufficient training. On the other hand, it establishes suitable reference models for the subsequent distillation-based unlearning process, facilitating the creation of accurate and consistent unlearned models. In addition, we have also designed a new distillation-based unlearning method to effectively and efficiently erase the information of unlearning samples from the target ensemble model. These innovative designs represent the methodological contributions of our study. Third, our framework is highly flexible and extensible. Specifically, our framework applies to various machine learning algorithms, allowing predictive service providers to use different algorithms to build their predictive models. Finally, we conduct extensive experiments with two datasets in predictive service scenarios. The experimental results demonstrate the superior performance of our framework over several state-of-the-art machine unlearning benchmarks. In particular, it not only constructs an ensemble predictive model with high accuracy performance but also can address the unlearning requests more efficiently and provide a more consistent and accurate unlearned model. Besides, the verifiability of the unlearned model generated by our method is also guaranteed.

This study also offers several managerial implications. First, it highlights the importance of adopting a holistic design when dealing with data erasure requests in predictive services to potentially fulfill machine unlearning desiderata. By integrating comprehensive designs, predictive service providers can ensure that data erasure processes are thorough and effective. Second, predictive service providers can leverage our proposed framework ETID to efficiently handle unlearning requests from data subjects, thereby mitigating the risk of fines for breaching the RTBF. According to GDPR regulations, this could potentially help companies save up to EUR 20 million or 4% of the company’s global turnover. Additionally, by implementing ETID, companies can simultaneously preserve the accuracy of their predictive services, which is crucial for profitable operations. Taking Google as an example, considering that revenues from predictive analytics constitute an important part of Google’s $305.63 billion total revenues, such improvement could translate into significant financial gains for Google. This dual benefit of regulatory compliance and operational efficiency positions ETID as a valuable tool for predictive service providers. Third, our framework enhances data erasure capabilities for data subjects and potentially promotes the data-driven predictive service market. By providing robust mechanisms for data subjects to exercise their right to be forgotten, ETID fosters greater trust in data-driven services. This trust, in turn, can lead to increased adoption and growth of the predictive service market. Finally, beyond privacy assurance through data unlearning, our ETID framework holds promise for a range of additional applications. For instance, it can address discrimination issues arising from biased data in recruitment and credit scoring models, mitigate harmful effects on predictive models caused by misleading or malicious content, and remove the negative impacts of outdated data in fields with evolving information, such as finance and healthcare. By addressing these issues, ETID can bolster predictive models’ fairness, security, and reliability. This broader applicability makes ETID a versatile tool for improving the overall quality and trustworthiness of predictive services. In conclusion, the adoption of ETID not only addresses immediate concerns related to data unlearning but also provides long-term benefits by enhancing model integrity and fostering a more trustworthy data ecosystem. This makes it a critical consideration for any organization or company involved in predictive analytics.

We further discuss the scenario in which a predictive model has been in use for an extended period, and a substantial amount of data has been forgotten. In this case, the condition described in Proposition(see E.q.) may no longer be satisfied, potentially reducing the business value of the unlearned model. To address these issues, predictive service providers can incorporate new data into the model. Specifically, they can collect new data and periodically rebuild the predictive model using the ROEL method. Moreover, we suggest the distillation technique may offer a more efficient solution. In this approach, service providers first add new, non-overlapping data samples to each data partition pre-defined by ROEL, ensuring that these partitions remain of equal size. They can then construct new subsets using these partitions as ROEL did. Finally, the distillation technique can be applied to fine-tune the corresponding sub-models on the new data subsets, analogous to the model rectification process described in Section. Using these approaches, service providers can increase the amount of common data samples between sub-models, effectively yielding retrained-like reference models to guarantee the business value of the unlearned model.

There are some future research directions that merit attention. Firstly, we note that the implementation and good performance of ETID require some realistic assumptions and conditions. Specifically, ETID needs the unlearning data to accomplish the machine unlearning process. In this work, we assume that the unlearning data is available to predictive service providers during the unlearning process, as in the literature. This is reasonable since it’s not prohibited by the current RTBF. However, if the RTBF in the future requires a "stricter forgetting" where the unlearning data cannot be used in any way once the unlearning request is initiated, it will become a very challenging problem. Thus, it would be interesting to study machine unlearning under this more stringent condition. Secondly, we mainly consider a realistic scenario where the size of unlearning data is not large. If the unlearning data is a very large subset of the training data (or even the entire training data), it would be extremely difficult to meet all the desiderata of machine unlearning, especially the business desiderata like accuracy. Therefore, studying the fine-grained impacts of the size of unlearning data on the desiderata of machine unlearning is also a very promising future research direction. Lastly, while ideally addressing data erasure requests for standard predictive models, this study illuminates some future research directions in machine unlearning, especially for the burgeoning Large Language Models (LLMs)and federated predictive modeling.

SECTION: References
SECTION: Appendices
In this Appendix, we provide the proofs of the propositions in Section A; besides, we introduce the detailed experimental designs of verifiability examination in Section B.

SECTION: A. Proofs
We have sub-model; moreover, the naïve retrained model of sub-modelis obtained by. Let further denote. Then, the sub-modelcan be rewritten as:

The naïve retrained model of sub-modelcan be rewritten as:

Since, for, and, the shared training samples ofandare; furthermore, the unique training samples ofandareand, respectively. Thus, according to Definition, we have:

Asandare of equal size, thus,i.e., sub-modelis a-alike () model of; in another word, sub-modelis a retrained-alike model of.

The proof of Propositionis similar to that of Proposition. We can deduce that updated reference modelis a-alike () model of(i.e., the naïve retrained version of). Therefore,is a retrained-alike model ofaccording to Definition.

We have the sub-model, and the sub-model. Assuming the unlearning data, according to Proposition, the sub-modelcan serve as a suitable reference model to refineto achieve unlearning by distillation.

Using ETID, the unlearned sub-modelis generated under the supervision ofwith the objective Eq., by enforcing the outputs ofon unlearning datato be close to those of,i.e.,. As the outputs ofonare different from those of,i.e.,, we can take the difference between the outputs of these two models,and, as a verification function to distinguish them from each other.

SECTION: B. Verifiability Examination
In this part, we demonstrate how we use the membership inference to conduct the verifiability examination in detail. It includes two steps, Membership Inference (MI) model construction (as illustrated in Figure) and M-AUC-based examination (as shown in Figure). We first introduce some notations. Specifically, we useto denote the testing dataset,denotes the features of the testing samples; whileis the same number of randomly sampled training samples as,is the features of these training samples. It is worth noting thatand the unlearning dataare non-overlapping. Moreover, we useto denote the features of the unlearning data.is the same number of randomly selected testing samples as, which is regarded as non-members to test the MI model,denoting their features. We further defineandas the membership label vectors of member samples(with label "1") and non-member samples(with label "0"), respectively.

In the first step, we input the features of training samplesand the same number of testing samplesinto the target model, and obtain the corresponding outputsand, respectively. Then, we combineand(as features), andand(as labels) to construct a training datasetfor MI model. Next, we train a binary MI modelusing a two-layer fully-connected neural network with the training dataset. During the examination step, we input the unlearning samplesand the same number of testing samplesinto the target modelto obtain the outputsand, and provide the membership label vectorand, respectively; similarly, we obtainandby the unlearned model, also company withand. Next, we respectively input the outputs of the target modeland the unlearned modelinto MI model, and calculate the M-AUC scores of two models. Finally, we obtain the absolute difference of the two M-AUC scores.