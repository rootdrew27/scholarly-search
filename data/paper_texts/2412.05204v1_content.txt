SECTION: Global Optimization with A Power-Transformed Objective and Gaussian Smoothing

We propose a novel method that solves global optimization problems in two steps: (1) perform a (exponential) power-transformation to the not-necessarily differentiable objective functionto obtain, and (2) optimize the Gaussian-smoothedwith stochastic approximations. Under mild conditions on, for any, we prove that with a sufficiently large power, this method converges to a solution in the-neighborhood of’s global maximum point. The convergence rate is, which is faster than both the standard and single-loop homotopy methods. Extensive experiments show that our method requires significantly fewer iterations than other compared algorithms to produce a high-quality solution.

SECTION: 1Introduction

In this work, we consider the global optimization problem of

whereis a continuous and non-concave function with a global maximum, andis a positive integer. The minimize-version of this problem is often encountered in machine learning, such as model training and adversarial attack in computer vision. The gradient-based algorithms, such as the (stochastic) gradient descent, are commonly used, which only guarantee to approximate a locally optimal solution in a general case.

Homotopy, also called graduated continuation, is a class of methods for finding a global solution to (1), with many successful applications in machine learning (e.g.,[]). It converts the original problem to

whereis called the scaling coefficient andis a random variable with a pre-selected distribution, such as a standard multivariate Gaussian distribution (Gaussian Homotopy, GH) or a uniform distribution in a unit sphere. Based on the observation thatapproaches111Note thatif.asdecreases to 0, the homotopy methods admits a double-loop mechanism: the outer loop iteratively decreases, and for each fixed value of, the inner loop solves, with the solution found in the current inner loop as the starting search point in the next inner loop.

The double-loop mechanism of the homotopy methods is costly in time. To tackle this issue,[9]propose a single-loop Gaussian homotopy (SLGH) method that iteratively performs one-step update ofand, which reduces the convergence rate fromto. However, in theory SLGH only guarantees to approximate a local optimum222Theorem 4.1 in[9]shows that SLGH approximates a solutionsuch that., which is not necessarily a global one. A time-efficient algorithm that aims at the global maximum is still to be found.

Therefore, in this work, we propose a new method, namely the Gaussian Smoothing with a Power-transformed Objective (GSPTO), for solving the optimization problem of (1). According to Corollary1, GSPTO converges to a neighborhood ofwith the rate of. It indicates that GSPTO is faster than the standard homotopy and SLGH, ifis pre-selected to lie in. This point is verified by experiments in Section5, which show that the GSPTO-based algorithms (PGS and EPGS, introduced later) are significantly faster than other algorithms to produce high-quality solutions.

Under the condition ofand an additional one, there is a thresholdsuch that whenever, the Gaussian-smoothed objectiveis concave in(see[16, Main Result (Corollary 9)]). Hence, Gaussian smoothing converts the original possibly non-concave maximization problem to a concave one, if the maximum pointcoincides with. Although this condition is not true in general333This is why smoothing alone is insufficent for optimization, and is typically used in conjunction with iteratively reducing the scaling parameter, which becomes the homotopy algorithm., we can modify the objective to makeclose to(global maximum point of the original objectivebefore modification).

Intuitively, if we modiftyto put sufficiently large weight on its global maximum, the global maximumshould get close enough to. One way of such modification is by taking powers of, if. The differenceis positively related with the power, which indicates that more weight is put onasincreases. Figure 1 (a) verifies this intuition with an example, and Figure 1(b) illustrates the effects of taking exponential powers.

From the above intuition, we propose GSPTO for solving the global optimization problem (1), which is a new method that places more weight on the objective’s maximum value (by increasing the gap between the global and local maximum values) before performing Gaussian smoothing. Based on GSPTO, we design two algorithms, Power Gaussian Smoothing (PGS) and Exponential Power Gaussian Smoothing (EPGS), which are featured with replacing the original objectivewith a (exponential) power transformation. Specifically, withandas two hyper-parameters, PGS solvesand EPGS solves, both using a stochastic gradient ascent algorithm derived in this paper, which does not require the differentiability of. Here,denotes a multivariate Gaussian distribution anddenotes an identity matrix of dimension.

The homotopy methods, firstly proposed in[2, Chapter 7], are intensively studied in the field of machine learning for global optimization problems.[15]derives a bound for the worst scenario of the GH algorithm in a deterministic setting (i.e., the expectationis not approximated with samples), while[8]provides a convergence analysis in a stochastic setting (i.e.,is estimated with samples). Specifically, the latter proves that with a probability greater than, the solutionproduced by their proposed homotopy algorithm is-optimal (i.e.,) aftersteps of solution-update.[6]changes the distribution of the perturbationfrom the commonly used Gaussian or uniform to the distribution that minimizes the estimation error of the gradient.[12]proposes an algorithm for learning the whole solution path produced by the homotopy. Specifically, their algorithm learns a modelthat predicts (for any) the solution to, whereis the set of model parameters to be trained.

The smoothing and homotopy methods have a large number of successful applications in machine learning, such as neural network training ([8]), adversarial attack on image classification models ([9]), solving-regularized least-square problems ([18]), neural combinatorial optimization ([6]), improving the optimization algorithms of stochastic gradient descent and Adam ([17]), and so on.

There are two existing studies,[5]and[3], that replace the originalwith a surrogate objective,, which also involves the exponential transformationbefore smoothing (andare pre-selected and fixed). But their works are different from ours. In[5], the proved result444is a convex problem given thatis positive definite andis convex ([5, Theorem 3.1]).that justifies their surrogate objective requires that, andbe selected so thatis positive semi-definite. This indicates that EPGS, for whichand, is not a special case of theirs, sinceis negative definite and violates their requirement. Moreover, their theory on the distance between the optimum point of the new surrogate andis incomplete (see[5, Section 3.2]).[3]focus on the case whereis close to 0 (see the setence below their Eq. (7)), which is very different from GSPTO’s requirement thatis sufficiently large.

SECTION: Contribution

This paper introduces a novel method, GSPTO, for solving global optimization problems, with the contributions summarized as follows.

To our knowledge, for global optimization problems, this is the first work that proposes the idea555Although the surrogate objective in[5]can be viewed as a special way of achieving the effect, they have not mentioned this idea.of putting more weight on the global maximum values of the objective, to decrease the distance between the optimum point before and after Gaussian smoothing (i.e.,). PGS and EPGS are two ways of realizing this idea, and future studies are motivated for finding better ones.

GSPTO is faster than the homotopy methods (which also apply smoothing) both in theory and practice. According to Corollary1, GSPTO has a convergence rate of, which is faster than the standard homotopy method (,[8, Theorem 5.1]), and SLGH (,[9, Theorem 4.1]), ifis pre-selected to lie in. Extensive experiments show that it is significantly faster than all other compared algorithms (including the homotopy ones) to produce solutions of quality.

Our convergence analysis does not require the Lipschitz condition on the original objective, which is assumed in the theoretical analysis of homotopy methods in other studies ([8,9]). Therefore, our analysis applies to more situations.

The theory derived in this work is on the distance between the found solution and the optimal one, while the convergence analysis in other studies on homotopy is on the objective value of the found solution. Therefore, our theory has a wider range of applications (e.g., for problems that cares the distance between the found solution and the optimal like inverse problems and adversarial attack in image recognition).

SECTION: 2Preliminaries

We rigorously prove the intuition that motivates PGS and EPGS: Given, for any, there exists a threshold such that wheneverexceeds this threshold, the global maximum point oflies within a-neighborhood of, where, and

Letbe a continuous function that is possibly non-concave (and non-negative only for the case of PGS), whereis compact. Assume thathas a global maximumsuch thatfor any. For, define

whereis defined in (LABEL:fN) for either PGS or EPGS. Then, for anyandsuch that, there exists, such that whenever, we have for anythat:if, andif. Here,anddenote theentry ofand, respectively, where.

See the appendix for the proof for the EPGS setting. The proof for the PGS setting is similar.
∎

SECTION: 3Gaussian Smoothing with Power-Transformed Objective

SECTION: 3.1The Solution Updating Rule

For the optimization problem (1), based on Theorem1, with the pre-selected hyper-parametersand, GSPTO follows a stochastic gradient ascent scheme to solve. Specifically, the rule for updating the solution candidate used is

where,are independently sampled from the multivariate Gaussian distribution, andis defined in (LABEL:fN). Note thatis a sample estimate of the gradient:

Based on GSPTO, PGS and EPGS are designed in Algorithm1. They normalize the gradient before updating the solution, which is a common practice to stabilize results.

SECTION: 4Convergence Analysis

We perform convergence analysis for the updating rule (4) under the PGS and EPGS setting (LABEL:fN) on the optimization problem of (1), with, for some.

We show that, for anyand any, GSPTO converges to a-neighborhood ofwith the iteration complexity of. Specifically, withtimes of updating,, wherecan be arbitrarily close to 0. The result is summarized in Corollary1.

SECTION: 4.1Notation

In this section, letandbe fixed, andbe such that for any:if, andif, for all. Such anexists because of Theorem1. Letbe as defined as in Theorem1. Unless needed, we omitandin this symbol as they remain fixed in this section, and writeinstead.refers to the gradient ofwith respect to. Letbe defined as in (LABEL:fN).

SECTION: 4.2Assumptions and Lemmas

Assume thatis a function satisfying the conditions specified in Theorem1.

Assume that the learning ratesatisfies

Under Assumption1, any local or global maximum pointofbelongs to the set of, wheredenotes theentry.

For any point, we show that. If, thenand there is somesuch that, which impliesbecause of the definition ofin Section4.1.

On the other hand, if, there is at least onesuch that. Then,

In sum, for any point,, which further implies that any local or global maximum pointofbelongs tosince.
∎

Under Assumption1, for any, the objective functionis Lipschitz Smooth. That is, for any,

wherefor the case of PGS andfor the case of EPGS.

, whereis as defined in (LABEL:fN)..
Then,

Hence,, which isfor PGS andfor EPGS.
∎

Under Assumption1, for any, letbe as defined in Algorithm1. Then,, where

For the case of EPGS,

where the third line is by Cauchy-Schwarz Inequality. Replacingfor EPGS andfor PGS.
∎

SECTION: 4.3Convergence Rate

Letbe produced by following the iteration rule of (4), with a pre-selected and deterministicand all the involved terms defined as in Section4.1. Then, under Assumption1and2, we have that

whereunder the PGS setting andunder the EPGS setting.

Ifwith. Then,

This inequality and Theorem2implies that aftertimes of updatingby GSPTO,. In sum, the GSPTO method (4) converges to a-neighborhood ofwith a rate of, wherecan be arbitrarily close to 0.

By the Gradient Mean Value Theorem, there existssuch that for each of theth entrylies betweenand, and

Hence, we have

Taking the expectation of both sides gives

where for the first line, note that

Taking the sum fromtoon both sides of (5) gives

Re-organizing the terms gives

∎

We summarize the above results in the following corollary.

Suppose Assumption1and2hold. Given anyand, there existssuch thathas all its local maximums in. For any, under either the PGS or EPGS setting, the updating rule (4) of GSPTO producesthat converges to a local maximum point of, which lies in a-neighborhood of, with the iteration complexity of. Specifically, aftertimes of-updating by (4),, whereis a parameter in the learning rateand can be arbitrarily close to 0.

SECTION: 5Experiments

SECTION: 5.1Effects of Increasing Powers

We illustrate the improvements made by increasingfor PGS/EPGS through an example problem of

the global maximum pointhas all its entries equal to, and the local maximum pointhas all its entries equal to. The graph of its 2D-version is plotted in Figure2.

With each value of, both the PGS and EGS are performed to solve this problem. The-candidate set isfor PGS andfor EGS. For eachvalue, we do 100 trials to stabilize the result. In each trial, the initial solution candidateis uniformly sampled from, whererepresents theentry of. We set the initial learning rate as 0.1, the scaling parameteris set as 0.5, and the total number of solution updates as 1000. The objective for Power-GS is modified to beto ensure that the PGS agent will not encounter negative fitness values during the 1000 steps.

We perform the experiments in two settings, one is two-dimensional () and the other is five-dimensional ().
The results, plotted in Figure3, show that, asincreases, the distance between the produced solutionand the global maximum pointapproaches zero (see the decreasing MSE curve in the plot), which is consistent with Theorem1and the idea that’s maximumapproaches the global maximum pointofas we put more weight on

SECTION: 5.2Performance on Benchmark Objective Functions

In this subsection, we test the performance of PGS and EGS on two popular benchmark objective functions, the Ackley and the Rosenbrock (max-version). The performances of other popular global algorithms (max-version) are also reported for comparison, including a standard homotopy method STD-Homotopy, ZO-SLGHd and ZO-SLGHr ([9]), the algorithms of ZO-SGD ([7]) and ZO-AdaMM([4]) for solving, as well as the evolutionary algorithm of particle swarm optimization (PSO, e.g.,[13, Section 3.1.5]and[14]). The hyper-parameters of these algorithms are selected by trials, and the optimal ones can be found in our codes athttp://github.com/chen-research/GS-PowerTransform.

The Ackley objective function features with a numerous number of local optimums and a single global optimum. We solve the max-version of the corresponding problem, which is

The graph of this function is plotted in Figure4(a). From both the functional form and the graph, it is not difficult to see thatattains its maximum at.

The solutions and their fitness values found by each of the compared algorithms are reported in Table1. From which we see that all of these algorithms are able to avoid the local maximum points and achieve the global maximum point.

The Rosenbrock objective is known to be difficult to optimize, since its global optimum pointis surrounded by a flat curved plane (see Figure). Specifically, the problem to be solved is, where

We use PGS, EPGS, and other algorithms to solve. Their performances are recorded in Table2, which shows that EPGS, STD-Homotopy, and PSO are superior than other algorithms on this task, since they are able to locate the true solution of (1,1).

For Ackley, all the algorithms are able to locate the true solution of (1,1), except PSO when the initial population is concentrated near the initial start of, which indicates that the performance of PSO depends more on the initial guess than other methods. For Rosenbrock, EPGS is one of the three algorithms that can locate the global optimum well.

SECTION: 5.3Performance on the Black-box Targeted Adversarial Attack

Letbe an black-box666A black-box classifier refers to a classification model whose parameters are not accessible.image classifier. The targeted adversarial attack onrefers to the task of modifying the pixels of a given imageso thatis equal to a pre-specified target label, wheredenotes the perterbation and. Another goal of this task is to minimize the modification. Hence, I set the loss as

wheredenotes the predicted logit (i.e., log probability) for theclass,is a hyper-parameter that controls the certainty level of the attack,is a regularization coefficient, anddenotes thenorm of(i.e., the square root of the sum of squares of entries in). This loss function resembles the popular one in Carlini and Wagner (2017).

With EPGS and other compared algorithms, I perform adversarial attacks on 100 randomly selected images from each of two image datasets, the set of MNIST figures and the CIFAR-10 set. Specifically, the goal is to solve:

The hyper-parameters for ZO-SLGHd and ZO-SLGHr are set according to Iwakiri (2022), which performed the same task (but with a difference loss and more iterations for each trial). For ZO-AdaMM, the hyper-parameters are set according to Chen (2019) (Section 4.2). For others, the hyper-parameters are set by trials. We choose EPGS over PGS for this task since the fitness functioncan be negative and hence EPGS is more convenient. (But note that we can modifyby adding a large positive constant to facilitate PGS).

The image size in MNIST hand-written figures ([11]) ispixels and we down-sample it toto reduce the computational complexity. The classifierfor MNIST is a feed-forward neural net trained777We use TensorFlow ([1]) for training.on the training images, with a classification accuracy ofon the testing images.

For each imagethat is randomly drawn from the testing dataset, where, we randomly generate a target label. Then, for each algorithm, we perform an attack (i.e., experiment) ofiterations. Letdenote all the perturbations (solutions) produced in theseiterations. We say that a perturbationis successful if the predicted log probability of the target label is at leastgreater than that of other classes (i.e.,). We say that an attack is successful if the producedcontains at least one successful perturbation. If the attack is successful, letdenote the successful perturbation with the largest-value among, and letdenote the number of iterations taken by the algorithm to produce. Here, the-value ofrefers to thestatistic betweenand the perturbed image, which is computed as. In this formula,andranges over all the pixels (entries) ofand.

With the above notations, we construct three measures on the performances of an algorithm. One is the success rate, which refers to the ratio of successful image attacks out of the total number of attacks (100). The second measure is the average, which equals, wheredenotes the set of indices of the successful attacks. The last measure is the averageof.

For ZO-SLGHd, ZO-SLGHr, ZO-SGD, and ZO-AdaMM, the hyper-parameters are set the same as those experiments performed in[9](if available), since they also use these algorithms for MNIST and CIFAR-10 image attacks. For other algorithms, the hyper-parameters are selected by trials.

Table3reports the results of each algorithm executed foriterations for each of the 100 images, from which we see that EPGS not only has asuccess rate, but also is the the fastest to produce a successful perturbed image that is close to the original one. Specifically, when, EPGS outperforms other algorithms in terms of accuracy (i.e.,) and time (i.e.,). This-score ofis not far from theproduced by other algorithms with 8,000 iterations.

The image size in CIFAR-10 dataset ([10]) ispixels and we down-sample it toto reduce the computational complexity. We train a convolutional neural neton the training images, which has a classification accuracy ofon the testing images. We perform per-image targeted adversarial attacks on 100 randomly drawn images from the testing set. The results are reported in Table4.

The experiments are performed in the same way as for figure-MNIST and their results are reported in Table4. Similar to the MNIST experiment, EPGS significantly outperforms other algorithms in terms of time complexity. Especially when, the quality (i.e.,) of its solution is much better, which is comparable to other algorithms performed foriterations.

SECTION: 6Conclusion

In this paper, we propose the method of GSPTO for solving the global optimization problem of (1), which is featured with putting more weight on the objective’s global optimum through power transformations. Both our theoretical analysis and numerical experiments show that GSPTO is significantly faster than other homotopy methods to produce high-quality solutions. This method provides a foundation for future studies to explore more efficient ways to increase the gap betweenand other values.

SECTION: References

SECTION: 7Appendix

SECTION: 7.1Proof to Theorem1for EPGS

Recall that for EPGS,For any given, defineand. Using this symbol, we re-writeas

where

where.

We derive an upper bound for. For any,

where the third line is because, and the fifth line is by the separability of a multivariate integral.

Sinceis continuous, for(because), there existssuch that whenever,

Using this result, we derive a lower bound forwhenand.

where the first equality is implied by the fact thatdoes not change sign astravels in(this fact is because of), and

The positive numberis constructed by solving the following inequality for, which involves the two bounds in (8) and (10).

The solution of this inequality is

whereand the numerator is negative for sufficiently large.
Therefore, whenever

we have

When,, and,

where the third line is because the integrand of the first term is always negative in the integration region.

On the other hand, when,, and,

Then, (12) and (13) imply the result in the theorem sinceandshare the same sign (see Eq. (7)).
∎