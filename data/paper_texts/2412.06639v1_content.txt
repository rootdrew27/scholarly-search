SECTION: Beyond Scalars: Concept-Based Alignment Analysis in Vision Transformers
Vision transformers (ViTs)can be trained using various learning paradigms, from fully supervised to self-supervised. Diverse training protocols often result in significantly different feature spaces, which are usually compared through alignment analysis. However, current alignment measures quantify this relationship in terms of a single scalar value, obscuring the distinctions between common and unique features in pairs of representations that share the same scalar alignment.
We address this limitation by combining alignment analysis with concept discovery, which enables a breakdown of alignment into single concepts encoded in feature space.
This fine-grained comparison reveals both universal and unique concepts across different representations, as well as the internal structure of concepts within each of them.
Our methodological contributions address two key prerequisites for concept-based alignment: 1) For a description of the representation in terms of concepts that faithfully capture the geometry of the feature space, we define concepts as the most general structure they can possibly form - arbitrary manifolds, allowing hidden features to be described by their proximity to these manifolds. 2) To measure distances between concept proximity scores of two representations, we use a generalized Rand index
and partition it for alignment between pairs of concepts.
We confirm the superiority of our novel concept definition
for alignment analysis over existing linear baselines in a sanity check. The concept-based alignment analysis of representations from four different ViTs reveals that increased supervision correlates with a reduction in the semantic structure of learned representations.

SECTION: Introduction
Vision Transformers are gaining increased popularity as backbones for various computer vision tasks.
There is a large zoo of pre-trained models trained with various learning paradigms and a range of supervision strengths. To guide practitioners, previous work has evaluated performance on various common downstream tasks.

A complimentary view of comparisons within and between models beyond quantitative accuracy is achieved by analyzing patterns in hidden activations and measuring representational alignment between them.

When choosing a model for a downstream task,
we want to understand how the model solves its pre-training task. Where does the model representation change the most and how? Which concepts, i.e. dominant structures in representation space, are encoded in lower layers vs. upper layers? Where does the model representation change the most and how? How structured are the representations? Does the model encode semantically similar concepts in spatial proximity to each other? How is the representation of model A different from that of model B across layers?
Answering these questions can aid the selection of pre-trained models and the design of fine-tuning strategies through detailed insights into robustness and generalization capabilities.
Previous work on alignment, however, only provides a single scalar value to measure alignment between representations at two different layers, leaving the questions above largely unanswered.
In this paper, we propose a more fine-grained alignment analysis based on concepts that structure the latent representation. To this end, we represent the original activations by concept membership scores that quantify proximity to the discovered concepts. Then, we measure alignment between concept proximity scores of representations and can therefore partition it into the concepts. This gives insights into universal and specific concepts between representations of different layers or models, as well as how a single representation is structured.

To achieve concept-based alignment we need solutions for 1), and 2) measuring thebetween concept proximity scores.

Previous work onranges from merely identifying neurons or other pre-existing units as conceptsto linear directions in feature space. The most general definition so far relies on concepts as multi-dimensional linear subspaces. The common strong assumption among these is the linearity of concept structures, which is challenging to verify and controversial. For concepts that faithfully represent the underlying geometry of the representation, we avoid the linearity assumption and consider concepts as the most general structure they can form, namely as nonlinear manifolds.
So far,between representations has been measured as the similarity of similarities, e.g. through linear or kernel-based Centred Kernel Alignment (CKA), which results in a single scalar value. Our fine-grained concept-based alignment measure requires a distance measure between concept proximity scores. Here, we choose a generalized Rand index between soft clusterings with pseudo metric propertiesthat we partition into pairwise concept distances.

To summarize, our key idea is the following:

We combinewithanalysis to provide insights into which concepts are universal or specific between two representations, and how structured a single representation is.

We make the following methodological contributions to realize concept-based alignment:

We propose a novel concept definition of concepts as nonlinear manifolds to faithfully capture the geometry of the feature space with concept proximity scores.

We leverage a generalized Rand index with pseudo-metric properties to measure the alignment between concept proximity scores of two representations and partition it for fine-grained concept alignment.

We complement concept-based alignment analysis of ViTs trained under varying degrees of supervision from fully supervised to self-supervised with additional characteristics of concepts such as their intrinsic dimensionality.
We find that representations of ViTs exhibit markedly different structures; specifically, increased supervision correlates with reduced structure in the learned representations. This insight is crucial for understanding the model’s reasoning processes and sheds light on the performance differences observed in quantitative analyses, such as those presented in the recent battle-of-the-backbones study. Code to reproduce our experiments is publicly available at.

SECTION: Concept Discovery for Representational Alignment
This section is partitioned into three parts: First, we introduce our novel concept definition based on the manifold hypothesis. Then, we describe our methodology for discovering these concepts in latent activations, shown in Fig.. Finally, we describe how our concept-based description of hidden representations can be used to measure alignment between representations, identify commonalities and uniqueness between models, and investigate information flow within one model.

SECTION: Concept definition
According to the manifold hypothesis, which is widely accepted in machine learning, many datasets, including image data that nominally lie in high dimensional space, can be described in terms of a few underlying latent factors and are thus concentrated on a (potentially disconnected) low-dimensional manifold embedded in high-dimensional space.shows how a neural network trained on a toy classification problem solves the task by transforming the topology of the input data, and layerwise reducing the Betti numbers of the class-wise components. We hypothesize that state-of-the-art vision models behave similarly and try to recover the connected components in the hidden representations, which we callconcepts.

We analyze the hidden representation at an intermediate feature layer of a neural network. To this end, we split the modelinto two parts,, whereis the mapping to a hidden feature layer. Our definition then relies on hidden representationsof input samplesfrom a set.is the number of spatially separable elements in the representation, i.e. the number of tokens in a transformer model or the number of superpixels in a convolutional feature map. We spatially decompose the feature mapsinto a set offeature vectors.
Previously, concepts have been mostly defined as linear structures. The most general linear structure would be affine subspaces, which would already represent an extension compared to the recently considered definition as linear subspaces.
In this work, we generalize this idea even one step further and define concepts as manifolds in the-dimensional feature space.

In the following, we want to compute concept proximity scores by which we measure alignment. Incorrect assumptions about the structure of the concept manifold, e.g., assuming it has no curvature (affine subspaces) or it is spherical and the distance to the manifold can be estimated by the distance to the centroid, directly lead to distorted concept proximity scores and hence to distorted alignment.
Later, in a sanity check our definition performs best for measuring representational alignment.

SECTION: Concept discovery
Having established our definition of concepts as manifolds in feature space, we now turn to the challenge of discovering these concepts through clustering.
As stated above, we assume that feature vectorsfrom a hidden representation are sampled from a set of low-dimensional concept manifolds.
Recovering these concept manifolds in high-dimensional space (in our experiments) is a challenging clustering problem. Therefore, we revert to density-based clustering on a low-dimensional embedding of the data.
For this embedding, we utilize UMAP (Uniform Manifold Approximation and Projection), a dimensionality reduction technique that preserves local and some global structure.
Given that we have no a priori knowledge about the number of clusters, we employ HDBSCAN (Hierarchical Density-Based Spatial Clustering of Applications with Noise), which can handle clusters of varying densities. HDBSCAN builds a hierarchy of clusters based on density, represented by a condensed tree, and allows for robust handling of noise, making it suitable for the possibly intricate structure of feature representation spaces. While UMAP does not fully preserve density, its ability to maintain the overall structure of the data makes it a valuable preprocessing step before applying HDBSCAN. We use the HDBSCAN implementation from.

We leverage soft clustering with HDBSCAN based on the condensed tree which is roughly a density function over the data points to compute fuzzy cluster membership as described in, which we formalize in the appendix for the reader’s convenience. It is based on the distance to concept anchor points a cluster and an outlier score, both derived from the condensed tree. We now have a fuzzy clustering, whereholds the concept proximity scores of each concept. We interpret the concept proximity scoresas the probability that a feature vectorbelongs to a conceptin clustering.
This approach contrasts with previous concept assignment paradigms, which often rely on hard clustering, where each feature vector is assigned to a single concept, or linear methods that project onto specific concept directions, limiting the representation to a more rigid framework. In contrast, our soft clustering method allows for nuanced membership scores that reflect the degree of belonging to multiple concepts.
In the following, we refer to our concept discovery method asNLMCD(non-linear multi-dimensional concept discovery).

SECTION: Concept-based Representational Alignment
We now address the question of measuring representational alignment based on the concept proximity scores derived from fuzzy clustering.

The concepts are at this point characterized by a probabilistic clustering, where. We want to measure the similarity between two probabilistic clusteringsfrom two different representations to evaluate how aligned their concepts are. For this purpose, we leverage an extension of the pair-based Rand index generalized to fuzzy clusterings proposed in. The original Rand index counts the number of concordant pairs (either two points are paired or not paired both clusterings) and disconcordant pairs (two points are paired in one clustering but not in the other). The distance between probabilistic clusteringis based on a generalized degree of concordance that is based on the:

A commonly used choice for the distanceis.
Finally, we refer to the similarity between two clusterings, derived from the uncovered concepts, as(CBA):

We choose this measure becauseis a pseudo-metric satisfying desirable propertiesthat ease interpretation Also, whenare crisp partitions, CBA reduces to the original Rand index.

In contrast to conventional measures for representational alignment that yield a single scalar value, our approach provides a more nuanced measure of representational alignment by assessing similarities and differences between clusters. To measure distance between two clusters,from two clusterings,, we decompose the distance in Eq.into the contribution of single concepts,and measure theof each feature

Due to the absolute value in Eq., summing over all pairsdoes not yield the total, but by the triangle inequalitythe sum is an upper bound for the overall distance between two clusterings.

SECTION: Related work
Most existing methods model concepts as linear directions. Generalizing this definition,suggest that concepts can be represented more faithfully as multidimensional linear subspaces, which they discover through sparse subspace clustering. While above methods operate unsupervised without concept labels,employ kernel classifier for supervised, nonlinear concept discovery, showing improvement over linear concepts. In the field ofmechanistic interpretability, many studies aim to enumerate allfeaturesencoded in the representations of neural networks. This line of work focuses mainly on language models, often identifying linear features using sparse autoencoders. However,find evidence for the existence of multi-dimensional non-linear features. Unlike these approaches, our main goal in concept discovery is representation summarization for alignment measurement, rather than interpretability or feature enumeration. For this reason, we employ the most general, non-linear concept definition.

Representational alignment measures are categorized, with a particular emphasis on Centered Kernel Alignment (CKA) in. CKA evaluates the similarity of similarities, either linearly or under a non-linear kernel. Similarly,measure alignment through the similarities of binary k-nearest neighbor adjacency matrices, which resembles CKA with a narrow Gaussian kernel.
Our method relates to CKA in that it condenses these similarities into clusters and subsequently measures the similarity between these clusterings.

On the one hand, alignment measures such as CKA have been used to compare the representations of various architectures, including ViTs and ResNets trained on different tasks, together with the analysis of patterns in attention maps. Further, the analysis of attention patterns reveals differences between self-supervised ViTs.
On the other hand, downstream performance is analyzed to guide the selection of pre-trained models for transfer learning. Through this,shows that models pre-trainined on ImageNet generalize well but when used as feature extractors in transfer learning, i.e. when weights are completely frozen, perform badly in some settings, suggesting that the features of the last layers do not generalize well.
An extensive evaluation of the downstream performance of a large selection of vision models on classification, detection, image retrieval, and generalization is available in.

SECTION: Results
We evaluate concept discovery in Sec., check the superiority of our new concept definition over linear baselines for concept alignment analysis in Sec., and perform a concept-alignment analysis between four ViTs in Sec..

SECTION: Concept discovery
First, we outline the concept discovery procedure as described in Sec.and evaluate the quality of the UMAP embeddings used for HDBSCAN clustering and the clustering itself.

For concept discovery and later analysis of representational alignment, we use a random subset of 25 % of the ImageNet train set, stratified samples across all 1000 classes.
We study four different ViTswith the same architecture (base, patch size 16, input size 224) but different training objectives and training datasets described in.
We perform concept discovery separately for the sequence (SEQ) and the CLS token. We extract activations at the last MLP layer of each of the twelve transformer blocks. For the sequence tokens, we average-pooltoken and select one of the pooled tokens from the sequence with more weight on the center of the image. For SEQ tokens, we discard the last block as for the considered models only the CLS token in the final layer enters the loss.
We evaluate how well the embedding on which we perform the clustering preserves the distances by measuring the mean squared error between the distance matrices in the original representation and its embedding (RMSE).
To evaluate the clustering, we compute a density-based validity index (DBCV), which measures intra- vs inter-cluster density. Further, we report the rate of points classified as noise by HDBSCAN. To treat the noise rate and validity index separately, we do not weight the average for the DBCV across clusters by the cluster size as proposed in. Lastly, we evaluate how robust our approach is by measuring the alignment between two runs with different initializations by CBA from Eq..

Before discussing the results on embedding and clustering quality (see Fig.), we detail the hyperparameter tuning process for UMAP and HDBSCAN.
For UMAP, we tune the minimal distance parameter to enhance local cluster density, acknowledging that a lower minimal distance can increase noise. The number of neighbors parameter controls the local structure captured by the embedding; smaller values capture finer local neighborhoods but may distort the global structure, which is important for subsequent concept alignment analysis. We also experiment with the embedding dimensionality, constrained by practical considerations—the curse of dimensionality renders density clustering in the original high-dimensional representation infeasible, whereis the practical limit for the embedding dimensionality.
For HDBSCAN, the minimum cluster size parameter is tuned to balance between identifying noise and merging distinct clusters; a too-small value may recognize noise as clusters, while a too-large value could merge distinct clusters. We set the min samples parameter, which controls the algorithm’s conservativeness regarding noise, relatively low due to sampling limitations - some concept manifolds may not be sampled densely enough. We tune all these hyperparameters to maximize the DBCV across models and layers. During hyperparameter tuning, we weight the average DBCV across clusters by their respective sizes to indirectly account for the noise rate. The final hyperparameters used in all subsequent experiments are reported in the appendix.
Turning to the results presented in Fig., we observe that
RMSE increases slightly across layer for most models. Only for FS there is a strong increase from layer eight onwards, indicating these representations are more difficult to embed and we can trust the clustering on the embedding less which has a high DBCV but low robustness.
The density-based validity is medium, but similar across models and SEQ tokens vs. CLS tokens. Given how challenging the clustering task is, we view this result as decent and refer to the convincing qualitative impression of the clusters inand.
Noise rates are rather high but decrease across layers.
The high noise may be due to insufficiently dense sampling, i.e. thorough sampling of noisy regions could result in concept clusters. However, the number of input samples is restricted computationally by UMAP and HDBSCAN.
Robustness decreases for all models across layers but stagnates at aroundfor most models in the late layers. This links back to the trend in RMSE which shows that higher layers are harder to embed.

For the qualitative evaluation of our concept discovery method, we constructconcept formation graphs(CFGs) that depict the flow of token assignments to concepts from one layer to the next as an unweighted, directed graph.displays the formation of the “apples” concept throughout the layers of the FS model. Note that these graphs may be incomplete, as some nodes might not be detected by the clustering method, illustrating the under-sampling problem described above. Additional examples for other models and the detailed algorithm for CFG construction are provided in the appendix.

SECTION: Sanity checking concept structure for alignment
We use a sanity check to demonstrate how concept-based alignment analysis benefits from concepts defined as non-linear manifolds by comparing against concept alignment based on other definitions and discovery methods. The sanity check is based on the assumption that neighboring representations should be most aligned. We measure the ratio of layers for which a neighboring layer is most aligned under CBA fromWe compare NLMCD concepts against one-dimensional linear subspaces discovered by, multi-dimensional linear subspaces discovered by MCD, and spherical concepts discovered by KMeans clustering. To obtain soft concept membership scores for the linear subspaces, we project the feature vector onto the concept subspace and clip to negative values to 0, as we argue that a feature vector pointing into the opposite direction of a concept signifies the concept not being active. For KMeans concepts, we measure concept proximity by the euclidean distance to the cluster centroid. We also normalize concept membership scoresas their sum is required to be less bounded by onein Eq.. There is no direct way to estimate the number of concepts for PCA, MCD and KMeans, so we use allcomponents for PCA for a conservative baseline, and the number of concepts discovered by NLMCD for MCD and KMeans discovery.

We present the scores in Tab.for SEQ and CLS token concept alignment. We find that our approach performs best across all models except DINO where PCA achieves the highest score. All other concept frameworks reach NLMCD scores only for single models. For the CLS token, the gap between NLCMD and the other methods is larger than for SEQ token alignment.

SECTION: Concept Alignment Analysis
We now investigate concept-based alignment described in Sec.between representations across layers and models. We structure the analysis intointra-modelandinter-model. Due to limited space, we focus on SEQ representation and defer the CLS representation analysis to the appendix.

We analyze how representations are transformed within one model and how they are structured across layers. To supplement concept-based alignment analysis between representations, we further evaluate alignment with labels from ImageNet-1k and token location and the intrinsic dimensionality of each concept.
With this analysis, we answer the questions: 1) Where does the model representation change the most and how? 2) Which concepts are encoded in lower layers vs. upper layers? 3) How structured are the latent representations - does the model encode semantically similar concepts in spatial proximity to each other? opened in the introduction.

First, we focus on the intra-model alignment heatmaps between SEQ representations across layers measured by CBA fromin the upper row of Fig..
Interestingly, the transformation process in CLIP, DINO and MAE models is split between the first, i.e., layer one to six, and the second model half, i.e., layer six to eleven. The concept characteristics in Fig.reflect this break and give insight into how the representation is transformed between the break from layers six and seven. The concept count increases rather smoothly across layers for these models, but picks up at layer seven. In contrast, class alignment has a marked increase at this point. For DINO and MAE, the average intrinsic dimensionality of concepts slightly decreases at this point but increases further for CLIP. Lastly, token location alignment also has the most significant decrease at this point.
In contrast to the models above, the FS model exhibits a pronounced change rate between nine and ten, resulting in a sudden enhancement in class alignment at layer 10, accompanied by a marked increase in the number of clusters and intrinsic dimensionality. This is reflected in a low alignment between representations in the last two blocks of the FS model and indicates a nucleation process, where concepts begin to separate into distinct classes used for supervised training. This nucleation process has been previously observed in ResNets.

We now zoom in and partition the representation into single concepts, at layer six just before the block separation in CLIP, DINO, MAE and at layer eleven as the last layer of the second model part.
We construct a UMAP embedding based on the distance between concept pairs measured byfrom. Each point in thisconcept atlascorresponds to a different concept. To convey their meaning, we show four random input tokens from the members of the concept cluster(framed by a yellow box). Concept atlases for the representation at layer six and eleven across all models in  give a visual impression of how semantically organized the concepts are. To guide the eye, we color-code the concept clusters based on categories derived from the ImageNet-1k labels of the images from which the patches were extracted. We first map these labels to more abstract categoriesusing the WordNet hierarchy. After mapping, we perform a majority vote among all patches in a cluster to assign the category.
At layer six, concepts appear structured, but not yet aligned with the WordNet categories. By visual inspection, concepts are less abstract and rather encode structures, shapes and object parts. Representations across ViTs at this layer show a similar level of structuredness.
In contrast, at layer eleven, the FS representation is notably less semantically organized than that of the other models. For CLIP, DINO, and MAE we point out how well the canine concepts are separated. To further exemplify, human body parts like neck, shoulder, and legs are grouped together in the representation of DINO and MAE. This alignment requires not only the preservation of local, or intra-cluster distances, but also the maintenance of broader, inter-cluster distances.
We conclude that supervised training for the FS model does not enforce this level of semantical organization. In fact, it might make sense to push similar concepts apart in feature space to avoid confusion. However, this likely has negative implications for generalization to other tasks.

We now analyze how the representations between two different models differ and presentfrombetween all layers of the models fromin the upper part of.
We observe higher alignment between the self-supervised models DINO and MAE than with CLIP and the FS model in the alignment heatmaps. Further, layers of the first are more aligned than those of the second half across all models pairs. We conclude that basic foundational features are learned similarly across models, while later layers diverge as the models specialize to concepts serving their pre-training task.

We zoom in into the distancefrombetween concept pairs from representations of DINO and MAE layer six in the lower part of. We visualize the distance matrix between all concepts. To select specific examples of pairs for inspection, we match concepts via the Hungarian algorithm that minimizes the sum of distances of pairs. From this selection, we show concept pairs with low distance (blurriness, satchel of a hedgehog, zebra stripes)
and high distance(complex high-frequency structure, vertically textured structure, fountain and fog-like). Both the universal concepts with low distance and the more specific concepts with high distance seem to correspond mainly to structure and texture but visual discrepancy is more pronounced for high-distance concepts.

SECTION: Conclusion
We propose a novel approach that combines concept discovery with representational alignment analysis in ViTs.
With concept-based alignment analysis, we answer the questions raised in the introduction and examine the structuredness in feature spaces of different ViTS, as well as fine details between the concepts of two different models. These insights are not available through traditional scalar alignment measures.
Understanding the structured nature of latent spaces can guide practitioners in choosing models that not only perform well on benchmark datasets but also exhibit robust feature representations for downstream tasks. For instance, the nucleation process in FS emphasizes the importance of model structure over mere classification accuracy when selecting a pre-trained model.

The computational scalability of HDBSCAN limits the sampling of feature vectors which makes undersampled concept regions appear as noise. The limited variability of ImageNet-1k might obfuscate the meaning of a concept, e.g. when a concept represents a color but there are only dog patches of that color.

This work was supported by the European Union’s Horizon Europe research and innovation programme (EU Horizon Europe) as grants [ACHILLES (101189689), TEMA (101093003)]; and the German Research Foundation (DFG) as research unit DeSBi [KI-FOR 5363] (project-id: 459422098).

SECTION: References
SECTION: HDBSCAN
After concept discovery with HDBSCAN, we compute concept proximity scores, whereholds the concept proximity scoresof each concept. These rely on the implementation of soft clustering with HDBSCAN from, which we formalize here for the reader’s convenience.

HDBSCAN first transforms the feature space using a density-informed metric calledmutual reachability distance

whereis the distance between a pointand its-nearest neighbor.
Based on the mutual reachability distance between all pairs, a minimum spanning tree is constructed that connects all points and minimizes the sum of the edges weighted by MRD. From this, a hierarchical tree is constructed via robust single linkage clustering.
The hierarchical tree is condensed by eliminating insignificant clusters and simplifying the hierarchy. This is achieved by selecting a range ofpersistencevalues, which are the inverses of the mutual reachability distances (). Clusters that persist over significant ranges of, i.e. they are stable across multiple density levels, are retained, while clusters that exist only over narrow ranges ofare considered noise and pruned from the tree. The result is a condensed tree that focuses on the most significant clusters.
Finally clusters are extracted from the condensed tree either based on their stability across different density levels or simply the leaf nodes are identified as clusters.

The soft cluster membership scores combine a distance-based membership with and an outlier score.

For theto cluster, firstexemplar points,, are extracted. A single centroid is not enough to characterize a cluster as its shape can be arbitrary. The exemplar points are the points within the leaf nodes beneath clusterwith maximum persistencein the condensed tree, i.e. the densest points where the cluster persists.

Then, the distance membership score between a pointand a clusteris the inverse minimum distance across the exemplar points,

normalized across all clusters.

Thecompares a point’s membership persistence to the total persistence of a cluster:

Here,is the persistence value at which clusterfirst appears, i.e. its birth point in the condensed tree andis the persistence value at which pointwould join cluster.

Finally, distance and outlier-based membership are combined with stronger emphasis on outlier-based membership,

and normalized.

This membership scorecan be interpreted as the probability that a pointbelongs to cluster, given that the point belongs to some cluster,

We want to compute the joint probability, which includes the probability thatmay be noise,

Here,is the probability thatbelongs to some cluster.
To estimate, thevalue at whichwould join the nearest cluster is compared to the maximumvalue of that cluster,

whereis the persistence value at which pointwould join its nearest clusterandis the maximumvalue of cluster.
Thus, the final probability, that pointbelongs to clusteris,

SECTION: Details on experimental setup
Here, we provide further details on the experiments.

We list the URL of each Vision Transformer provided by the timm library:

FS:

CLIP:

DINO:

MAE:

We tune hyperparameters of UMAP and HDBSCAN such that the density-based validity index DBCV is maximized across models and layers. Here, for DBCV, the average across clusters is weighted by their respective size such that the noise rate is indirectly included. We re-iterate the effect of the most influential hyperparameters that we tune and state the final value we used:

: a low minimal distance in UMAP enhances local cluster density but may also increase noise. We use a value of 0.01 in all experiments.

: the number of neighbors controls the local structure, the smaller the finer it captures local neighborhoods but distorts global structure which is important for concept alignment analysis later. We use a value of 30 in all experiments.

: We use the practical limit for HDBSCAN ofin all experiments.

: a too small minimum cluster size may identify noise as a cluster, whereas, when too large, distinct clusters will merge. We use a value of 50 in all experiments.

: controls how conservative the algorithm is about noise. We need this to be rather low because of sampling limitations which means that most likely some concept manifolds are not sampled densely enough. We use a value of 20 in all experiments.

Additionally, we assume that clusters are rather uniform in size and select the leaf nodes in the HDBSCAN hierarchical condensed tree as clusters.
Sampling one pooled SEQ token (we average-pool overtokens) or one CLS token from each representation of images within a 25% subset of the ImageNet1-1k train set results in 315.770 feature vectorsfor clustering. We use the cuMLversions of HDBSCAN and UMAP for computation on the GPU.

To assign a label from the WordNet Hierarchy to each concept cluster, we first assign the ImageNet-1k label of the image from which a token is extracted to its representation feature vector. Then we map this to a label higher in the WordNet hierarchy by the mapping in. We then assign the most frequent label among the cluster membersto the cluster.

Our concept-based alignment measure CBA is based on pairs of feature vectors. To reduce run-time, we sub-sample 20% of the 315.770 feature vectors before computing CBA.

SECTION: Concept Formation Graphs
The algorithm for construction of a concept formation graph is defined as follows:

We begin by assigning each token in each layer to either one or more concepts or marking it as noise. Soft assignments are thresholded.

Next, we compute transition matrices for each pair of consecutive layers,. Each matrix entry represents the count of tokens transitioning from a concept in layerto a concept in layer.

The CFG for a target node is then constructed recursively. Starting from the target node, we add all predecessor concepts whose “contribution” (the proportion of incoming transitions) surpasses a specified threshold. The resulting CFG is a binary, unidirectional graph in which nodes representing noise are excluded.

,andillustrate additional exemplary CFGs for CLIP and DINO.

SECTION: Concept alignment analysis
SECTION: CLS representations
We investigate concept-based alignment within and across models based on the CLS token representations analogous to the SEQ token analysis in the main paper.

First, we focus on the intra-model alignment heatmaps between CLS representations across layers measured by CBA in the upper row ofand compare it to the same analysis between SEQ representations shown in the main paper.
For the CLS representations of the FS model we see a very similar pattern as for the SEQ representations. Also for CLIP and MAE, the CLS intra-model alignment mirrors that of the SEQ representations; however, the first two and one blocks, respectively, show significantly lower alignment than in the SEQ tokens. This is reasonable since the model might not use these for processing information in the early blocks. Interestingly, for DINO, the CLS token alignment across layers is significantly lower than the SEQ token alignment. Class label alignment, intrinsic dimensionality of concept clusters and concept count for the CLS representations inare also similar to the SEQ results except for DINO. Here, DINO CLS concepts exhibit a notable difference to DINO SEQ concepts: the concept count, class alignment, and intrinsic dimensionality increase sharply between blocks 9 and 10 for the CLS representation but not for the SEQ representation. Lastly, the structure of the concept atlases in the lower part ofdiffers the most from the structure of the SEQ concept atlases for DINO, where CLS concepts at layer 11 are less semantically organized than SEQ concepts. These observations suggest that the differences in how CLS and SEQ tokens represent and abstract information are most pronounced in DINO among the models.

Second, we analyze how the CLS representations between two different models differ and present CBA alignment between all layers and model in the upper part of. Like for the SEQ representations, CLS representations at layers of the first are more aligned than those of the second half across all models pairs, suggesting that basic foundational features are learned similarly across models, while later layers diverge as the models specialize to concepts serving their pre-training task. However, the overall alignment between models is weaker for CLS representations than for SEQ, also in low layers.
Next, we zoom in into the distancebetween concept pairs from CLS representations of DINO layer 3 and MAE layer four in the lower part of. We visualize the distance matrix between all concepts and inspect pairs of concepts matched via the Hungarian algorithm. Most of the concepts in the pairs seem to correspond to the color composition of the images.
Visual discrepancy is more pronounced for high-distance concepts than for the other pairs with lower distance.

SECTION: Additional results for SEQ representations
To give a more detailed view of the organization of concepts across the layers of one model, we select the DINO model and show the respective concept atlases at layer one, six and eleven in,, and, respectively. To give an overview of the structure within a concept atlas, we group the concepts in the UMAP embedding via KMeans and show four random concepts for each group. In layer one, many concepts correspond to color, in layer six, they represent mostly textures, and in layer eleven they correspond to abstract concepts. Moslty, concepts within a group are of similar nature.

In the main paper, we show fine-grained inter-model concept distances between DINO and MAE at layer six in the center of the both models. Here, we add fine-grained concept distance anaylsis in the first and last part of the models inand.
We show the full pairwise distance matrix as well as how distances between matched pairs are distributed. We partition the pairs into four regimes of distances with low, medium-low, medium-high, and high distance.
The concept pairs between MAE layer 3 and DINO layer 2 seem to correspond mostly to edge detectors or abstract patterns. Among the low and medium-low distance pairs are grid vs. stripes (second low-distance concept pair) and diagonal edge detectors (seond medium-low distance concept pair). The common nature of the medium-high to high-distance pairs is hard to interpret but pairs include warm vs. bright light (first medium-high distance concept pair), and blurriness (third high-distance concept pair). The limitation of visualizing low-level concepts through ImageNet-1k images, as described in the main paper, becomes apparent here.
In contrast, the matched concept pairs between MAE and DINO layer 10 are easier to interpret - e.g. owl face or flame.