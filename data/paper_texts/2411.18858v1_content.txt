SECTION: COMPrompter: Rethink SAM in Camouflaged Object Detection with Multi-Prompt Network

In this paper, we rethink the Segment Anything Model (SAM) and propose a novel multi-prompt network called COMPrompter for camouflaged object detection (COD).
SAM has zero-shot generalization ability beyond other models and is able to provide an ideal framework for COD. Our network aims to improve the single prompt strategy in SAM to a multi-prompt strategy. To achieve this, we propose an Edge Gradient Extraction Module, which generates a mask containing gradient information related to the boundaries of camouflaged objects. This gradient mask is then utilized as a novel boundary prompt, enhancing the segmentation process. Then, we design a Box-Boundary Mutual GuidanceModule. The modulefosters more precise and comprehensive feature extraction through the mutual guidance between the boundary prompt and the box prompt. This collaboration enhances the modelâ€™s ability to detect camouflaged objects accurately. In addition, we employ the discrete wavelet transform to extract high-frequency features from the imageembeddings. The high-frequencyfeatures serve as a supplementary component to the multi-prompt system. Finally, our COMPrompter guides the network to achieve improved segmentation results, thereby advancing the development of SAM in COD. Experimental results on COD benchmarks are demonstrated that COMPrompter has reached the cutting-edge performance,surpassing the current leading model by an average positive metric of 2.2% in COD10K. In the specific application of COD, the experimental results in polyp segmentation show that our model is also superior to top-tier methods.The code will be made available at https://github.com/guobaoxiao/COMPrompter.

SECTION: 1Introduction

Camouflaged object detection (COD)[fan2023advances]has been extensively studied as a subset of image segmentation tasks, finding applications in medical image segmentation[fan2020pranet], nature conservation and wildlife research[lidbetter2020search]as well as search and rescue missions.

Within the COD domain, diverse methods center around essential information sources, including context (e.g., MSCAF-Net[liu2023mscaf], C2FNet[sun2021context]), edge (e.g., JCSOD[li2021uncertainty], R-MGL[zhai2021mutual], TINet[zhu2021inferring]), gradient (e.g., DGNet[ji2023deep]). Other methodsemploy a range of effective strategies such as amplification (e.g., ZoomNet[pang2022zoom]), humans attention (e.g., SegMaR[jia2022segment]), predation (e.g., SINetV2[fan2021concealed], LSR[lv2021simultaneously], PFNet[mei2021camouflaged], PraNet[fan2020pranet], SINet[9156837]), uncertainty (e.g., UGTR[yang2021uncertainty], UCNet[zhang2020uc]). In recent studies, notable efforts such as SAM-Adapter[chen2023sam]and MedSAM[ma2023segment]leverage the Segment Anything Model (SAM)[Kirillov_2023_ICCV]to address the COD task.SAM excels in segmentation across various scenarios, including camouflage. This is attributed to its robust zero-shot generalization ability.By providing COD with preliminary segmentation results at minimal computational cost, SAM empowers researchers to craftmore approaches tailored to the unique characteristics of camouflaged targets.Despite these strides, existing methods often neglect the constraints associated with a single prompt.More critically, these methodsfail to explore alternative prompt types beyond those provided by SAM. In the context of COD, a noticeable disparity persists between SAM-based methods and the current state-of-the-art (SOTA).

In this paper, we propose COMPrompter, a multi-prompt networkfor COD. COMPrompter leverages the strengths of SAMand expandsits utility to the COD domain. Departing from the direct utilization of SAM, COMPrompter introduces a multi-prompt strategy, integrating both the original box prompt of SAM and boundary prompt. In the boundary prompt, we particularly emphasize edges and gradients due to their extensive exploration. Identifying edges is more straightforward than recognizing the entire camouflage target, and gradients offer a fresh perspective on segmentation. Yet, both approaches come with their challenges: designing an edge module significantly increases computational overhead, and the targeted nature of internal gradients for different objects poses limitations. In the specific application domain of COD, such as the polyp segmentation, similar challenges are also prevalent.

In response to these challenges, we do not perform edge prediction. Instead, we integrate edge information with gradients into the network through prompts.That results in improved accuracy.Our proposed boundary prompt not only circumvents the aforementionedissues. In conjunctionwith the box prompt, it provides a more accurate prior for COD. Specifically, the boundary prompt is derived from our proposed Edge Gradient Extraction Module (EGEM). EGEM uses dilation and canny operations on GT and image, respectively. Then, EGEMobtain edge masks containing gradient instead of the whole camouflage target.Acquiring the gradient-enhanced boundary operation is straightforward, yet innovative, as prior research has not emphasized the gradient at the edge.To effectively guide segmentation using both the box and boundary prompts, we introduce the Box-Boundary Mutual Guidance Module (BBMG). BBMG strengthens the connection between dense box embedding and dense boundaryembedding. It achievesthis using the adapted pointwise convolution of depthwise separable convolution[Laurent2014Rigid]and residual connection. Additionally, inspired by Heet al.[he2023camouflaged], we incorporate Discrete Wavelet Transform (DWT) to obtain high-frequency signals, representing details or rapidly changing parts of the signal.
Finally, through the judicious combination of EGEM, BBMG, and introduced DWT, we present COMPrompter for COD, a variant of SAM tailored to COD. In COMPrompter, we adjust the SAM structure to accommodate our multi-prompt strategy. Explicitly, we integrate a prompt encoder into SAM to handle the proposed boundary prompt. Experimental results on four benchmark datasets substantiate the superiority of our method, outperforming all other SOTA methods, as illustrated in Fig.1. The complete network structure is depicted in Fig.2.

Our contributions are summarized as follows:

We propose a multi-prompt network (COMPrompter) for COD, a structural variant of SAM for COD. Precisely, we propose a multi-prompt strategy, the original box prompt of SAM and the newly designed boundary prompt, as the user prompt of COMPrompter.

We propose two efficient designs in COMPrompter, EGEM and BBMG. EGEM obtains the gradient mask of the boundary from image and ground truth (GT). Box prompt and boundary prompt guide and complement each other through BBMG for accurate prompt.

We verify the performance of COMPrompter on COD benchmark datasets. COMPrompter outperforms the existing SOTA methods. We also conduct extensive experiments in polyp segmentation, and conclude that COMPrompter reaches the cutting-edge in this domain.

SECTION: 2Related Work

SECTION: 2.1Segment Anything Model (SAM)

As a new foundation model, SAM uses a huge dataset for training and has excellent zero-shot ability.
As shown in Fig.3, SAM consists of three modules: image encoder, prompt encoder and mask decoder. The image encoder is large-scale pre-trained by masked auto-encoder modeling, and has good feature extraction ability. The prompt encoder encodes the user prompt to obtain sparse embedding and dense embedding. Important for the mask decoder is the design of self-attention and cross-attention.
But it often splits the object with the same semantic information into multi masks[ji2023sam]. The reason is that SAM lacks the guidance of semantic information.
In a specific field, SAM is unable to segment accurately of fine structures, due to the lack of professional knowledge, or a lack of strong prior[ma2023segment]. Maet al.[ma2023segment]usedbox prompt as manual prompt,fine-tunedmask decoder, and achieved a good improvement. Chenet al.[chen2023sam]usedadapter to adapt SAM to COD, andachievedgood results, but the improvementwasnot significant.
Due to the inherent complexity of COD tasks, there exists a gap in the application of SAM within the COD domain. In this paper, we propose a multi-prompt strategy that leverages both a box prompt and a novel boundary prompt. The boundary prompt, a concept we propose, captures critical edge gradient information related to the target object. The multi-prompt strategy enhances the precision of prompts, thereby adapting to the difficulty of COD segmentation.

SECTION: 2.2Camouflaged Object Detection (COD)

Object detection[10149422][peng2022small]is a crucial task in the field of computer vision, aiming to identify specific objects present in images and determine their locations. Its application in videos involves object tracking[jiang2024box]. The subtask of detecting camouflaged targets is referred to as COD[10007893][10234216]. Some COD methodspay attention to visual features (color, texture, brightness, etc) of the object. Compared with these, the strategy of paying attention to boundary in COD is more and more widely accepted.
Zhuet al.[zhu2022can]designeda boundary guider module to accurately highlight the boundaries of hidden objects. Zhaiet al.[zhai2021mutual]designedspecified modules to improve the visualization of the edge. Jiet al.[ji2022fast]obtainedinitial edge prior through selective edge aggregation.Sunet al.[sunboundary]employed the excavation and integration of boundary-related edge semantics to enhance the efficacy of camouflaged object detection. Lyuet al.[10183371]decoupled uncertainty reasoning and boundary estimation into two branches: uncertainty-guided and boundary-guided features. These branches were then effectively aggregated to provide accurate segmentation information. Sunet al.[sun2023edge]proposed EAMNet, consisting of an edge detection branch and a segmentation branch. The edge detection branch provided enhanced foreground representations, thereby aiding the edge detection process itself. Donget al.[dong2023unified]grounded in the unified query-based paradigm, proposed UQFormer, which employs queries to derive boundary cues.On the other hand, object gradient generation is also applied in COD as an auxiliary task. Jiet al.[ji2023deep]minedtexture information by learning object-level gradients. The application of object-level gradients for obtaining texture information is more deterministic than boundarymodeling. It eliminatespotential noise from modeling.

However, a single boundary provides limitedinformation. When providingthe gradient of the whole target, the features learned by the network are messy because of the different types of camouflaged targets. Therefore, this paper proposes a novel boundary mask with gradient information of the object-background junction. Compared with the gradient information of the whole object, the gradient information of the object edge is easier to learn.

SECTION: 3Methodology

In this section, we present the details of multi-prompt network (COMPrompter). First, we describe the overall architecture of COMPrompter and present the architecture in Fig.2. Then we explain the core of this article, boundary prompt. At last, we discuss the necessity of introducing discrete wavelet transform (DWT).

SECTION: 3.1Overall Architecture

The feature extraction part of COMPrompter can be divided into two parts, the prompt encoder part and the image encoder part. Inspired by[ma2023segment], we freeze image encoder and prompt encoder, fine-tune mask decoder. In addition, the image encoder is precomputed and stored as npz. The results of image encoder can be read directly during real training. In this way, the calculation amount of Segment Anything Model (SAM) large model is greatly decreased, and the training threshold of large model is reduced. We design the boundary prompt branch. This branch contains the edge gradient extraction module (EGEM), the box-boundary mutual guidance module (BBMG) and a parameter frozen prompt encoder. Among them, EGEM is also designed to be computed inadvance. The resultingimage embedding of the image encoder is saved as an npz file, so that it can be read directly later. The boundary prompt combined with the original box prompt is used as the user prompt of COMPrompter. During inference, we use the GT to generate boundaries and boxes as user prompts, simulating user interaction scenarios. We apply DWT to image embedding to extract boundary features for supplementing the feature with frequency details.

SECTION: 3.2Boundary Prompt

We design a new boundary prompt branch with main modules consisting of EGEM and BBMG. In this paper, we first obtain the boundary mask with gradient by image, GT, edge detection and other operations. EGEM takes the boundary mask with gradient as input to the second prompt encoder to obtain the boundary embedding. Boundary prompt compensates for the original box promptâ€™s inability to provide precise boundary information. Specifically, the original box embedding and boundary embedding are fused by BBMG to achieve the purpose of mutualguidance. Finally akey embedding is obtained as the input of mask decoder.

The boundary mask indicates the masks containing gradient between the object and the background. In camouflaged object detection (COD), because the target is disguised, it is very difficult to directly identify thetarget. The difficultyof identifying the boundary is relatively small,
so boundary detection is added to COD as an auxiliary task[zhai2021mutual]. Gradient information is also widely used as another important information source. Jiet al.[ji2023deep]minedtexture information by learning object-level gradients. However, compared with the gradient of the overall object, the gradient of the boundary has a more rapid change, making it more representative. So, we propose boundary mask with gradient.
As shown in Fig.4, EGEM uses operations such as dilate and canny to extract boundary mask with gradients from image andGT. The maskis as the input of prompt encoder.
Specifically, we first perform the dilation operation of GT with, and the obtained image is subtracted from GT. In contrast to Premachandranet al.[premachandran2017pascal], where a pixel-wide boundary is employed, we utilize a dilate operation with akernel to obtain a thicker boundary. This choice is motivated by the necessity not only for the boundary itself but also for its gradient. A boundary that is too narrow may lack sufficient information, while one that is too wide may extend beyond the desired range and introduce noise. At this point, we obtain the edge image of the camouflaged target in the image. For the purpose of learning more boundary information, this paper performs the dilation operation of GT withon the obtained edge image to expand the edge of the image. In the prediction, the dilation operation of GT withalso models the case where the user prompt may be inaccurate.Their delineations tending to encompass a broader scope compared to actual boundaries. This reduces the difficulty of obtaining boundaries at inference.The expanded edge image is multiplied with the canny image to obtain the final edge image with gradient information, the boundary mask.
The boundary mask with gradientis generated as follows:

whereanddenotes severally dilate operation withand,denotes multiplication,denotes canny operation, anddenotes original image corresponding to.

In addition, we adopt the strategy of pre-calculation of EGEM like imageencoder. This is due to EGEMâ€™s independence from the subsequent modules, reducing the amount of calculation during training.Then, we store the calculated images and features in npz files instead of common image formats.

With the intention of making box prompt and boundary prompt guide each other and fuse each other, we propose BBMG. Box prompt is a sparse prompt, while boundary prompt is a dense prompt. Box prompt indicates the location of the target in the form of fourpoints. Boundary promptuses a mask to segment the boundary of the target to make up for the lack of boundary details in box prompt. Dense box embedding and dense boundary embedding are the results of box prompt and boundary prompt after prompt encoder, respectively. As shown in the right of Fig.2, we use dense box embedding and dense boundary embedding to perform join operation on the channel dimensionfirstly. Then, we apply a residual operation and pass through the CBR module (), composed of basic units of conv, bn, and rule.The optimized box-boundary embedding () is generated as follows:

wherestands for dense box embedding anddenotes dense boundary embedding.denotes the join operation by channel dimension.represents an adapted pointwise convolution of depthwise separable convolutions[Laurent2014Rigid].

SECTION: 3.3DWT

In image processing, DWT can capture features with different frequencies. Among them, the high-frequency part represents the edges and subtle changes in the image. Wanget al.[wang2022objectformer]extractedthe high-frequency features of the image.Liuet al.[Liu2023explicit]usedhigh-frequency component as prompting to adapt to various downstream tasks.

Inspired by Heet al.[he2023camouflaged], we apply DWT to image embedding. DWT focuses on the regions of diagonal high frequency in the image, that is, the rapid changes of the signal in the diagonal direction or edge information. DWT obtains the diagonal high frequency by the diagonal difference of the originalsignal. The formulaof the diagonal high-frequency information (HF) is defined as follows:

whereandrepresent respectively the horizontal and vertical components of the low-frequency signal, whileandrepresent respectively the horizontal and vertical components of the high-frequency signal.Then, the high frequency extracted by DWT is added to BBMG. The optimized box-boundary embedding () is connected withaccording to dimension. Then the adapted pointwise convolution of depthwise separable
convolutions[Laurent2014Rigid]is performed. The optimized dense embedding () is generated as follows:

wheredenotes the join operation by channel dimension,denotes an adapted pointwise convolution of depthwise separable convolutions[Laurent2014Rigid].

SECTION: 4Experiments

SECTION: 4.1Datatset

We conduct experiments on four widely recognized datasets, namely CAMO[le2019anabranch], CHAMELEON[skurowski2018animal], COD10K[fan2021concealed],and NC4K[lv2021simultaneously].This is to examine the effect of COMPrompter in the task of camouflaged object detection (COD).CAMO consists of 1250 images, randomly split into a train dataset of 1000 images and a test dataset of 250 images. CHAMELEON has 76 images of COD. The number of images of COD10K is 5066, of which 3040 are the train dataset and 2026 are the test dataset. NC4K is quite large, with a total of 4121 images. NC4K is used as test dataset for experiments to examine the generalization ability of COMPrompter.
Following Fanet al.[fan2021concealed], we adopt that the dataset is composed of the train datasets of COD10K and CAMO, which are 3040 images and 1000 images, respectively. The remaining images of COD10K and CAMO, the entire NC4K dataset and the entire CHAMELEON dataset are used as the test dataset.
In addition, we test COMPrompter on a more specific application, polyp segmentation, to achieve a more in-depth evaluation. Following Fanet al.[fan2020pranet], we use five public benchmarks datasets, ETIS-Larib[silva2014toward], CVC-ClinicDB[bernal2015wm], CVC-ColonDB[tajbakhsh2015automated], CVC300[vazquez2017benchmark],and Kvasir-SEG[jha2020kvasir].

SECTION: 4.2Experimental Setup

Implementation Details.COMPrompter is implemented using PyTorch, employing the Adam optimizer with a learning rate of. To achieve optimal performance, the model undergoes 300 epochs, completing the process inhours on an NVIDIA 3080TI GPU with a batch size of 32. We scale all the input images toby bilinear interpolation, scaling them up or down. In addition, we truncate and normalize the input imagedata. This ensures the pixel values are in the appropriate range while maintaining the relative distribution relationship of the data.

Evaluation Metrics.We adopt four metrics from COD10K[fan2021concealed]. The four metrics are widely used and recognized in the field of COD: structure measure (), weighted F-measure (),mean enhanced-alignment measure (), and mean absolute error (). In the polyp segmentation experiment, we choose mean dice similarity coefficient ()andmean IoU (). The structure measure measures the structural similarity between the predicted results and the actual segmented regions. The weighted F-measure combines precision and recall, and weights them. The enhanced-alignment measure evaluates the prediction result by comparing the alignment relationship between the predicted value and the actual value. The mean absolute error is a measure of the mean absolute error between the predicted value and the true value.

SECTION: 4.3Comparisons with Cutting-Edge Methods

Here, we compare COMPrompter with Segment Anything Model (SAM)[Kirillov_2023_ICCV]and other existing COD algorithms, such as UCNet[zhang2020uc], SINet[9156837], PraNet[fan2020pranet], C2FNet[sun2021context], TINet[zhu2021inferring], UGTR[yang2021uncertainty], PFNet[mei2021camouflaged],
R-MGL[zhai2021mutual], LSR[lv2021simultaneously], JCSOD[li2021uncertainty], SINetV2[fan2021concealed],
ZoomNet[pang2022zoom], SegMaR[jia2022segment],
DGNet[ji2023deep], MSCAF-Net[liu2023mscaf],
SAM-Adapter[chen2023sam],
MedSAM[ma2023segment].
Although MedSAM is the field of medical image processing, its method is to improve SAM universally, rather than design a network specifically for medicine. When the algorithm is applied to the COD task, it greatly improves the index. So we list MedSAM as one of the comparison algorithms. For MedSAM, we retrain and validate based on the official code.
We also compare the proposed COMPrompter with existing methods for polyp segmentation, such as U-Net[ronneberger2015u], UNet++[zhou2018unet++], ResUNet++[jha2019resunet++], SFA[fang2019selective], PraNet[fan2020pranet],
EU-Net[patel2021enhanced], SANet[wei2021shallow], LDNet[zhang2022lesion], FAPNet[zhou2022feature], SAM[Kirillov_2023_ICCV], and MedSAM[ma2023segment].
As shown in Tab.1and Tab.2, in the COD domain and polyp segmentation domain, our proposed COMPrompter achieves SOTA performance. Later, we present a detailed qualitative and quantitative analysis of the results in these two areas.

Quantitative Result.COMPrompter introduces detailed prompts and fine-tuning techniques specifically designed for COD tasks. In comparison to SAM, COMPrompter leads to a significant advancement in evaluation metrics. When compared to SAM-Adapter, another COD method based on SAM, COMPrompter stands out with several advantages. On the COD10K dataset, COMPrompter achieves enhancements, including arise in, aincrease in, aboost in, and aimprovement inover SAM-Adapter.Taking a broader perspective, COMPrompter achieves an average improvement of 4.9%, 1.7%, 4.5%, and 1.2% across three datasets compared to SAM-Adapter. This corresponds to four evaluation metrics:,,, and, respectively.When compared to non-SAM methods, COMPrompter also demonstrates its superiority. On the CAMO dataset, COMPrompter outperforms MSCAFNet with aboost in, aenhancements in, aprogress in, and aincrease in.From a holistic dataset viewpoint, COMPrompter showcases an average enhancement of 2.6%, 1.2%, 1.3%, and 0.03% for,,, and, respectively, compared to MSCAFNet across the four evaluated datasets. When compared with MSCAFNet on the CHAMELEON dataset, COMPrompter still demonstrates certain shortcomings.Overall, these results underscore the effectiveness of COMPrompter in COD tasks. Experimental results of polyp segmentation are shown in Tab.2. Compared with MedSAM, COMPrompter has an average gain ofinandin.

Qualitative Results.With a view to more intuitively show the segmentation effect of our proposed COMPrompter on COD datasets and polyp datasets, we compare the original image and GT with the predictions generated by COMPrompter, MedSAM, andSAM. This comparisonis depicted in Fig.5, Fig.6and Fig.7.
Fig.5shows the learning ability of COMPrompter. Fig.6shows the generalization ability of COMPrompter. Since there is a lack of certain semantic information when SAM is directly applied to COD, only a part of the target is segmented, as shown in the first and last column in Fig.5. Because of providing a strong prior, the segmentation effect of MedSAM greatly improved.Due to the fact that the bounding box only provides an approximate location, there still exists a certain level of semantic ambiguity. This leads to occasional segmentation errors, as demonstrated in the second image of Fig.5for MedSAM.In addition, the detail processing of the edges and occlusions of the target are not particularly ideal.In particular, in the fifth line in Fig.6, MedSAM is affected by the weed and does not segment out the target hidden behind it.Our proposed COMPrompter can segment the whole object completely and take into account the details. The foot of the bird in the third column in Fig.5is segmented.In terms of foreground occlusion, COMPrompter can clearly distinguish between target and occlusion, and finely segment them out, as shown in the sixth column of fig.5and the fifth line of Fig.6.

SECTION: 4.4Ablation study

We verify the effectiveness of box prompt, boundary prompt, and DWT through ablation experiments.
We add boundary prompt, box prompt, and DWT module to SAM in turn, using the same experimental setup as for training. Specifically, we design five models to verify the effectiveness of the three modules. The results in COD10K and NC4K are shown in Tab.3. Each module in general plays a positive role in the experimental results. Finally, our proposed COMPrompter achieves SOTA performance.

As shown in Fig.7, directly applying SAM to polyp segmentation results in a large number of incorrectly segmented regions. MedSAM can roughly segment the polyp, but the edge is not clear. COMPrompter adds boundary prompt on the basis of box prompt and segments polyps more clearly.

Efficiency Analysis.We compare input size, parameters and inference speed of our model with the COD-related models and the polyp-related models to comprehensively describe our model. It can be seen from Tab.4, the SAM-based model has a larger parameters and a longer inference time. Compared with SAM, COMPrompter greatly reduces the number of parameters and improves the inference speed by four times. Above all, the segmentation ability of COMPrompter greatly exceeds that of existing models, whether based on SAM or not. The inference times in the table is obtained by testing in one NVIDIA RTX 3080TI GPU. Except for SAM, we refer to the data on the official website.

Effectiveness of Box Prompt.The efficiency of box prompt can be verified by comparing two pairs of models: from M1 to M2, from M3 to M4. From M1 to M2, we can see that box prompt greatly improves the model performance. The enhancement achieved in COD10K isin, while in NC4K, it reachesin. From M3 to M4, on top of the guidance already with boundary prompt, we also see a performance increase ofindue to the introduction of box prompt in NC4K.

Effectiveness of Boundary Prompt.The efficiency of boundary prompt can be verified by comparing two pairs of models: from M1 to M3, from M2 to M4. Looking at four metrics, the average augmentation of boundary prompt on two datasets is(),(),(),()from M1 to M3. Compared to M2, M4 achieves an average increase of(),(),(), and(). These enhancements directly reflect the strong efficiency of boundary prompt.

In the boundary prompt, EGEM obtains a gradient-containing boundary through appropriate dilation operations. The rationale behind the setting of dilation parameters can be observed in Tab.5, showing a general trend of gradual decrease from D1 to D5. However, considering potential biases in boundary acquisition during inference, the dilation parameter setting of D1 appears overly precise (see Fig.8). Therefore, we adopt the parameters from D2.

To vividly illustrate the advantages of the multi-prompt strategy, we showcase the feature maps in the mask decoder of M2, M3, and COMPrompter, as depicted in Fig.9. Solely relying on M2 (SAM + Box prompt) yields feature maps that roughly capture the target but suffer from edge blurriness (first line). Additionally, there is insufficient attention to finer details (second line) and incomplete focus (third line). Feature maps generated by M3 (SAM + Boundary) exhibit higher edge attention (second line) but come with a broader activation range (first line). Meanwhile, COMPrompter with the multi-prompt strategy demonstrates superior edge attention and appropriate activation ranges. In some instances, it even achieves complementary activation ranges (third line).

Effectiveness of DWT.The efficiency of DWT can be verified by comparing a pair of models: from M4 to M5. Although the improvement brought by DWT is not as significant as that brought by boundary prompt and box prompt, it still exists. In addition, we conduct comparative experiments on which part of the frequencies in DWT are specifically adopted. The obtained experimental results are shown in Tab.3. We show the results by a line chart, as shown in Fig.10. The figure shows thatgets the best score on all four metrics. Coincidentally, the curves ofandin (d) coincide exactly.

SECTION: 5Conclusion

We propose COMPrompter, a novel network designed to advance the development of Segment Anything Model (SAM) in camouflaged object detection (COD). It utilizes a multi-prompt strategy incorporating box prompt and boundary prompt for accurate priors.The state-of-the-art performance of COMPrompter is demonstrated across multiple datasets.In addition, we highlight concerns COMPrompter faces challenges in accurately and completely segmenting multi objects within a single box. A single box can emphasize non-target areas between multiple targets, causing segmentation errors. A possible solution is to use a box prompt with multiple sub-boxes to accurately cover all targets.We note that the potential boundary prompt, may provide a novel perspective for COD as well as related fields. We hope COMPrompter can contribute to the advancement of applying SAM to COD.