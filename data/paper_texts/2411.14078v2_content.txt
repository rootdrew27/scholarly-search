SECTION: Self-supervised learning for radio-astronomy source classification: a benchmark

The upcoming Square Kilometer Array (SKA) telescope marks a significant step forward in radio astronomy, presenting new opportunities and challenges for data analysis. Traditional visual models pretrained on optical photography images may not perform optimally on radio interferometry images, which have distinct visual characteristics.

Self-Supervised Learning (SSL) offers a promising approach to address this issue, leveraging the abundant unlabeled data in radio astronomy to train neural networks that learn useful representations from radio images. This study explores the application of SSL to radio astronomy, comparing the performance of SSL-trained models with that of traditional models pretrained on natural images, evaluating the importance of data curation for SSL, and assessing the potential benefits of self-supervision to different domain-specific radio astronomy datasets.

Our results indicate that, SSL-trained models achieve significant improvements over the baseline in several downstream tasks, especially in the linear evaluation setting; when the entire backbone is fine-tuned, the benefits of SSL are less evident but still outperform pretraining. These findings suggest that SSL can play a valuable role in efficiently enhancing the analysis of radio astronomical data. The trained models and code is available at:https://github.com/dr4thmos/solo-learn-radio

SECTION: 1Introduction

Radio astronomy, a branch of astronomy that studies celestial objects through their radio emissions, has revolutionized our understanding of the universe. Unlike traditional optical telescopes, radio telescopes are essentially highly sensitive antennas designed to detect faint radio signals from space. These sophisticated instruments can range from single dish antennas to vast arrays of interconnected antennas spread over large distances. By capturing and analyzing these radio waves, astronomers can observe phenomena invisible to optical telescopes, penetrating cosmic dust and gas to reveal hidden aspects of our universe. This field is now on the cusp of a data revolution, with next-generation telescope arrays like the Square Kilometre Array (SKA)[10]set to generate unprecedented volumes of high-resolution data.

The SKA, an international effort to build the world’s largest radio telescope, promises unparalleled sensitivity and survey speed. Its precursors, such as MeerKAT[15]in South Africa and ASKAP[26]in Australia, are already producing vast amounts of high-quality data, foreshadowing the data deluge expected from SKA. This surge in data quantity and quality presents both opportunities and challenges for machine learning applications in astronomy.

Machine Learning (ML) techniques have become increasingly crucial in analyzing radio astronomical data. From source detection[30]to classification[31]and anomaly detection[22], ML algorithms are helping astronomers sift through terabytes of data efficiently. However, the unique characteristics of radio interferometry images pose challenges for traditional computer vision models, often pre-trained on optical images.

Self-Supervised Learning (SSL)[21]has emerged as a powerful paradigm to address these challenges. By leveraging large amounts of unlabeled data, SSL enables models to learn meaningful representations without manual annotations. This is particularly valuable in radio astronomy, where labeled datasets are often limited but unlabeled data is abundant. Moreover, the labeling schemes in radio astronomical datasets can vary significantly depending on the specific study or survey objectives, making it challenging to create large, consistently labeled datasets. SSL offers a way to leverage the vast amounts of unlabeled data while potentially bridging the gaps between different labeling conventions.

While recent works have explored SSL in radio astronomy[20], they often focus on a single SSL method or a limited set of downstream tasks. This leaves a gap in our understanding of how different SSL techniques perform across various radio astronomy datasets and tasks.

Our study aims to provide a comprehensive benchmark of SSL methods applied to radio astronomical images, with the following objectives:

Evaluate the performance of SSL-trained models compared to traditional models pretrained on natural images across various radio astronomy tasks.

Assess the impact of data curation on SSL effectiveness in the radio astronomy domain.

Investigate the transferability of self-supervised representations across different domain-specific radio astronomy datasets.

Provide insights into the most effective SSL techniques for radio astronomical data analysis.

We conduct experiments using a range of state-of-the-art SSL methods, including SimCLR[7], BYOL[18], DINO[6], WMSE[13], SwAV[5]and All4One[14]. These methods are applied to both curated and uncurated radio astronomy datasets. Our evaluation encompasses multiple downstream tasks, focusing on source classification across diverse datasets such as Radio Galaxy Zoo (RGZ)[2], MiraBest[28], and VLASS[17].
Additionally, we present the Multi-Survey Radio Sources (MSRS) dataset, a curated collection from four existing radio surveys, labeled according to a new schema specifically developed for this study. This dataset provides a unique resource for evaluating self-supervised learning methods across different radio surveys and source morphologies.

Our results demonstrate the potential of SSL in radio astronomy, consistently outperforming ImageNet pre-trained baselines across all datasets, highlighting the value of domain-specific pre-training even by simply performing linear adaptation of SSL features.
By providing this comprehensive benchmark of SSL methods in radio astronomy, we aim to contribute to the development of effective and efficient techniques for leveraging the vast amounts of unlabeled data in this domain. These insights may prove valuable not only for upcoming large-scale projects like SKA but also for informing similar approaches in other scientific fields characterized by abundant unlabeled data and domain-specific challenges.

SECTION: 2Related works

Computer vision techniques have become increasingly important in astronomy, finding applications across various wavelengths, including infrared, optical, and radio. Traditionally, machine learning approaches in astronomy have focused on unsupervised learning methods to extract representations from astronomical images, which are then visually explored using dimensionality reduction algorithms. These feature extraction techniques include autoencoders[4], self-organizing maps (SOM)[25], and SSL[32,24].
The extracted representations serve multiple purposes beyond visual inspection, including anomaly detection, classification, and instance segmentation.

In addressing these tasks, radio astronomy has followed a logical progression mirroring the broader evolution of computer vision techniques. Initially, astronomers primarily relied on supervised learning methods[31], favoring this approach due to its historical precedence and relative simplicity in implementation and interpretation.
As the field advanced, researchers began to explore more sophisticated techniques, leading to the adoption of SSL in astronomy. However, a recent survey[20]notes that while SSL methods have gained traction, they have been applied primarily to non-radio images, such as optical data. This highlights a gap in the application of these techniques to radio astronomy, which presents unique challenges and opportunities.

In the specific domain of radio astronomy, recent work by Slijepcevic et al.[33]demonstrates the potential of SSL methods. They employed BYOL[18]on the Radio Galaxy Zoo Data Release 1 (RGZ-DR1) dataset[2]to pretrain a general model applicable to various downstream tasks. The model’s performance was quantitatively evaluated using the MiraBest dataset[28], which provides physically meaningful morphological classifications. However, this evaluation was limited by the relatively small size of the MiraBest dataset (about 800 images) and its binary classification schema (FRI vs. FRII radio galaxies).
Riggi et al.[29]addressed this limitation by constructing both curated and uncurated unlabeled datasets, reserving the labeled RGZ-DR1 data for the evaluation phase.

SECTION: 3Materials and Methods

SECTION: 3.1Overview

Deep radio sky observations are nowadays carried out with large arrays of radio telescopes, that collect sky visibility data across multiple frequency channels. These raw data undergo complex interferometric processing, including calibration and imaging, to produce either single-frequency radio continuum maps or multi-frequency spectral-line data cubes. Our study focuses on radio-continuum maps, which are single-channel grayscale images in FITS format. These images represent radio flux brightness in Jy/beam, with pixel values ranging fromJy/beam to several Jy/beam, including negative values often associated with imaging artifacts. The radio continuum maps generated by each survey presents different resolutions, but generally consist of very large images (e.g., for SMGPS[15], 75007500 pixels).

In this section, we present the methodology carried out for our systematic study of SSL approaches for radio-astronomy data analysis. We first introduce the dataset employed in this work for pretraining backbone models in a self-supervised fashion and describe data preprocessing modalities. We then introduce the variety of SSL techniques employed in this work, briefly presenting their characteristics and training objectives. Finally, we present the list of publicly-available datasets used in this work as downstream tasks, and the evaluation procedure for assessing the performance of SSL pretraining on those tasks.

SECTION: 3.2Self-supervision datasets

Compared to traditional supervised learning, SSL approaches provide the important advantage of not requiring manual labeling of data samples, which is well-known as a time-consuming and error-prone task. However, while natural image datasets are inherently built ensuring that each data sample has meaningful and somewhat unique content, radio-astronomy data present significant challenges in this regard.

The easiest way to build a largeuncuratedradio dataset is to randomly extract (i.e., without any knowledge of the position of radio sources) cutout images from radio maps using a sliding window with fixed-size. This procedure can potentially sample a high variety of object morphologies, but, as the sky is dominated by compact point-like sources and by background, while the number of peculiar and extended objects is significantly smaller, the result is the unavoidable construction of an unbalanced dataset, where more interesting objects (e.g., diffused or extended sources) are relatively rare. As is known[1], SSL methods suffer when dealing with unbalanced data. Additionally, considering the multi-scale nature of objects in the sky, using a fixed size of the sliding window likely results in truncated or partially captured sources.

An alternative approach consists in building acurateddataset by extracting cutouts around known source celestial positions reported in existing radio source catalogues. In this case, it is possible to adaptively set the image cutout size to be large enough to fully include the catalogued source and part of its surrounding region (including the background or other nearby sources). As can be imagined, source catalogues need to be manually labeled, and inevitably include fewer objects than the totality that can be found in radio maps.

In our work, we assess the impact of data curation by using two different datasets for SSL training, indicated in the following asCuratedandUncurateddataset. These datasets are primarily collected from two radio surveys:

The SARAO MeerKAT Galactic Plane Survey (SMGPS)[15]: Covers a large portion of the 1st, 3rd and 4th Galactic quadrants (-,-,) in the L-band (886-1678 MHz), with 8" angular resolution and10-20Jy/beam noise rms at 1.3 GHz.

The ASKAP EMU pilot survey[26]: Covers approximately 270 deg2of the Dark Energy Survey area, with 11"-18" angular resolution and30Jy/beam noise rms at 944 MHz.

Uncurated dataset.A set of 285,585 radio images of fixed size (256256 pixels, equivalent to a6.4’6.4’ sky portion). As stated before, data are extracted from radio maps using a sliding windows, with a 50% overlap. Since an intrinsic limitation of that dataset is the fixed sliding window size, we choose it to be large enough to capture most of the extended sources in the maps. As the data are extracted from mosaicked maps, those images may contain missing values on the border (filled in with the minimum value from the corresponding cutout) and mosaicking artifacts (see Fig.1).

Curated dataset.A collection of 17,062 radio images, derived from the SMGPS integrated maps. These images are centered on objects cataloged in the SMGPS extended source catalogue[16].
Unlike fixed-size datasets, images have variable dimensions, each scaled to 2.5 times the bounding box of its central object. This adaptive sizing ensures comprehensive capture of source structures. The dataset encompasses a rich variety of radio source morphologies, including multi-component sources (e.g. radio galaxies), and diffuse structures.

Examples of images extracted from the Curated and Uncurated datasets are presented in Fig.2.

SECTION: 3.3Self-supervision methods

From the plethora of methods available from the state of the art, we select a subset of SSL techniques minimizing the overlap within training strategies, to provide readers with a comprehensive analysis. Given the limited research on applying SSL methods to radio-astronomy images and in order to favor a comparison with the literature, we believe it is prudent to build a solid baseline with well-established CNN models, leaving out vision transformers (as they require significantly amount of computational resources and since those can exhibit instability during training). Therefore, methods that principally rely on ViT[11](e.g. MAE[19]or DinoV2[27]) are not considered.

Additionally, we focus on methods based on view augmentation rather than on pretext tasks, since the latter may not make sense with some kinds of radio sources: for instance, some sources may be rotation-invariant, while the large amount of background in certain images (especially in the uncurated dataset) hinders the application of inpainting/jigsaw-based tasks.

In the following, we present an overview of the SSL methods employed in this study. As mentioned above, the methods under analysis all involve the generation of two augmented views,and, from the same starting image, by means of random method-specific transformations. This approach is pivotal in learning robust feature representations, as it enables the model to understand and capture the intrinsic properties of the images across possible variants.

InSimCLR[7], the views are processed by a model producing representationsand. The method relies on attracting representations of views generated by the same image, while repelling views generated by different images. To this aim, SimCLR uses a projection network and a loss defined as:

whereandare the projections ofand,simis cosine similarity, andis a temperature parameter.

BYOL[18]tackles the problem from a slightly different perspective, without leveraging negative examples. It involves two networks,onlineandtarget, and a predictor on top of the online projector. Both networks are trained simultaneously in a teacher-student fashion, with the online target attempting to predict the target’s representations; in turn, the target network does not receive parameter updates through gradient descent, but its parameters are obtained through an exponential moving average of the student’s. BYOL’s loss can be summarized as:

whereis the predictor network, andandare the representations obtained by the online and target networks, respectively.

DINO[6]addresses SSL using a similar teacher-student setting in a knowledge distillation framework, with the student network predicting the output of the teacher with a standard cross-entropy loss:

whereandare the outputs of the teacher and student networks, respectively,denotes the softmax function, andandare temperature parameters.

WMSE[13]employs a single encoder network and positive samples only, preventing feature collapse by using a whitening operation that maps the representation space into a zero-mean and identity-covariance distribution.
The loss could be represented as: uses the mutual information maximization in combination with whitening the representations.

wheredenotes the whitening transformation applied to representation.

Clustering is traditionally one of the most suitable methods for unsupervised analysis.SwAV[5]adapts clustering to SSL by assigning pseudo-labels to different views of the same image.
Given viewsandof the same image, SwAV trains a model to compute featuresand, which are then mapped to soft assignmentsandbased on their similarity to a set of prototypes. Then, the model is trained to predict the soft assignment of one view from the representation of the other view:

where () is the cross-entropy.

Other approaches, such as NNCLR[12], propose to increase the diversity of positive pairs by pulling together a view of a sample with the nearest neighbor (NN) among the augmented views of another sample.All4One[14]builds upon this concept and extends it by efficiently including multiple neighbors through a self-attention mechanism and integrating a redundandy reduction loss inspired by Barlow Twins[35].

In our experiments, we use the implementations of the above methods provided by thesolo-learn[9], ensuring that all experiments are implemented with a consistent standard, reducing variability and potential biases that might arise from different coding practices.

SECTION: 3.4Downstream datasets

To assess the effectiveness of self-supervised pretraining across the methods under analysis, we utilize publicly available radio-astronomy classification benchmarks asdownstream tasks.
We take into account datasets generated from various sky surveys, each encompassing distinct source types. Each dataset exhibits unique visual characteristics, as shown in Fig.3. It should be noted that the original versions of the employed datasets feature a large class imbalance. Since this work addresses the quality of SSL representations, we resample each dataset so that all classes are balanced, either by undersampling more populated classes or by duplicating samples from less populated ones. The total number of samples included in each dataset after resampling is reported in the following.

Multi Survey Radio Sources (MSRS).This dataset is a collection of sources of different morphologies observed in various radio surveys (FIRST[3], EMU[26], SCORPIO[34], SMGPS[16]), covering galactic and extragalactic plane regions and showing different SNR ratios, angular resolutions, artifact patterns.
Sources were labelled according to the following taxonomy:1C-NP: small single-island sources with N peaks, e.g., point-like (N=1), double (N=2), triple (N=3);Diffuse: faint diffuse structures with roundish or irregular shape;Extended: single-component sources with extended morphology;Extended-MI: Multi-island extended sources, consisting in disjoint regions belonging to the same source.
Besides being a multi-survey dataset, this is the only downstream dataset considered in this work that include samples of diffuse sources (the most challenging class) and images with pure background noise. Image cutouts are rectangular and equal to the original source size. The total number of samples in this dataset is 11,550.

Radio Galaxy Zoo (RGZ)[2]is retrieved from the crowd labeling campaing on Zooniverse111https://www.zooniverse.org/. This includes radio images from the VLA Faint Images of the Radio Sky at Twenty cm (FIRST) extragalactic survey (1.4 GHz, angular resolution5")[3]. We use the data release 1, where angular size is also available for each source, therefore giving us the abilty to suitably crop the image around the source, extracting squared bounding boxes with side equal to 1.5 times the source size. The dataset classification schema includes 6 classes comprising different amount of components C and peaks P, namely: 1C-1P, 2C-1P, 2C-2P, 3C-1P, 3C-2P, 3C-3P. The resulting dataset includes 27,000 samples.

MiraBest[28]is a small dataset comprising FRI and FRII radio galaxies, as well as hybrid sources from extragalactic plane regions. For comparison with[33]we consider the sources tagged as “certain” and discarded hybrid source. Cutout size is fixed to 150150 pixels. The dataset contains 397 FRI samples and 435 FRII samples, for a total of 832 (we do not perform resampling in this case).

VLASSis a survey[17]covering galactic and extragalactic plane regions. We use Quick Look epoch 1 version 3 and extract sources from the Table 2 of the catalogue222https://cirada.ca/vlasscatalogueql0, providing radio loud sources associated to their host spotted in the infrared band. The original source cutouts have a 500500 size, probably to include the host galaxy in the infrared band, which however leads to the inclusion of a lot of background. For this reason, we reduce the cutout to 224224: the background is still wide, but reasonable. The taxonomy of sources within the dataset includes: single-component sources; sources with two close components; sources with three close components; sources with two asymmetric radio components, many of which may be instances of a radio core blended with a lobe; sources that are notably brighter than their close neighboring components in the radio frequency. The total size of the resampled dataset is 14,500.

SECTION: 3.5Downstream evaluation

Following the literature on SSL, we compare the performance of the methods under analysis by carrying out alinear evaluationon the downstream tasks, i.e., by directly training a linear classifier mapping output features from the SSL backbone to the target classes. This procedure is intended to directly measure whether the representation learned by the model contains distinguishing features for the target classes. Additionally, given the relatively small size of the target datasets, we also performfine-tuningof the SSL backbone on the downstream tasks, to investigate the effect of directly updating backbone features.

SECTION: 4Experimental results

SECTION: 4.1Training and evaluation details

Following common practice in radio-astronomy, input images are normalized using the minimum and maximum values within a single cutout; we then resize them to 224224. We employ both ResNet-18 and ResNet-50 as backbones for SSL. All methods are trained for using the LARS[8]optimizer, with a batch size of 512. Training on the Uncurated dataset is carried out for 100 epochs; on the Curated dataset, since it is significantly smaller, we train for 600 epochs. For all augmentation-based SSL methods, we apply the following set of transformations, with a certain probability: horizontal/vertical flip (); Gaussian blur withbetween 0.1 and 2 (); contrast adjustment by a random value between 0.2 and 1.8 (); random crop with scale between 0.65 and 1 (). The selection of other hyperparameters is carried out independently for each SSL method, by manually varying key parameters and observing the average loss on the Curated and Uncurated datasets. In the following, we detail the final hyperparameters chosen for each method:

SimCLR. Base learning rate: 1.2; output projection size: 512; temperature: 0.2.

BYOL. Base learning rate: 1.2; projection size: 512; predictor hidden size: 1024.

DINO. Base learning rate: 0.016; projection size: 256.

WMSE. Base learning rate: 0.002; projection size: 128; whitening size: 256.

SWAV. Base learning rate: 1.2; projection size: 128; number of prototypes: 300; temperatur: 0.1.

All4One. Base learning rate: 1.0; projection size: 512; predictor hidden size: 4096; temperature: 0.2.

When training on a downstream task with the fine-tuning strategy, we employ the AdamW[23]optimizer with a batch size of 256 and a learning rate of 0.0005, with a linear warmup followed by a cosine annealing schedule. For linear evaluation, we use a standard SGD optimizer, with the same batch size and initial learning rate. We employ a step scheduler, with learning rate decay steps of 0.1 factor at epochs 10 and 80. For both fine-tuning and linear evaluation, the total number of epochs is 100. During downstream training, we apply random vertical/horiziontal flip () and random crop with scale between 0.95 and 1 ().

Evaluation results on the downstream tasks are reported in terms of classification accuracy. Using the above final hyperparameters, we train each SSL method with each backbone on each pretraining dataset for three times with random initialization. The only exception is that, for the Uncurated dataset, we only use ResNet-18, for timing constraints. Then, we evaluate each trained model on all downstream tasks, using 3-fold cross-validation on each task. In practice, for a given combination of SSL method, backbone, pretraining dataset and downstream dataset, we have nine values of accuracy, for which we report the corresponding mean and standard deviation.

As an additional baseline for comparison, we also report the results obtained when pretraining BYOL on the ImageNet-100 (for ResNet-18) and ImageNet-1k (for ResNet-50) datasets. This provides useful information on the suitability of features extracted from natural images when applied to the analysis of radio-astronomy imaging data.

All experiments we carried out on a single NVIDIA A100-PCIE-40GB GPU.

SECTION: 4.2Linear evaluation

Results for linear evaluation are reported in Table1. A high-level analysis across methods shows that All4one, BYOL and SimCLR generally achieve the best performance on the downstream tasks, while DINO, SwAV and WMSE seem to perform worse on average. In particular, All4one yields the highest accuracy on three downstream tasks out of four, excluding MiraBest. The superior trend of All4one is confirmed when varying across the backbone architectures, as well as on both the Curated and Uncurated pretraining datasets.

From a quantitative perspective, dataset curation positively impacts results, as all SSL methods benefit from the higher sample quality more than from a larger dimension of the dataset. Interestingly, even though MSRS partially overlaps with the Uncurated pretraining dataset (since both contain some of the same sky regions) the models pretrained on the Curated dataset perform better. This is likely because the Curated dataset includes entire, more complex structures, whereas the Uncurated dataset contains only portions of these structures. As a result, pretraining on the Curated dataset allows the models to learn more comprehensive and transferable features. Backbone architecture has a more limited effect, with ResNet-18 generally yielding slightly better results than ResNet-50, which can be easily explained by the simplicity of the image patterns, not requiring a particularly high architectural complexity.

It is interesting to note that the SSL baseline using ImageNet variants almost always performs significantly worse than when using radio-astronomy data for pretraining. Only in the case of MSRS, which is characterized by larger and more structured object shapes, do the baselines yield closer (but still lower) accuracy, which might indicate that features learned from natural images may be overly complex (and thus less transferable) for the tasks at hand. However, it should also be noted that MSRS exhibits a significantly higher standard deviation, compared to the other downstream datasets. Hence, the similarity in terms of accuracy may also be due to an instability in the representations learned during self-supervision. Further investigations are therefore in order to clarify this aspect.

SECTION: 4.3Fine-tuning evaluation

Fine-tuning results are reported in Table2. As can be expected, results are higher than the linear evaluation setting, since the backbone models’ features are explicitly updated for each downstream task. Of course, this comes with a higher training cost, as gradients for the entire backbone must be computed at training time. In this setting, the differences between SSL methods observed for linear evaluation are basically flattened: there is no marked superiority of one approach over the others. Even the ImageNet-based baselines achieve results on par with models pretrained on the radio-astronomy datasets.

In this setting, we introduce, as an additional baseline for comparison, the results of the work by Slijepcevic et al.[33], where a ResNet-18 is pretrained on RGZ through BYOL, and then fine-tuned on MiraBest. To the best of our knowledge, this study is the most similar to ours from the literature, although it is significantly more limited in scope. Also in this case, the results are in line with the ones obtained in our study: however, due to the relative high performance that all approaches are able to achieve for MiraBest, we suggest that other downstream datasets might be more suitable for benchmarking in future works.

Despite the lack of significant differences in fine-tuning results, it is important to note that some tasks require data representations that are agnostic to specific classification schemas. For instance, visual data exploration tasks using dimensionality reduction techniques benefit from more general representations. In these scenarios, non-finetuned models can still provide valuable insights, offering representations that are useful for exploratory data analysis rather than specific classification tasks.

SECTION: 5Conclusions

In this work, we investigated the potential of self-supervised learning (SSL) for enhancing the analysis of radio astronomical data, notably outperforming traditional models pretrained on natural images in several domain-specific downstream tasks. Our results indicate that SSL-trained models, particularly those using the All4one method, achieve notable improvements in accuracy during linear evaluation, suggesting that SSL can effectively leverage the unique characteristics of radio interferometry images. Advantages of SSL become less pronounced in the fine-tuning setting, though they still surpass the performance of models pretrained on natural images. Another key finding is the importance of data curation, which positively impacts SSL performance more significantly than the sheer size of the dataset.

Given that ResNet-50 did not outperform ResNet-18 (likely due to the simplicity of the image patterns) it might seem counterintuitive to explore more complex architectures like transformers. However, we propose that future work should investigate multimodal large language models and incorporate additional modalities such as infrared and optical bands. By integrating data from multiple spectral bands, these multimodal transformers could learn more meaningful and rich representations, potentially enhancing the analysis of radio astronomical data beyond what single-modality models can achieve.

SECTION: 6Acknowledgements

This paper is supported by the Fondazione ICSC, Spoke 3 Astrophysics and Cosmos Observations. National Recovery and Resilience Plan (Piano Nazionale di Ripresa e Resilienza, PNRR)
Project ID CN 00000013 "Italian Research Center for HighPerformance Computing, Big Data and Quantum Computing"
funded by MUR Missione 4 Componente 2 Investimento 1.4:
Potenziamento strutture di ricerca e creazione di "campioni nazionali di R&S (M4C2-19)" - Next Generation EU (NGEU). We also acknowledge partial funding from the INAF SCIARADA project.

We acknowledge the CINECA award under the ISCRA initiative, for the availability of high-performance computing resources and support. In particular, we sincerely thank Andrea Piltzer and Giuseppe Fiameni.

SECTION: References