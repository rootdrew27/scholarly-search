SECTION: TEAM: Temporal Adversarial Examples Attack Model against Network Intrusion Detection System Applied to RNN

With the development of artificial intelligence, neural networks play a key role in network intrusion detection systems (NIDS). Despite the tremendous advantages, neural networks are susceptible to adversarial attacks. To improve the reliability of NIDS, many research has been conducted and plenty of solutions have been proposed. However, the existing solutions rarely consider the adversarial attacks against recurrent neural networks (RNN) with time steps, which would greatly affect the application of NIDS in real world. Therefore, we first propose a novel RNN adversarial attack model based on feature reconstruction calledTemporal adversarialExamplesAttackModel(TEAM), which applied to time series data and reveals the potential connection between adversarial and time steps in RNN. That is, the past adversarial examples within the same time steps can trigger further attacks on current or future original examples. Moreover, TEAM leverages Time Dilation (TD) to effectively mitigates the effect of temporal among adversarial examples within the same time steps. Experimental results show that in most attack categories, TEAM improves the misjudgment rate of NIDS on both black and white boxes, making the misjudgment rate reach more than 96.68%. Meanwhile, the maximum increase in the misjudgment rate of the NIDS for subsequent original samples exceeds 95.57%.

SECTION: IIntroduction

With the rapid development of modern network technology, the means of network intrusion attacks are becoming increasingly complex. The traditional static defense method[1]cannot adapt to the current complex and dynamical security requirements. To achieve active defense, Network Intrusion Detection System (NIDS)[2],[3]has been widely used and achieved good results. Traditional NIDS technology achieves intrusion detection by building a knowledge base in advance and comparing the signatures in the knowledge base with the signatures extracted from the traffic[4]. Hence, NIDS based on traffic signatures can only detect existing attack types and is difficult to detect current complex and changeable network attacks. With the continuous development of Deep Neural Networks (DNN)[5][6], experts and scholars have discovered that DNN only requires to pre-train the model through a large amount of existing data to detect new intrusion attacks without the need for a priori knowledge base, which brings a new direction for the development of NIDS.

Recurrent Neural Network (RNN)[7],[8], a kind of DNN, has been widely used in NIDS because it can fully consider the temporal properties of network traffic in the characterization learning[9]. Specifically, network traffic is continuously generated over time and has a temporal relationship with each other. RNN with time steps can also fully consider the impact of the previous moment data in the same time step when learning the traffic at the current moment, which greatly enhances the performance of NIDS. However, almost all DNNs have been proven to be vulnerable to Adversarial Examples (AEs)[10],[11], which brings new challenges to NIDS.

At present, a large number of researchers have conducted in-depth research on AEs attacks in NIDS, hoping to improve the defects of NIDS and enhance the robustness of NIDS[12]. Unfortunately, we found that there is a lack of research on adversarial attacks against RNN models with time steps in NIDS, and there are the following problems. Firstly, the RNN model is a temporal model, and traditional AEs do not consider the time characteristics of network traffic. Hence, when traditional AEs are used to attack the RNN model of NIDS, the AEs attack on the RNN model will have a large deviation due to the RNN model’s learning of past moment content, resulting in a reduction of AEs attack and transferability[13]success rate; Secondly, in the RNN model, due to differences in network traffic structure, the time distribution of network traffic will be different. Attackers can typically only generate adversarial samples using a small portion of the network traffic dataset to simulate the data distribution. This causes the AEs have a large deviation due to the difference in time distribution when attacking the RNN model, thus reducing the attack success rate and transferability of AEs; Last but not least, because the RNN model learns to characterize part of the traffic content from past moments, the characteristics of AEs from those past moments may influence the Original Examples (OEs) in the current or future moments. This occurs due to the temporal nature of the RNN’s learning process, and as a result, it could reduce the detection rate of the NIDS (OEs in this paper specifically refers to the original attack traffic in network traffic).

To solve the above problems, we first propose a model calledTemporal adversarialExamplesAttackModel(TEAM)to reveal the potential connection between adversarial and time steps in RNN. In RNN models with time steps, we observe the impact of the presence of temporal between AEs within the same time step. Due to the weights[14]related to past moment data in the RNN model will vary greatly depending on the data structure. Hence, targeted continuous adversarial attacks constructed by attackers using partial data have certain limitations in attacking RNN models due to the influence between AEs. In our proposed method, TEAM uses the idea of expanding the relevant weights of past moments to make the weight distribution between the attack model and the target model overlap as much as possible, effectively alleviating the above problems and realizing this type of targeted adversarial attacks. Moreover, we also observe for the first time that AEs from the past moment within the same time step have an impact on OEs at the current or future moment. Attackers can use carefully crafted AEs to cause NIDS to misjudge subsequent OEs in the same time step. This new type of attack also provides new ideas for subsequent research on the robustness of NIDS. The specific attack scenario of TEAM is shown in Figure1

Our main contributions can be summarized as follows:

We systematically study adversarial attacks against RNN models with time steps in NIDS. To the best of our knowledge, we are the first to reveal potential connection between adversarial and time-stepping in such attacks. That is, past AEs in the same time step can trigger further attacks on current or future normal samples; consecutive AEs in the same time step will affect with each other, affecting the attack success rate of adversarial samples.

We first propose TEAM to implement adversarial attacks against RNN models with time steps in NIDS. Meanwhile, we discovered that carefully designed AEs in an RNN model with time steps can affect the model’s judgment of OEs in the same subsequent time step, and propose the concept of the next moment attack.

We first propose a Time Dilation (TD) method for guided AEs generation in TEAM. The TD method adjusts the RNN model’s retention of past moment content by expanding the weight of past moments, effectively alleviating the weight distribution differences in the RNN model caused by differences in data structure, thereby further improving the attack success rate of AEs.

We designed a corresponding prototype system and conducted extensive experiments on the NSL-KDD dataset and the CIC-IDS2017 dataset to verify the phenomena we revealed. Experimental results show that in most attack categories, TEAM improves the misjudgment rate of NIDS on both black and white boxes, making the misjudgment rate reach more than 96.68%. Meanwhile, in the RNN model, the next-moment attack of AE on subsequent OE generally increases the misjudgment rate of NIDS on OE, with the highest improvement reaching 95.57%.

SECTION: IIRelated Works

SECTION: II-ANetwork Intrusion Detection System

Recently, deep learning[15]has been widely applied in NIDS. Due to the excellent representation learning capabilities, deep learning has effectively improved the detection ability of NIDS against new intrusion attacks. Mirza et al.[16]proposed a sequential AutoEncoder framework based on Long Short-Term Memory (LSTM) neural network to implement intrusion detection. Zhou et al.[17]presented an intelligent anomaly detection variational LSTM based on reconstructed feature representation for intrusion detection. Javed et al.[18]designed a new intrusion detection method called CANintelliIDS for vehicle intrusion attack detection on the CAN bus. Assis et al.[19]proposed a SDN defense system based on the analysis of single IP traffic records, which uses the Gated Recurrent Unit (GRU) to detect DDos and intrusion attacks. Mushtaq et al.[20]designed a hybrid framework including deep AutoEncoders, LSTM and Bidirectional Long Short-Term Memory (Bi-LSTM). Fu et al.[21]proposed a real-time malicious traffic detection system based on machine learning, which achieves high detection accuracy and high detection throughput by utilizing frequency domain features. Wang et al.[22]introduced GRU into the improved AlexNet to build an intrusion detection model for urban rail transit management systems. It can be seen that the existing NIDS methods are mainly based on RNN-based models.

SECTION: II-BAdversarial Attacks for NIDS

Adversarial attacks have attracted widespread attention from the academic community due to their excellent attack effects on DNN-based NIDS. Yang et al.[23]studied how AEs affect the performance of DNN trained to detect anomalous behavior in black-box models. Alhajjar et al.[24]explored the use of evolutionary computation (particle swarm optimization and genetic algorithms) and generative adversarial networks as tools for adversarial example generation. Clements et al.[25]explored the potential for adversarial entities to compromise such vulnerabilities to disrupt deep learning-based NIDS. Han et al.[12]used adversarial machine learning techniques to search for features located at the decision boundary of ML models, and for the first time systematically studied adversarial attacks in the gray-box/black-box traffic space. Sharon et al.[26]presented a novel temporal-based end-to-end adversarial network traffic shaping attack that could bypass most NIDS. Lin et al.[27]proposed a generative adversarial network framework called IDSGAN for generating adversarial malicious traffic records, aiming to attack NIDS by deceiving and evading detection. Mohammadian et al.[28]utilized jacobian saliency maps to find the best feature groups with different features and perturbation magnitudes to generate AEs.

Although the above schemes provide a lot of research ideas for adversarial attacks against NIDS, we find that there is still a lack of systematic research on adversarial attacks in RNN models with time steps. TableIsummarizes the comparison of solutions related to adversarial attacks in NIDS.

SECTION: IIIMotivation

SECTION: III-AThreat Model

We introduce a hypothetical threat scenario,i.e., the NIDS uses an RNN to build the detection model. Note that RNN in this paper refers to the collective name of recurrent neural networks such as the Original Recurrent Neural Network (ORNN) model, the Gated Recurrent Unit (GRU) model, and the LSTM model. The attacker conducts a tentative attack on the NIDS model by accessing the network system and performing a sniffing attack[30], accessing and monitoring the traffic, and then obtains the correct data category, traffic characteristics and approximate time step of the model from NIDS. Moreover, attackers do not know anything else about the model, such as its specific parameters, detection scheme and structure. Since the NIDS model can accurately detect anomalous traffic and process it accordingly, such as discard, purification, and other strategies, attackers want to realize targeted attacks,i.e., to make NIDS recognize abnormal traffic as normal by adversarial means. Meanwhile, due to the data set used in our work is a network traffic feature data set (i.e., the input data of NIDS and the data we generate AE are both ”flow”). Therefore, our adversarial attacks work is also GFLA[29]based on network traffic feature.

SECTION: III-BObservations

Network traffic is a kind of data with time continuity characteristics. Unlike traditional text data that has temporal continuity within a sentence, the temporal continuity of network traffic is reflected in the inter-traffic, such as traffic that users continue to access, continuous Dos[31]traffic attacks,etc. Therefore, there exists a situation in NIDS where time steps are set in the RNN model for continuous detection of traffic data within the time steps.

The RNN model is a neural network structure that can efficiently process time series, and it can learn the data of the current moment while considering the influence of the data of the past moments on the current moment. Hence, the judgment of the current moment network traffic of NIDS based on RNN model over a period of time step not only depends on the current input traffic, but also is influenced by the traffic of the past moments.

Hence, we can easily infer that the past moment AEs within the same time step in the RNN model will affect the OEs in the current or future moments as a way to realize the next moment attack; the consecutive AEs within the same time step will affect each other, and we need to design a new mechanism to realize the normal adversarial attack in the RNN model.

SECTION: IVMethodology

SECTION: IV-APreliminaries

AutoEncoder[32]is an unsupervised learning neural network model that is commonly used for data dimensionality reduction, feature learning and data reconstruction. Its basic structure includes two parts: Encoder and decoder. In this paper, we will use AutoEncoder to reconstruct data to generate AEs. The specific implementation formulas of encoder and decoder are as follows:

whererepresents the encoded result,represents the input of the encoder,represents the bias of the encoder layer,represents the weight of the encoder layer andrepresents the activation function of the encoder layer.

whererepresents the decoded result,represents the bias of the decoder layer,represents the weight of the encoder layer andrepresents the activation function of the decoder layer.

Recurrent Neural Network (RNN)[33]is a type of neural network with memory ability. In RNN, neurons can not only receive information at the current moment, but also from past moments. Compared with feedforward neural networks, RNNs are more consistent with the structure of biological neural networks. The existing base RNN models mainly include original RNN, LSTM[34]and GRU[35]. These base RNN models are widely used in tasks such as speech recognition, NIDS and natural language generation.

In NIDS, network traffic has multiple attack categories and corresponding function implementations. Therefore, the selection of indicators for network traffic features is complex and diverse, which results in the features of network traffic including functional features related to current function implementation, and non-functional features that are not related to current functions. In this paper, we introduce the concepts of functional features and non-functional[27]features in network traffic, whose specific meanings are as follows:

Functional features: Functional features refer to the features that affect the transmission of network traffic and the realization of specific functions (the function of a piece of network traffic is to implement Dos attacks or message transmission,etc.) of network traffic. Modification of this type of network traffic will cause abnormalities in the protocols and functions in the network traffic, that is, the network traffic cannot be sent or received, and the original functions cannot be realized,etc.

Non-functional features: Non-functional features refer to the features parts of network traffic that do not affect normal transmission or the realization of currently expected functions. For example, in U2RR2L[36]attack analysis of NIDS, there is almost no need to consider time-related traffic. The analysis of Dos attacks needs to consider the impact of time, but there is almost no need to consider the impact of host traffic. Therefore, for U2RR2L attacks, time-related traffic is non-functional traffic; for Dos attacks, host-related traffic is non-functional traffic.

In our approach, we only make changes to non-functional features. Therefore, even if no special adversarial constraints are imposed, the original functions of network traffic will not be affected.

SECTION: IV-BTemporal Adversarial Examples Attack Model

To reveal the potential connection between confrontation and time step in RNN-based NIDS, we design a new model called TEAM, which consists of two main parts: AutoEncoder and our proposed Time Dilation RNN (TDRNN). Among them, the AutoEncoder is used to generate AEs suitable for RNN; the TDRNN is a model that has been trained to guide the generation of this AEs. Figure2illustrates the pipeline of the TEAM method, whererepresents the non-functional features of traffic,represents the reconstructed non-functional features,represents the functional features of traffic,represents the original data that needs to be reconstructed into AEs at the same time step,represents the non-functional feature part of,represents the functional feature part of,represents AEs reconstructed bythrough AutoEncoder,represents network traffic with adversarial effect recomposed byand,represents the attack traffic of original data in the same time step. This part of the symbolic content applies to Algorithm1below.

Adversarial attacks under non-RNN models can be achieved by using part of the data set to restore the feature distribution of the target model, and using similar feature distributions to guide the generation of AEs. However, the RNN model not only needs to judge the input features at the current moment in the process of realizing the detection, but also needs to consider the influence of the features in the past moment on the current moment. Hence, adversarial attacks implemented against RNN models are more complex. Particularly, we find that the AEs generated by the RNN model constructed through partial data sets (PD-RNN, the training model held by attacker) are difficult to effectively apply to the RNN model constructed through all data sets (AD-RNN, the target model that the attacker will attack),i.e., there is an interaction between the AEs in the same time step (the current moment AEs is affected by the AEs of the past moments). This is because different data structures lead to variations in the content retained by the RNN model from past moments, and these variations cause deviations in the influence of previous data on the current moment, resulting in significant differences in the weight distributions between the PD-RNN and AD-RNN models (as shown in Figure3(a)).

To solve the above problems, we propose an improved RNN model called Time Dilation RNN (TDRNN) to implement RNN adversarial attacks in NIDS. In TDRNN, we adjust the degree of preservation of past moment content in PD-RNN by enlarging the weights used to control past moment data, so that the weight distribution of PD-RNN and the target RNN model overlap as much as possible (as shown in Figure3(b) shown), thereby mitigating the influence between AEs within the same time step. Our proposed TD method works on all RNN models. Below we will show the specific formulas of Time Dilation Original RNN (TDORNN), Time Dilation LSTM (TDLSTM) and Time Dilation GRU (TDGRU).

The specific implementation formula of TDORNN is as follows:

whererepresents the input at the current moment,represents the weight input to the hidden state,represents the hidden state at the current moment,represents the hidden state at the previous moment,represents the weight of the hidden state at the previous moment whenis updated, andrepresents the time dilation coefficient of the weight relative to the past moment

The specific implementation formula of TDLSTM is as follows:

whererepresents the Sigmoid activation function,represents the input at the current moment,represents the weight input to the forget gate,represents the hidden state at the previous moment,represents the weight of hidden content in the past moment in the forget gate, andrepresents the time dilation coefficient of the weight relative to the past moment, andrepresents the forget gate, which is used to control whether to forget part of the previous cell state in LSTM.

whererepresents the weight input to the input gate,represents the weight of hidden content in the past moment in the input gate,represents the weight input to the cell candidate status,represents the weight of hidden content in the past moment in the cell candidate status,represents the input gate, which is used to decide which new information in LSTM should be added to the cell state,represents the candidate value for updating cell state in LSTM, andrepresents the cell state of the current time step.

whererepresents the weight input to the output gate,represents the weight of hidden content in the past moment in the output gate,is used to control the hidden state to be output in LSTM, andrepresents the hidden state at the current moment.

The specific implementation formula of TDGRU is as follows:

whererepresents the Sigmoid activation function,andrepresent reset gate and update gate,represents the input at the current moment,represents the hidden state at the current moment,represents the hidden state at the past moment,andrepresent the weight assigned byin the reset gate and update gate respectively,andrepresent the weight assigned byin the reset gate and update gate respectively, andrepresents the time dilation coefficient of the weight relative to the past moment.

whererepresents the candidate state,represents the weight assigned toin the candidate state, andrepresents the weight assigned toin the candidate state. Note that we also add a TD coefficient to the weight ofin, which is to balance the ratio of current moment data and past moment data in the candidate set.

whererepresents the currently hidden state.

It is worth noting that in our proposed method, the aboveis used as the weight time dilation coefficient of the past time in the RNN to participate in the training phase of the model, and is still retained in the attack phase after the training.

Because TDRNN is used to guide the generation of AutoEncoders during training, we use the cross-entropy loss function as a condition for generating AEs during AutoEncoder training. It is worth noting that the functional characteristics in network traffic will affect the specific function implementation of network traffic. In our method, we feed non-functional features of network traffic into an AutoEncoder for adversarial example generation. Non-functional changes will not have a major impact on the functionality of network traffic. Therefore, we believe that there is no need to add too many constraints to the changes in this part. The specific loss function of this part is as follows:

Since RNN can fully consider the time impact between network traffic, we find that AEs can be used in RNN to change the model’s judgment of OEs at subsequent moments in the same time step. Specifically, attackers only need to send a small number of consecutive AEs to influence the model’s judgment on most traffic in the same time step, which greatly affects the reliability and robustness of the NIDS model. Meanwhile, it also gives attackers greater operating space and lower costs. We use TEAM to implement this type of attack. Specifically, we only need to splice the OEs behind the AEs generated by the AutoEncoder when training the RNN AEs in the same time step. Then, Time Dilation RNN (TDRNN) is used to conduct guided training on the spliced data, where the loss function given for the OE part is as follows.

We use this loss function to make the generated past moment AEs influence the current or future OEs as much as possible to achieve the next moment attack. Therefore, by combining with the loss function when generating adversarial samples in the previous section, we can know that the total loss function of TEAM is as follows.

The specific training and implementation algorithms for adversarial attacks and the next attack on the RNN model are shown in Algorithm1. In Algorithm1, we useandto represent the training set and test set in the overall data, respectively.

Input:,,,,,Parameter:(length of time step),(the number of AEs used to generate in a time step),(the number of original samples in the time step),(number of iteration cycles)Output:

SECTION: VExperiments

SECTION: V-AExperimental Settings

In this paper, we use NSL-KDD[37]and CIC-IDS2017[38]datasets as experimental datasets.

NSL-KDD:As one of the most widely used benchmark datasets in NIDS, the NSL-KDD dataset contains 125,973 training samples and 22,544 test samples, with four different attack types. We refer to the existing NIDS adversarial attack literature, make a detailed division of the functional and non-functional features of the NSL-KDD dataset[27]. In network attacks, attackers can use sniffing attacks to obtain part of the network access traffic. Therefore, we use half of the training set for model training (i.e.PD-RNN) to generate AE, and use the full training set to train the target NIDS (i.e.AD-RNN) to test AE and next-moment attacks.

CIC-IDS2017:The CIC-IDS2017 dataset is often used in NIDS detection experiments because it reflects the characteristics of modern network traffic. It contains 12 traffics of different attack types. Each traffic in the official CSV file for machine learning consists of 78 features. The entire dataset is collected from Monday to Friday. In this experiment, we conducted a targeted adversarial attack to make NIDS misjudge the attack traffic as normal. Due to all the data collected by the official on Monday is normal data, this experiment excludes the data of that day from the dataset. Therefore, in this experiment, the training set is divided into 1,802,513 and the test set is 339,599. Similar to NSL-KDD, we use half of the training set for model training (i.e.PD-RNN) to generate AE, and use the full training set to train the target NIDS (i.e.AD-RNN) to test AE and the next moment attack. In order to more effectively verify the effectiveness of our proposed method, this half of the CIC-IDS2017 dataset is shuffled, which has a higher randomness of temporal sequence. Meanwhile, to ensure the data balance of the experimental data as much as possible, we merge all Dos attacks in CIC-IDS2017 into one Dos attack. Infiltration and Botnet both involve infiltrating the network, hiding activities, maintaining infection for a long time and performing malicious operations. Therefore, these two are merged into one InfiltrationBotnet attack, and SSH-Patator and FTP-Patator types are merged into Patator attacks. In addition, since there are only 11 traffic in Heartbleed attack types and it is difficult to merge them with other types, we do not consider this attack type in this experiment.

We refer to the official literature of CIC-IDS2017[38]and divide the functional and non-functional features of traffic in combination with the properties of each attack type. For example, in Dos traffic, we need to exclude those features that directly involve core traffic patterns such as traffic magnitude, packet size, and time interval. It is worth noting that we directly classify the features related to the flag bit into the functional features, because such features are usually only discrete specific values. Imposing disturbances on such features will cause excessive damage or reduce the concealment of the attack. For example, mistakenly changing the FIN or RST flag bit may cause the connection to be closed or reset in advance. In addition, as far as we know, there is no clear division between the non-functional and functional features of the attack types of CIC-IDS2017 in the existing literature. Most of them only divide the weight of the features in different attacks of CIC-IDS2017 (such as literature[39][40]). Therefore, in the division process, we only take the feature types that are irrelevant to the functional implementation of this type of attack. We acknowledge that this may cause some non-functional features to be missed, but adding perturbations to fewer non-functional features to achieve adversarial attacks can better illustrate the effectiveness of our proposed method. The attack types and corresponding non-functional feature selections in this experiment are shown in TableII.

To the best of our knowledge, ours is the first work to investigate the potential connection between adversarial and time stepping of RNN models in NIDS. In addition, because the RNN model with time steps will consider the impact of past moment traffic on current moment traffic when characterization learning, other existing work on adversarial attacks against NIDS difficult to be directly adapted to RNN models with time steps. Based on the above reasons, in this paper, we will compare the existing typical adversarial attack methods PGD[41], CW[42], IDSGAN[27]and J-Attack[28]to verify the adversarial and transferability of our proposed method.

In our experiments, we implemented a targeted attack, use Attack Success Rate (ASR) as an evaluation metric, use Misjudgment Accuracy Rate (MAR) to represent the probability that normal attack traffic in NIDS is misjudged as normal traffic, use MAR1 to represent the probability that NIDS misjudged the OE attack traffic at the first moment after AEs as normal traffic in the original model, use MAR2 to represent the probability that NIDS misjudged the OE attack traffic at the second moment after AEs as normal traffic in the original model. Note that our adversarial attack is a targeted adversarial attack. When the AE of a certain attack category in the test set is identified as normal traffic, we can consider that the ASR of the adversarial attack is the same as the MSR of this attack category by NIDS. Moreover, in the table of experimental results, we bold the optimal data of each item. If the data in a category are all optimal values, we bold the data of our proposed method.

We conduct adversarial attacks and next time step attacks on three existing baseline RNN models (ORNN, LSTM and GRU) respectively. Meanwhile, we also perform black-box transferability between models. Furthermore, all our attacks are targeted attacks (making NIDS identify abnormal traffic as normal traffic). In the NSL-KDD data set, exceptions are the U2RR2L attack categories, the functional features and non-functional feature areas of the other attack categories are different. Therefore, different AEs will be generated according to categories for experiments.

For the NSL-KDD dataset, the number of network iteration epochs used by TEAM to generate AE is 100, the gradient optimization method is Adam, and the learning rate is 0.001. For the CIC-IDS2017 dataset, the maximum number of network iteration epochs used by TEAM to generate AE is 2000, and we will take the better AE generated in the epoch cycle, the gradient optimization method is Adam, and the learning rate is 0.001. Meanwhile, the intermediate layer of AutoEncoder is 4, and the time step of the RNN model is set to 8. In the same time step, the first 6 samples are AEs and the remaining 2 are OEs.

SECTION: V-BResults and Evaluations

In this section, we compare the differences between our proposed method and other four typical RNN model methods in terms of AE white-box attack success rate and black-box transferability. Ablation experiments were conducted to verify the effectiveness of our proposed TDRNN method. At the same time, we experimentally verified the concept of next-moment attack. Since our proposed method uses the first 6 OEs for AE in each time step, and the last two OEs are used to verify the concept of attack at the next moment. Therefore, in this experiment, we will take the same number of AEs for comparison and verification.

In this section, we first conduct adversarial attacks on RNN-based NIDS on the NSL-KDD dataset to verify the effectiveness of the proposed method. The experimental results are shown in TableIII.

From TableIII, we can see that in the NSL-KDD dataset, the TEAM method we proposed better guides the generation of AEs, and the attack success rate and transferability of the generated AEs on RNN, LSTM and GRU are significantly better than those of other comparison methods. The reason is the AE generated by the PGD and CW methods is affected by the difference in the weight distribution due to data differences between the PD-RNN model and the target RNN model, cannot accurately implement adversarial attacks against the target RNN. In the IDSGAN method, due to the generator and discriminator use traditional fully connected neural networks, the PD-RNN model only serves as a query for generating results. Therefore, the AE generated by IDSGAN is difficult to adapt to the temporal of RNN-type models. J-Attack is limited by the scope of feature selection (that is, it can only select perturbation to add targets in non-functional features), and its method of directly using masks to add perturbations is also difficult to effectively deal with the timing differences between RNNs. The TEAM method we proposed not only guides AE generation through the RNN model, but also uses the time dilation method we proposed to minimize the difference in weight distribution between the PD-RNN model and the target RNN model, and then the generated AE can utilize the temporal of the model itself in adversarial attacks as much as possible to achieve effective AE white-box attacks and black-box transferability attacks.

We can also see that IDSGAN has extremely low ASR in Dos and Probe[43]. We observed the experimental results and found that the RNN classifier misclassified AE as other attack types. For example, the vast majority of Probe attack AEs are predicted to be Dos attacks by the RNN classifier. This is because in attack types with slightly higher temporal such as Probe, the AE generated by IDSGAN will cross the boundary excessively because the RNN model retains past content, affecting the normal judgment of the RNN model and causing the attack to fail.

The adversarial attack effect of the J-Attack method on the NSL-KDD dataset is generally poor, and there is even a situation where the ASR is 0. This is because the adversarial attack of J-Attack is based on feature selection and is implemented by directly adding perturbations to the selected features. However, the NSL-KDD dataset itself has fewer statistical features, and statistical features are usually an important component of NIDS detection under deep learning. The lack of statistical features makes it difficult for J-Attack, a method that directly adds perturbations to selected features, to achieve accurate adversarial attacks. Furthermore, the selection of non-functional feature areas narrows the feature selection range of J-Attack and weakens the adversarial effect of J-Attack. Meanwhile, the information difference between PD-RNN and the target RNN in the past moments also increases the uncertainty of the adversarial effect of J-Attack, making it perform poorly on the NSL-KDD dataset.

In addition, in U2RR2L and Probe attacks, the PGD method uses multi-step iterations of small distance reverse gradients to implement AE attacks. Therefore, most AEs will not have a one-time iteration reverse gradient distance that is too large, causing AEs to approach the decision boundary on the other side of the attack target, making the AEs generated by the PGD method is relatively less affected by the difference weight distribution between PD-RNN and target RNN. Meanwhile, the U2RR2L attack itself basically does not have temporal, and the Probe attack has low temporal. Therefore, we believe that the AE generated by the PGD method on the U2RR2L and Probe attack categories is less affected by time interference. This is also the reason why the PGD method generates a part of AE white-box attack success rates and black-box transferability on the U2RR2L and Probe attack categories and is close to our TEAM method.

It is worth noting that in this paper, NIDS misjudges U2RR2L attacks as normal traffic with a high probability. This is because in network attacks, U2RR2L attacks are usually hidden in normal traffic, do not have high temporal, and have similar characteristics to normal traffic. Therefore, it is normal for NIDS to have a high probability of misjudging U2RR2L attacks as normal traffic.

In this section, we further verify the effectiveness of our proposed TEAM method on the CIC-IDS2017 dataset. The experimental results are shown in TableIV.

From TableIV, we can see that the proposed TEAM method shows excellent attack effects in all types of attacks compared with the existing four adversarial attack methods on the CIC-IDS2017 dataset, and is only slightly inferior to the IDSGAN method in the LSTM white-box attack of the Patator attack category. The reason is that the temporal of Patator, Web Attack and InfiltrationBotnet is lower than that of Dos, Portscan and DDos attacks, and is less affected by temporal. Therefore, the CW, IDSGAN and J-Attack methods are less affected by the temporal difference between PD-RNN and the target RNN in these three types of attacks, and their adversarial attacks have good effects. In addition, we can see that the CW method has a good adversarial attack effect on LSTM and GRU of Dos, Portscan and DDos, but the effect of adversarial attacks on the original RNN is extremely poor. We believe that this is because the CW method directly optimizes the decision boundary of the classifier, making the adversarial sample as far away from the classification boundary as possible and close to the decision center of the target category. At the same time, LSTM and GRU can better control the flow of past information through the gating mechanism compared with the original RNN, thereby reducing the impact of past information on current information. Therefore, the CW method has achieved good results in Dos, Portscan and DDos LSTM and GRU adversarial attacks, but it is very susceptible to the impact of past information on original RNN, resulting in extremely poor results. The PGD method uses multi-step iterations of small distance reverse gradients to implement AE attacks. Therefore, the AE generated by it is usually close to the decision boundary and is easily disturbed by the difference in past information, resulting in slight inferior adversarial attack effects on all attack types. The TEAM we proposed can use the time dilation method to make the weight distribution between PD-RNN and the target RNN closer, thereby achieving better adversarial attacks at any temporal strength. However, it should be admitted that this time dilation method is difficult to make the weight distribution between PD-RNN and the target RNN completely fit. In the Patator attack type that is inferior affected by temporal, since the time dilation method needs to take into account the effectiveness of various RNN attacks, this makes the goal of the time dilation weight distribution fitting more inclined to the universality of various RNN adversarial attacks, rather than specific RNN attacks. Therefore, compared with the white-box adversarial attack on LSTM in IDSGAN, the attack success rate is slightly lower.

In addition, we also observed that the success rate of adversarial attacks achieved by the four existing methods on the CIC-IDS2017 dataset is much higher than that on the NSL-KDD dataset. The reason is the CIC-IDS2017 dataset contains a large number of statistical features, which provide important judgment basis for NIDS detection methods based on deep learning. Meanwhile, statistical features usually have little impact on the functional implementation of network traffic. Even if the attack categories are different, in most cases, statistical features are usually retained as non-functional features. Adding adversarial perturbations to some statistical features reduces the difficulty of implementing adversarial attacks. Therefore, the ASR of the four existing methods on the CIC-IDS2017 dataset is higher than that on the NSL-KDD dataset.

In this section, we conduct ablation experiments on the time dilation method in our proposed TEAM method to verify the effectiveness of our proposed time dilation method.

As can be seen from TableVand TableVI, the TEAM model that does not use the time dilation method performs poorly in white-box adversarial attacks and black-box transferability of the RNN model. The reason is there is a difference in retention of past moments between PD-RNN and target RNN during the training of the TEAM model. Therefore, the AE generated by TEAM will be affected by this difference, which in turn affects the corresponding adversarial attacks and transferability. Due to TEAM with time dilation method overlaps the weight distribution between PD-RNN and target RNN as much as possible, TEAM with time dilation method has better effect than TEAM without time dilation method. In addition, the attack on the next moment is also considered in the TEAM method, which intensifies AE’s focus on temporal characteristics and amplifies the difference between PD-RNN and target RNN in data retention of past moments. Therefore, when the time dilation method is not used, the AE generated by our proposed TEAM is less effective in white-box adversarial attacks and black-box transferable attacks.

In this section, we use experiments to verify the impact of AEs on subsequent OEs. That is, the attack at the next moment. Specifically, In the RNN model, the recombined data will change the structure of the data and affect the time distribution between the generated AEs, which will in turn affect the adversarial attacks of the AEs on the RNN model and the subsequent attacks. Since the experiment in this section aims to verify the concept of attack at the next moment, we did not conduct other comparative experiments. This concept is experimentally verified using only TEAM with time dilation method.

It can be seen from TableVIIthat AEs can effectively affect the detection of subsequent OEs by the RNN model.

In NSL-KDD dataset, our proposed method shows good attack and transferability performance on Dos and Probe. However, the performance on U2RR2L is poor, which is because Dos is a type of high-intensity continuous attack. This attack has strong temporal and is sensitive to the content of the past moment. Therefore, in the RNN model, a large amount of AEs data in the past moment can push the OEs at the next moment to cross the decision boundary of the model, thereby exacerbating the error of NIDS in misjudging the OEs of the Dos category as normal traffic. TEAM works better overall in next moment attacks because it retains a lot of past moment content.

In the Probe attack, although the temporal of the Probe attack is not as good as the temporal of the Dos attack type. However, the temporal of this type of attack also makes Probe more sensitive to the content of the past moment. Therefore, the attack at the next moment will have similar analysis and effects on the Probe attack type as on the Dos attack type. We also observed that in the Probe attack type, some next moment attack have extremely low ASR. We observed the experimental results and found that the reason is that the past moment AEs generated by the Probe attack type have a greater impact on the temporal of current moment OEs, causing the past moment content to have an excessive impact on the current moment OEs, making the current moment OEs excessively cross the decision boundary, and it is judged as a Dos attack.

However, U2RR2L pays more attention to the content of the current moment, exhibit less temporal, and is not sensitive to the impact of time. Therefore, it is difficult for us to use the content of AEs in the past moment to push the OEs of U2RR2L at the next moment to cross the decision boundary of the model. In addition, the content of AEs in the past time may make the characteristic difference between U2RR2L and normal traffic more obvious, which is even beneficial to the detection of NIDS. This is why the next moment attack has poor effect on U2RR2L.

In CIC-IDS2017 dataset, we can see that before the next attack, continuous Dos and Patator attacks can already affect the RNN classifier, causing the classifier to greatly misjudge the Dos and Patator attack type traffic of the OE (i.e., with higher MSR1 and MSR2). This is because Dos data has a strong temporal nature, making it extremely susceptible to the influence of past information. Even if the previous moment is OE traffic, it can easily cause the subsequent Dos attack to cross the model decision boundary and be misjudged as normal traffic. Patator is because its statistical characteristics are usually very similar to those of normal traffic. Even if the previous moment is OE traffic, the influence of its information on the statistical characteristics of subsequent moments can easily cause the Patator attack type to cross the model’s decision boundary and form a misjudgment.

When we perform the next moment attack, we can find that the next moment attack effect of Dos and Patator attack types is poor. This is because the traffic that was AE at the previous moment increases the influence of the past moment information on the subsequent moment, which in turn causes the next moment attack to cross the boundary (for example, Patator should have been identified as normal, but some subsequent moments OE crossed the decision boundary of normal and were identified as Dos). In addition, in other attack categories, we can clearly see that the AE in the past moment effectively affects the detection of OE attack types in the next moment and the next next moment by the NIDS based on RNN. It makes the samples that should have been detected as attacks by NIDS have a very high probability of being misjudged as normal examples, with the maximum probability even being 100%. This greatly affects the security of NIDS based on RNN.

In addition, we can see that the next moment attack misjudgment rate on the CIC-IDS2017 dataset is generally higher than that on the NSL-KDD dataset. The reason is the CIC-IDS2017 dataset has more traffic features that are consistent with modern machine learning discrimination than NSL-KDD, such as more statistical features. This also indirectly improves the misjudgment rate of the NIDS model based on RNN.

Overall, the attack at the next moment increases the misjudgment rate of OE by NIDS. In Dos and Probe of NSL-KDD dataset, the increase of NIDS misjudgment rate even exceeds 2 times, and in the DDos of CIC-IDS2017, the misjudgment rate of NIDS increased from the original 0% to an astonishing 95.57%. The attacker only needs to create a small number of AEs to greatly affect subsequent OEs in the same time step and carry out further attacks. This is a very dangerous new problem for NIDS.

SECTION: VIConclusion

In this paper, we conducted the study of adversarial attacks on RNN models with time steps in NIDS. We first designed a new AEs generation method for RNN models called TEAM. Then, we used TEAM to generate AEs for adversarial attacks and next moment attacks on RNN model, revealing the potential connection between adversarial and time steps in RNN model. Finally, through a large number of experiments, we verified that the AEs generated by TEAM can be effectively used for adversarial attacks and next moment attacks on the RNN model in NIDS.

In the future, we will devote ourself to defense adversarial attacks and defense adversarial attacks at the next moment. Meanwhile, we will investigate how to defend against temporal adversarial attacks and next moment attacks caused by temporal in RNN-based NIDS, thereby enhancing the security of NIDS.

SECTION: References