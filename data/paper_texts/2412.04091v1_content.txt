SECTION: Machine learning enhanced multi-particle tracking in solid fuel combustion

Particle velocimetry is essential in solid fuel combustion studies, however, the accurate detection and tracking of particles in high Particle Number Density (PND) combustion scenario remain challenging. The current study advances the machine-learning approaches for precise velocity measurements of solid particles. For this, laser imaging experiments were performed for high-volatile bituminous coal particles burning in a laminar flow reactor. Particle positions were imaged using time-resolved Mie scattering. Various detection methods, including conventional blob detection and Machine Learning (ML) based You Only Look Once (YOLO) and Realtime Detection Transformer (RT-DETR) were employed and bench marked. Particle tracking was performed using the Simple Online Realtime Tracking (SORT) algorithm. The results demonstrated the capability of machine learning models trained on low-PND data for prediction of high-PND data. Slicing Aided Hyper Inference (SAHI) algorithm is important for the better performance of the used models. By evaluating the velocity statistics, it is found that the mean particle velocity decreases with increasing PND, primarily due to stronger particle interactions. The particle dynamics are closely related to the position of combustion zone observed in the previous study. Thus, PND is considered as the dominant factor for the particle group combustion behavior of high-volatile solid fuels.

tao.li@rsm.tu-darmstadt.de

SECTION: 1Introduction

Understanding the solid fuel (SF) combustion process is crucial for the advancement of various industrial applications, including electricity production, propulsion systems, and environmental protection. The fundamental of SF combustion, which is a complex chemical reaction involving fuel and oxidizer in multiple phases, relies on the understanding of the physical, chemical and other interactive processes in flows. Obtaining such knowledge require accurate experimental data, such as particle dynamics during the combustion process, which is non-trivial to collect.

Particle velocity is an essential parameter closely related to combustion behavior[1]. Balusamy et al.[2]reported that larger particles exhibited lower velocity, which was measured by both particle image velocimetry (PIV) and Laser Doppler velocimetry (LDV). Attili et al.[3]noted that gas-phase ignition delay time decreased with increasing particle slip velocity from simulations. Li et al.[4]measured particle velocity using PIV and observed that particles near the boundary of a particle cloud exhibited higher velocities compared to those at the center.

In literature, different techniques have been employed to measure particle velocity during combustion. The LDV was used to measure the velocities of SF particles[2]by analyzing the Doppler shift of the laser light scattered by particles. Yao et al.[5]employed high-speed Digital In-line Holography (DIH) to image burning coal particles and subsequently calculated particle velocity using the algorithm described in[6]. PIV is another widely used method due to its simple setup and robustness. Particle motion in fluids is captured by taking two sequential images in a short time interval and evaluating the displacement of particle patterns based on cross-correlation[7]. To resolve the particles, we adopted Particle Tracking Velocimetry (PTV), a technique that measures the velocity of individual particles by tracking their positions over time. PTV has been utilized in previous research[8,6]to measure the velocity of glass beads and particles in digital holography. However, according to Dracos et al.[9], PTV is not suitable for high PND scenarios due to the difficulty in distinguishing individual particles. To address this issue, ML-based detection methods are proposed to enhance the accuracy of particle velocity calculation.

Building upon the previous work by Li et al.[10,11], this study aims to further explore particle motion in high PND scenarios using PTV based on machine learning detection methods. The primary objectives are to assess the feasibility of ML techniques to train models on simpler data and subsequently apply them to more complex scenarios, thereby enhancing the model generalization and overall accuracy of particle velocity calculation. The models are validated on tracking a single-particle trajectory. The velocity statistics are evaluated, showing clear dependence on the particle-particle interaction. In the following, a concise overview of the experimental setup and the data set used in this study are firstly introduced. Subsequently, traditional blob detection algorithm, ML methodologies, and the performance assessment of implemented detection and tracking methods are elaborated. The outcomes of these various approaches are presented and discussed.

SECTION: 2Experimental data set

SECTION: 2.1Experimental setup

In order to study the combustion process of coal particles, optical experiments focusing on particle groups burning in laminar flow reactor were performed. Figure1illustrates the experimental setup of the optical measurement. The detailed experimental setup was reported previously[10]and is briefly introduced here. A laminar flow reactor (LFR), Figure1(c), was used to provide solid fuel particles into a gas atmosphere with well-defined temperature, and species concentrations. A fully premixed flat flame was stabilized above the ceramic honeycomb structure. By adjusting the flow rate of\ceCH4,\ceO2 and\ceN2, the desired post-combustion gas with homogeneous temperature and flow profile can be obtained[12]. These gas conditions were denoted as A10/A20/A30/A40 representing the 10%, 20%, 30% and 40% volume fraction of oxygen in the gas atmosphere, while A20 is focused in the current work. High-volatile bituminous (hvb) coal particles were injected into the burner through a capillary tube with a diameter of 3 mm by carrier flow with same gas composition and velocity as the flat flame inlet gas.

Particles were visualized by the high-speed Mie-scattering measurements at 10 kHz, as reported in[10]. A diode-pumped single-head ND:YAG laser (Innoslab, Edgewave), as shown in Figure1(f), with a pulse energy of 2.5 mJ at 532 nm. To cover the entire particle region, the laser beam thickness was expanded to approximately 8 mm. For a later employment of tomographic PTV, four CMOS cameras were used that are equipped with with macro lens (Sigma,= 180 mm,/32, DOF >10 mm). A pair of Photron SA-X2 cameras ((d) and (e) in Figure1) were set up withto the laser beam. On the other side, another pair of Phantom v711 cameras ((a) and (b) in Figure1) were set with a angle of. The exposure time was set to 5s to reduce the interference signal from the luminescent flame. The field of view (FOV) of the Mie-scattering covered an area of 37.7 (height)21.6 (width)with a pixel resolution ofm/pixel. The extensive FOV enabled by Mie-scattering facilitates the acquisition of the particle position and velocity across the full duration of the combustion process. In this paper, only data from the (d) camera was used to develop the algorithm for particle detection and tracking. Tomographic PTV using the data from the other cameras will be investigated in the future.

SECTION: 2.2Experimental data

In this experiment, hvb coal particles with a mean diameter of 125 µm were investigated. The experimental data were divided into four cases that are shown in Table.1. The cases are defined as PA, where P represents the particle combustion,denotes the particle number (), and A represents the gas condition, andindicates the oxygen mole fraction. Detailed calculation ofand corresponding PND is elaborated in the result section.

SECTION: 3Detection and tracking approaches

This section outlines the methodologies employed for particle position detection and tracking. The detection methods include both traditional blob detection techniques and advanced machine learning approaches, such as YOLO[13]and RT-DETR[14]. For particle tracking, the SORT[15]algorithm is utilized.

SECTION: 3.1Blob detection

Blob detection techniques are designed to identify circular or blob-like structures in images, making them suitable for SF particle analysis. The common approach for edge detection in blob detection is the Laplacian operator (), which measures the concentration or dispersion at a given point within a scalar field by computing the gradient field’s divergence. A negative result indicates a local maximum (potentially noise or an edge), while zero indicates a flat region. To minimize noise, the image is smoothed using the Gaussian operator (). Thus, the Laplacian of Gaussian (LoG), which combines the Gaussian and Laplacian operators, is suitable for blob detection. The Gaussian and LoG operators are given as follows[16]:

When, the LoG operator maximizes its response on circular blobs withstanding for the radius of the blob, allowing detection of varying blob sizes by adjusting. Asincreases, the LoG response becomes smoother and weaker. But this variation will influence theselection since the maximum response occurs at the finest scale and the minimum at the coarsest. To compensate this response decrease at larger, a factoris applied, resulting in the normalized LoG operator:

Although it is feasible to detect the blob by locating the maximum response of, the calculation is time-intensive. Hence, the Difference of Gaussian (DoG) operator is introduced as an efficient approximation. Defined as follows, DoG approximates LoG by computing the difference between two Gaussian operators[17]. When considering the difference of the nearby scale atand, the DoG operator approximates the normalized LoG as described in the following equation:

Here,represents the standard deviation ratio used to compute the DoG. The DoG operator is computationally efficient while retaining the capability to detect blobs across various scales.

SECTION: 3.2Machine learning detection

Although DoG has significant performance on particle detection, it still requires complex pre-processing for different combustion cases, which is time-consuming. Inspired by the development of recently developed ML-based object detection models, the implementation of YOLOv8 and RT-DETR is anticipated to be trained on a small scale of low-PND case data and then applied to high-PND case data. This section elaborates the principle of the used models, as well as the performance evaluation methods.

The objective of ML object detection is to find and classify the objects in images by providing the bounding boxes and the class labels. The primary approaches to achieve object detection include two-stage methods and one-stage methods. Examples of the two-stage methods include R-CNN[18], Res-Net[19], and fast R-CNN[20]. In the first stage, a Region Proposal Network (RPN)[21]generates a set of candidate object regions, also known asregion proposals, within the image. This step focuses on identifying potential areas that may contain objects, significantly reducing the search space. In the second stage, these region proposals are further processed to classify objects and refine bounding box predictions. The two-stage methods possesses higher accuracy but requires more computation resources. On the contrast, the one-stage approach eliminates theregion proposalstep and directly performs classification and localization in a single pass over the image. Models such as YOLO , as its name indicates, is an representative model using this approach. By predicting bounding boxes and object classes for the entire image at once, one-step models achieve significantly faster detection speeds. As the development of the one-stage models, a new model RT-DETR was developed based on transformer architecture. Considering the one-stage models show significantly better performance on accuracy and speed, both YOLO and RT-DETR are adopted in this study for particle detection.

After years of iteration, the latest version of YOLO has already presented a fantastic performance on object detection purpose. This is contributed by its innovated design, which works in following steps. It firstly divides the image into a grid of certain size. Each grid cell is responsible for detecting objects whose centers fall within the cell. Then in each grid cell, YOLO predicts a certain number of bounding boxes consisting of coordinates and a confidence score. The coordinates include the object center as well as the width and height of the bounding box (both relative to the whole image). After that, the cell predicts a probability distribution over predefined object classes within the cell and the assigns the highest class probability to the bounding box with highest confidence score. Finally, it will eliminate the redundant bounding boxes by applying the Non-Maximum Suppression (NMS).

The Fig.2briefly illustrates the architecture of YOLOv8 that has been implemented in this work. It consists of a backbone to extract features at different scales and 3 detection heads to make the prediction. The backbone, which includes several convolutional layers and special blocks, is able to reduce the spatial dimensions while increasing the channels of the feature maps. Then, the head part up-samples and concatenates the feature maps from different scales and transmits them to the detection heads. The detection head will finally generate the possible bounding boxes.

The second machine learning model adopted for the current experimental data is RT-DETR. The key feature of the RT-DETR include the end-to-end object detection architecture, transformer-based attention mechanism, and use of set-based loss for direct object detection[14]. These features allow DETR to simplify the object detection pipeline and achieve high performance.

Comparing to the YOLO model, the prediction head of the architecture is replaced by the transformer-based structure as shown in Fig.3. The transformer encoder-decoder structure is used to capture global context across the entire image. The self-attention mechanism allows the model to understand relationships between different parts of the image, enhancing its ability to recognize and localize objects, even those that are small or partially occluded. The transformer decoder introduces object queries, which act as learnable embeddings that interact with the feature map to detect specific objects. Each object query learns to focus on a unique part of the image, enabling efficient object detection without relying on anchor boxes. The set-based loss function assigns a one-to-one match between predicted and ground truth objects. This Hungarian matching algorithm ensures that each object is detected only once, eliminating the need for NMS to associate the bounding boxes with the grid cell. The set-based loss encourages the model to focus on unique object instances, reducing duplicate detection. The performance of RT-DETR will be further discussed in the result section.

SECTION: 3.3Detection performance evaluation

To compare the performance of traditional blob detection method and the machine learning enabled detection, an evaluation method based on confusion matrix was adopted. The employed metrics were able to statistically analyse the agreement between detected bounding boxes and the ground truth bounding boxes. To evaluate the prediction performance, the ground truths were manually labeled using the open source detection labeling toolLabelImg[22]. The similarity of the two bounding boxes are quantified by Intersection over Union (IoU). In the detection field, the IoU is equal to the overlap area between the bounding box of detectionand the bounding box of ground-truthover the the area of their union ().

When IoU, it indicates a perfect match between the two bounding boxes, while IoUsignifies no overlap. Thus, a higher IoU value corresponds to better detection accuracy. An IoU threshold is set to assess detection quality: values above the threshold are consideredtrue, and those below arefalse.

To evaluate the detection performance, the confusion matrix is used. Four detection classes are defined: True Positive (TP), True Negative (TN), False Positive (FP), and False Negative (FN), as shown in Figure4. ’True’ and ’False’ indicate the correctness of the model’s detection as described before, while ’Positive’ and ’Negative’ refer to the existence of the ground-truth detection.

When evaluating the performance of detection methods, it is essential to consider not only the accuracy but also the coverage of the detections. An ideal model should detect all possible targets with high precision. Therefore, the concepts of precision and recall are introduced to assess the model’s performance. Precision indicates the model’s ability to correctly identify objects, represented by the percentage of true positive detections over all detections. Recall reflects the model’s capability to find all objects in the dataset, represented by the percentage of true positive detections over all ground-truth instances. These parameters are derived from the confusion matrix as follows:

SECTION: 3.4The tracking method

The SORT algorithm is a simple but effective method for Multiple Objects Tracking (MOT). SORT is designed to track objects across frames in real-time, making it also suitable for particle tracking of the current data. The algorithm is based on the principles of data association and motion prediction, using a combination of the Kalman Filter, Hungarian algorithm, and IOU-based bounding box matching to track objects efficiently[15].

The SORT algorithm leverages a Kalman Filter to predict the subsequent position of each tracked object, relying on the object’s prior state for this estimation. The Kalman Filter effectively estimates both position and velocity, allowing for adjustments that accommodate minor variations in motion and account for noise between consecutive frames. For data association, SORT employs the Hungarian algorithm, which optimally matches predicted object locations with new detections by minimizing the distance between them, typically quantified through Euclidean distance in the image plane. Object detection matches in SORT are further refined using the IoU threshold. A detection is assigned to an existing tracker only if the IoU exceeds a certain threshold (0.3 used in this experiment), ensuring that only closely aligned objects are paired. In instances where new detections do not match any existing tracker, new trackers are initialized. Conversely, trackers that fail to receive updates, or matching detections, within a predefined frame interval are removed, effectively filtering out noise and managing lost objects in the tracking process.

SECTION: 4Results and discussions

SECTION: 4.1Particle Number Density

The particle number density is an important parameter to assess particle-particle interaction, which is defined as PND=/[10]. The reference volumeof the particle jet was derived using particle images across all cases. These images were divided into 12 subgroups based oncalculated within a HAB range of 0 – 7.8 mm, where no soot particles form. A threshold was applied to the averaged binary image of each group to determine the boundary of the particle jet. This boundary was then fitted using a polynomial fitting function. Subsequently, the reference volume was calculated based on this fitted boundary by assuming 3D symmetry. The correlation between the reference volume and particle number is illustrated in Fig.5(a). The particle jet trends to expand with increasing(as shwon in Figure.5(c), (d) and (e)) and remain unchanged afterreaches around 100, as indicated in Figure.5(a). The curve was fitted and further used to calculate PND. The relationship between PND andis depicted in Fig.5(b) and is further used for velocity statistic analysis. Compared to our previous work[10], the particle reference volume shows high consistency, while PND andare lower in this study. This is mainly due to the fact that Mie scattering has a lower pixel resolution (36.8 µm/pixel) compared to the previous diffuse-backlight illumination measurements (9.2 µm/pixel). Thus, potential line-of-sight overlapping of particles underestimate the particle number and PND.

SECTION: 4.2Particle detection

One objective of our training plan is to assess the feasibility of training the model on simpler cases with less particles and subsequently applying it to complex cases with more particles. As shown in Table2, two models are trained, denoted as M1 and M2. Firstly, both M1 and M2 were trained based on YOLOv8 and RT-DETR, respectively, including 80 images from the data P040A20, in which the particle numberis below 40. The training data were cropped (200200 pixel) from the raw image to emphasize the features of the particles, as shown in Fig.6(a) and (b). The two models all use blob detection as ground truth and were trained 300 iterations. To evaluate the models’ performance on complex cases, the trained models were validated on the cropped and up-scaled images from data set P100A20 with>80, as illustrated in Fig.6(c). The ground truth of test images was based on blob detection for a quick evaluation. Both M1 and M2 exhibit a precision score higher than 75% and recall higher than 80%, indicating a well performance on particle detection. These findings suggest that training with a low-PND data set still yield effective performance on high-PND cases.

Although both M1 and M2 exhibit high precision score, focusing on the bounding boxes of M1 and M2, as shown in Fig.6(c), the M2 model trends to over predict ( produce more predictions on one particle) when particles form soot. This may be caused by its transformer-based architecture, which lacks a NMS mechanism to filter out redundant detections. The performance of M1 and M2 on full-scale image were further investigated.

When applied to full-scale images, both M1 and M2 exhibit sub-optimal performance as shown in Fig.7(a) and (b). This is due to the images being down-scaled to 640640 pixels when direct performing the detection model, which results in a loss of detail in the particle features. To address this, the SAHI method is introduced, a strategy designed to improve detection of small or densely packed objects within large images. SAHI employs asliding strategythat systematically divides large images into overlapping smaller patches, which are independently processed by M1 and M2. Post-processing is then applied to merge results, using NMS to remove duplicate detections along slice boundaries, yielding cohesive detection results for the entire image. As illustrated in Fig.7(c) and (d), the SAHI method significantly improve M1 and M2 performance on full-scale images, particularly for particles with low contrast against the background. However, similar to the results with cropped and up-scaled images, M2 combined with SAHI (M2s) continue to exhibit over-detection issues for particles with soot. Therefore, M1 combined with the SAHI method (M1s) is selected as the final approach for particle tracking.

SECTION: 4.3Particle tracking

After the detection, the SORT method is applied to acquire the particle velocity data. In Fig.8, the tracking results for an individual particle in the P040A20 case, based on M1s, are presented. The particle velocities are calculated using the Five-Point Difference Method based on the tracked particle center over time. The left diagram in Fig.8illustrates the velocity changes of particles with HAB. Due to the resolution limitations of Mie-scattering, particles appear about 10 pixels in diameter. Consequently, even a positional error of one pixel can introduce significant noise in the velocity analysis. To mitigate this, a polynomial fitting algorithm was applied to the velocities obtained from SORT tracking results, providing a more accurate velocity analysis. The over all velocity is a little bit lower than the average velocity from previous work[23](). The right side of Figure8displays cropped particle images at various HABs. Videos of tracking results with both cropped and full scales, provided in the supplementary materials, demonstrate the robust tracking capability of the SORT method.

To evaluate the improvement in tracking performance with the introduce of the machine learning methods, the probability density function (PDF) of the number of frames per track () based on blob detection and M1s within a single event are calculated, as shown in the Figure.9. Tracking results from M1s exhibits a higher probability density at around 100 frames per track. In contrast, blob detection tracking shows a higher probability density around 50 frames per track. After reviewing the tracking video and trajectories, it is observed that blob detection struggles with particles with soot. As a result, the tracking using blob detection tends to pause at the soot formation area, resuming only after the soot disappears, thus continuing with the residuals of the combustion.

SECTION: 4.4Particle velocity statistic

The motion behaviour of particles in low-PND scenarios are investigated by presenting the mean velocity (), its standard deviation, and the velocity difference of particles for the PND < 0.18 (40) cases, derived from the tracking results of both blob detection and M1s detection, as shown in Figure.10. The average velocities obtained from the two methods are similar, as shown the velocity difference () on the right y-axis. Although blob detection-tracking does not sufficiently detect particles with soot, the average velocity is not influenced, since the SORT algorithm continues tracking particles in regions with less soot particles. The standard deviation of particle velocity between HAB 10 - 25 mm is higher than that at other heights, as this region corresponds to the primary area of soot formation. The average velocity of the particles in single particle combustion (the brown line in the Figure), as denoted in previous work[10], is similar with the, since the particles in low-PND cases posses no interaction, which is similar with the single particle combustion cases. As the PND is relatively low in this data set, particles eventually accelerate to match the ambient gas flow velocity, which is 1.67 m/s for the A20 condition.

To further investigate the particle-particle interaction of group particle combustion, the axial velocity () iso-contours of different PND cases are presented, as shown in Fig.11. Tracked particles within each PND case in the HAB range 0 - 8 mm (before soot formation) were divided into 0.5 mm grids, with the average velocity calculated for each grid cell to form the axial velocity iso-contour. Generally, as PND increases, the particle jet expands outward, consistent with observations in Fig.5. Additionally, the overall velocity decreases in higher PND cases. At lower HAB (0 - 3 mm), particle velocity initially decreases before increasing in the radial direction. However, at higher PND, the zone where velocity begins to increase shifts outward. This trend aligns with findings from previous research[10], which demonstrated that the flame zone (responsible for accelerating particles through thermal expansion) tends to shift downward and outward with higher PND. This shift of the flame zone location further explains the downward movement of the radial velocity increasing zone at higher HAB.

SECTION: 5Conclusions

In this study, high-volatile bituminous coal combustion was conducted in a laminar flow reactor. Particle positions were detected using the Mie-scattering imaging. Traditional blob detection and machine learning detection methods, including YOLOv8 and RT-DETR, were applied to detect particles from different PND cases. Particle tracking was subsequently performed using the SORT algorithm. The reference volume was calculated to determine the PND. Finally, the velocities of particles from different PND cases were analyzed. The following conclusions can be drawn from the results:

(1) Machine learning methods demonstrated superior performance in particle detection. Training the model on simple combustion cases and applied to predict complex cases proved feasible. (2) YOLO combined with SAHI provided better detection on full-scale images, making it suitable for subsequent tracking. (3) The SORT algorithm exhibited robust tracking capabilities for particles. (4) The average velocity of particles in low PND cases was higher than in high PND cases, primarily due to increased particle interactions.

SECTION: 6Acknowledgement

The authors kindly acknowledge financial support through Deutsche Forschungsgemeinschaft (DFG) - Projektnummer 215035359 - TRR 129 for its support through CRC/Transregio 129 ”Oxy-flame: development of methods and models to describe solid fuel reactions within an oxy-fuel atmosphere.”

SECTION: 7References

SECTION: References