SECTION: NM-FlowGAN: Modeling sRGB Noise without Paired Images using a Hybrid Approach of Normalizing Flows and GAN

Modeling and synthesizing real sRGB noise is crucial for various low-level vision tasks, such as building datasets for training image denoising systems. The distribution of real sRGB noise is highly complex and affected by a multitude of factors, making its accurate modeling extremely challenging. Therefore, recent studies have proposed methods that employ data-driven generative models, such as Generative Adversarial Networks (GAN) and Normalizing Flows. These studies achieve more accurate modeling of sRGB noise compared to traditional noise modeling methods. However, there are performance limitations due to the inherent characteristics of each generative model. To address this issue, we propose NM-FlowGAN, a hybrid approach that exploits the strengths of both GAN and Normalizing Flows. We combine pixel-wise noise modeling networks based on Normalizing Flows and spatial correlation modeling networks based on GAN. Specifically, the pixel-wise noise modeling network leverages the high training stability of Normalizing Flows to capture noise characteristics that are affected by a multitude of factors, and the spatial correlation networks efficiently model pixel-to-pixel relationships. In particular, unlike recent methods that rely on paired noisy images, our method synthesizes noise using clean images and factors that affect noise characteristics, such as easily obtainable parameters like camera type and ISO settings, making it applicable to various fields where obtaining noisy-clean image pairs is not feasible. In our experiments, our NM-FlowGAN outperforms other baselines in the sRGB noise synthesis task. Moreover, the denoising neural network trained with synthesized image pairs from our model shows superior performance compared to other baselines.

SECTION: IIntroduction

Real-world image denoising is a fundamental task in low-level vision. However, training effective neural networks for real-world image denoising is highly challenging, due to the difficulty in obtaining noisy-clean image pairs for training image denoising neural networks. A noisy-clean image pair consists of a noisy image and a corresponding clean image that shares the same noise-free content. Because noise is affected by factors such as lighting conditions, sensor limitations, or environmental influences, achieving the perfect alignment between noisy and clean images is a significant challenge.

Therefore, existing real-world image denoising datasets have been limited to those captured in controlled environments, where stationary imaging devices are used to capture static scenes[1,2,3]. Consequently, image denoising neural networks trained solely on data obtained under such conditions may exhibit degraded performance when processing images from uncontrolled environments, such as dynamic scenes.

One effective approach to overcome this challenge is noise modeling, which involves estimating noise characteristics of imaging devices such as smartphone cameras. Specifically, noise modeling neural networks can be trained using data captured in controlled environments to model the noise from imaging devices. Once trained, these noise modeling neural networks can synthesize noise into clean images captured in various environments, generating a large amount of noisy-clean image pairs for training image denoising networks. This method can generate noisy-clean image pairs even in uncontrolled environments where obtaining noisy-clean image pairs is not feasible due to physical constraints. Consequently, image denoising neural networks trained on such synthesized noisy-clean image pairs can demonstrate robust performance on scenes captured in various environments. Figure1illustrates the process of training a noise modeling network and using it to train image denoising neural networks.

Furthermore, noise modeling can also be applied to medical imaging[4], such as X-ray imaging, where the acquisition of noisy-clean image pairs is particularly challenging. In X-ray imaging, capturing multiple images of the same scene can result in unnecessary radiation exposure, raising serious health concerns for patients. Additionally, involuntary movements of internal organs make it difficult to acquire perfectly aligned image pairs, which are essential for supervised learning in denoising tasks. By utilizing noise modeling techniques that rely solely on clean images and known imaging parameters, we can generate synthetic noisy images without subjecting patients to additional radiation or relying on impractical imaging conditions. This approach not only preserves patient safety but also facilitates the development of more effective denoising algorithms for medical applications.

Due to these advantages, numerous studies have focused on accurate noise modeling. The simplest and most commonly used noise models include additive white Gaussian noise (AWGN) and Poisson noise. However, these simple models are insufficient to capture the complex distribution of real-world noise. To address this issue, more advanced models like the Poisson-Gaussian noise model[5]and the heteroscedastic Gaussian noise model[6,1]have been proposed. While these methods have shown improved performance over simpler models, they still do not fully encapsulate the intricate characteristics of real-world noise.

Recently, numerous data-driven methods[7,8,9,10,11,12]based on deep learning have been proposed. These methods are more sophisticated than previous ones, capable of representing more complex distributions. They use neural networks trained on large-scale datasets of noisy images to learn the noise distribution, focusing on modeling both signal-dependent and signal-independent noise from raw sensor images. These approaches can model noise much more accurately, and the denoising neural networks trained on the modeled noise also show promising performance.

Building on the success of noise modeling from raw sensor images, studies have been proposed to perform noise modeling in the standard RGB (sRGB) color space[13,14,15,16,12]. Generally, noise modeling is categorized based on the image domain in which it is conducted, either in the raw-RGB or the sRGB domains. Images in the raw-RGB domain are unprocessed raw sensor data without the application of image signal processing (ISP), maintaining the original data captured by the sensor. In contrast, images in the sRGB domain have undergone the ISP, resulting in standardized and enhanced visuals suitable for various displays and environments.

Noise modeling is notably more difficult in the sRGB domain than in the raw-RGB domain due to the ISP’s impact on both clean signals and noise, resulting in a complex noise distribution[17]. Nevertheless, noise modeling in the sRGB domain is essential because the conversion from raw-RGB to sRGB is performed by in-camera processing[13]. Often, image denoising is not applied or is insufficiently applied prior to the ISP. Consequently, effective noise modeling in the sRGB domain becomes necessary.

Most deep learning-based noise modeling methods in the sRGB domain employ generative models because they can learn complex, high-dimensional data distributions, which is essential for accurately capturing the statistical properties of noise. Efforts have been made to model sRGB noise using generative models such as Generative Adversarial Networks (GAN)[18]and Normalizing Flows[19,20]. These methods have shown promising performance in sRGB noise modeling; however, each of these generative models has its own strengths and weaknesses, limiting their effectiveness.

GAN-based methods[14,15,16]are well-suited to handling high-dimensional and complex data distributions, enabling them to generate realistic noise images in the sRGB domain. However, they have limitations in training stability when dealing with small-sized datasets. Noise modeling often involves insufficient datasets because generating noisy-clean pairs is highly time-consuming. Additionally, the noise distribution is affected by various camera conditions (e.g., types, settings)[1,2]. Therefore, it is crucial to employ a generative model that can maintain high training stability even with limited data for each specific condition.

In contrast, Normalizing Flows-based methods[13,21]exhibit higher training stability with small datasets by directly learning the probability density function of the data. However, due to the constraints of Normalizing Flows, where each layer must be invertible, there are limitations on the expressiveness of the transformation functions. Consequently, generating realistic noise images remains challenging compared to GAN-based methods.

To address the limitations of both GAN-based and Normalizing Flows-based methods, we propose a novel data-driven sRGB noise modeling method named NM-FlowGAN, which is a hybrid approach that combines the strengths of Normalizing Flows and GAN. Our method is designed to effectively model the highly complex noise distribution found in the sRGB image domain. By integrating the high training stability of Normalizing Flows with the powerful expressiveness of GAN, we can overcome the individual limitations of each method.

Moreover, unlike recently proposed methods such as NeCA-W[14]and NAFlow[21], which have demonstrated promising noise modeling performance but rely on real noisy images paired with clean images111This implies that additional synthesized noisy-clean image pairs are generated from the original noisy-clean pair., our method synthesizes noisy images without such pairs. Using real paired noisy images enables the generation of realistic noise and can enhance the performance of image denoising neural networks through data augmentation. However, the requirement for paired real noisy images to synthesize noise makes it impossible to apply these methods in environments where obtaining noisy-clean image pairs is not feasible. By relying only on clean images and factors that affect noise characteristics, such as camera type or ISO settings, our method broadens the applicability of noise modeling to various environments such as dynamic scenes.

In our proposed method, we first take advantage of the high training stability offered by Normalizing Flows to model pixel-wise noise. Our analysis of noise in the sRGB domain reveals that pixel-wise noise depends on the clean image intensity, surrounding image structures, and camera conditions. To address this, we design novel invertible layers that can effectively model these dependencies. Additionally, we employ GAN to model high-dimensional noise features, such as spatial correlations induced by in-camera imaging processes like demosaicing. This combined approach enables the generation of realistic sRGB noise images while ensuring high training stability. To validate our method, we compared the performance of noise modeling in the sRGB image domain in real-world scenarios. In the experiments, our method shows superior performance compared to the other baselines.

SECTION: IIRelated Works

SECTION: II-AGenerative Adversarial Network

GAN has been actively adopted for modeling complex noise that occurs in real-world scenarios. There are a few efforts to apply this for modeling noise in the sRGB image domain. Firstly, C2N[15]attempts to model noise in the sRGB image domain using unpaired noisy-clean image pairs. However, because they do not consider camera conditions that affect the noise distribution, the noise images generated from the model suffer from color shift problems.

To address the issue, a noise modeling method NeCA[14]is proposed, which estimates the noise level using an additional noisy image and models spatially correlated noise[22]using GAN. While this method can generate realistic noise images, its performance is significantly affected by the noisy image used in gain estimation. In addition, the method has the problem that it requires extensive training time due to the necessity of training neural networks for each camera type.

Consequently, GAN-based methods are highly effective in modeling high-dimensional noise features and generating realistic noise images in the sRGB image domain. However, they have limitations in considering camera conditions that affect noise distribution due to the problem of training stability on small-sized datasets.

SECTION: II-BNormalizing Flows

Normalizing Flows is another well-known generative model in computer vision. Compared to GAN, Normalizing Flows shows higher training stability even with small-sized datasets. This feature makes them effective for sRGB noise modeling where the available datasets are often limited in size. Recently, Koushaet al.[13]proposed a conditional Normalizing Flows-based noise modeling method in the sRGB image domain. This method allows stable training of a noise model considering clean images and camera conditions. However, due to the constraints of Normalizing Flows where each layer must be invertible, the expressiveness of the transformation function is limited. Consequently, this leads to performance limitations in learning data representations. Therefore, the method has limitations in synthesizing realistic noise images compared to GAN-based models. Specifically, there are issues in modeling the spatial correlation of the noise, which is commonly present in the sRGB image domain.

To address these challenges, Kimet al.[21]proposed a method called NAFlow, which focuses on improving the handling of spatially correlated noise through the use of multi-scale noise embedding techniques and Gaussian mixture models. By incorporating these techniques, NAFlow effectively models the spatial correlation of noise. However, NAFlow has a limitation in that it uses real-world noisy images paired with clean images to synthesize the noise. Using real noisy-clean image pairs limits NAFlow’s ability to perform noise synthesis in real-world scenarios. This constraint specifically restricts its applicability, such as when processing images captured in uncontrolled environments such as dynamic scenes where obtaining noisy-clean image pairs is not feasible. As a result, the challenge of effectively modeling the spatial correlation of noise using Normalizing Flows remains.

To sum up, while both GAN and Normalizing Flows have been actively adopted for noise modeling in the sRGB image domain, each method has its own strengths and weaknesses. Unlike previous attempts to model noise with a single generative model, we propose a hybrid approach that leverages the strengths of both models. By exploiting GAN’s capability in extracting high-dimensional noise features to model spatial correlation and Normalizing Flows’ high training stability with small-sized datasets, our approach effectively captures the factors affecting noise distribution, such as camera conditions, without requiring separate neural networks for each camera type. Additionally, our method does not require the paired noisy image corresponding to the clean image for noise synthesis, further enhancing its applicability in diverse real-world scenarios.

SECTION: IIIMethod

SECTION: III-AAnalyzing sRGB Noise

sRGB noise has unpredictable and complex distributions. For accurate noise modeling, identifying the factors that affect its distribution is crucial. Therefore, we analyzed the distributions of sRGB noise from the SIDD dataset under different scenarios. Our analysis of the SIDD dataset, summarized in Figure2and3, confirms that sRGB noise is affected by three main factors: clean image intensity, image structure, and spatial correlation.
For accurate noise modeling, it is essential to consider all factors that affect the noise. Detailed descriptions of each factor are given below.

The primary factor affecting the sRGB noise distribution is the clean image intensity. We first present the noise distribution in the raw-RGB image domain to clearly demonstrate this relationship. In the raw-RGB domain, one of the most commonly used noise models is the heteroscedastic Gaussian noise[6]. This model describes raw-RGB noise as a signal-dependent noise with a zero mean and Gaussian distribution. Given a paired raw-RGB clean imageand its noisy counterpartsuch that, the Gaussian distribution of noise at pixelcan be represented as:

where,are noise distribution parameters that represent signal-dependent and signal-independent. These parameters are determined for each channel and are affected by the camera type and ISO setting.

Given that sRGB images are transformed version of raw-RGB images via the ISP, a clean sRGB imageand noisy sRGB imagecan be represented as. This relationship can be related to their paired raw-RGB images by the equation:

wheredenotes the ISP. From this equation, we can deduce that sRGB noise is affected by the noise present in raw-RGB; therefore, it can be affected by the clean image intensity, camera type, and ISO setting. Figure2aand2bdemonstrate that sRGB noise is affected by the clean image intensity in a complex, non-linear fashion and varies depending on the camera type and ISO setting.

In addition, the distribution of noise in the sRGB domain is also affected by image structures. This is evident when comparing Figure2band2c; despite having the same camera type, ISO settings, and illuminant settings, the noise distribution can vary depending on the captured scene. This variability is due to signal processing techniques, such as local adjustments in the ISP. Therefore, to estimate the noise variation of a specific pixel, it is essential to consider the surrounding image structure.

Considering the two previously mentioned factors - clean image intensity and image structure, the mean and standard deviation of the pixel-wise noise distribution for the channelof theth pixel can be expressed by the following equation:

whereanddenote the camera type and ISO settings respectively,denotes the local image patch composed of the pixeland its neighboring pixels, anddenotes the non-linear relationship between the parameters of the noise distribution and the factors that affect it. This allows us to model the pixel-wise noiseat each pixel as a Gaussian distribution:

The final factor to consider in the distribution of sRGB noise is spatial correlation. Previously, we introduced pixel-wise noise, assuming that the distribution of sRGB noise is independent for each pixel. However, as shown in Figure3, the actual sRGB noise of each pixel is highly correlated with the noise values of its neighboring pixels. This spatial correlation arises due to the demosaicing process of the ISP on the Bayer filter[23,24], which interpolates from neighboring noisy subpixels. Therefore, it is crucial to account for this correlation during noise synthesis.

Spatial correlation arises mainly due to the Bayer demosaicing process, which is typically performed without regard to camera settings[25,26,27]. As shown in Figure3, spatial correlation is consistent regardless of camera type or ISO settings, unlike pixel-wise noise distribution, which is affected by a multitude of factors.

To analyze this inter-pixel relationship shown in Figure3, we used Pearson correlation. The correlationis calculated as:

whererepresents the set of pixels in the noise image, anddenotes the set of pixels at a specific distance from each pixel:

with the distancebetween pixels calculated as:

Considering spatial correlation, the sRGB noise for each pixel can be modeled using the following equation:

wheredenotes a function that maps spatial correlation between the pixelof the noise image and its neighboring pixels.

SECTION: III-BHybrid Architecture

Inspired by our analysis, we introduce our novel sRGB noise modeling method named NM-FlowGAN, which is a hybrid approach that combines Normalizing Flows and GAN. As shown in Figure4, our proposed neural network for synthesizing real sRGB noise includes two main components: the pixel-wise noise modeling network and the spatial correlation modeling network.

The pixel-wise noise modeling network based on Normalizing Flows assumes that the distribution of noise value for each pixel is identical. As mentioned above, pixel-wise noise is affected not only by the clean image intensity and image structures but also by camera conditions such as camera type and ISO settings. Considering these aspects, a network based on Normalizing Flows, which ensures stable training even with small-sized datasets, is advantageous for pixel-wise noise modeling. However, networks based on Normalizing Flows are not well-suited for modeling spatial correlation.

To model spatial correlation, it is crucial to consider the complex relationships among neighboring pixels. However, due to the invertibility constraint in normalizing flows, it is challenging to fully capture these relationships. For example, affine coupling[28]is adopted in sRGBFlow[13]to model spatial correlation, which considers only a subset of input channels to estimate the scale and translation factors applied to the remaining channels. The limitation of not being able to generate an output feature that takes into account all input features is a constraint on representing complex correlations between neighboring pixels. Furthermore, sRGBFlows primarily focus on learning representations through inter-channel operations such as affine coupling and invertibleconvolution[29], they are less suited for modeling pixel-to-pixel spatial correlations.

To address this issue, we adopt a GAN-based spatial correlation modeling network. GAN-based methods are well-suited for handling high-dimensional and complex data distributions. In addition, unlike Normalizing Flows, there are no constraints on designing network architecture, allowing for flexible modeling of pixel-to-pixel relationships. As mentioned above, GAN-based models have a weakness of low training stability on small-sized datasets. However, spatial correlation is not affected by camera type or ISO setting. As a result, this shortcoming is not evident when modeling spatial correlations.

SECTION: III-CPixel-wise Noise Modeling Network

In our pixel-wise noise modeling network, the distribution of each pixel is assumed to be identical, and Gaussian distributions are estimated for each pixel. Our network, based on Normalizing Flows, comprises three flow layers: conditional linear flow, signal-dependent conditional linear flow (SDL), and structure-aware conditional linear flow (SAL). Each layer effectively estimates the pixel-wise noise distribution by considering the factors affecting it.

Recently, a simple invertible form of the conditional linear flow layer has been proposed in sRGBFlow[13]. This layer linearly transforms the input feature using values determined by the camera typeand ISO setting:

wheredenotes the input of theth pixel in theth flow layer,denotes element-wise multiplication, andandare simple neural networks designed to output the scale and translation factors, considering the values ofand. While this layer can perform a transformation that considers the camera conditions, the non-linearity and complexity of real sRGB noise make it difficult to model accurately with such a simple transformation.

To address these limitations, we designed enhanced layers that estimate the pixel-wise noise distribution by considering factors such as the clean image intensity and the image structure. SDL performs a linear transformation based on the clean image intensity:

whereandconsist of pointwise convolution layers and non-linear activation layers, designed to output scale and translation factors based on the clean image intensity and camera conditions. SAL performs a linear transformation by considering the surrounding structure of pixel:

whereandare designed to have limited receptive fields withconvolution layers and non-linear activation layers. They output scale and translation factors considering both the image structure and camera conditions.

Figure5illustrates the detailed architecture of the core components of our pixel-wise noise modeling network: SDL and SAL. These layers are designed to estimate and apply scale and bias values for each pixel using a clean image and conditions, including camera type and ISO setting. SDL and SAL first apply a one-hot encoding of the camera type and the ISO setting, and then extract the features using an architecture consisting of residual blocks. This method of encoding camera conditions is adopted from sRGBFlow[13]. The extracted features are then channel-wise concatenated with the clean image to serve as input to the feature extraction networks (FEN) of SDL and SAL. Each of these layers has a different architecture for feature extraction, and the outputs from these layers are used as scale and bias parameters for each pixel.

Specifically, SDL consists mainly of pointwise convolution layers, instance normalization layers, and activation layers. This design aims to estimate log scale and bias parameters based on the clean image intensity of each pixel. On the other hand, SAL consists mainly of convolution layers withfilters and activation layers. Its design aims to estimate log scale and bias parameters based on the image structure surrounding each pixel.

Like other architectures that rely on Normalizing Flows, our pixel-wise noise modeling network is trained to minimize the negative log-likelihood (NLL) of the data. Once trained, we can employ this network to synthesize pixel-wise noise. This synthesis is achieved by sampling from the base distributionand subsequently applying the inverse flow:

wheredenotes our invertible pixel-wise noise modeling network.

SECTION: III-DSpatial Correlation Modeling Network

Given the synthesized pixel-wise noise, our GAN-based spatial correlation modeling network models the pixel-to-pixel correlation to reduce the discrepancy between the real noiseand synthesized pixel-wise noise. Specifically, as represented in (8), the final noise value is determined by considering the surrounding pixel-wise noise values. We adopt the U-Net[30]for the generator network and a VGG network-based architecture[31]for the discriminator network. Consequently, by using our spatial correlation modeling network, we can generate the final synthesized sRGB noise imageas follows:

Figure6provides visual examples of a pixel-wise noisy image and a noisy image considering spatial correlation.

SECTION: III-ELoss Functions

NLL Loss:Our pixel-wise noise modeling networkis composed of a sequence offlow layers:

For each layer, the input and output relations can be expressed as:

without the necessity of training separate neural networks for each camera or using paired noisy images.
For the sake of clarity, we defineandfor conciseness. To train this network, we employ the NLL loss. It can be formulated as:

wheredenotes a function that outputs the Jacobian matrix ofat the given input.

GAN Loss:To train our generator network, we employ WGAN-GP[32,33]approach to calculate the adversarial loss. The adversarial loss foris given by:

wheredenotes our discriminator, andanddenote the clean image and the synthesized pixel-wise noise image, respectively. In addition,is the balance parameter between the pixel-wise noise modeling networks and the spatial correlation modeling networks, the operatordenotes the channel-wise concatenation, anddenotes the stop-gradient operation[34]. This equation indicates that our discriminator evaluates the authenticity of the noise synthesized by, with consideration of the clean image. Meanwhile, to ensure that the discriminator is effectively trained with the generator, we define the critic lossfor our discriminator as follows:

whereis the weight for the gradient penalty term, set to 10 in all our experiments, andis the original critic loss, defined as:

In addition,is the gradient penalty loss, defined as:

whereand.

SECTION: IVExperiments

SECTION: IV-AExperimental Setup

Dataset:To evaluate the performance of sRGB noise modeling, we use the Smartphone Image Denoising Dataset (SIDD[1]). The SIDD medium split contains 320 noisy-clean image pairs captured with various camera types: LG G4 (G4), Google Pixel (GP), iPhone 7 (IP), Motorola Nexus 6 (N6), and Samsung Galaxy S6 Edge (S6), each under various ISO settings. For a fair comparison, we follow the sRGBFlow[13]dataset settings, using 80% of the data for training and 20% of the data for validation.

Implementation Details:We extract patches of sizewith a step size ofto optimize NM-FlowGAN222Our code is available at:https://github.com/YoungJooHan/NM-FlowGAN. During training, we augment all of the training patches by randomly flipping and rotating them by. We employ the Adam[35]optimizer for training with an initial learning rate set to. The learning rate decreases by half every 10 epochs, and our model trains over 40 epochs. In addition, we settoin our experiments.

Baselines:Our NM-FlowGAN is compared with several existing sRGB noise modeling methods in the experiments. We include traditional methods such as Additive White Gaussian Noise(AWGN), heteroscedastic Gaussian noise, and deep learning-based modeling methods such as C2N[15], sRGBFlow[13], NeCA-W[14], and NAFlow[21]. For the synthesis using AWGN and heteroscedastic Gaussian noise, we estimate the parameters corresponding to each noise model and apply them to each pixel. For C2N, sRGBFlow, NeCA-W, and NAFlow, we use the official codes provided by the authors. Specifically,in TableIand Figure7refers to a method that uses paired noisy images for noise synthesis.

Using paired noisy images allows for more accurate noise generation. However, the need for paired noisy images for noise synthesis does not take one of the main advantages of noise modeling mentioned in Section 1, which is the ability to generate noisy-clean image pairs in scenes that are not achievable in real-world environments. Therefore, its applicability in real-world scenarios is limited. For NeCA-W, since the method can perform noise synthesis using both paired noisy images and unpaired noisy images, we present the experimental results for both scenarios.

SECTION: IV-BResults on sRGB Noise Modeling

TableIlists the discrete Kullback-Leibler(KL) divergence results for NM-FlowGAN and several baseline models. We evaluate the performance of the noise modeling using the KL divergence, which determines the similarity between the distributions of the real and synthesized noise by comparing the histogram. Specifically, the histogram range is set from -260 to 260, with 130 intervals.

In our experimental results, our NM-FlowGAN showed the best performance among the methods that do not use paired noisy images for noise synthesis. Specifically, NM-FlowGAN shows a lower KL divergence of 0.043 and 0.020 compared to the recently proposed NeCA-W and sRGBFlow, respectively. Notably, our NM-FlowGAN achieves a slightly lower KL divergence compared to NeCA-W†and NAFlow†, both of which use paired noisy images. Figure7shows a qualitative comparison between the real noise images and the synthesized noise images generated by our NM-FlowGAN and other baselines.

To further validate the noise modeling performance of our model, we present additional experimental results in this section. First, Figure8shows the standard deviation as a function of clean image intensity for our NM-FlowGAN, sRGBFlow, and NeCA-W. This figure indicates that our model shows similar behavior to real noise compared to the other baselines.

SECTION: IV-CAblation Study

TableIIsummarizes the KL divergence for different architectural choices of our proposed NM-FlowGAN. In the experiment using only a GAN-based architecture, we observe a high KL divergence due to the lack of consideration for features that affect the noise distribution.
In the experiments using the flow layers, the KL divergences are gradually decreased with the addition of signal-dependent and structure-aware conditional linear flow layers. Notably, in the experiment consisting only of flow layers (without GAN), it is observed that the KL divergence is marginally higher than when both flow layers and GAN are used simultaneously. This is because KL divergence, which is based on histogram similarity, may not effectively capture factors that are not revealed in the histogram, such as spatial correlation. Therefore, in the following subsection, we further evaluate the closeness of the synthesized noise to the real noise by comparing the performance of image denoising networks trained with the synthesized noise from each method.

SECTION: IV-DResults on Real-world Image Denoising

Preparation:To further investigate the quality of the synthesized noise, we evaluate its performance in real-world image denoising. We use the widely adopted image denoiser DnCNN[36]to train on the synthesized noisy-clean image pairs generated by each of the baselines. The clean images used to generate the synthesized noisy-clean image pairs are obtained from the sRGB images in the SIDD medium split. In addition, we adopt the SIDD validation and benchmark dataset for validation and testing of image denoising networks. The SIDD validation and benchmark dataset contain 1,280 patches, each of size. Although the ground truth for the SIDD benchmark dataset used in testing is not publicly available, peak signal-to-noise ratio (PSNR) and structural similarity index measure (SSIM) results for denoising can be obtained through the online submission system provided on the SIDD website333https://www.eecs.yorku.ca/~kamel/sidd/benchmark.php. In our real-world image denoising experiments, we include not only the baselines used in sRGB noise modeling but also a supervised method trained on real noisy-clean image pairs to estimate the upper bound performance.

Results:TableIIIlists the performance of image denoising networks trained on noisy-clean image pairs synthesized by our proposed method in comparison to other baselines. The results indicate that our method outperforms the other baselines in terms of PSNR and SSIM. Specifically, NM-FlowGAN achieves significant PSNR gains of 1.11dB and 2.30dB over NeCA-W and sRGBFlow respectively. These results indicate that the noise generated by our model has a more similar distribution to the real noise compared to the other baselines. A visual comparison between NM-FlowGAN and the baselines is shown in Figure9.

Ablation Study:TableIVsummarizes the image denoising performance of different architecture choices for our method. Notably, the experiment consisting only of flow layers (without GAN), while showing a low KL divergence in TableII, shows a degraded image denoising performance. This indicates that efficient modeling of spatial correlation plays a crucial role in improving the applicability of the noise model. In experiments using the flow layers based on the hybrid architecture (with GAN), both PSNR and SSIM are progressively improved with the addition of signal-dependent and structure-aware conditional linear flow layers.

SECTION: IV-EApplicability in Real-world Scenario

As mentioned in Section 1, modeling sRGB noise enables the generation of noisy-clean image pairs across various environments, even in scenarios where obtaining such pairs is challenging due to physical constraints. This allows for training image denoising networks with synthesized pairs that are similar to real usage scenarios, thereby enhancing the generalization ability of the model and ensuring robust performance.

To demonstrate the importance of training with scenes similar to real usage environments, we utilize the SIDD+[37]dataset, which contains scenes different from those in the SIDD dataset. Specifically, we use our NM-FlowGAN to generate synthetic noisy-clean image pairs from 50% of the SIDD+ dataset, and then add these to the SIDD dataset to train the image denoising networks. Subsequently, we evaluate the performance of the denoiser using the remaining 50% of the SIDD+ dataset. In the experiment, the camera settings for noise synthesizing in the SIDD+ dataset are randomly selected for each image.

TableVand Figure10demonstrate that image denoising performance improves when networks are trained on datasets that are enlarged with synthesized noisy-clean image pairs derived from scenes similar to actual usage environments. Specifically, when compared to the results using only the SIDD dataset, enlarging the dataset with synthesized noisy-clean image pairs generated by our NM-FlowGAN results in a PSNR gain of 0.54. Furthermore, our proposed method achieves higher gains in PSNR and SSIM compared to recently proposed methods such as sRGBFlow and NeCA-W. These experimental results highlight the accuracy of our sRGB noise modeling method and emphasize its applicability in real-world scenarios.

SECTION: IV-FCamera-Specific Noise Modeling

We demonstrated that our NM-FlowGAN effectively models the noise in the SIDD dataset, which consists of images captured by various cameras, by training a single unified model. However, as mentioned, sRGB noise is significantly affected by hardware specifications such as image sensors. In scenarios where the noise modeling data is captured by cameras with widely varying hardware specifications, employing camera-specific training becomes a suitable solution to improve performance.

In the case of camera-specific training for noise modeling networks, compared to training a unified single model, it may not be necessary to consider the variety of camera types in the noise synthesis process. Instead, training may need to be performed on a small-sized dataset. Therefore, to effectively train noise modeling networks, it is crucial that the noise modeling networks is trained stably even from a small-sized dataset.

TableVIdemonstrates that our proposed NM-FlowGAN shows promising performance even in camera-specific training. This is due to our hybrid architecture, which exploits the advantages of both Normalizing Flows and GAN, allowing our NM-FlowGAN to be stably trained even with small-sized datasets. Specifically, in our pixel-wise noise modeling networks based on Normalizing Flows, stable training can inherently be achieved even on small-sized datasets. Moreover, our GAN-based spatial correlation modeling networks model spatial correlations from synthesized pixel-wise noise, enabling more consistent modeling compared to other GAN-based noise modeling networks. This consistency leads to more stable training.

SECTION: IV-GSimultaneous Training

Our NM-FlowGAN consists of two distinct neural networks: pixel-wise noise modeling networks and spatial correlation networks. These networks are based on Normalizing Flows and GAN, respectively. Our method is capable of training multiple networks simultaneously. However, each network is optimized independently according to its respective loss function, ensuring that the optimization of one network does not affect the other networks. In this paper, we indicate this training strategy to simultaneous training. This implementation is possible because each neural network tends to synthesize a distinct form of noise, and it can improve the training stability and performance of our model in sRGB noise synthesis. TableVIIshows the comparison of noise modeling performance for three different training strategies: the simultaneous training strategy, the joint training strategy without using a stop gradient function, and the two-stage training strategy where the pixel-wise and spatial correlation modeling networks are trained sequentially.

In the case of the two-stage training strategy, it shows comparable performances to our proposed simultaneous training strategy. The two-stage training strategy can also be adopted due to our approach of training the neural networks independently. However, in the case of simultaneous training, our use of simple pixel-wise modeling networks leads to rapid convergence of the negative log likelihood (NLL) loss. As a result, the model is trained in a manner similar to the two-stage training strategy. Therefore, our proposed simultaneous training strategy and the two-stage training strategy show similar performances. In addition, the training time is longer compared to the other training strategy because each neural network needs to be trained sequentially. Therefore, we adopt the simultaneous training strategy for efficiency.

SECTION: IV-HLatency

As shown in TableVIII, our method not only demonstrates better noise synthesis performance compared to NeCA-W, but also has lower latency. Although our method exhibits a higher latency compared to sRGBFlow, the significant performance improvement brings justifies this increase and makes it tolerable in practice. We measured latency using a batch of 16 images, each with a resolution of, on a single NVIDIA A6000 GPU.

SECTION: VConclusion

In this paper, we introduce a novel hybrid method for modeling sRGB noise. We begin by analyzing the characteristics of sRGB noise and exploring the factors that affect its distribution. From this analysis, we present NM-FlowGAN, noise modeling neural networks that combine two generative models: Normalizing Flows and GAN. By leveraging the strengths of both networks, our method combines pixel-wise noise modeling with Normalizing Flows and spatial correlation modeling with GAN. This combination allows our method to effectively capture noise characteristics and model pixel-to-pixel relationships in sRGB noise. In particular, our approach synthesizes noisy images using only clean images and noise-related factors like camera type or ISO settings, thereby enhancing its applicability in scenarios where paired data is unavailable. Our experimental results show that our method outperforms other baseline methods in sRGB noise modeling and image denoising. Furthermore, we demonstrate the effectiveness of our proposed method and its applicability in real-world scenarios through various experiments.

SECTION: References