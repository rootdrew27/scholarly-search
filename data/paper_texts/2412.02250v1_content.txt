SECTION: Vision Transformers for Weakly-Supervised Microorganism Enumeration

Microorganism enumeration is an essential task in many applications, such as assessing contamination levels or ensuring health standards when evaluating surface cleanliness. However, it’s traditionally performed by human-supervised methods that often require manual counting, making it tedious and time-consuming. Previous research suggests automating this task using computer vision and machine learning methods, primarily through instance segmentation or density estimation techniques. This study conducts a comparative analysis of vision transformers (ViTs) for weakly-supervised counting in microorganism enumeration, contrasting them with traditional architectures such as ResNet and investigating ViT-based models such as TransCrowd. We trained different versions of ViTs as the architectural backbone for feature extraction using four microbiology datasets to determine potential new approaches for total microorganism enumeration in images. Results indicate that while ResNets perform better overall, ViTs performance demonstrates competent results across all datasets, opening up promising lines of research in microorganism enumeration. This comparative study contributes to the field of microbial image analysis by presenting innovative approaches to the recurring challenge of microorganism enumeration and by highlighting the capabilities of ViTs in the task of regression counting.

SECTION: IIntroduction

Enumeration of microorganisms is crucial across diverse sectors including medicine, pharmaceutical quality control, or environmental monitoring[1,2,3]. This task is relevant in microbiology, and methods have been researched and improved for decades[4]. Traditional techniques are usually tedious, as counting manually (agar plate or hemocytometry) or the indirect estimations with turbidimetry[5,6,7]depends on specialized equipment, team, and time in order to improve efficiency. Hence, there has been a pursuit of automated and efficient enumeration techniques to improve this practice[8].

As a result, the efficiency of computer vision methods has improved microbial enumeration in later years. Machine learning, and later, deep learning, has made it possible to count the number of particles in images and extract various characteristic parameters of them, reducing workload and improving the accuracy of the analysis[9,10]. Research to improve numeration through deep learning is extensive and follows two lines of research: detection-based methods and regression-based methods, like image masks estimation, or density map regression[11,12]. These approaches have set the baseline and brought a new standard for efficiency all over the academic corpus.

Although density estimation and instance segmentation offer benefits, they are not always feasible due to the lack of detailed spatial information. For example, microbial swab testing assesses surface cleanliness by providing a total bacterial count without precise localization[13]. Spatial-aware datasets complicate enumeration by requiring detailed annotations and increasing computational burden[13]. Instead, focusing on aggregate counts provides a simpler, faster, and equally effective solution.

To address this issue, weakly-supervised counting (WSC) is used as an approach that applies regression to images to predict the total number of instances without spatial information, as shown in Figure1. CNNs are the most common architectural choice to solve this problem[14,15], but recent advances have shown the effectiveness of vision transformers (ViTs) for the same task, outperforming CNNs[16,17]. This is the result of the inherent self-attention mechanisms of ViTs, which, in contrast to CNNs, outperform in capturing global image context and contextual dependencies, proving effective in image classification and segmentation[18].

The goal of this study is to highlight the use of ViTs in weakly-supervised counting and make use of its applicability in the task of microorganism enumeration as an effective solution. To achieve this, we conducted a comprehensive analysis of ViT-based backbone regression architectures. We compared them to the most popular benchmark architectures: CNNs, ResNet50, and ResNet101, by training them under the same strategy (no use of pre-trained weights nor fine-tuning to optimize results) to achieve the task of microorganism enumeration. We used four different microscopic-based datasets: the Fluorescent Neuronal Cells dataset[19], VGG-Cells dataset[20], U2OS/HL60 Human Cancer Cells dataset[21]and a self-made artificial fluorescent bacteria dataset, that is composed of high-resolution images. We created this dataset for the task of WSC in order to cover the gaps the former three datasets have in regards of dataset size, density sparsity through the images, and image resolution.

Our experimental evaluation indicates that although traditional architectures such as ResNet achieve better performance, ViTs, especially CrossViT, can achieve comparable results to ResNet. CrossViT also performed exceptionally well on homogeneously distributed datasets, outperforming other ViT variants and CNNs in terms of computational efficiency. These results underscore the need to explore the use of ViTs, as further research holds the potential to achieve effective architectures for the task of weakly-supervised microorganism enumeration.

This study contributes to microorganism enumeration[8]by direct enumeration without the need for spatial information. We also analyze the use of vision transformers (ViTs) in regression counting. We evaluate popular and novel weakly-supervised counting methods, adapt them to microbial imaging, and evaluate ViTs in this context. Our analysis covers the capability of ViTs in a regression task, comparing different ViT approaches to identify the best one depending on the use case. By evaluating the performance of ViTs under the same training strategy as the other methods when configured for weakly-supervised counting, we provide insight into the limitations and potential of this architecture, thus contributing to the field of feature extraction using self-attention mechanisms[22]. We also contribute to the study by developing an artificial fluorescent bacteria dataset designed for the task of weakly-supervised microorganism enumeration. An implementation of the method and the artificial dataset generation tool are available athttps://github.com/JavierUrenaPhDProjects/vits_for_WSC.

SECTION: IIRelated work

SECTION: II-AMachine Learning in microorganism enumeration

Automating enumeration of microorganisms has been researched for decades, with traditional techniques like PCA, LDA or SVM and subsequently advancing to feature extraction with deep learning[8,23]. Two research strategies have been developed: detection-based and regression-based enumeration. Detection-based methods refer to the enumeration of instances once they are located in the image, being image segmentation as the most accurate method of instance detection.[24,11,25]extend the U-Net architecture[26]in its ability to count cells and bacteria by discretizing them from background and subsequently enumerating them. Regression-based methods solve the task either through density map estimation or direct regression without spatial details. Convolutional neural networks (CNNs) for density estimation treats image pixels as real-valued feature vectors and constructs density functions over pixel grids, enabling object count estimation by integrating over specific image regions[20,27,28,12]. The task is also accomplished with weak annotations, such as centroid position information of the instances, to estimate dense proximity maps[29,30].

But segmentation and density map regression in image analysis both rely on spatial information to identify instances, with segmentation using binary masks for pixel discretization[26]and density regression assessing instance agglomeration[20]. Even weakly-supervised models sometimes require centroid annotations[30]. However, in high-density scenarios common in microorganism analysis, detecting individuals becomes challenging. Moreover, when the goal is to simply count microorganisms globally, spatial details may be unnecessary. This necessitates datasets that bypass spatial data, focusing instead on correlating image features with total microorganism counts for efficiency[31,14,15]. This is avoided through direct regression, or "weakly-supervised counting" which is a form of supervised learning where the annotation of the images is kept to a minimum, such as providing only the overall global count[15], or the patch-labeled count[14]. This approach emerges as an end-to-end application-oriented solution for microorganism enumeration.

SECTION: II-BWeakly-supervised enumeration

Weakly-supervised counting refer to the enumeration approach based on direct regression, and is tackled with machine learning when problems such as high instance density or occlusion arise, and also bypasses the hard detection problem and reduces labeling cost by requiring only the ground truth number of instances in the training images. This has been extensively studied in the use case of crowd counting, by the use of CNNs[32], and microorganisms too[15,33].[33]for example implements an end-to-end WSC architecture by concatenating a ResNet with a CNN-based regressor that captures the global features of the entire microscopic image.

But CNNs convolution kernels fail to model global context information due to the limited receptive field, which is crucial when it comes to dense instance counting[34], and do not establish interactions between image patches, which makes them unable to learn contrast features between the background and the elements to count. Vision transformers[18]circumvent this issue with the self-attention mechanism that captures global dependencies and thus learn global context information.TransCrowd[17], first uses ViT for weakly-supervised crowd counting as a backbone to extract information and concatenating a regression head, creating an end-to-end architecture. Others follow example. creating end-to-end architectures that achieve crowd counting with refined iterations[35,36].

SECTION: II-CObject counting with transformer architectures

As ViTs capture better global context information, most approaches use them as feature extraction backbone modules[37]. Images are segmented into fit-size patches, which are then processed through a linear embedding layer and sometimes summed with task-oriented tokens, which are then fed into the standard transformer encoder. The first use case where semantic segmentation was achieved using ViT instead of CNN as the backbone isSETR[38], which achieved state-of-the-art results on theADE20kdataset.

For regression methods, transformers are considered as an effective solution to estimate density maps for crowd counting[39,40,16]by using specialized patch tokens as a form is dense supervision[40]or achieving multi-scale 2D feature maps from a pyramid ViT backbone, namedCCTrans[16].CounTR[16]leverages the instance counting task by creating a class-agnostic counting architecture by exploiting the attention mechanisms to explicitly capture the similarity between image patches or "exemplars".

Weakly-supervised counting has also been achieved using transformers[17,35,36,41].CCTwins[42], uses a U-shaped architecture, featuring an adaptive Twins-SVT-L backbone to extract multi-level features, uses a multi-level count estimator to regress these features to a crowd number in a coarse-to-fine manner.Learn to Count Anything[43]accomplishes class-agnostic instance counting likeCounTR[16], but without using exemplars or reference patches. Instead, it employs WSC with self-supervised knowledge distillation, where a teacher network processes global image slices and a student network processes smaller local slices.

Promising results have been achieved in the paradigm of instance counting using transformer-based architectures, but to date little to no research has been done in the field of microbiology. Research in this area can contribute to the development of more effective models for counting microorganisms.

SECTION: IIIMethodology

We subject a comparison of different architecture approaches covering three different categories: state-of-the-art approaches in the task of weakly-supervised counting, ViT-based backbones for regression architectures, and finally baseline traditional deep learning computer vision architectures commonly used for the task. The explanation can be followed in sectionIII-B.

The models were trained from scratch on four microorganism-based datasets consisting of neuronal cells, cancer cells, or bacteria. These datasets represent different types of use cases because they present different challenges, such as dataset size, density per image, or variability between images. The metrics used to compare the architectures are Mean Absolute Error (MAE) and Root Mean Squared Error (RMSE). Datasets and metrics are further explained in sectionIV-B.

SECTION: III-AArchitecture pipeline

A common approach for WSC architectures is to concatenate two main parts: the backbone and the regression head (also called counter). The backbone is responsible for extracting the image features and placing the visual data into the latent space as feature embeddings. These are then sent to a regression head, which is used exclusively to predict the number of instances in the image. This general architectural approach, illustrated in the example of a ViT backbone in Figure2, is widely used in most studies investigating WSC[44,17,33,35,41]. Feature extraction is the most important part of the whole architecture, so this study focuses on exploring different backbones. The simplest regression head is a linear regressor, but the use of nonlinear regressors is preferable. In this study, it is implemented as a single layer fully connected network.

SECTION: III-BArchitecture backbones

TransCrowd[17]is a pioneering ViT-based WSC model, featuring two implementations: TransCrowd-GAP and TransCrowd-Token. TransCrowd-GAP employs global average pooling on the transformer’s output tokens, while TransCrowd-Token adds a learnable token for enumeration. This model shows significant improvements in crowd counting on datasets like ShanghaiTech, outperforming both weakly-supervised (MAE andMSE improvement over MATT[45]) and fully-supervised methods (MAE andMSE improvements compared to CRSNet and BL[46,47]).

ViT research offers various backbones for feature extraction, chosen for their performance and proclaimed computational efficiency from novel architectural approaches. The first one being the vanilla ViT[18], which introduced the multi-head self-attention mechanism (MHSA) of the transformer as an encoder for image recognition, processing images as patch sequences. This method outperforms traditional CNNs in image classification benchmarks like ImageNet and CIFAR-100.

A different ViT approach is the DeepViT[48]which addresses "attention collapse", a problem with ViTs that make them plateau in performance when made deeper, by introducing "re-attention", a technique that regenerate attention maps with minimal computational cost, improving top-1 classification accuracy by 1.6% on ImageNet with 32 transformer blocks.

An interesting approach to achieve great computational efficiency is CrossViT[49]which features a dual-branch transformer that processes different-sized patches with an efficient cross-attention mechanism that fuses these patches, reducing computational costs significantly. This model outperforms DeiT on ImageNet1K by 2%, with minimal additional computational complexity and model size.

To achieve higher model complexity without compromising parameter and compute neutrality, Parallel ViT[50]proposes parallelizing the MHSA and feed-forward blocks by reorganizing the same blocks by pairs, resulting in the same number of parameters but wider and shallower, increasing the dimension of the embedding for better spatial feature separability.

Finally, to address the quadratic complexity of ViTs (), XCiT[51]introduces cross-covariance attention (XCA), which applies self-attention across feature channels. This reduces the computational cost for high-resolution images while maintaining performance for WSC tasks common in bioinformatics.

Two different common computer vision architectures are used as feature extractors. This will provide an unbiased baseline approach to achieve WSC more traditionally. The ResNet[52]was chosen because it is commonly used as a feature extractor in both academia and industry services because its residual connections allow it to be deep while being computationally affordable.[33]achieved WSC of cancer cells by implementing their version of ResNet calledxResNet. In this study, we implement ResNet50 and ResNet101 as competing backbones. Likewise, normal convolutional neural network backbones were also implemented, called CNN base, CNN medium, and CNN deep, each with different depths. These architectures are used to contrast the ResNet as computationally cheap architectures to achieve WSC.

SECTION: IVExperiments

SECTION: IV-AImplementation details

The experimental framework was developed in Python 3.10, using the PyTorch library for model implementation and training, which supports CUDA GPU computation. The models are implemented from scratch in the case of the ResNets, and from thevit-pytorch111Lucidrainsvit-pytorch Github page in the case of the ViT backbones:https://github.com/lucidrains/vit-pytorchlibrary was used, which faithfully implements the selected vision transformers and adapts them for WSC. The datasets go through a preprocessing stage of transformations for input normalization by the torchvision library: They are transformed into tensors, resized to a size ofpixels, normalized according to their corresponding mean and standard deviation characteristics, and finally processed as 32-bit floating point values for computational ease. Then, depending on the type of architecture, the images are tokenized (for transformers) at different patch sizes, depending on the configuration described in each architecture’s respective paper:for implementations of TransCrowd, XCiT, Parallel ViT, or DeepViT, andfor ViT. CrossViT uses both patch sizes since it works at multi-granularity. In ResNets, the images are entered as a whole. The architectural implementation of each type of model is defined by the hyperparameter configuration in its own paper. The tableIsummarizes the architectural properties of each chosen model variant.