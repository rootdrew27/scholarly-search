SECTION: Multiclass Post-Earthquake Building Assessment Integrating Optical and SAR Satellite Imagery, Ground Motion, and Soil Data with Transformers

Timely and accurate assessments of building damage are crucial for effective response and recovery in the aftermath of earthquakes. Conventional preliminary damage assessments (PDA) often rely on manual door-to-door inspections, which are not only time-consuming but also pose significant safety risks. To safely expedite the PDA process, researchers have studied the applicability of satellite imagery processed with heuristic and machine learning approaches. These approaches output binary or, more recently, multiclass damage states at the scale of a block or a single building. However, the current performance of such approaches limits practical applicability. To address this limitation, we introduce a metadata-enriched, transformer-based framework that combines high-resolution post-earthquake satellite imagery with building-specific metadata relevant to the seismic performance of the structure. Our model achieves state-of-the-art performance in multiclass post-earthquake damage identification for buildings from the Mw 7.8 Turkey-Syria earthquake on February 6, 2023. Specifically, we demonstrate that incorporating metadata, such as seismic intensity indicators, soil properties, and synthetic aperture radar (SAR) damage proxy maps not only enhances the model’s accuracy and ability to distinguish between damage classes, but also improves its generalizability across various regions. Furthermore, we conducted a detailed, class-wise analysis of feature importance to understand the model’s decision-making across different levels of building damage. This analysis reveals how individual metadata features uniquely contribute to predictions for each damage class. By leveraging both satellite imagery and metadata, our proposed framework enables faster and more accurate damage assessments for precise, multiclass, building-level evaluations that can improve disaster response and accelerate recovery efforts for affected communities.

SECTION: 1Introduction

In the aftermath of an earthquake, conducting a Preliminary Damage Assessment (PDA) is typically the first step in evaluating the extent of damage and determining the need for governmental assistance[1]. The PDA process typically begins at the local level, where initial damage data is collected by local authorities through door-to-door inspections[2]to determine the magnitude of damage, the impact of the disaster, and identify the worst-hit regions. These inspections can be unsafe due to falling hazards and other safety concerns due to loss of structural integrity or the risk of aftershocks. Additionally, delays from the large number of structures to be assessed can also significantly hinder the speed of governmental aid deployment, exacerbating the recovery period for affected communities. In 2017, following the Mexico City earthquake, the Civil Engineering Association of Mexico took approximately three weeks to complete evaluations across the entire city, which delayed recovery efforts and left thousands of people without access to their homes[3,4]. Similarly, in 2023, the Turkey–Syria earthquakes affected 15 million people, with the preliminary damage assessments taking more than one month to complete.[5,6,7,8,9]. These cases underscore a critical need for alternative methods that can accelerate the PDA process for quicker and more effective response effort.

The time-consuming part of the PDA process is the door-to-door building damage assessment. To help speed up access to information for decision making, researchers have proposed frameworks to automate the post-earthquake damage assessment process for the identification of the damage state at the individual building level[10,11,12]. We discuss these frameworks by adopting a categorization based on two criteria: (i) data type, including images from unmanned aerial vehicles (UAVs) and satellites and (ii) data processing methods, either heuristic-based approaches relying on predefined rules or data-driven approaches, such as machine learning (ML) and deep learning (DL) techniques, which learn patterns and make predictions based on past data.

Researchers have employed various data sources for post-earthquake damage assessment, including aerial imagery obtained from UAVs[13,14,15], synthetic aperture radar (SAR) satellite data[16,17,18,19,20,21], and optical satellite imagery[22,23,24,25,26,27]. Data collection with UAVs can result in high-resolution and actionable imagery as demonstrated in[14,15]. However, scaling UAV data collection to large areas can be time consuming and challenging due to restrictions on flying beyond visual line of sight (BVLOS) and limited battery life. For earthquakes that affect large areas, satellite imagery can be very valuable due to its wide coverage, time efficiency, and on-demand availability. In a paper by Rao et al. the authors attempted multiclass and binary damage classification for four recent earthquakes using SAR imagery. For three out of the four earthquakes studied, the trained model achieved close to 50% accuracy in detecting damaged buildings using binary classification[19]. Similarly, Ahmadi et al. proposed a two-stage, dual-branch UNet architecture with shared weights between the two branches using optical data[22]. However, the paper highlights the problem of low accuracy for intermediate classes in multiclass classification. Macchiarulo et al. utilized post-earthquake SAR imagery with a method that involved combining textural features from the imagery. The output was a map that classifies damage into five damage states at the level of city blocks, each consisting of an average of 48 buildings. However, this approach is not suitable for building-level damage assessment[17,28]. A common limitation in these papers is the challenge of multiclass building-level damage assessment, primarily because nadir images make it difficult to differentiate between intermediate damage classes in earthquake-affected buildings. Additionally, the resolution of SAR imagery is often insufficient for precise building-level predictions.

On the basis of data processing methods, frameworks can be categorized into heuristic-based[29,30,31,32]and data-driven approaches[22,18,25,15,33,34,23,35,36]. Heuristic-based methods, such as the normalized difference built-up index (NDBI) derived from optical satellite imagery, utilize electromagnetic radiation to detect surface changes in objects like vegetation and building[37]. While NDBI effectively highlights impervious surfaces such as buildings, it is susceptible to cloud occlusion. In contrast, SAR-derived indices like the amplitude dispersion index (ADI)[38]and damage proxy maps (DPMs)[30]are not affected by environmental factors[39]. DPMs derived from bi-temporal SAR imagery, are frequently used for rapid post-earthquake damage assessment. However, due to low resolution, DPMs are less effective at the building level, as seen in the weak correlation with building damage during the 2015 Nepal earthquake[32,30].
Furthermore, damage maps produced using different satellite-based remote sensing techniques often show significant discrepancies, and extensive validation data are still required to accurately characterize the performance of these methods at both high and medium resolutions[12].

Data-driven methods[22,18,25,15], which include machine learning (e.g., support vector machines (SVM), Random Forest (RF), etc.) and deep learning approaches (e.g., U-net, ResNet, etc.), are increasingly being applied for post-earthquake assessments. ML models are generally trained on tabular data. Rao et al. proposed a ML framework that utilizes earthquake-related indices, such as peak ground acceleration (PGA), and DPMs[19]for building-level damage assessment. Similarly, Yu et al. further combined NDBI and ADI with DPMs and PGA to train a random forest model for PDA[37]. The result shows ML methods outperform the traditional practice of relying solely on DPMs. However, the results are still limited to binary classification and do not perform well in multiclass classification scenarios. On the other hand, the training of deep learning approaches often require large amounts of high-resolution optical imagery. Recent studies[22,40]have proposed convolutional neural network-based two-staged models for localization and classification. The results clearly demonstrate that deep neural network architectures outperform SVM and Random Forest in binary building damage classification. However, low accuracy in multiclass classification remains a challenge. One major reason for the low accuracy in multiclass classification is the imbalanced dataset. For instance, in the largest disaster dataset, xBD[41], which categorizes building damage into four levels, only 3 out of 51,500 buildings are classified as completely destroyed, highlighting the severe class imbalance.

These studies highlight that each data type and methodology offers unique insights, along with certain limitations. For instance, earthquake-related indices derived from SAR provide valuable insights into structural changes, PGA offers local estimates of seismic intensity of the event, and optical imagery offers detailed visual information. However, the current state-of-the-art methods don’t fully utilize all of these sources and primarily rely on satellite imagery. As a result, they fall short of achieving the required accuracy for practical use, particularly in multiclass classification scenarios. Additionally, Singh et al. demonstrated a significant improvement in post-hurricane building assessments using transformer vs CNN models, motivating the study of these methods for earthquakes[42,43]. This underscores the importance of carefully integrating these different approaches to develop a more effective post-disaster assessment (PDA) framework.

This study proposes a novel PDA framework for earthquakes (Figure1) integrating high-resolution post-earthquake satellite imagery with publicly available metadata with a novel transformer-based network. Metadata includes geographical attributes, disaster intensity variables, and soil properties. The novel contributions of our research include (i) the development of an earthquake-specific multiclass dataset at the building level with corresponding metadata, (ii) a new deep learning approach termed QuakeMetaFormer, a transformer-based model that integrates metadata with optical imagery for post-earthquake PDA, and (iii) a class-wise comparative analysis of the impact of different metadata on damage assessment. This paper is organized as follows.Section 2provides a detailed discussion of the proposed framework, including the processes of data collection and processing, and the architecture of QuakeMetaFormer.Section 3describes four experiments conducted to test our hypotheses: (i) the impact of adding metadata on model accuracy, (ii) comparison of QuakeMetaFormer and previously published machine learning frameworks, (iii) feature importance across various metadata and (iv) testing generalization capability of QuakeMetaFormer across regions.Section 4presents and analyzes the results from these experiments. Finally,Section 5concludes the paper by summarizing the key findings and their implications.

SECTION: 2Proposed Framework

The framework outlined in Figure1consists of three main steps. First, high-resolution satellite imagery and its corresponding metadata are collected for the earthquake-affected region, ensuring that the metadata overlaps with the geographic area covered by the satellite imagery. Next, this raw data is processed to extract building-level information, with building footprints sourced from OpenStreetMap. Finally, a novel multi-input transformer model termed QuakeMetaFormer is proposed, trained, and validated to process the extracted building-level imagery and metadata and produce a multiclass damage state. We now discuss the methodology behind these steps in more detail.

SECTION: 2.1Dataset Collection

To evaluate our proposed framework, we curate a novel dataset from buildings affected by the Turkey-Syria earthquake of February 6, 2023, where a magnitude 7.8 quake was centered near Kahramanmaraş in southern Turkey, as shown in Figure2(a). Strong aftershocks, including those of magnitudes 7.5 and 7.6[44], further contributed to the widespread destruction, causing additional damage. The earthquake damaged more than 200,000 buildings and led to the collapse of approximately 20,000 structures.[5,7]. We now discuss details involved in the extraction of satellite imagery and corresponding metadata.

The satellite imagery used in this study were obtained through MAXAR Technologies’ open data program[45], which provides before and after satellite images during disasters. These images are geotagged and have a resolution of 30 cm ground sample distance (GSD)[46]. In this study, we exclusively used post-earthquake imagery and filtered the images based on the areas affected by the earthquake. To extract building-level images, corresponding building footprints from OpenStreetMap (OSM) were utilized[47]. OSM is a free and open-source geographic database, that is continuously updated and maintained by a global community. Figure2illustrates a sample from the dataset for the city Kahramanmaraş, highlighting the satellite imagery and corresponding building footprints. The final output for each building is a cropped section of the satellite imagery, containing three-channel (RGB) pixel-level data within the boundaries of the building footprint.

The different sources utilized to collect the relevant metadata for this study are shown in Figure3. We define metadata as data consisting of single-valued real numbers extracted using the centroid coordinates of the corresponding buildings. The metadata can be categorized into three groups: (i) seismic intensity indicators, (ii) SAR-derived parameters, and (iii) soil properties.

Seismic intensity indicators include the Modified Mercalli Intensity (MI or MMI), Peak Ground Acceleration (PGA), Peak Ground Velocity (PGV) and Pseudo-Spectral Acceleration (PSA) at intervals of 0.3 s, 1.0 s, and 3.0 s. MI assesses earthquake impact by considering its effects on people, structures, and the landscape, with values ranging from 1 to 10, where higher numbers indicate more intense shaking and damage. PGA is a quantitative measure of the maximum ground acceleration during an earthquake, particularly relevant for short buildings (up to seven stories)[48]. PGV is an indicator of hazard for taller buildings[48]. PSA accounts for the hazard to buildings but is more closely aligned with how buildings respond to seismic forces at different frequencies, compared to peak ground motion parameters. These indices offer meaningful insights into earthquake severity and were obtained through the USGS website[49]. Additionally, the final condition of a structure can result not only from the primary earthquake but also from subsequent aftershocks. To account for the impact of aftershocks, we have included the top five earthquakes by magnitude in our metadata for all seismic intensity indicators.

SAR-derived parameters include geocoded single look complex (SLC) amplitude data and DPMs. Geocoded SLC amplitudes data provides information about back-scattered amplitude of the Earth’s surface in the microwave wavelength. In this study, we used VV (vertical transmit, vertical receive) and VH (vertical transmit, horizontal receive) polarization values derived from Sentinel-1 ground range detected (GRD) data. These polarizations reveal details about surface orientation and scattering properties. DPMs serve as indicators of surface changes, and are derived by detecting changes in coherence between pre- and post earthquake images. SAR data was accessed through the Alaska Satellite Facility (ASF) via NASA’s Earthdata Search API[50], while DPMs were extracted from the Jet Propulsion Laboratory’s data repository[51].

To account for soil properties, we incorporate the average shear-wave velocity to a depth of 30 meters, known as VS30[52]. VS30 is widely used as a parameter to characterize site response in simplified earthquake-resistant design. VS30 maps were downloaded from the USGS website[53].

SECTION: 2.2Data Pre-Processing

An important step after collecting the imagery and the metadata, is to accurately map the ground truth of damage state of the building with the satellite imagery and it’s corresponding metadata. The ground truth damage state for the buildings was acquired from the Turkish Ministry of Environment, Urbanization and Climate Change[54]. The damage severity in the dataset were classified into 4 damage classes, numbered 1-4, Slightly Damaged, Heavily Damaged, Needs to be demolished, and Collapsed. Mapping the ground truth with the dataset was done in two steps: mapping the ground truth to the building footprint, and then retrieving its corresponding meta data. In the first step, the nearest building footprint for each ground truth damage location (latitude, longitude) was identified by calculating spatial distances using an R-tree index[55]. Then, the data was filtered based on whether each ground truth damage location fell within its corresponding building footprint to ensure accurate mapping. In the second step, metadata was associated with the mapped building footprints by using the geometric centroid of each footprint as a query point. For contour shapefile data, such as seismic intensity indicators, interpolation was employed to estimate values at the query point. SAR-derived parameters and soil properties were extracted from raster GeoTIFF files. The raster data, originally in a global coordinate system measured in degrees (EPSG:4326), was reprojected into a local coordinate system measured in meters (EPSG:32637) to ensure precise alignment with the ground truth damage locations. This approach ensured that each building point was accurately associated with the relevant metadata.

In addition to our primary dataset, we utilized another dataset developed by Xiao Y et al[37]to train the model and ensure a fair comparison with other methods. We extracted the satellite imagery for this dataset following the methodology described above and mapped it to the corresponding metadata. This dataset includes five metadata features: damage proxy (DP) derived from Sentinel-1 and ALOS-2 PALSAR-2, ADI, NDBI, and PGA. The dataset has 5 damage classes numbered 0-4, No damage, Slightly Damaged, Heavily Damaged, Needs to be demolished, and Collapsed. The details of both datasets are summarized in the table1.

SECTION: 2.3QuakeMetaFormer

Levaraging the MetaFormer architecture proposed by Diao et al. 2022[56], illustrated in Figure4, QuakeMetaFormer is a multi-input model that takes both image data and metadata as inputs optimized for post-earthquake PDA by accounting for extreme class imbalance. MetaFormer employs a hybrid approach where convolution is utilized to encode visual data, while transformer layers focus on combining this visual information with metadata, which is encoded using a non-linear embedding. The initial three stages of MetaFormer primarily utilize MBConv blocks, followed by the adoption of Relative Transformer blocks in the final two stages. To optimize computational efficiency, overlapping patch embedding is implemented for tokenizing the feature map and performing downsampling. The model configuration utilizes key hyperparameters listed in Table2. The hyperparameters from the original MetaFormer paper were directly adopted from[56].

QuakeMetaFormer modifies MetaFormer to handle the class-imbalanced nature of datasets typically available for post-earthquake damage classification where examples of severe damage are naturally fewer compared to buildings with little or no damage. Specifically, we implement a modified focal loss that incorporates the class weights into the focal loss introduced by Lin et al.[57]. Class weights are scaling factors to give more importance to underrepresented classes, calculated using the inverse frequency of each class in the dataset. The modified focal loss is defined as:

whererepresents the class weight for the true class,is the predicted probability of the true class,is the focusing parameter, anddenotes the cross-entropy loss. We found that a gamma value of 4 worked best for our dataset, effectively focusing on hard-to-classify samples.

In addition to the QuakeMetaFormer model, we also employ a variant that only takes imagery as input and excludes the non-linear embedding segment for metadata. This variant, referred to as the QuakeImageFormer in this study, serves as a baseline for evaluating the impact of adding metadata, while keeping the rest of the model architecture the same for a fair comparison.

SECTION: 3Experiments

In this section, we evaluate the performance of the proposed PDA framework by conducting four experiments: (i) impact of integrating metadata with satellite imagery on the overall model performance, (ii) comparing the performance of the proposed framework with two previously published state-of-the art machine learning frameworks, (iii) assessing the influence of individual metadata features on damage state prediction, and (iv) evaluating the effect of metadata in improving the trained model’s generalizability to different regions.

SECTION: 3.1Impact of Adding Metadata on Performance: QuakeMetaFormer

Satellite imagery provides essential visual information for damage assessment, while earthquake-related metadata, such as PGA, SAR, VS30, etc., offers unique insights into event intensity and structural changes. However, relying on either data source individually often lacks the detail necessary for distinguishing between intermediate damage classes. The objective of this experiment is to evaluate how incorporating metadata with satellite imagery impacts the performance of the QuakeMetaFormer model.To achieve this, we conducted three experiments: (i) QIF-Turkey-L, where the QuakeImageFormer (QIF) was trained using only satellite imagery to establish baseline performance, (ii) QMF-Turkey-L, where the QuakeMetaFormer (QMF) model was trained using both satellite imagery and all the metadata, including aftershock seismic intensity indicators; and (iii) QMF-Turkey-L1, where the QuakeMetaFormer model was trained using both satellite imagery and metadata, but with the seismic intensity indicators for aftershocks removed, retaining only data from the main event of the largest magnitude. Similarly, two additional experiments, QIF-Turkey-S and QMF-Turkey-S, were conducted on the Turkey-S dataset. Comparing the results from these experiments allows us to understand the impact of adding metadata to satellite imagery in multiclass damage classification. Additionally, to evaluate the impact of metadata on the model’s ability to interpret imagery, we conducted four additional experiments. In these experiments, metadata was incorporated during training but masked during testing, simulating real-world scenarios where high-latency data, such as SAR, may not be readily available. Different models trained are summarized in Table3. In each of our experiments, we utilize 85% of the data for training and reserve 15% for the testing set to evaluate model performance. Each experiment is discussed in detail in the following sections.

SECTION: 3.2Comparison of QuakeMetaFormer and Machine Learning Frameworks

To evaluate the performance of our proposed framework against other state-of-the-art PDA frameworks for earthquake damage assessment, we compared different architectures trained on the same dataset. For this experiment, we trained the QuakeMetaFormer model (QMF-Turkey-S) on the Turkey-S dataset and compared its results with the best-performing machine learning model (random forest) as reported by Xiao et al. on the same dataset[37]. On scanning the literature, we found another paper, Rao et al.[19]that conducted a multiclass classification study for post-earthquake damage evaluation across regions impacted by 2015 Gorkha, 2017 Puebla, 2020 Puerto Rico, and 2020 Zagreb earthquakes. However, the datasets from Rao et al.[19]were not accessible, so we report the average performance of our model across both our datasets and the average performance across all datasets in Rao et al. The experiments are summarized in Table4.

SECTION: 3.3Feature Importance Across Metadata

Various metadata provide different insights related to earthquake damage assessment. To assess the contribution of individual metadata features, we conducted a detailed analysis using SHapley Additive exPlanations (SHAP)[58]. SHAP provides a robust method for understanding the output of machine learning models by perturbing each feature and measuring the resulting changes in prediction probabilities. These changes are then used to assign an importance score based on the feature’s contribution to the predictions. For this experiment, we applied SHAP to the QMF-Turkey-L1 model to evaluate the influence of various metadata inputs on damage state prediction. This analysis helps in understanding the impact of different earthquake-related indices on model performance. We also performed a class-wise analysis of metadata features to better understand the impact on different classes.

SECTION: 3.4Generalization Across Regions

To evaluate the generalization capability of the QuakeMetaFormer model, we divided the Turkey-L dataset into four major regions: Kahramanmaraş, Adıyaman, Osmaniye, and Malatya. The locations of the training and testing regions are illustrated in Figure5. For this experiment, we trained two separate models on the Kahramanmaraş region (i) QuakeMetaFormer with metadata and imagery, and (ii) QuakeImageFormer with imagery only. These two trained models were then tested on the remaining three regions (see Table5). This approach allows us to assess not only how well a model trained in one region generalizes to others, but also to determine whether adding metadata enhances generalization. This experiment will enable us to evaluate the model’s effectiveness in real earthquake scenarios, highlighting its potential for practical applications.

SECTION: 3.5Classification Metrics

To evaluate the experimental results, we employed five standard classification metrics, including accuracy, precision, recall, F1 score, and the average area under the receiver operating characteristic (AUC-ROC) curve. Accuracy is the overall correctness of the model, calculated as the ratio of correctly predicted instances to the total number of instances. Precision measures the model’s ability to minimize false positives by calculating the proportion of correctly predicted positive instances, averaged across all classes to ensure balanced consideration. Similarly, recall assesses the model’s effectiveness in identifying true positives by averaging recall values across classes. The F1 score, combines precision and recall, serves as a balanced metric for accuracy, particularly in datasets with imbalanced class distribution. The AUC-ROC curve, widely used as a performance evaluation metric in classification models, particularly in fields like remote sensing and natural hazard monitoring, provides a comprehensive assessment of a classifier’s ability to distinguish between classes[59,60,37,61]. The AUC-ROC curve offers a comprehensive view of the classifier’s ability to distinguish between positive and negative instances by plotting the true positive rate (TPR) against the false positive rate (FPR). A higher AUC-ROC score indicates better ability to separate positive and negative instances.[59,60,37]. Table6summarizes the metrics and their formulas.

SECTION: 4Results and Discussion

This section provides a detailed analysis of the four experiments discussed in the previous section, highlighting the performance outcomes and insights derived from each.

SECTION: 4.1Impact of Adding Metadata on Performance: QuakeMetaFormer

The objective of this experiment is to assess the impact of integrating metadata with satellite imagery in improving the performance of PDA framework. The results, as shown in the Table7, demonstrate that incorporating metadata enhances model performance across all metrics.

QMF-Turkey-S achieved 77% accuracy compared to 71% for the QIF-Turkey-S model, while for the Turkey-L dataset, accuracy increased from 70% to 77%. In both sets of experiments, adding metadata resulted in a 7% accuracy improvement. Beyond accuracy, AUC-ROC and F1-score offer a clearer evaluation of model performance, especially in imbalanced datasets where some damage classes are underrepresented. For instance, the QMF-Turkey-S model achieved an AUC-ROC of 0.85, compared to 0.79 for the QIF-Turkey-S model, and an F1-score of 0.54, compared to 0.51 for QIF-Turkey-S. These improvements indicate that incorporating metadata significantly enhances the model’s ability to differentiate between multiple damage classes, providing a more reliable performance across all damage categories. The AUC-ROC learning curve (see Figure6) for Turkey-L dataset shows the consistent improvement in performance for the models trained with metadata and without metadata for 150 epochs. QuakeMetaFormer reaches a 6% higher AUC-ROC than the QIF model, underscoring the importance of metadata in enhancing the model’s capacity for classifying damage more accurately. Another important observation is that adding metadata improves precision by 9% in the case of Turkey-L and 5% in the case of Turkey-S, demonstrating that incorporating metadata helps the model reduce false positives. This means the model becomes more reliable in correctly identifying buildings with actual damage, minimizing the number of undamaged buildings mistakenly classified as damaged. Notably, adding metadata not only improves the accuracy but also enhances the model’s ability to interpret imagery. For instance, QMF-Turkey-L1 achieves an AUC-ROC of 0.81, compared to QMF-Turkey-L1-M’s 0.78, reflecting only a minimal decrease in performance. Similarly, QMF-Turkey-L1-M-DPM, which simulates a scenario where only DPM data is masked during testing, achieves an AUC-ROC of 0.80. The drop in AUC-ROC is minor compared to the case of QIF-Turkey-L1, where no metadata is added during training. This experiment underscores the model’s applicability and robustness in practical scenarios where some or no metadata may be unavailable. This is particularly useful for rapid post-earthquake damage assessment, where high-latency data, such as SAR-derived parameters, may be delayed.

We evaluated the effect of incorporating aftershock metadata (seismic intensity indicators) by comparing QMF-Turkey-L, which includes aftershock data, with QMF-Turkey-L1, which uses only the main earthquake event data. The inclusion of aftershock metadata resulted in a 4% increase in precision, demonstrating its role in reducing false positives. However, other metrics such as AUC-ROC and F1 showed an improvement of 1%. To understand the combined impact of multiple seismic events across different regions, we plotted the Modified Mercalli Intensity (MI) for the top 5 earthquakes and their combined MI. Figure7highlights that in the Turkey-Syria earthquake, the main event impacted the largest area, explaining the limited increase in model effectiveness after incorporating aftershock metadata.

We plotted the evaluation map for the city of Kahramanmaraş using the QMF-Turkey-S model on the test dataset to assess the extent of misclassification (see Figure8). The evaluation map is also useful for identifying the worst-hit regions after an earthquake. The map includes three key components: the true damage class of each building, the predicted damage class, and the absolute difference between the true and predicted values. The misclassification analysis reveals that most buildings are accurately classified, with 76.7% of predictions being correct. Additionally, 17.7% of the predictions were off by ±1 class, and 1.2% by ±2 classes. Larger errors, with a difference of ±3 and ±4 classes, occurred in only 3.6% and 0.8% of cases, respectively. This analysis demonstrates the model’s robustness in predicting building-level damage with very few significant misclassifications.

SECTION: 4.2Comparison of QuakeMetaFormer and Machine Learning Frameworks

We evaluate the effectiveness of our proposed models with state-of-the art models published in the literature. Xiao Y et al.[37]proposed a machine learning approach using a random forest classifier trained on metadata from the Turkey-S dataset. The model achieved an AUC-ROC of 0.69, outperforming DPM based methods by 11.25%. We train our proposed QuakeMetaFormer with the entire Turkey-S dataset including the satellite imagery and the results are shown in Table8. Notably, QuakeMetaFormer achieves an AUC-ROC of 0.85, which is 16% higher than the machine learning approach (RF-Xiao). We also plot the ROC curve to understand the model’s performance across each damage class see Figure9). The QuakeMetaFormer model demonstrated consistent performance across all classes, with a lowest AUC-ROC of 0.79 for class 3 (Needs to be demolished), indicating greater difficulty in distinguishing this class compared to others.

Similarly, Rao et al. demonstrated an ensemble approach using random forest for multiclass building damage classification across multiple datasets and reported an average F1 score of 0.29[19]. In contrast, the QuakeMetaFormer models achieved an average F1 score of 0.51 across Turkey-S and Turkey-L dataset, demonstrating a significant improvement in multiclass classification. This comparison highlights that the QuakeMetaFormer architecture not only enhances overall model performance but also provides more balanced results across all damage classes, making it more reliable for building-level damage assessment.

SECTION: 4.3Feature Importance Across Metadata

Using SHAP, we quantify the contribution of each metadata feature and satellite imagery to the model’s predictions. Figure10illustrates the impact of all input features, including imagery, on the model’s performance across four damage classes: Slightly Damaged, Heavily Damaged, Needs to be Demolished, and Collapsed. In the bar plot, higher values indicate features with a stronger influence on the model’s predictive accuracy. As anticipated, satellite imagery demonstrates the highest contribution, as its detailed representation of visible building damage plays a crucial role in decision-making, far outweighing the influence of metadata.

Among metadata features, seismic intensity indicators such as PGV, PGA, and PSA show a substantial impact on predictions across all damage classes, highlighting their strong correlation with building damage. Notably, PSA values measured at 0.3 s, 1.0 s, and 3.0 s reveal that PSA at 1.0 s provides the most relevant information. This aligns with the natural frequency of many structures in the dataset, making it particularly relevant to structural response under seismic conditions.

SAR-derived parameters exert a smaller influence on predictions. Within the group, the damage proxy is more informative than SLC amplitude SAR data data, likely due to bitemporal data providing more insights into structural changes before and after the earthquake. Comparing SLC amplitude SAR data data, the results suggest that VH polarization contributes more to decision-making than VV polarization, indicating VH’s higher sensitivity to structural changes in buildings. VS30, which represents shear wave velocity, contributes little to the model; this may be due to its limited spatial variability at the building level, which reduces its effectiveness for multiclass damage classification. The limited contribution of SAR-derived parameters and VS30, compared to other features, may result from the low spatial resolution of these data sources, which fails to capture building-level changes necessary for accurate damage prediction.

To understand the influence of metadata on each damage classes, we generated class-wise SHAP summary plots for all categories. Figure11consists of four subplots representing damage classes 1 through 4, highlighting the contributions of various features to the model’s predictions for each class. The X-axis displays feature importance, showing how each feature influences the prediction, with values ranging from negative to positive. Positive values indicate that a feature supports the prediction towards the target class, while negative values suggest the feature pushes the prediction away from the specific class. Notably, negative values do not indicate that the feature negatively impacts the model’s performance. Instead, they reflect whether the feature contributes to selecting the specific class or steers the prediction away from it. The Y-axis ranks metadata features by importance in descending order. The color gradient from blue to red represents each feature’s value (low to high) within the test dataset, showing how high or low values of a feature affect the prediction. Each feature appear as a violin plot, showing the distribution of data points for that feature.

The SHAP summary plots reveal several key insights about feature contributions to damage class predictions. The contribution patterns are more distinct in the extreme damage classes, Slightly Damaged and Collapsed. For the top five features, low feature values support predictions toward the Slightly Damaged class. However, in the Collapsed damage class, these low feature values yield negative feature importance values, suggesting that they push predictions away from the class. Similarly, for metadata feature MI, high values (indicated in red) drive the model’s prediction toward the Collapsed class and away from the Slightly Damaged class. This trend is also observed for the intermediate classes, Heavily Damaged and Needs to be Demolished, indicating that QuakeMetaFormer associates higher feature values with more severe damage (Classes 3 and 4) and lower values with less severe damage (Classes 1 and 2), thereby reducing misclassification by narrowing the gap between true and predicted classes. SAR-derived parameters (except DPM) and soil properties show minimal influence on predictions for both classes compared to other metadata features. Additionally, there are instances where high and low feature values intermingle and deviate from general trends, reflecting the complex relationships between features and damage class predictions. This complexity is particularly evident in intermediate classes. Overall, the plots illustrate how the QuakeMetaFormer model leverages metadata in its decision-making process, providing a detailed view of feature impacts on classification.

SECTION: 4.4Generalization Across Regions

Figure12summarizes the results of our experiments, aimed at evaluating the model’s ability to generalize across regions. The findings indicate that the model trained with both metadata and imagery (QMF) consistently achieved high AUC-ROC and F1 scores, demonstrating strong generalization to unseen regions. For instance, the QMF model trained on Kahramanmaraş region and tested on Adıyaman region, achieved an AUC-ROC of 0.79 and an F1 score of 0.45, while achieving 0.81 and 0.47, respectively, when both training and testing were conducted in Kahramanmaraş. This trend continues in Osmaniye and Malatya, where the QMF model demonstrates a stronger ability to generalize to unseen regions. We observe that testing the QMF model on unseen regions resulted in an average reduction of only 0.026 in AUC-ROC and 0.04 in F1 score, highlighting the model’s strong generalization ability across different regions while maintaining performance.

We also trained the model without metadata (QIF) to assess the impact of adding metadata on generalization. As shown in Figure12, the QIF model experienced a significantly larger drop in performance across unseen regions, with an average reduction of 0.12 in AUC-ROC and 0.08 in F1 score, compared to QMF model (with metadata). The results show an average improvement of 15.8% in AUC-ROC and 22.8% in F1 score when metadata is included. This substantial difference highlights the positive contribution of metadata to the model’s generalization ability, making it more robust and adaptable for practical applications.

SECTION: 5Conclusion

In this study, we proposed a novel framework for post-earthquake preliminary damage assessment (PDA), achieving state-of-the-art performance for the 5-class damage classification task. This problem has received limited attention in the literature to-date because of the very challenging nature of making multiclass assessments after earthquakes. Our framework achieved an AUC-ROC of 0.85, surpassing the previous leading PDA framework by 16%. Notably, the performance was consistent across all damage classes, with a minimum AUC-ROC of 0.79 for damage class 3 (Buildings that need to be demolished), and maximum AUC-ROC of 0.91 for damage class 2 (Buildings heavily damaged). We achieved this through our proposed framework, QuakeMetaFormer (QMF), which integrates high-resolution post-earthquake satellite imagery with metadata, including ground motion, SAR, and soil data. Our key contributions include (i) the development of an earthquake-specific multiclass dataset at the building level, mapped with metadata, (ii) QuakeMetaFormer, and (iii) a class-wise detailed comparative analysis of the impact of various metadata features on building-level damage assessment. To evaluate the framework, we conducted four experiments: analyzing the impact of metadata on model accuracy, comparing QuakeMetaFormer with other machine learning frameworks, assessing feature importance across metadata, and testing QuakeMetaFormer’s generalization across regions. Our results show that adding metadata to satellite imagery enhances accuracy, yielding a 7% improvement over the transformer model trained without metadata. Additionally, the model achieves an AUC-ROC of 0.8 even without high-latency metadata like SAR, demonstrating its robustness in scenarios with limited or no metadata. Compared to other ML-based methods, QuakeMetaFormer demonstrated superior performance in multiclass damage assessment, achieving an average F1-score of 0.51, significantly higher than the 0.29 achieved by competing approaches. We also conducted a detailed analysis to evaluate and understand the influence of individual metadata features on the model’s predictive performance, utilizing SHapley Additive exPlanations (SHAP). This analysis revealed that seismic indicators such as PGV, PGA, and SAR-derived parameters like DPM have a substantial impact across damage classes as compared to other parameters. We further examined how various metadata features influence model predictions at the class level, providing valuable insights into QuakeMetaFormer’s decision-making processes and its association of feature values with the extent of building damage. Lastly, incorporating metadata significantly enhanced the model’s generalization capability, improving performance when applied to new regions. The results demonstrated that adding metadata improved AUC-ROC by an average of 15.8% and F1 score by 22.8%. These improvements underscore the significant potential of our framework to accelerate disaster recovery efforts, including prioritizing inspection regions, streamlining the federal aid process, and estimating recovery costs.

SECTION: 6Funding

This work was performed at the University of Houston under a contract with the Commercial Smallsat Data Scientific Analysis Program of NASA (NNH22ZDA001N-CSDSA) and the NASA Decadal Survey Incubation Program: Science and Technology (NNH21ZDA001N-DSI).

SECTION: 7Acknowledgments

The research was carried out at the University of Houston, under a contract with the National Aeronautics and Space Administration. The authors also acknowledge the use of the Carya Cluster and the advanced support from the Research Computing Data Core at the University of Houston to carry out the research presented here.

SECTION: References