SECTION: Sliced-Wasserstein-based Anomaly Detection and Open Dataset for Localized Critical Peak Rebates

In this work, we present a new unsupervised anomaly (outlier) detection (AD) method using the sliced-Wasserstein metric. This filtering technique is conceptually interesting for MLOps pipelines deploying machine learning models in critical sectors, e.g., energy, as it offers a conservative data selection. Additionally, we open the first dataset showcasing localized critical peak rebate demand response in a northern climate. We demonstrate the capabilities of our method on synthetic datasets as well as standard AD datasets and use it in the making of a first benchmark for our open-source localized critical peak rebate dataset.

SECTION: 1Introduction

Québec, Canada, stands as an outlier in the electrical grid decarbonization paradigm. As there is a global tendency to invest in intermittent renewable energy sources to decarbonize grids worldwide, Québec, while not totally stranger to this trend, is generally mostly carbon-free thanks to its impressive hydroelectric power capacity. One of its main challenges comes from its northern climate, its reliance on electric baseboard heating systems for residential heating, and its unrestrictive home insulation policies[1]. During glacial winter days, as electric heaters are all running at once, and peak consumption hours hit, Québec’s hydropower capacity can be reached[2]. To accommodate winter peak power needs, Hydro-Québec, the state-owned company in charge of electric power generation, transmission, and distribution, must operate its only on-grid thermal power plant and import electricity from neighbouring provinces and states. These imports are usually expensive and produce much more greenhouse gas emissions in comparison to local energy sources[3].

To remediate this issue without solely relying on the deployment of new generation and transmission infrastructures, demand response (DR) initiatives have flourished in the province[4]. Demand response can be defined as changes in normal electrical power consumption patterns by end-use customers in response to a signal, e.g., financial incentives or control setpoints[5]. With Québec’s long tradition of fixed electricity rates, one of its main DR mechanisms is critical peak rebates (CPR). Residential customers enrolled in a CPR program receive financial compensation during pre-specified time periods, referred to as challenges, for reducing their energy consumption with respect to their expected baseload[6]. CPR programs are purely voluntary and virtually penalty-free. They thus depend on consumers’ goodwill, motivation, and sensitivity. Yet, as we have seen in our work, CPR events can be powerful tools for shifting power consumption before and after each event.

We work with a variation of CPR, viz., localized CPR (LCPR), in which the events are called for localized relief in the grid instead of being cast for the whole system. LCPR can diversify the types of services offered by typical CPR programs, e.g., they can alleviate stress on local equipment like substation transformers[7]or they can be paired with generation forecasts of distributed energy resources (DERs), e.g., roof solar panels and private windfarms, to balance demand and generation during peak hours. LCPR is highly underexplored in the literature and is a valuable application to benchmark trustworthy machine learning (ML) models. Indeed, the higher spatial granularity, the critical aspect of the task, the dependence on behavioural tendencies, and the lower margin for error require the deployment of forecasting models that offer performance guarantees[8], robustness to noise[9], interpretability[10], physical constraints satisfaction[11], a sense of prediction confidence[12,13], or a combination of them[14]. Being able to predict and utilize localized peak-shaving potential in the electrical grid, through programs similar to LCPR, could accelerate the integration of DERs and, specifically for Québec, phase out its dependence on fossil energy-based imports. To the best of our knowledge, no published open-source datasets are showcasing either LCPR or CPR schemes, in a northern climate.

As with most smart grid applications, dataset quality can highly influence the performance of ML models when used for training. The adversarial properties stemming from the amalgam of numerical errors, noise in sensor readings, telemetry issues, meter outages, and unusual extreme events can disrupt the prediction quality of ML models. Anomaly detection (AD) and outlier filtering are thus primordial in a reliable ML pipeline[15]. Unsupervised AD methods are preferable as they do not need human-made labels and their hyperparameters can be tuned simultaneously with other ML models’ included in the loop. Popular unsupervised AD methods[16]include local outlier factor (LOF)[17], isolation forest[18], k-nearest neighbours (KNN)[19], connectivity-based outlier factor[20], and one-class support vector machine (SVM)[21]. These methods either use clustering or local density to assign an outlier score. We are interested in optimal transport-based (OT) metrics for AD. Reference[22]proposed a Wasserstein generative adversarial network for AD tasks and authors from[23]have designed a differentiable training loss function using the Wasserstein metric for deep classifiers. To the best of our knowledge, no unsupervised OT method has been proposed yet for AD.

In this work, we address the lack of open-source datasets showcasing CPR demand response mechanisms in northern climates by releasing two years of aggregated consumption data for customers participating in an LCPR program in Montréal, Québec, Canada111Available athttps://github.com/jupall/lcpr-data, as well as,https://donnees.hydroquebec.com/explore/dataset/consommation-clients-evenements-pointe. These customers are spread in three adjacent distribution substations. With it, we hope to stimulate research on trustworthy ML models for demand response applications. We also address the challenges of training ML models with unfiltered smart grid data by proposing a new simple unsupervised outlier filter leveraging the Sliced-Wasserstein distance[24]. We showcase the performance of this filter on standard anomaly detection datasets and leverage it to present a benchmark for the prediction of the localized energy consumption of LCPR participants on our open-source dataset.

SECTION: 2Localized critical peak rebates in Québec

Québec’s CPR and LCPR programs have been carried out under the banner of Hilo, a division of Hydro-Québec in charge of DR aggregation. Hilo, calls a DRchallengea day ahead of the event, and users choose their degree of participation for the next day. Hilo subscribers are equipped with smart thermostats and their respective heating setpoints are controlled by Hilo, according to an agreed-upon strategy, throughout the event. With the Hilo mobile application and different connected objects, customers can program the response of their house to differentscenes. For example, they can choose the heating setpoint of each thermostat when there is a DR event, or when nobody is home. When notified, smart thermostats to augment user comfort during events which typically last 4 hours: either between 6 AM and 10 AM or 5 PM and 9 PM. A maximum of 30 CPR events can be called per year. LCPR is an additional program currently under testing. Testers can be asked for up to 10 extra LCPR events. Rewards are proportional to the total amount of energy shaved during the event, i.e., heating-related curtailment and others, with respect to their estimated baselines[25].

SECTION: 3Open dataset

The dataset we share contains the aggregated hourly consumption of 197 anonymous LCPR testers located in three substations. Additional hourly weather data and LCPR information are also present. Table1details the features and the label. Note that we also provide cyclical encoding of temporal features, e.g., month, day of the week, and hour. We remark that outliers and anomalies are present in the dataset because of metering and telemetry issues or even blackouts, e.g., an aberrant (and impossible) 32.2 MWh energy consumption is registered at some point.

colspec=m5cm|m5cm|c,hline1,25 = 1.5pt, hline2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24=1ptName&DescriptionPossible valuessubstationSubstation identifier  {'A', 'B', 'C'}timestamp_localTimestamp in local time (UTC-5) and ISO 8601 format [AAAA-MM-DD hh:mm:ss]connected_clientsNumber of clients connected to the substation during the considered hourconnected_smart_tstatsNumber of smart thermostats connected to the substation during the considered houraverage_inside_temperatureHourly average indoor temperature measured by smart thermostats in substation [∘C]average_temperature_setpointHourly average setpoint of smart thermostats in substation [∘C]average_outside_temperatureHourly average outside temperature at substation [∘C]average_solar_radianceHourly average solar radiance at substation [W/m2]average_relative_humidityHourly average relative humidity at substation [%]  [0,100]average_snow_precipitationHourly average amount of snow precipitation at substation [mm]  [0.0,306.0]average_wind_speedHourly average wind speed at substation [m/s]  [0, 15.68 ]dateDate [AAAA-MM-DD] [2022-01-01, 2024-06-30]monthMonthdayDay of the monthday_of_weekDay of the week with Sunday and Saturday being 1 and 7, respectivelyhourHour of the daychallenge_typeType of challenge during the given hour  {'None', 'CPR', 'LCPR'}challenge_flagFlag indicating hours in challengepre_post_challenge_flagFlag indicating hours in pre-challenge or post-challengeis_weekendFlag indicating weekendsis_holidayFlag indicating Québec holidaysweekend_holidayFlag indicating whether a weekend or a holidaytotal_energy_consumedHourly energy consumption of the substation [kWh]

We refer readers to AppendixAfor additional analyses and visualizations of the dataset’s features and labels.

The yearly energy demand in Québec should double by 2050, requiring an additional production of 60 TWh by 2035 and the addition of 8 to 9 GW of peak power to Québec’s 38 GW capacity[26]. Québec’s energy landscape must evolve rapidly to meet the increasing demand and DR is a powerful tool to mitigate infrastructure growth.

Hydro-Québec recognizes the importance of sharing data to foster research, innovation, and informed decision-making. Through its plateform222https://www.hydroquebec.com/documents-data/open-data/, it provides historical and real-time data on energy production and consumption in Québec as well as other datasets, e.g., geolocated hydrometeorological data from its remote weather stations. This new dataset is Hydro-Québec’s first dedicated to DR research.

By supporting data democratization, Hydro-Québec encourages the emergence of a culture of transparency and openness in the energy sector which is needed to accelerate the energy transition. This approach aims to stimulate researchers, citizens, and businesses in their desire to participate in the design of innovative applications for a more sustainable, interoperable, reliable, and safe power grid.

SECTION: 4Sliced-Wasserstein Filter

The Wasserstein distance is a metric that provides a sense of distance between two distributions. Also called earth mover’s distance, it can be conceived as the minimal effort it would take to displace a pile of a weighted resource to shape a specific second pile[27]. The order-Wasserstein distance with respect to some normbetween distributionsandis defined as:

whererepresents all the possible joint distributionsbetweenand,andare the marginals ofand, respectively, andis the set of all possible values ofand[9]. In general, computing the Wasserstein distance is of high computational complexity[28]except for some special cases. For example, the Wasserstein distance for one-dimensional distributions has a closed-form solution that can be efficiently approximated. The sliced-Wasserstein (SW) distance is a metric that makes use of this property by calculating infinitely many linear projections of the high-dimensional distribution onto one-dimensional distributions and then computing the average of the Wasserstein distance between these one-dimensional representations[24,28]. Interestingly, it possesses similar theoretical properties to the original Wasserstein distance while being computationally tractable[29]. The order-SW distance’s approximation under a Monte Carlo scheme is defined as:

whereis a single projection of the Radon transform of distribution functionover a fixed sample. Interested readers are referred to references[24,28]for in-depth mathematical explanations.

We now utilize this approximation of the sliced-Wasserstein distance to formulate a simple outlier filter. Consider an empirical distribution, whereis a Dirac delta function assigning a probability mass of one at each known sample. Consider the notationto denote a variation ofin which we remove sample. As the weight of each sample is identical and because the SW distance compares distributions of equal weights, we propose an outlier filter by using a simple voting system in which we compare the SW distance between the empirical distribution minus the outlier candidate and the empirical distribution minus a random sample. Letanddenote the sets of outlier and inlier samples, respectively, under the perspective of the filter and letbe the available dataset. A vote is positive if the distance between the two empirical distributions exceeds the threshold. A sample is labelled an outlier if the proportion of positive votes is greater than the threshold.

wheredenotes an indicator function,is the number of points used for the vote,is the voting threshold required to label a sample as an outlier, and.

This filter is interesting for several reasons. It is unsupervised, purely analytical, and uses a well-known explainable mathematical distance to filter data points that seem out-of-sample under the SW metric. The intuition is that we remove samples that are costly in the transportation plan when compared to other random samples of the same distribution. We can use the voting percentage to measure the algorithm’s confidence in its labelling. It is also parallelizable, as seen in our implementation provided on our GitHub page333https://github.com/jupall/swfilter. Numerical results and figures are presented in AppendixB.

This method does not scale with large datasets as is: the SW distance computational burden increases as bigger distributions are compared. We propose a smart splitting method to accelerate the procedure, but we remark that the transportation plan between a distribution minus a sample and the same distribution minus another sample can be roughly approximated by the Euclidian distance between the two removed samples. As such, we introduce a fast Euclidian approximation for:

whereis the threshold of the Euclidian distance. This method is not as accurate as the first proposal to filter out-of-sample data points. But, because (SWAD) and (FEAD) use the same principle, they share similar classification patterns whenandare tuned accordingly, as can be seen in Figure7.

SECTION: 5Benchmark

We now propose a first benchmark on our LCPR dataset. Our goal is to predict the aggregated hourly consumption at each substation in winter when peak demand is critical. To follow the literature[30], and propose a simple yet meaningful benchmark, we implement a Gaussian process[31]in a rolling horizon fashion. Samples dating from before 2023-12-15 are used for hyperparameter tuning while those between 2023-12-15 and 2024-04-15, during the most recent winter DR season, are used for testing. We train one model per week and the training window size is a hyperparameter to be tuned. The SW filter is used to preprocess data in the tuning phase and increase generalization in testing. Our method is interesting because it can filter clear out-of-sample points while avoiding sparse LCPR events that other methods could consider as local outliers. We refer interested readers to our GitHub page for more details. Testing mean average errors (MAE) and root mean squared errors (RMSE) are presented in Table2for each substation. See AppendixCfor additional figures.

SECTION: 6Closing remark

In this work, we present a new unsupervised outlier filter by leveraging the sliced-Wasserstein metric. This filter is interesting for MLOps integration on applications where global outliers may be adversarial to the prediction quality of trained models, e.g., smart grid data. We also hope to stimulate research on trustworthy ML models in critical sectors by releasing the first open dataset showcasing localized critical peak rebate demand response schemes in a northern climate. This dataset has a strong potential for benchmarking of such models as it opens a window to a real-world critical application where accuracy and robustness are equally important. To get the ball rolling, we provide a first benchmark by tuning simultaneously our SW filter and a Gaussian process.

SECTION: References

SECTION: Appendices

SECTION: ADetailed analysis of the dataset

In this section, we present some additional insights on the LCPR dataset. Figure1presents the distribution count of some key features for each substation. We observe that meteorological features are identical for each substation as they are geographically adjacent and located in dense neighborhoods.

Figure2shows a correlation heatmap of important features and label for each substation. We observe that each substation follows the same general tendencies. We remark significant correlations between the energy consumed, the month of the year, the outside temperatures, and the temperature setpoints. This is also highlighted in Figure3which presents the Spearman coefficients ranking[32]between each feature and the label. A positive sign indicates that both the label and the feature grow or decrease in the same direction while a negative sign indicates an opposite direction. The coefficients are ranked in decreasing importance from left to right.

To have a more nuanced analysis of the contribution of each feature to the output, we also provide in Figure4an analysis of Shapley values of a trained extreme gradient boosting model (XGBoost)[33]for each substation. These analyses were realized with the Python packageSHAP[34]. As we see, some lower-ranked features, viz., the challenge flags, sometimes have a strong impact on the model’s output even though their general impact is null.

SECTION: BNumerical study of the Sliced-Wasserstein Filter

We first begin this section by showing the AD mechanism of the SW filter on a simple two-dimensional example. We generate three Gaussian distributions with different population sizes. As shown in Figure5, the first distribution is the majority group, the second is the minority group, and the third represents clear statistical outliers.

We now merge the three distributions into a single one to test our SW filter. We vary the radius of the Wasserstein ball to see how the filter behaves. The results are presented in Figure6.

As we see, we can generate three filtering scenarios by modifying the value of. With, we filter only the statistical outliers. With, we only keep the majority group. And, with, we only keep the samples closest to the barycenter of the majority group. This is very interesting in a safe ML pipeline as we can tune theconservatismof the training dataset that is used at each run during hyperparameter optimization.

In Figure7, we compare different AD algorithms on synthetic datasets provided inscikit-learn’s example collection[35]. Hyperparameters are fixed for each algorithm to see how a single hyperparameter choice influences the labelling on each dataset.

As can be seen, the SW filter and its fast Euclidian approximation are better at isolating outliers when there is a clear majority group but are not as precise in identifying local outliers based on local density, e.g., one-class SVM.

Finally, we run a more thorough experiment with typically used real-world benchmark datasets. We run experiments on theLymphography,Ionosphere,Glass,Shuttle,WPBC,Arrhythmia, andPima, datasets presented in[36]for AD benchmarking. We compare isolation forest and LOF to our method. We implement a grid search and select each model’s run with the best accuracy. We then extract the precision scorefrom this run. The performance indicators are defined as follows:

where,,, andstand for true positives, false positives, true negatives, and false negatives, respectively. Results are presented in Figure8. We observe a similar performance between each model, except on theIonospheredataset where the SW filter lags behind the other models, and onArrhythmiawhere the fast Euclidian approximation is underperforming. The SW filter’s strength is that it considers the global distributional properties of the population to guide its labelling. We remark that our method fails at detecting local outliers as it is purely designed to locate global outliers that areriskyto keep in the training set. This is a reasonable choice to make when designing data preprocessing methods for safer ML training but not necessarily to filter local outliers.

Every experiment is available on our GitHub page.

SECTION: CSupplementary content to the benchmark

This section presents visual test predictions of the best validation runs for each substation as well as the test error of the benchmark.

As can be seen in both Figure9and Table2, substation C is the hardest to predict for the Gaussian process. In general, the confidence of the model is also low (standard deviation is high). This hints at the complexity of the patterns.

SECTION: DAcknowledgements:

Special thanks to Odile Noël, Ahmed Abdellatif, Steve Boursiquot, and everyone from Hydro-Québec’s open data initiative, especially Andrée-Anne Gauthier, and Robert Row. This work was partially funded by NSERC, FRQNT, Mitacs, and Hydro-Québec.